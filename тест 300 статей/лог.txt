[2018-03-02 14:35:16,781 INFO settings] BiblioMeter (v1.4.10) March 02 2018, 14:35:16
[2018-03-02 14:35:16,781 INFO settings] Initializing argument parser, version: 1.1
[2018-03-02 14:35:16,782 DEBUG settings] Parse arguments.
[2018-03-02 14:35:16,782 INFO settings] Initializing logbook.
[2018-03-02 14:35:16,783 DEBUG settings] Copy startlog in logbook.
[2018-03-02 14:35:16,783 INFO dbutils] Initializing connection to sqlite database, version: 2.6.0.
[2018-03-02 14:35:17,747 INFO settings] DB connection initialized.
[2018-03-02 14:35:17,747 INFO settings] Parsing the control file.
[2018-03-02 14:35:17,748 INFO settings] Parsing was successful.
[2018-03-02 14:35:17,748 DEBUG settings] Parameters:
[2018-03-02 14:35:17,749 DEBUG settings]   command = 'get_papers_by_key_words_and_get_pdf_from_scihub'
[2018-03-02 14:35:17,749 DEBUG settings]   query = 'Use deep learning to create a chatbot'
[2018-03-02 14:35:17,749 DEBUG settings]   max_google_papers = '300'
[2018-03-02 14:35:17,750 DEBUG settings]   max_researchgate_papers = '100'
[2018-03-02 14:35:17,751 DEBUG settings]   google_clusters_handling = 'False'
[2018-03-02 14:35:17,752 DEBUG settings]   patents = 'false'
[2018-03-02 14:35:17,752 DEBUG settings]   citations = 'false'
[2018-03-02 14:35:17,753 DEBUG settings]   date_to = '2016'
[2018-03-02 14:35:17,753 DEBUG settings]   http_contiguous_requests = '20'
[2018-03-02 14:35:17,754 DEBUG settings]   commit_iterations = '10'
[2018-03-02 14:35:17,755 DEBUG settings]   google_captcha_retry_by_proxy_count = '0'
[2018-03-02 14:35:17,755 DEBUG settings]   researchgate_captcha_retry_by_proxy_count = '4'
[2018-03-02 14:35:17,756 DEBUG settings]   sci_hub_captcha_retry_by_proxy_count = '0'
[2018-03-02 14:35:17,762 DEBUG settings]   limit_resp_for_one_code = '20'
[2018-03-02 14:35:17,763 DEBUG dbutils] Enters transaction proxy for function: ADD_Transaction.
[2018-03-02 14:35:17,763 DEBUG dbutils] Execute sql with params: type=insert sql='
            INSERT INTO transactions(
                from_date,
                to_date,
                command,
                parameters,
                result) VALUES (
                :from_date,
                :to_date,
                :command,
                :parameters,
                "USER STOPPED"
                )
            '; params={'from_date': datetime.datetime(2018, 3, 2, 14, 35, 17, 763068), 'to_date': datetime.datetime(2018, 3, 2, 14, 35, 17, 763068), 'command': 'get_papers_by_key_words_and_get_pdf_from_scihub', 'parameters': "{'command': 'get_papers_by_key_words_and_get_pdf_from_scihub', 'query': 'Use deep learning to create a chatbot', 'max_google_papers': '300', 'max_researchgate_papers': '100', 'google_clusters_handling': 'False', 'patents': 'false', 'citations': 'false', 'date_to': 2016, 'http_contiguous_requests': 20, 'commit_iterations': 10, 'google_captcha_retry_by_proxy_count': 0, 'researchgate_captcha_retry_by_proxy_count': 4, 'sci_hub_captcha_retry_by_proxy_count': 0, 'limit_resp_for_one_code': 20}"}
[2018-03-02 14:35:17,764 DEBUG dbutils] Query result: 1
[2018-03-02 14:35:17,764 DEBUG dbutils] Commiting transaction for function: ADD_Transaction.
[2018-03-02 14:35:18,911 DEBUG utils] Load proxies list from 'proxies_good.txt'
[2018-03-02 14:35:18,912 DEBUG utils] Load proxies list from 'proxies_good.txt'
[2018-03-02 14:35:18,912 DEBUG utils] Load proxies list from 'proxies_good.txt'
[2018-03-02 14:35:18,912 DEBUG utils] Load proxies list from 'proxies_good.txt'
[2018-03-02 14:35:18,912 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for www.researchgate.net
[2018-03-02 14:35:18,912 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for scholar.google.com
[2018-03-02 14:35:18,912 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for sci-hub.tw
[2018-03-02 14:35:18,913 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for otherhost
[2018-03-02 14:35:18,913 DEBUG utils] Generate User-Agent.
[2018-03-02 14:35:18,913 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:35:19,078 DEBUG __main__] command get_papers_by_key_words_and_get_pdf_from_scihub.
[2018-03-02 14:35:19,078 DEBUG __main__] Processing command 'get_papers_by_key_words_and_get_pdf_from_scihub'.
[2018-03-02 14:35:19,078 DEBUG __main__] Search papers from google.scholar.
[2018-03-02 14:35:19,079 DEBUG scholar] Load html from 'https://scholar.google.com/scholar?as_q=Use%20deep%20learning%20to%20create%20a%20chatbot&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=&as_publication=&as_ylo=&as_yhi=2016&btnG=&hl=en&as_sdt=1%2C5&as_vis=1'.
[2018-03-02 14:35:19,079 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:35:19,079 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:35:19,101 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:35:21,236 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?as_q=Use%20deep%20learning%20to%20create%20a%20chatbot&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=&as_publication=&as_ylo=&as_yhi=2016&btnG=&hl=en&as_sdt=1%2C5&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:35:21,594 DEBUG __main__] 1170
[2018-03-02 14:35:21,603 DEBUG scholar] Find papers on page #1 (max_google_papers = 300)
[2018-03-02 14:35:21,603 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:35:21,604 DEBUG scholar] Handle paper #1 (total 1170)
[2018-03-02 14:35:21,604 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:35:21,608 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:21,608 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:35:21,608 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for scholar.google.com
[2018-03-02 14:35:21,625 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:35:23,444 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_LR6pDsHH7cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lbU3CaV-gPrLn9ePlaO8aFPQN8tl&scisf=3&ct=citation&cd=0&hl=en HTTP/1.1" 200 194
[2018-03-02 14:35:23,445 DEBUG scholar] EndNote file:
%0 Journal Article
%T Technologies in use for second language learning
%A Levy, Mike
%J The Modern Language Journal
%V 93
%N s1
%P 769-782
%@ 1540-4781
%D 2009
%I Wiley Online Library

[2018-03-02 14:35:23,445 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:23,445 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:23,445 DEBUG __main__] Process content of EndNote file #1
{"title": "Technologies in use for second language learning", "url": "http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4781.2009.00972.x/full", "author": [{"shortname": "M Levy", "gid": ""}], "year": 2009}
{"citedby": 320, "type": "Journal Article", "title": "Technologies in use for second language learning", "author": ["Levy, Mike"], "journal": "The Modern Language Journal", "volume": 14, "numberorissue": "s1", "pages": "769-782", "isbn/issn": "1540-4781", "year": "2009", "publisher": "Wiley Online Library", "start_page": 769, "end_page": 782, "EndNote": "%0 Journal Article\n%T Technologies in use for second language learning\n%A Levy, Mike\n%J The Modern Language Journal\n%V 93\n%N s1\n%P 769-782\n%@ 1540-4781\n%D 2009\n%I Wiley Online Library\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_LR6pDsHH7cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lbU3CaV-gPrLn9ePlaO8aFPQN8tl&scisf=3&ct=citation&cd=0&hl=en"}
[2018-03-02 14:35:23,445 DEBUG dbutils] Get paper id {"DOI": null, "title": "Technologies in use for second language learning", "auth_count": 1, "g_type": "Journal Article", "pages": 14, "year": 2009, "rg_id": null, "start_page": 769, "end_page": 782}.
[2018-03-02 14:35:23,446 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Technologies in use for second language learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 14, 'year': 2009, 'rg_id': None, 'start_page': 769, 'end_page': 782}
[2018-03-02 14:35:23,446 DEBUG dbutils] Query result: []
[2018-03-02 14:35:23,446 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:23,446 DEBUG dbutils] Add new paper (title='Technologies in use for second language learning')
[2018-03-02 14:35:23,446 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Technologies in use for second language learning', 'year': 2009, 'publisher': 'Wiley Online Library', 'start_page': 769, 'end_page': 782, 'pages': 14, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Technologies in use for second language learning\n%A Levy, Mike\n%J The Modern Language Journal\n%V 93\n%N s1\n%P 769-782\n%@ 1540-4781\n%D 2009\n%I Wiley Online Library\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:23,447 DEBUG dbutils] Query result: 1
[2018-03-02 14:35:23,449 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.jstor.org/stable/25612273?casa_token=6hIIj5RPGMQAAAAA:-TRdEaYT1gShG1BlG7fpivPkbPnTJA0N2Pbs8P_ClhLUwMF2lqsOUEDYyM4QHYR2gOroO8zt-7B-y9Ksjr8P-0ab1WWGdSZQocZsjU8bYYxPhRd_Osw.
[2018-03-02 14:35:23,453 WARNING utils] Download file (url='http://www.jstor.org/stable/25612273?casa_token=6hIIj5RPGMQAAAAA:-TRdEaYT1gShG1BlG7fpivPkbPnTJA0N2Pbs8P_ClhLUwMF2lqsOUEDYyM4QHYR2gOroO8zt-7B-y9Ksjr8P-0ab1WWGdSZQocZsjU8bYYxPhRd_Osw') and save (filename='PDF//1.pdf')
[2018-03-02 14:35:23,454 DEBUG utils] Get current proxy for www.jstor.org.
[2018-03-02 14:35:23,454 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:35:23,472 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.jstor.org
[2018-03-02 14:35:25,316 DEBUG requests.packages.urllib3.connectionpool] "GET /stable/25612273?casa_token=6hIIj5RPGMQAAAAA:-TRdEaYT1gShG1BlG7fpivPkbPnTJA0N2Pbs8P_ClhLUwMF2lqsOUEDYyM4QHYR2gOroO8zt-7B-y9Ksjr8P-0ab1WWGdSZQocZsjU8bYYxPhRd_Osw HTTP/1.1" 200 None
[2018-03-02 14:35:25,503 DEBUG utils] Server do not give PDF.
[2018-03-02 14:35:25,505 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4781.2009.00972.x/full.
[2018-03-02 14:35:25,506 DEBUG scihub] Get page from sci-hub for paper with DOI=http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4781.2009.00972.x/full.
[2018-03-02 14:35:25,533 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): sci-hub.tw
[2018-03-02 14:35:25,794 DEBUG requests.packages.urllib3.connectionpool] "GET //http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4781.2009.00972.x/full HTTP/1.1" 200 None
[2018-03-02 14:35:25,795 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:35:25,795 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:35:25,984 DEBUG requests.packages.urllib3.connectionpool] "GET //http://onlinelibrary.wiley.com/doi/10.1111/j.1540-4781.2009.00972.x/full HTTP/1.1" 200 None
[2018-03-02 14:35:25,990 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true.
[2018-03-02 14:35:25,990 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true') and save (filename='PDF//1.pdf')
[2018-03-02 14:35:26,006 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cyber.sci-hub.tw
[2018-03-02 14:35:26,012 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F8C198>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F8C198>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F8C198>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,012 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for sci-hub.tw
[2018-03-02 14:35:26,029 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): cyber.sci-hub.tw
[2018-03-02 14:35:26,033 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F9BBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F9BBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F9BBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,033 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for sci-hub.tw
[2018-03-02 14:35:26,049 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): cyber.sci-hub.tw
[2018-03-02 14:35:26,055 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F95BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F95BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F95BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,055 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for sci-hub.tw
[2018-03-02 14:35:26,070 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): cyber.sci-hub.tw
[2018-03-02 14:35:26,074 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F71BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F71BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F71BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,074 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for sci-hub.tw
[2018-03-02 14:35:26,089 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): cyber.sci-hub.tw
[2018-03-02 14:35:26,094 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F96BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F96BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F96BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,094 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for sci-hub.tw
[2018-03-02 14:35:26,108 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): cyber.sci-hub.tw
[2018-03-02 14:35:26,113 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F74BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F74BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F74BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,113 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for sci-hub.tw
[2018-03-02 14:35:26,128 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): cyber.sci-hub.tw
[2018-03-02 14:35:26,132 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,132 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for sci-hub.tw
[2018-03-02 14:35:26,147 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (8): cyber.sci-hub.tw
[2018-03-02 14:35:26,151 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F75BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F75BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F75BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,151 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for sci-hub.tw
[2018-03-02 14:35:26,166 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (9): cyber.sci-hub.tw
[2018-03-02 14:35:26,170 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE9BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE9BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE9BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,171 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for sci-hub.tw
[2018-03-02 14:35:26,186 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (10): cyber.sci-hub.tw
[2018-03-02 14:35:26,189 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F79BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F79BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F79BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,190 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for sci-hub.tw
[2018-03-02 14:35:26,204 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (11): cyber.sci-hub.tw
[2018-03-02 14:35:26,208 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DF8BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DF8BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DF8BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,209 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for sci-hub.tw
[2018-03-02 14:35:26,223 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (12): cyber.sci-hub.tw
[2018-03-02 14:35:26,227 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DFEBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DFEBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DFEBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,228 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for sci-hub.tw
[2018-03-02 14:35:26,242 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (13): cyber.sci-hub.tw
[2018-03-02 14:35:26,247 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F94BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F94BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F94BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,247 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for sci-hub.tw
[2018-03-02 14:35:26,262 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (14): cyber.sci-hub.tw
[2018-03-02 14:35:26,266 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F92BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F92BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F92BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,267 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for sci-hub.tw
[2018-03-02 14:35:26,283 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (15): cyber.sci-hub.tw
[2018-03-02 14:35:26,287 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE5BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE5BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703DE5BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,288 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for sci-hub.tw
[2018-03-02 14:35:26,302 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (16): cyber.sci-hub.tw
[2018-03-02 14:35:26,307 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F61BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F61BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F61BA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,307 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for sci-hub.tw
[2018-03-02 14:35:26,321 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (17): cyber.sci-hub.tw
[2018-03-02 14:35:26,325 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7EBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7EBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7EBA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,325 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for sci-hub.tw
[2018-03-02 14:35:26,340 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (18): cyber.sci-hub.tw
[2018-03-02 14:35:26,344 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703F7ABA8>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,344 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for sci-hub.tw
[2018-03-02 14:35:26,373 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (19): cyber.sci-hub.tw
[2018-03-02 14:35:26,377 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D23EF0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D23EF0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D23EF0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,377 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for sci-hub.tw
[2018-03-02 14:35:26,394 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (20): cyber.sci-hub.tw
[2018-03-02 14:35:26,399 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 75, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 363, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 964, in send
    self.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 167, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 151, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D230F0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D230F0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='cyber.sci-hub.tw', port=80): Max retries exceeded with url: /MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x0000007703D230F0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed',))

[2018-03-02 14:35:26,400 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for sci-hub.tw
[2018-03-02 14:35:26,403 DEBUG scholar] Handle paper #2 (total 1170)
[2018-03-02 14:35:26,403 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:35:26,408 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:26,408 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:35:26,758 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:CGL_stsdg9EJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lYY_TpPBiADhqqXowX7UvO-cjWD1&scisf=3&ct=citation&cd=1&hl=en HTTP/1.1" 200 255
[2018-03-02 14:35:26,759 DEBUG scholar] EndNote file:
%0 Journal Article
%T Bringing chatbots into education: Towards natural language negotiation of open learner models
%A Kerly, Alice
%A Hall, Phil
%A Bull, Susan
%J Knowledge-Based Systems
%V 20
%N 2
%P 177-185
%@ 0950-7051
%D 2007
%I Elsevier

[2018-03-02 14:35:26,759 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:26,759 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:26,759 DEBUG __main__] Process content of EndNote file #2
{"title": "Bringing chatbots into education: Towards natural language negotiation of open learner models", "url": "https://www.sciencedirect.com/science/article/pii/S0950705106001912", "author": [{"shortname": "A Kerly", "gid": ""}, {"shortname": "P Hall", "gid": ""}, {"shortname": "S Bull", "gid": "TONyepAAAAAJ"}], "year": 2007}
{"citedby": 89, "type": "Journal Article", "title": "Bringing chatbots into education: Towards natural language negotiation of open learner models", "author": ["Kerly, Alice", "Hall, Phil", "Bull, Susan"], "journal": "Knowledge-Based Systems", "volume": 9, "numberorissue": "2", "pages": "177-185", "isbn/issn": "0950-7051", "year": "2007", "publisher": "Elsevier", "start_page": 177, "end_page": 185, "EndNote": "%0 Journal Article\n%T Bringing chatbots into education: Towards natural language negotiation of open learner models\n%A Kerly, Alice\n%A Hall, Phil\n%A Bull, Susan\n%J Knowledge-Based Systems\n%V 20\n%N 2\n%P 177-185\n%@ 0950-7051\n%D 2007\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:CGL_stsdg9EJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lYY_TpPBiADhqqXowX7UvO-cjWD1&scisf=3&ct=citation&cd=1&hl=en"}
[2018-03-02 14:35:26,759 DEBUG dbutils] Get paper id {"DOI": null, "title": "Bringing chatbots into education: Towards natural language negotiation of open learner models", "auth_count": 3, "g_type": "Journal Article", "pages": 9, "year": 2007, "rg_id": null, "start_page": 177, "end_page": 185}.
[2018-03-02 14:35:26,759 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Bringing chatbots into education: Towards natural language negotiation of open learner models', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 9, 'year': 2007, 'rg_id': None, 'start_page': 177, 'end_page': 185}
[2018-03-02 14:35:26,759 DEBUG dbutils] Query result: []
[2018-03-02 14:35:26,760 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:26,760 DEBUG dbutils] Add new paper (title='Bringing chatbots into education: Towards natural language negotiation of open learner models')
[2018-03-02 14:35:26,760 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Bringing chatbots into education: Towards natural language negotiation of open learner models', 'year': 2007, 'publisher': 'Elsevier', 'start_page': 177, 'end_page': 185, 'pages': 9, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Bringing chatbots into education: Towards natural language negotiation of open learner models\n%A Kerly, Alice\n%A Hall, Phil\n%A Bull, Susan\n%J Knowledge-Based Systems\n%V 20\n%N 2\n%P 177-185\n%@ 0950-7051\n%D 2007\n%I Elsevier\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:26,760 DEBUG dbutils] Query result: 2
[2018-03-02 14:35:26,762 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.ai-research.org.uk/AliceKerly/html/Kerly_Hall_AI-06_for_web.pdf.
[2018-03-02 14:35:26,763 WARNING utils] Download file (url='http://www.ai-research.org.uk/AliceKerly/html/Kerly_Hall_AI-06_for_web.pdf') and save (filename='PDF//2.pdf')
[2018-03-02 14:35:26,763 DEBUG utils] Get current proxy for www.ai-research.org.uk.
[2018-03-02 14:35:26,764 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:35:26,764 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for otherhost
[2018-03-02 14:35:26,786 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.ai-research.org.uk
[2018-03-02 14:35:27,004 DEBUG requests.packages.urllib3.connectionpool] "GET /AliceKerly/html/Kerly_Hall_AI-06_for_web.pdf HTTP/1.1" 200 792563
[2018-03-02 14:35:27,004 DEBUG utils] Content-length=792563
[2018-03-02 14:35:27,005 DEBUG utils] Create file PDF//2.pdf, start download.
[2018-03-02 14:35:28,465 DEBUG utils] End download file PDF//2.pdf.
[2018-03-02 14:35:28,468 DEBUG dbutils] Update pdf_transaction for paper id=2.
[2018-03-02 14:35:28,468 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 2'
[2018-03-02 14:35:28,469 DEBUG dbutils] Query result: null
[2018-03-02 14:35:28,469 DEBUG scholar] Handle paper #3 (total 1170)
[2018-03-02 14:35:28,469 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:35:28,476 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:28,476 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:35:28,476 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for scholar.google.com
[2018-03-02 14:35:28,500 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:35:30,247 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_AWfECOgqWAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lSDVAdkrnluio1odFo2efqqD-Tma&scisf=3&ct=citation&cd=2&hl=en HTTP/1.1" 200 357
[2018-03-02 14:35:30,248 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Freudbot: An investigation of chatbot technology in distance education
%A Heller, Bob
%A Proctor, Mike
%A Mah, Dean
%A Jewell, Lisa
%A Cheung, Bill
%B EdMedia: World Conference on Educational Media and Technology
%P 3913-3918
%@ 1880094568
%D 2005
%I Association for the Advancement of Computing in Education (AACE)

[2018-03-02 14:35:30,248 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:30,248 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:30,248 DEBUG __main__] Process content of EndNote file #3
{"title": "Freudbot: An investigation of chatbot technology in distance education", "url": "https://www.learntechlib.org/p/20691/", "author": [{"shortname": "B Heller", "gid": ""}, {"shortname": "M Proctor", "gid": "6DeEyb0AAAAJ"}, {"shortname": "D Mah", "gid": ""}, {"shortname": "L Jewell", "gid": ""}], "year": 2005}
{"citedby": 27, "type": "Conference Proceedings", "title": "Freudbot: An investigation of chatbot technology in distance education", "author": ["Heller, Bob", "Proctor, Mike", "Mah, Dean", "Jewell, Lisa", "Cheung, Bill"], "secondarytitle": "EdMedia: World Conference on Educational Media and Technology", "pages": "3913-3918", "isbn/issn": "1880094568", "year": "2005", "publisher": "Association for the Advancement of Computing in Education (AACE)", "start_page": 3913, "end_page": 3918, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Freudbot: An investigation of chatbot technology in distance education\n%A Heller, Bob\n%A Proctor, Mike\n%A Mah, Dean\n%A Jewell, Lisa\n%A Cheung, Bill\n%B EdMedia: World Conference on Educational Media and Technology\n%P 3913-3918\n%@ 1880094568\n%D 2005\n%I Association for the Advancement of Computing in Education (AACE)\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_AWfECOgqWAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lSDVAdkrnluio1odFo2efqqD-Tma&scisf=3&ct=citation&cd=2&hl=en"}
[2018-03-02 14:35:30,249 DEBUG dbutils] Get paper id {"DOI": null, "title": "Freudbot: An investigation of chatbot technology in distance education", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 6, "year": 2005, "rg_id": null, "start_page": 3913, "end_page": 3918}.
[2018-03-02 14:35:30,249 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Freudbot: An investigation of chatbot technology in distance education', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2005, 'rg_id': None, 'start_page': 3913, 'end_page': 3918}
[2018-03-02 14:35:30,249 DEBUG dbutils] Query result: []
[2018-03-02 14:35:30,249 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:30,249 DEBUG dbutils] Add new paper (title='Freudbot: An investigation of chatbot technology in distance education')
[2018-03-02 14:35:30,249 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Freudbot: An investigation of chatbot technology in distance education', 'year': 2005, 'publisher': 'Association for the Advancement of Computing in Education (AACE)', 'start_page': 3913, 'end_page': 3918, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Freudbot: An investigation of chatbot technology in distance education\n%A Heller, Bob\n%A Proctor, Mike\n%A Mah, Dean\n%A Jewell, Lisa\n%A Cheung, Bill\n%B EdMedia: World Conference on Educational Media and Technology\n%P 3913-3918\n%@ 1880094568\n%D 2005\n%I Association for the Advancement of Computing in Education (AACE)\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:30,249 DEBUG dbutils] Query result: 3
[2018-03-02 14:35:30,251 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/20691/proceedings_20691.pdf.
[2018-03-02 14:35:30,254 WARNING utils] Download file (url='https://www.learntechlib.org/p/20691/proceedings_20691.pdf') and save (filename='PDF//3.pdf')
[2018-03-02 14:35:30,255 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 14:35:30,255 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:35:30,275 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:35:31,903 DEBUG requests.packages.urllib3.connectionpool] "GET /p/20691/proceedings_20691.pdf HTTP/1.1" 302 137
[2018-03-02 14:35:32,163 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/20691 HTTP/1.1" 301 0
[2018-03-02 14:35:33,640 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/20691/ HTTP/1.1" 200 17346
[2018-03-02 14:35:33,695 DEBUG utils] Content-length=17346
[2018-03-02 14:35:33,696 DEBUG utils] Create file PDF//3.pdf, start download.
[2018-03-02 14:35:33,698 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 17346

[2018-03-02 14:35:33,698 DEBUG __main__] Failed get_pdf from Google Scholar for paper #2. URL=2
[2018-03-02 14:35:33,701 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/20691/.
[2018-03-02 14:35:33,701 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/20691/.
[2018-03-02 14:35:33,894 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/20691/ HTTP/1.1" 302 None
[2018-03-02 14:35:33,915 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:35:35,474 DEBUG requests.packages.urllib3.connectionpool] "GET /p/20691/ HTTP/1.1" 200 17336
[2018-03-02 14:35:35,476 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:35:35,476 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:35:35,664 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/20691/ HTTP/1.1" 302 None
[2018-03-02 14:35:35,687 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:35:38,375 DEBUG requests.packages.urllib3.connectionpool] "GET /p/20691/ HTTP/1.1" 200 15587
[2018-03-02 14:35:38,509 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:35:38,510 DEBUG scholar] Handle paper #4 (total 1170)
[2018-03-02 14:35:38,510 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:35:38,515 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:38,515 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:35:38,854 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:IYzm7dvrs5oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lf6-9VVnE48t4CXiv5ZM7UxXd3FK&scisf=3&ct=citation&cd=3&hl=en HTTP/1.1" 200 225
[2018-03-02 14:35:38,855 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Assessing students in Second Life with scripted chatbots
%A Crisp, Geoffrey
%A Hillier, Mathew
%A Joarder, Shamim
%B Australian Technology Network Assessment Conference
%P 256-261
%D 2010

[2018-03-02 14:35:38,855 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:38,855 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:38,855 DEBUG __main__] Process content of EndNote file #4
{"title": "Assessing students in Second Life with scripted chatbots", "url": "https://espace.library.uq.edu.au/view/UQ:309422/CRISP_2010_ATN_assessment.pdf", "author": [{"shortname": "G Crisp", "gid": "kN2jxUkAAAAJ"}, {"shortname": "M Hillier", "gid": "NMkrK2wAAAAJ"}, {"shortname": "S Joarder", "gid": ""}], "year": 2010}
{"citedby": 8, "type": "Conference Proceedings", "title": "Assessing students in Second Life with scripted chatbots", "author": ["Crisp, Geoffrey", "Hillier, Mathew", "Joarder, Shamim"], "secondarytitle": "Australian Technology Network Assessment Conference", "pages": "256-261", "year": "2010", "start_page": 256, "end_page": 261, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Assessing students in Second Life with scripted chatbots\n%A Crisp, Geoffrey\n%A Hillier, Mathew\n%A Joarder, Shamim\n%B Australian Technology Network Assessment Conference\n%P 256-261\n%D 2010\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:IYzm7dvrs5oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lf6-9VVnE48t4CXiv5ZM7UxXd3FK&scisf=3&ct=citation&cd=3&hl=en"}
[2018-03-02 14:35:38,855 DEBUG dbutils] Get paper id {"DOI": null, "title": "Assessing students in Second Life with scripted chatbots", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 6, "year": 2010, "rg_id": null, "start_page": 256, "end_page": 261}.
[2018-03-02 14:35:38,855 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Assessing students in Second Life with scripted chatbots', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2010, 'rg_id': None, 'start_page': 256, 'end_page': 261}
[2018-03-02 14:35:38,856 DEBUG dbutils] Query result: []
[2018-03-02 14:35:38,856 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:38,856 DEBUG dbutils] Add new paper (title='Assessing students in Second Life with scripted chatbots')
[2018-03-02 14:35:38,856 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Assessing students in Second Life with scripted chatbots', 'year': 2010, 'publisher': None, 'start_page': 256, 'end_page': 261, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Assessing students in Second Life with scripted chatbots\n%A Crisp, Geoffrey\n%A Hillier, Mathew\n%A Joarder, Shamim\n%B Australian Technology Network Assessment Conference\n%P 256-261\n%D 2010\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:38,856 DEBUG dbutils] Query result: 4
[2018-03-02 14:35:38,858 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://espace.library.uq.edu.au/view/UQ:309422/CRISP_2010_ATN_assessment.pdf.
[2018-03-02 14:35:38,859 WARNING utils] Download file (url='https://espace.library.uq.edu.au/view/UQ:309422/CRISP_2010_ATN_assessment.pdf') and save (filename='PDF//4.pdf')
[2018-03-02 14:35:38,860 DEBUG utils] Get current proxy for espace.library.uq.edu.au.
[2018-03-02 14:35:38,860 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:35:38,860 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for otherhost
[2018-03-02 14:35:38,879 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): espace.library.uq.edu.au
[2018-03-02 14:35:41,054 DEBUG requests.packages.urllib3.connectionpool] "GET /view/UQ:309422/CRISP_2010_ATN_assessment.pdf HTTP/1.1" 302 None
[2018-03-02 14:35:42,526 DEBUG requests.packages.urllib3.connectionpool] "GET /data/UQ_309422/CRISP_2010_ATN_assessment.pdf?Expires=1520077009&Signature=ab3bzfu-3VHqMupmWAzWqvGY0MxdH5wTLQhtVJAq5mUy2cSIhFmG5g~N2zTYrbYTP49YSioMFON5gevVIlR9tx1Zy7E3CcEhHIZTxFaV9iUL0J3vbRF-xGUP5Wy4C7xftP8ITZnDUFaiJouiOcjugzX6vjRi0YujRat8uynyzD~e2A0kbKJse~jWQXC~9k-mzDVNbOsA0Z~bddxn6ejYR-2fBoW5OFbrOjRseilV0XiB5KfHyX3fyItH8NcwCLlMT2FSYAot5-eZZnc1EM03lWD-iK0bnjYUvaAYIY~LJXhwCn1iZbCpEao-0Ih~~n0hjLTAK-iN~epFOWw9E9teiw__&Key-Pair-Id=APKAJKNBJ4MJBJNC6NLQ HTTP/1.1" 200 98558
[2018-03-02 14:35:42,529 DEBUG utils] Content-length=98558
[2018-03-02 14:35:42,533 DEBUG utils] Create file PDF//4.pdf, start download.
[2018-03-02 14:35:43,727 DEBUG utils] End download file PDF//4.pdf.
[2018-03-02 14:35:43,729 DEBUG dbutils] Update pdf_transaction for paper id=4.
[2018-03-02 14:35:43,729 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 4'
[2018-03-02 14:35:43,729 DEBUG dbutils] Query result: null
[2018-03-02 14:35:43,729 DEBUG scholar] Handle paper #5 (total 1170)
[2018-03-02 14:35:43,730 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:35:43,736 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:43,736 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:35:43,736 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for scholar.google.com
[2018-03-02 14:35:43,763 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:35:45,366 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:y-MJaFtRwKgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lepE9e2SXlfE1tjk_s7ufoh8UguF&scisf=3&ct=citation&cd=4&hl=en HTTP/1.1" 200 221
[2018-03-02 14:35:45,366 DEBUG scholar] EndNote file:
%0 Journal Article
%T CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning
%A Jia, Jiyou
%J Knowledge-Based Systems
%V 22
%N 4
%P 249-255
%@ 0950-7051
%D 2009
%I Elsevier

[2018-03-02 14:35:45,367 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:45,367 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:45,367 DEBUG __main__] Process content of EndNote file #5
{"title": "CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning", "url": "https://www.sciencedirect.com/science/article/pii/S0950705109000045", "author": [{"shortname": "J Jia", "gid": ""}], "year": 2009}
{"citedby": 41, "type": "Journal Article", "title": "CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning", "author": ["Jia, Jiyou"], "journal": "Knowledge-Based Systems", "volume": 7, "numberorissue": "4", "pages": "249-255", "isbn/issn": "0950-7051", "year": "2009", "publisher": "Elsevier", "start_page": 249, "end_page": 255, "EndNote": "%0 Journal Article\n%T CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning\n%A Jia, Jiyou\n%J Knowledge-Based Systems\n%V 22\n%N 4\n%P 249-255\n%@ 0950-7051\n%D 2009\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:y-MJaFtRwKgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lepE9e2SXlfE1tjk_s7ufoh8UguF&scisf=3&ct=citation&cd=4&hl=en"}
[2018-03-02 14:35:45,367 DEBUG dbutils] Get paper id {"DOI": null, "title": "CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning", "auth_count": 1, "g_type": "Journal Article", "pages": 7, "year": 2009, "rg_id": null, "start_page": 249, "end_page": 255}.
[2018-03-02 14:35:45,368 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 7, 'year': 2009, 'rg_id': None, 'start_page': 249, 'end_page': 255}
[2018-03-02 14:35:45,368 DEBUG dbutils] Query result: []
[2018-03-02 14:35:45,368 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:45,368 DEBUG dbutils] Add new paper (title='CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning')
[2018-03-02 14:35:45,368 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning', 'year': 2009, 'publisher': 'Elsevier', 'start_page': 249, 'end_page': 255, 'pages': 7, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning\n%A Jia, Jiyou\n%J Knowledge-Based Systems\n%V 22\n%N 4\n%P 249-255\n%@ 0950-7051\n%D 2009\n%I Elsevier\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:45,368 DEBUG dbutils] Query result: 5
[2018-03-02 14:35:45,369 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S0950705109000045.
[2018-03-02 14:35:45,369 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S0950705109000045.
[2018-03-02 14:35:45,585 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0950705109000045 HTTP/1.1" 200 None
[2018-03-02 14:35:45,586 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:35:45,587 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:35:45,587 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for sci-hub.tw
[2018-03-02 14:35:45,774 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0950705109000045 HTTP/1.1" 200 None
[2018-03-02 14:35:45,780 DEBUG scihub] URL for PDF: http://dacemirror.sci-hub.tw/journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true.
[2018-03-02 14:35:45,781 WARNING utils] Download file (url='http://dacemirror.sci-hub.tw/journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true') and save (filename='PDF//5.pdf')
[2018-03-02 14:35:45,797 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dacemirror.sci-hub.tw
[2018-03-02 14:35:46,024 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true HTTP/1.1" 200 704496
[2018-03-02 14:35:46,024 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:35:46,024 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:35:46,040 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dacemirror.sci-hub.tw
[2018-03-02 14:35:46,336 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:35:46,339 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:35:46,339 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:35:51,789 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:35:51,789 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:35:52,078 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:35:52,079 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:35:52,079 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:35:52,079 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for sci-hub.tw
[2018-03-02 14:35:52,093 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): dacemirror.sci-hub.tw
[2018-03-02 14:35:52,295 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/0a8b1a261e2e8a52829edcbad79fa687/jia2009.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:35:52,301 DEBUG scholar] Handle paper #6 (total 1170)
[2018-03-02 14:35:52,301 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:35:52,305 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:52,306 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:35:52,643 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:qoAhu_C1LdQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lXoUi7FyFod7Xt4a3RJkc4v3VCgL&scisf=3&ct=citation&cd=5&hl=en HTTP/1.1" 200 251
[2018-03-02 14:35:52,644 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Ontbot: Ontology based chatbot
%A Al-Zubaide, Hadeel
%A Issa, Ayman A
%B Innovation in Information & Communication Technology (ISIICT), 2011 Fourth International Symposium on
%P 7-12
%@ 1612846750
%D 2011
%I IEEE

[2018-03-02 14:35:52,644 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:52,644 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:52,645 DEBUG __main__] Process content of EndNote file #6
{"title": "Ontbot: Ontology based chatbot", "url": "http://ieeexplore.ieee.org/document/6149594/", "author": [{"shortname": "H Al", "gid": ""}], "year": 2011}
{"citedby": 24, "type": "Conference Proceedings", "title": "Ontbot: Ontology based chatbot", "author": ["Al-Zubaide, Hadeel", "Issa, Ayman A"], "secondarytitle": "Innovation in Information & Communication Technology (ISIICT), 2011 Fourth International Symposium on", "pages": "7-12", "isbn/issn": "1612846750", "year": "2011", "publisher": "IEEE", "start_page": 7, "end_page": 12, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Ontbot: Ontology based chatbot\n%A Al-Zubaide, Hadeel\n%A Issa, Ayman A\n%B Innovation in Information & Communication Technology (ISIICT), 2011 Fourth International Symposium on\n%P 7-12\n%@ 1612846750\n%D 2011\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:qoAhu_C1LdQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lXoUi7FyFod7Xt4a3RJkc4v3VCgL&scisf=3&ct=citation&cd=5&hl=en"}
[2018-03-02 14:35:52,645 DEBUG dbutils] Get paper id {"DOI": null, "title": "Ontbot: Ontology based chatbot", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 6, "year": 2011, "rg_id": null, "start_page": 7, "end_page": 12}.
[2018-03-02 14:35:52,645 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Ontbot: Ontology based chatbot', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2011, 'rg_id': None, 'start_page': 7, 'end_page': 12}
[2018-03-02 14:35:52,645 DEBUG dbutils] Query result: []
[2018-03-02 14:35:52,645 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:52,645 DEBUG dbutils] Add new paper (title='Ontbot: Ontology based chatbot')
[2018-03-02 14:35:52,645 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Ontbot: Ontology based chatbot', 'year': 2011, 'publisher': 'IEEE', 'start_page': 7, 'end_page': 12, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Ontbot: Ontology based chatbot\n%A Al-Zubaide, Hadeel\n%A Issa, Ayman A\n%B Innovation in Information & Communication Technology (ISIICT), 2011 Fourth International Symposium on\n%P 7-12\n%@ 1612846750\n%D 2011\n%I IEEE\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:52,645 DEBUG dbutils] Query result: 6
[2018-03-02 14:35:52,647 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/document/6149594/.
[2018-03-02 14:35:52,647 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/document/6149594/.
[2018-03-02 14:35:52,936 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/document/6149594/ HTTP/1.1" 200 None
[2018-03-02 14:35:52,937 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:35:52,937 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:35:53,143 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/document/6149594/ HTTP/1.1" 200 None
[2018-03-02 14:35:53,149 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTEwOS9pc2lpY3QuMjAxMS42MTQ5NTk0/alzubaide2011.pdf?download=true.
[2018-03-02 14:35:53,150 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTEwOS9pc2lpY3QuMjAxMS42MTQ5NTk0/alzubaide2011.pdf?download=true') and save (filename='PDF//6.pdf')
[2018-03-02 14:35:53,168 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (21): cyber.sci-hub.tw
[2018-03-02 14:35:53,797 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2lpY3QuMjAxMS42MTQ5NTk0/alzubaide2011.pdf?download=true HTTP/1.1" 200 768532
[2018-03-02 14:35:53,798 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:35:53,798 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:35:53,798 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for sci-hub.tw
[2018-03-02 14:35:53,813 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (22): cyber.sci-hub.tw
[2018-03-02 14:35:53,991 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2lpY3QuMjAxMS42MTQ5NTk0/alzubaide2011.pdf?download=true HTTP/1.1" 200 768532
[2018-03-02 14:35:53,992 DEBUG utils] Content-length=768532
[2018-03-02 14:35:53,993 DEBUG utils] Create file PDF//6.pdf, start download.
[2018-03-02 14:35:55,628 DEBUG utils] End download file PDF//6.pdf.
[2018-03-02 14:35:55,629 DEBUG dbutils] Update pdf_transaction for paper id=6.
[2018-03-02 14:35:55,629 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 6'
[2018-03-02 14:35:55,629 DEBUG dbutils] Query result: null
[2018-03-02 14:35:55,629 DEBUG scholar] Handle paper #7 (total 1170)
[2018-03-02 14:35:55,630 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:35:55,633 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:35:55,633 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:35:55,633 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for scholar.google.com
[2018-03-02 14:35:55,649 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:35:57,533 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:-E0S_902i2AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lfhjjPVN9BOB5OdBpl2T4Z-ynbyk&scisf=3&ct=citation&cd=6&hl=en HTTP/1.1" 200 413
[2018-03-02 14:35:57,534 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Nlgml: A markup language for question generation
%A Cai, Zhiqiang
%A Rus, Vasile
%A Kim, Hyun-Jeong Joyce
%A Susarla, Suresh C
%A Karnam, Pavan
%A Graesser, Arthur C
%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education
%P 2747-2752
%@ 1880094606
%D 2006
%I Association for the Advancement of Computing in Education (AACE)

[2018-03-02 14:35:57,534 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:35:57,534 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:35:57,534 DEBUG __main__] Process content of EndNote file #7
{"title": "Nlgml: A markup language for question generation", "url": "https://www.learntechlib.org/p/24121/", "author": [{"shortname": "Z Cai", "gid": "33wi1moAAAAJ"}, {"shortname": "V Rus", "gid": "k8jqnc8AAAAJ"}, {"shortname": "HJJ Kim", "gid": ""}, {"shortname": "SC Susarla", "gid": ""}], "year": 2006}
{"citedby": 7, "type": "Conference Proceedings", "title": "Nlgml: A markup language for question generation", "author": ["Cai, Zhiqiang", "Rus, Vasile", "Kim, Hyun-Jeong Joyce", "Susarla, Suresh C", "Karnam, Pavan", "Graesser, Arthur C"], "secondarytitle": "E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education", "pages": "2747-2752", "isbn/issn": "1880094606", "year": "2006", "publisher": "Association for the Advancement of Computing in Education (AACE)", "start_page": 2747, "end_page": 2752, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Nlgml: A markup language for question generation\n%A Cai, Zhiqiang\n%A Rus, Vasile\n%A Kim, Hyun-Jeong Joyce\n%A Susarla, Suresh C\n%A Karnam, Pavan\n%A Graesser, Arthur C\n%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education\n%P 2747-2752\n%@ 1880094606\n%D 2006\n%I Association for the Advancement of Computing in Education (AACE)\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:-E0S_902i2AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lfhjjPVN9BOB5OdBpl2T4Z-ynbyk&scisf=3&ct=citation&cd=6&hl=en"}
[2018-03-02 14:35:57,534 DEBUG dbutils] Get paper id {"DOI": null, "title": "Nlgml: A markup language for question generation", "auth_count": 6, "g_type": "Conference Proceedings", "pages": 6, "year": 2006, "rg_id": null, "start_page": 2747, "end_page": 2752}.
[2018-03-02 14:35:57,535 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Nlgml: A markup language for question generation', 'auth_count': 6, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2006, 'rg_id': None, 'start_page': 2747, 'end_page': 2752}
[2018-03-02 14:35:57,535 DEBUG dbutils] Query result: []
[2018-03-02 14:35:57,535 DEBUG dbutils] Paper id = None.
[2018-03-02 14:35:57,535 DEBUG dbutils] Add new paper (title='Nlgml: A markup language for question generation')
[2018-03-02 14:35:57,535 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Nlgml: A markup language for question generation', 'year': 2006, 'publisher': 'Association for the Advancement of Computing in Education (AACE)', 'start_page': 2747, 'end_page': 2752, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Nlgml: A markup language for question generation\n%A Cai, Zhiqiang\n%A Rus, Vasile\n%A Kim, Hyun-Jeong Joyce\n%A Susarla, Suresh C\n%A Karnam, Pavan\n%A Graesser, Arthur C\n%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education\n%P 2747-2752\n%@ 1880094606\n%D 2006\n%I Association for the Advancement of Computing in Education (AACE)\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 14:35:57,535 DEBUG dbutils] Query result: 7
[2018-03-02 14:35:57,537 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/24121/proceeding_24121.pdf.
[2018-03-02 14:35:57,539 WARNING utils] Download file (url='https://www.learntechlib.org/p/24121/proceeding_24121.pdf') and save (filename='PDF//7.pdf')
[2018-03-02 14:35:57,539 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 14:35:57,539 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:35:57,554 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:35:58,613 DEBUG requests.packages.urllib3.connectionpool] "GET /p/24121/proceeding_24121.pdf HTTP/1.1" 302 137
[2018-03-02 14:35:58,853 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/24121 HTTP/1.1" 301 0
[2018-03-02 14:35:59,424 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/24121/ HTTP/1.1" 200 None
[2018-03-02 14:35:59,580 DEBUG utils] Server do not give PDF.
[2018-03-02 14:35:59,582 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/24121/.
[2018-03-02 14:35:59,582 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/24121/.
[2018-03-02 14:35:59,823 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/24121/ HTTP/1.1" 302 None
[2018-03-02 14:36:01,387 DEBUG requests.packages.urllib3.connectionpool] "GET /p/24121/ HTTP/1.1" 200 17942
[2018-03-02 14:36:01,389 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:36:01,389 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:36:01,642 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/24121/ HTTP/1.1" 302 None
[2018-03-02 14:36:01,689 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:36:05,289 DEBUG requests.packages.urllib3.connectionpool] "GET /p/24121/ HTTP/1.1" 200 17939
[2018-03-02 14:36:05,628 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:36:05,629 DEBUG scholar] Handle paper #8 (total 1170)
[2018-03-02 14:36:05,630 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:36:05,634 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:05,634 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:36:05,992 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:oOz5EpsV6UsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lZwNoScEBalME5npZyAvYPujybXA&scisf=3&ct=citation&cd=7&hl=en HTTP/1.1" 200 229
[2018-03-02 14:36:05,993 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Chatbot evaluation and database expansion via crowdsourcing
%A Yu, Zhou
%A Xu, Ziyu
%A Black, Alan
%A Rudnicky, Alexander
%B Proceedings of the chatbot workshop of LREC
%V 63
%P 102
%D 2016

[2018-03-02 14:36:05,994 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:05,994 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:05,994 DEBUG __main__] Process content of EndNote file #8
{"title": "Chatbot evaluation and database expansion via crowdsourcing", "url": "https://pdfs.semanticscholar.org/a950/b42d3e46f4e1fb0e7e6959bc85a66246adb8.pdf", "author": [{"shortname": "Z Yu", "gid": "jee2Dy0AAAAJ"}, {"shortname": "Z Xu", "gid": "sqDgNQ4AAAAJ"}, {"shortname": "A Black", "gid": "Es-YRKMAAAAJ"}, {"shortname": "A Rudnicky", "gid": "axOnEnQAAAAJ"}], "year": 2016}
{"citedby": 7, "type": "Conference Proceedings", "title": "Chatbot evaluation and database expansion via crowdsourcing", "author": ["Yu, Zhou", "Xu, Ziyu", "Black, Alan", "Rudnicky, Alexander"], "secondarytitle": "Proceedings of the chatbot workshop of LREC", "volume": "63", "pages": "102", "year": "2016", "EndNote": "%0 Conference Proceedings\n%T Chatbot evaluation and database expansion via crowdsourcing\n%A Yu, Zhou\n%A Xu, Ziyu\n%A Black, Alan\n%A Rudnicky, Alexander\n%B Proceedings of the chatbot workshop of LREC\n%V 63\n%P 102\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:oOz5EpsV6UsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lZwNoScEBalME5npZyAvYPujybXA&scisf=3&ct=citation&cd=7&hl=en"}
[2018-03-02 14:36:05,994 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbot evaluation and database expansion via crowdsourcing", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 63, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:36:05,994 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbot evaluation and database expansion via crowdsourcing', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 63, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:36:05,994 DEBUG dbutils] Query result: []
[2018-03-02 14:36:05,994 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:05,994 DEBUG dbutils] Add new paper (title='Chatbot evaluation and database expansion via crowdsourcing')
[2018-03-02 14:36:05,994 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbot evaluation and database expansion via crowdsourcing', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 63, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Chatbot evaluation and database expansion via crowdsourcing\n%A Yu, Zhou\n%A Xu, Ziyu\n%A Black, Alan\n%A Rudnicky, Alexander\n%B Proceedings of the chatbot workshop of LREC\n%V 63\n%P 102\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:05,994 DEBUG dbutils] Query result: 8
[2018-03-02 14:36:05,996 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/a950/b42d3e46f4e1fb0e7e6959bc85a66246adb8.pdf.
[2018-03-02 14:36:05,999 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/a950/b42d3e46f4e1fb0e7e6959bc85a66246adb8.pdf') and save (filename='PDF//8.pdf')
[2018-03-02 14:36:05,999 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:36:05,999 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:36:05,999 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for otherhost
[2018-03-02 14:36:06,015 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 14:36:08,720 DEBUG requests.packages.urllib3.connectionpool] "GET /a950/b42d3e46f4e1fb0e7e6959bc85a66246adb8.pdf HTTP/1.1" 200 90953
[2018-03-02 14:36:08,720 DEBUG utils] Content-length=90953
[2018-03-02 14:36:08,721 DEBUG utils] Create file PDF//8.pdf, start download.
[2018-03-02 14:36:10,010 DEBUG utils] End download file PDF//8.pdf.
[2018-03-02 14:36:10,011 DEBUG dbutils] Update pdf_transaction for paper id=8.
[2018-03-02 14:36:10,011 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 8'
[2018-03-02 14:36:10,012 DEBUG dbutils] Query result: null
[2018-03-02 14:36:10,012 DEBUG scholar] Handle paper #9 (total 1170)
[2018-03-02 14:36:10,012 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:36:10,016 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:10,016 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:36:10,016 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for scholar.google.com
[2018-03-02 14:36:10,033 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:36:11,732 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:e097KjoebocJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lR3IcgVoMv1VunR-4R9PQ3o1BVgr&scisf=3&ct=citation&cd=8&hl=en HTTP/1.1" 200 356
[2018-03-02 14:36:11,733 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework
%A Yamada, Masanori
%A Goda, Yoshiko
%A Matsukawa, Hideya
%A Hata, Kojiro
%A Yasunami, Seisuke
%B International Conference on Web-Based Learning
%P 43-55
%D 2014
%I Springer

[2018-03-02 14:36:11,733 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:11,733 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:11,734 DEBUG __main__] Process content of EndNote file #9
{"title": "What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework", "url": "https://link.springer.com/chapter/10.1007/978-3-319-09635-3_5", "author": [{"shortname": "M Yamada", "gid": "4dOyLHAAAAAJ"}, {"shortname": "Y Goda", "gid": "hIk4QDAAAAAJ"}, {"shortname": "H Matsukawa", "gid": ""}, {"shortname": "K Hata", "gid": ""}], "year": 2014}
{"citedby": 4, "type": "Conference Proceedings", "title": "What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework", "author": ["Yamada, Masanori", "Goda, Yoshiko", "Matsukawa, Hideya", "Hata, Kojiro", "Yasunami, Seisuke"], "secondarytitle": "International Conference on Web-Based Learning", "pages": "43-55", "year": "2014", "publisher": "Springer", "start_page": 43, "end_page": 55, "volume": 13, "EndNote": "%0 Conference Proceedings\n%T What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%B International Conference on Web-Based Learning\n%P 43-55\n%D 2014\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:e097KjoebocJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5lR3IcgVoMv1VunR-4R9PQ3o1BVgr&scisf=3&ct=citation&cd=8&hl=en"}
[2018-03-02 14:36:11,734 DEBUG dbutils] Get paper id {"DOI": null, "title": "What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 13, "year": 2014, "rg_id": null, "start_page": 43, "end_page": 55}.
[2018-03-02 14:36:11,734 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 13, 'year': 2014, 'rg_id': None, 'start_page': 43, 'end_page': 55}
[2018-03-02 14:36:11,734 DEBUG dbutils] Query result: []
[2018-03-02 14:36:11,734 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:11,734 DEBUG dbutils] Add new paper (title='What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework')
[2018-03-02 14:36:11,734 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework', 'year': 2014, 'publisher': 'Springer', 'start_page': 43, 'end_page': 55, 'pages': 13, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T What psychological factors enhance a language learning community? Toward effective CSCL design for language learning based on a CoI framework\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%B International Conference on Web-Based Learning\n%P 43-55\n%D 2014\n%I Springer\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:11,734 DEBUG dbutils] Query result: 9
[2018-03-02 14:36:11,736 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/34070923/what_psychological_fac_llc_yamada.pdf.
[2018-03-02 14:36:11,737 WARNING utils] Download file (url='http://www.academia.edu/download/34070923/what_psychological_fac_llc_yamada.pdf') and save (filename='PDF//9.pdf')
[2018-03-02 14:36:11,737 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 14:36:11,737 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:36:11,754 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 14:36:12,145 DEBUG requests.packages.urllib3.connectionpool] "GET /download/34070923/what_psychological_fac_llc_yamada.pdf HTTP/1.1" 404 None
[2018-03-02 14:36:12,148 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-09635-3_5.
[2018-03-02 14:36:12,149 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-09635-3_5.
[2018-03-02 14:36:12,332 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-09635-3_5 HTTP/1.1" 302 None
[2018-03-02 14:36:12,352 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): libgen.io
[2018-03-02 14:36:15,733 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=F4B59BF85E583E79E2FBAC1A31125906 HTTP/1.1" 200 10282
[2018-03-02 14:36:15,813 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:36:15,813 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:36:15,813 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for sci-hub.tw
[2018-03-02 14:36:16,012 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-09635-3_5 HTTP/1.1" 302 None
[2018-03-02 14:36:19,233 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=F4B59BF85E583E79E2FBAC1A31125906 HTTP/1.1" 200 10282
[2018-03-02 14:36:19,476 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:36:19,477 DEBUG scholar] Handle paper #10 (total 1170)
[2018-03-02 14:36:19,477 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:36:19,480 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:19,480 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:36:19,812 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:sJHo0__2R50J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5ldcYmlrmVBnXD3C9rhRG_SbaaRuZ&scisf=3&ct=citation&cd=9&hl=en HTTP/1.1" 200 374
[2018-03-02 14:36:19,813 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Docchat: An information retrieval approach for chatbot engines using unstructured documents
%A Yan, Zhao
%A Duan, Nan
%A Bao, Junwei
%A Chen, Peng
%A Zhou, Ming
%A Li, Zhoujun
%A Zhou, Jianshe
%B Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
%V 1
%P 516-525
%D 2016

[2018-03-02 14:36:19,813 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:19,813 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:19,813 DEBUG __main__] Process content of EndNote file #10
{"title": "Docchat: An information retrieval approach for chatbot engines using unstructured documents", "url": "http://www.aclweb.org/anthology/P16-1049", "author": [{"shortname": "Z Yan", "gid": "Z_IPFVYAAAAJ"}, {"shortname": "N Duan", "gid": ""}, {"shortname": "J Bao", "gid": "hcRREnsAAAAJ"}, {"shortname": "P Chen", "gid": ""}, {"shortname": "M Zhou", "gid": ""}, {"shortname": "Z Li", "gid": ""}], "year": 2016}
{"citedby": 18, "type": "Conference Proceedings", "title": "Docchat: An information retrieval approach for chatbot engines using unstructured documents", "author": ["Yan, Zhao", "Duan, Nan", "Bao, Junwei", "Chen, Peng", "Zhou, Ming", "Li, Zhoujun", "Zhou, Jianshe"], "secondarytitle": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "volume": 10, "pages": "516-525", "year": "2016", "start_page": 516, "end_page": 525, "EndNote": "%0 Conference Proceedings\n%T Docchat: An information retrieval approach for chatbot engines using unstructured documents\n%A Yan, Zhao\n%A Duan, Nan\n%A Bao, Junwei\n%A Chen, Peng\n%A Zhou, Ming\n%A Li, Zhoujun\n%A Zhou, Jianshe\n%B Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\n%V 1\n%P 516-525\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:sJHo0__2R50J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5ldcYmlrmVBnXD3C9rhRG_SbaaRuZ&scisf=3&ct=citation&cd=9&hl=en"}
[2018-03-02 14:36:19,813 DEBUG dbutils] Get paper id {"DOI": null, "title": "Docchat: An information retrieval approach for chatbot engines using unstructured documents", "auth_count": 7, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 516, "end_page": 525}.
[2018-03-02 14:36:19,813 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Docchat: An information retrieval approach for chatbot engines using unstructured documents', 'auth_count': 7, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 516, 'end_page': 525}
[2018-03-02 14:36:19,814 DEBUG dbutils] Query result: []
[2018-03-02 14:36:19,814 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:19,814 DEBUG dbutils] Add new paper (title='Docchat: An information retrieval approach for chatbot engines using unstructured documents')
[2018-03-02 14:36:19,814 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Docchat: An information retrieval approach for chatbot engines using unstructured documents', 'year': 2016, 'publisher': None, 'start_page': 516, 'end_page': 525, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Docchat: An information retrieval approach for chatbot engines using unstructured documents\n%A Yan, Zhao\n%A Duan, Nan\n%A Bao, Junwei\n%A Chen, Peng\n%A Zhou, Ming\n%A Li, Zhoujun\n%A Zhou, Jianshe\n%B Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\n%V 1\n%P 516-525\n%D 2016\n', 'RIS': None, 'authors': 7, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:19,814 DEBUG dbutils] Query result: 10
[2018-03-02 14:36:19,815 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/P16-1049.
[2018-03-02 14:36:19,816 WARNING utils] Download file (url='http://www.aclweb.org/anthology/P16-1049') and save (filename='PDF//10.pdf')
[2018-03-02 14:36:19,816 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:19,817 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:36:19,817 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for otherhost
[2018-03-02 14:36:19,832 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 14:36:20,465 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P16-1049 HTTP/1.1" 200 None
[2018-03-02 14:36:20,465 DEBUG utils] Downloading the entire file.
[2018-03-02 14:36:20,466 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:20,466 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:36:20,480 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 14:36:21,099 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P16-1049 HTTP/1.1" 200 None
[2018-03-02 14:36:22,586 DEBUG utils] Save file PDF//10.pdf.
[2018-03-02 14:36:22,588 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/P16-1049.
[2018-03-02 14:36:22,588 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/P16-1049.
[2018-03-02 14:36:22,829 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/P16-1049 HTTP/1.1" 302 None
[2018-03-02 14:36:23,217 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P16-1049 HTTP/1.1" 200 None
[2018-03-02 14:36:24,084 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:36:24,085 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:36:24,272 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/P16-1049 HTTP/1.1" 302 None
[2018-03-02 14:36:24,597 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P16-1049 HTTP/1.1" 200 None
[2018-03-02 14:36:28,257 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:36:28,258 DEBUG dbutils] Commiting transaction 10.
[2018-03-02 14:36:28,380 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:36:28,380 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:36:28,380 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:36:28,380 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for scholar.google.com
[2018-03-02 14:36:28,398 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:36:31,512 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=10&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:36:32,516 DEBUG scholar] Find papers on page #2 (max_google_papers = 300)
[2018-03-02 14:36:32,516 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:36:32,517 DEBUG scholar] Handle paper #11 (total 1170)
[2018-03-02 14:36:32,517 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:36:32,520 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:32,520 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:36:32,538 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:36:35,804 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:M2Oeuih4l9kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk529ab9BYLUFoCNivXG5ViWybe6AUm&scisf=3&ct=citation&cd=10&hl=en HTTP/1.1" 200 307
[2018-03-02 14:36:35,805 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge
%A Zhou, Xiaoqiang
%A Hu, Baotian
%A Lin, Jiaxin
%A Wang, Xiaolong
%B Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)
%P 210-214
%D 2015

[2018-03-02 14:36:35,805 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:35,805 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:35,805 DEBUG __main__] Process content of EndNote file #11
{"title": "ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge", "url": "http://www.aclweb.org/anthology/S15-2037", "author": [{"shortname": "X Zhou", "gid": "OaXahwQAAAAJ"}, {"shortname": "B Hu", "gid": "5NiJ1VoAAAAJ"}, {"shortname": "J Lin", "gid": ""}, {"shortname": "X Wang", "gid": "Q2-9VWsAAAAJ"}], "year": 2015}
{"citedby": 7, "type": "Conference Proceedings", "title": "ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge", "author": ["Zhou, Xiaoqiang", "Hu, Baotian", "Lin, Jiaxin", "Wang, Xiaolong"], "secondarytitle": "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)", "pages": "210-214", "year": "2015", "start_page": 210, "end_page": 214, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge\n%A Zhou, Xiaoqiang\n%A Hu, Baotian\n%A Lin, Jiaxin\n%A Wang, Xiaolong\n%B Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)\n%P 210-214\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:M2Oeuih4l9kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk529ab9BYLUFoCNivXG5ViWybe6AUm&scisf=3&ct=citation&cd=10&hl=en"}
[2018-03-02 14:36:35,806 DEBUG dbutils] Get paper id {"DOI": null, "title": "ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 5, "year": 2015, "rg_id": null, "start_page": 210, "end_page": 214}.
[2018-03-02 14:36:35,806 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2015, 'rg_id': None, 'start_page': 210, 'end_page': 214}
[2018-03-02 14:36:35,806 DEBUG dbutils] Query result: []
[2018-03-02 14:36:35,806 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:35,806 DEBUG dbutils] Add new paper (title='ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge')
[2018-03-02 14:36:35,806 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge', 'year': 2015, 'publisher': None, 'start_page': 210, 'end_page': 214, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T ICRC-HIT: A deep learning based comment sequence labeling system for answer selection challenge\n%A Zhou, Xiaoqiang\n%A Hu, Baotian\n%A Lin, Jiaxin\n%A Wang, Xiaolong\n%B Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015)\n%P 210-214\n%D 2015\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:35,807 DEBUG dbutils] Query result: 11
[2018-03-02 14:36:35,808 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/S15-2037.
[2018-03-02 14:36:35,809 WARNING utils] Download file (url='http://www.aclweb.org/anthology/S15-2037') and save (filename='PDF//11.pdf')
[2018-03-02 14:36:35,809 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:35,810 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:36:35,810 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for otherhost
[2018-03-02 14:36:35,828 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.aclweb.org
[2018-03-02 14:36:36,435 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/S15-2037 HTTP/1.1" 200 None
[2018-03-02 14:36:36,435 DEBUG utils] Downloading the entire file.
[2018-03-02 14:36:36,435 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:36,435 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:36:36,450 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): www.aclweb.org
[2018-03-02 14:36:37,129 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/S15-2037 HTTP/1.1" 200 None
[2018-03-02 14:36:39,287 DEBUG utils] Save file PDF//11.pdf.
[2018-03-02 14:36:39,289 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/S15-2037.
[2018-03-02 14:36:39,289 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/S15-2037.
[2018-03-02 14:36:39,488 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/S15-2037 HTTP/1.1" 302 None
[2018-03-02 14:36:39,775 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/S15-2037 HTTP/1.1" 200 None
[2018-03-02 14:36:41,153 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:36:41,153 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:36:41,154 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for sci-hub.tw
[2018-03-02 14:36:41,352 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/S15-2037 HTTP/1.1" 302 None
[2018-03-02 14:36:41,646 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/S15-2037 HTTP/1.1" 200 None
[2018-03-02 14:36:46,739 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:36:46,741 DEBUG scholar] Handle paper #12 (total 1170)
[2018-03-02 14:36:46,741 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:36:46,744 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:46,745 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:36:46,745 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for scholar.google.com
[2018-03-02 14:36:46,765 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:36:48,094 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ZoG8lJue3JAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk529hq0Lu6h9qXbdes9coUehmDYsal&scisf=3&ct=citation&cd=11&hl=en HTTP/1.1" 200 195
[2018-03-02 14:36:48,095 DEBUG scholar] EndNote file:
%0 Journal Article
%T Imagining the use of intelligent agents and artificial intelligence in academic law libraries
%A Talley, Nancy B
%J Law Libr. J.
%V 108
%P 383
%D 2016
%I HeinOnline

[2018-03-02 14:36:48,095 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:48,095 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:48,095 DEBUG __main__] Process content of EndNote file #12
{"title": "Imagining the use of intelligent agents and artificial intelligence in academic law libraries", "url": "http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26", "author": [{"shortname": "NB Talley", "gid": ""}], "year": 2016}
{"citedby": 8, "type": "Journal Article", "title": "Imagining the use of intelligent agents and artificial intelligence in academic law libraries", "author": ["Talley, Nancy B"], "journal": "Law Libr. J.", "volume": "108", "pages": "383", "year": "2016", "publisher": "HeinOnline", "EndNote": "%0 Journal Article\n%T Imagining the use of intelligent agents and artificial intelligence in academic law libraries\n%A Talley, Nancy B\n%J Law Libr. J.\n%V 108\n%P 383\n%D 2016\n%I HeinOnline\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ZoG8lJue3JAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk529hq0Lu6h9qXbdes9coUehmDYsal&scisf=3&ct=citation&cd=11&hl=en"}
[2018-03-02 14:36:48,095 DEBUG dbutils] Get paper id {"DOI": null, "title": "Imagining the use of intelligent agents and artificial intelligence in academic law libraries", "auth_count": 1, "g_type": "Journal Article", "pages": 108, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:36:48,095 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Imagining the use of intelligent agents and artificial intelligence in academic law libraries', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 108, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:36:48,095 DEBUG dbutils] Query result: []
[2018-03-02 14:36:48,095 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:48,095 DEBUG dbutils] Add new paper (title='Imagining the use of intelligent agents and artificial intelligence in academic law libraries')
[2018-03-02 14:36:48,096 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Imagining the use of intelligent agents and artificial intelligence in academic law libraries', 'year': 2016, 'publisher': 'HeinOnline', 'start_page': None, 'end_page': None, 'pages': 108, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Imagining the use of intelligent agents and artificial intelligence in academic law libraries\n%A Talley, Nancy B\n%J Law Libr. J.\n%V 108\n%P 383\n%D 2016\n%I HeinOnline\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:48,096 DEBUG dbutils] Query result: 12
[2018-03-02 14:36:48,098 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26.
[2018-03-02 14:36:48,098 DEBUG scihub] Get page from sci-hub for paper with DOI=http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26.
[2018-03-02 14:36:52,710 DEBUG requests.packages.urllib3.connectionpool] "GET //http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26 HTTP/1.1" 307 None
[2018-03-02 14:36:56,018 DEBUG requests.packages.urllib3.connectionpool] "GET /http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26 HTTP/1.1" 200 None
[2018-03-02 14:36:56,019 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:36:56,019 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:36:58,492 DEBUG requests.packages.urllib3.connectionpool] "GET //http://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/llj108&section=26 HTTP/1.1" 200 None
[2018-03-02 14:36:58,498 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:36:58,499 DEBUG scholar] Handle paper #13 (total 1170)
[2018-03-02 14:36:58,499 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:36:58,503 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:36:58,504 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:36:58,793 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ImcVRnwinQ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52-igIQ3UE2EJx4B1O1K5LB9Y7NYa&scisf=3&ct=citation&cd=12&hl=en HTTP/1.1" 200 293
[2018-03-02 14:36:58,793 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Strategy and policy learning for non-task-oriented conversational systems
%A Yu, Zhou
%A Xu, Ziyu
%A Black, Alan W
%A Rudnicky, Alexander
%B Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue
%P 404-412
%D 2016

[2018-03-02 14:36:58,794 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:36:58,794 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:36:58,794 DEBUG __main__] Process content of EndNote file #13
{"title": "Strategy and policy learning for non-task-oriented conversational systems", "url": "http://www.aclweb.org/anthology/W16-3649", "author": [{"shortname": "Z Yu", "gid": "jee2Dy0AAAAJ"}, {"shortname": "Z Xu", "gid": "sqDgNQ4AAAAJ"}, {"shortname": "AW Black", "gid": "Es-YRKMAAAAJ"}, {"shortname": "A Rudnicky", "gid": "axOnEnQAAAAJ"}], "year": 2016}
{"citedby": 17, "type": "Conference Proceedings", "title": "Strategy and policy learning for non-task-oriented conversational systems", "author": ["Yu, Zhou", "Xu, Ziyu", "Black, Alan W", "Rudnicky, Alexander"], "secondarytitle": "Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue", "pages": "404-412", "year": "2016", "start_page": 404, "end_page": 412, "volume": 9, "EndNote": "%0 Conference Proceedings\n%T Strategy and policy learning for non-task-oriented conversational systems\n%A Yu, Zhou\n%A Xu, Ziyu\n%A Black, Alan W\n%A Rudnicky, Alexander\n%B Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue\n%P 404-412\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ImcVRnwinQ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52-igIQ3UE2EJx4B1O1K5LB9Y7NYa&scisf=3&ct=citation&cd=12&hl=en"}
[2018-03-02 14:36:58,794 DEBUG dbutils] Get paper id {"DOI": null, "title": "Strategy and policy learning for non-task-oriented conversational systems", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 9, "year": 2016, "rg_id": null, "start_page": 404, "end_page": 412}.
[2018-03-02 14:36:58,794 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Strategy and policy learning for non-task-oriented conversational systems', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 9, 'year': 2016, 'rg_id': None, 'start_page': 404, 'end_page': 412}
[2018-03-02 14:36:58,794 DEBUG dbutils] Query result: []
[2018-03-02 14:36:58,794 DEBUG dbutils] Paper id = None.
[2018-03-02 14:36:58,794 DEBUG dbutils] Add new paper (title='Strategy and policy learning for non-task-oriented conversational systems')
[2018-03-02 14:36:58,794 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Strategy and policy learning for non-task-oriented conversational systems', 'year': 2016, 'publisher': None, 'start_page': 404, 'end_page': 412, 'pages': 9, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Strategy and policy learning for non-task-oriented conversational systems\n%A Yu, Zhou\n%A Xu, Ziyu\n%A Black, Alan W\n%A Rudnicky, Alexander\n%B Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue\n%P 404-412\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:36:58,794 DEBUG dbutils] Query result: 13
[2018-03-02 14:36:58,796 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/W16-3649.
[2018-03-02 14:36:58,797 WARNING utils] Download file (url='http://www.aclweb.org/anthology/W16-3649') and save (filename='PDF//13.pdf')
[2018-03-02 14:36:58,797 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:58,797 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:36:58,797 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for otherhost
[2018-03-02 14:36:58,815 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.aclweb.org
[2018-03-02 14:36:59,454 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W16-3649 HTTP/1.1" 200 None
[2018-03-02 14:36:59,454 DEBUG utils] Downloading the entire file.
[2018-03-02 14:36:59,454 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:36:59,454 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:36:59,470 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): www.aclweb.org
[2018-03-02 14:37:00,088 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W16-3649 HTTP/1.1" 200 None
[2018-03-02 14:37:01,015 DEBUG utils] Save file PDF//13.pdf.
[2018-03-02 14:37:01,020 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/W16-3649.
[2018-03-02 14:37:01,020 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/W16-3649.
[2018-03-02 14:37:01,221 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/W16-3649 HTTP/1.1" 302 None
[2018-03-02 14:37:01,564 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W16-3649 HTTP/1.1" 200 None
[2018-03-02 14:37:02,086 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:37:02,086 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:37:02,087 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for sci-hub.tw
[2018-03-02 14:37:02,271 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/W16-3649 HTTP/1.1" 302 None
[2018-03-02 14:37:02,544 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W16-3649 HTTP/1.1" 200 None
[2018-03-02 14:37:04,367 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:37:04,370 DEBUG scholar] Handle paper #14 (total 1170)
[2018-03-02 14:37:04,370 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:37:04,374 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:04,374 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:37:04,374 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for scholar.google.com
[2018-03-02 14:37:04,394 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:37:05,971 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:8vJVGwILdRwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52_JbZqatGsrIDCaCTMTxKaQBRJgr&scisf=3&ct=citation&cd=13&hl=en HTTP/1.1" 200 326
[2018-03-02 14:37:05,972 DEBUG scholar] EndNote file:
%0 Journal Article
%T Design and implementation of a 3D multi-user virtual world for language learning.
%A Ibanez, Maria Blanca
%A Rueda, Jose Jesus Garcia
%A Galan, Sergio
%A Maroto, David
%A Morillo, Diego
%A Kloos, Carlos Delgado
%J Educational Technology & Society
%V 14
%N 4
%P 2-10
%D 2011
%I JSTOR

[2018-03-02 14:37:05,972 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:05,972 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:05,972 DEBUG __main__] Process content of EndNote file #14
{"title": "Design and implementation of a 3D multi-user virtual world for language learning.", "url": "http://www.jstor.org/stable/jeductechsoci.14.4.2", "author": [{"shortname": "MB Ib\u00e1\u00f1ez", "gid": ""}, {"shortname": "JJG Rueda", "gid": ""}, {"shortname": "S Gal\u00e1n", "gid": ""}, {"shortname": "D Maroto", "gid": ""}], "year": 2011}
{"citedby": 62, "type": "Journal Article", "title": "Design and implementation of a 3D multi-user virtual world for language learning.", "author": ["Ib\u00e1\u00f1ez, Mar\u00eda Blanca", "Rueda, Jos\u00e9 Jes\u00fas Garc\u00eda", "Gal\u00e1n, Sergio", "Maroto, David", "Morillo, Diego", "Kloos, Carlos Delgado"], "journal": "Educational Technology & Society", "volume": 9, "numberorissue": "4", "pages": "2-10", "year": "2011", "publisher": "JSTOR", "start_page": 2, "end_page": 10, "EndNote": "%0 Journal Article\n%T Design and implementation of a 3D multi-user virtual world for language learning.\n%A Ib\u00e1\u00f1ez, Mar\u00eda Blanca\n%A Rueda, Jos\u00e9 Jes\u00fas Garc\u00eda\n%A Gal\u00e1n, Sergio\n%A Maroto, David\n%A Morillo, Diego\n%A Kloos, Carlos Delgado\n%J Educational Technology & Society\n%V 14\n%N 4\n%P 2-10\n%D 2011\n%I JSTOR\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:8vJVGwILdRwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52_JbZqatGsrIDCaCTMTxKaQBRJgr&scisf=3&ct=citation&cd=13&hl=en"}
[2018-03-02 14:37:05,973 DEBUG dbutils] Get paper id {"DOI": null, "title": "Design and implementation of a 3D multi-user virtual world for language learning.", "auth_count": 6, "g_type": "Journal Article", "pages": 9, "year": 2011, "rg_id": null, "start_page": 2, "end_page": 10}.
[2018-03-02 14:37:05,973 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Design and implementation of a 3D multi-user virtual world for language learning.', 'auth_count': 6, 'g_type': 'Journal Article', 'pages': 9, 'year': 2011, 'rg_id': None, 'start_page': 2, 'end_page': 10}
[2018-03-02 14:37:05,973 DEBUG dbutils] Query result: []
[2018-03-02 14:37:05,973 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:05,973 DEBUG dbutils] Add new paper (title='Design and implementation of a 3D multi-user virtual world for language learning.')
[2018-03-02 14:37:05,973 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Design and implementation of a 3D multi-user virtual world for language learning.', 'year': 2011, 'publisher': 'JSTOR', 'start_page': 2, 'end_page': 10, 'pages': 9, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Design and implementation of a 3D multi-user virtual world for language learning.\n%A Ibanez, Maria Blanca\n%A Rueda, Jose Jesus Garcia\n%A Galan, Sergio\n%A Maroto, David\n%A Morillo, Diego\n%A Kloos, Carlos Delgado\n%J Educational Technology & Society\n%V 14\n%N 4\n%P 2-10\n%D 2011\n%I JSTOR\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:05,973 DEBUG dbutils] Query result: 14
[2018-03-02 14:37:05,975 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.jstor.org/stable/jeductechsoci.14.4.2.
[2018-03-02 14:37:05,975 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.jstor.org/stable/jeductechsoci.14.4.2.
[2018-03-02 14:37:07,584 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.jstor.org/stable/jeductechsoci.14.4.2 HTTP/1.1" 200 None
[2018-03-02 14:37:07,585 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:37:07,585 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:37:07,772 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.jstor.org/stable/jeductechsoci.14.4.2 HTTP/1.1" 200 None
[2018-03-02 14:37:07,783 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:37:07,785 DEBUG scholar] Handle paper #15 (total 1170)
[2018-03-02 14:37:07,785 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:37:07,789 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:07,789 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:37:08,084 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:0HVglzaLIzoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk526CW92Qgx-DNf45iAmQMqZ5C3N03&scisf=3&ct=citation&cd=14&hl=en HTTP/1.1" 200 192
[2018-03-02 14:37:08,085 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Making nifty assignments niftier and not so nifty assignments nifty with online technologies
%A Imberman, Susan P
%D 2008
%I AI Education Colloquium Workshop

[2018-03-02 14:37:08,085 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:08,085 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:08,085 DEBUG __main__] Process content of EndNote file #15
{"title": "Making nifty assignments niftier and not so nifty assignments nifty with online technologies", "url": "http://www.aaai.org/Papers/Workshops/2008/WS-08-02/WS08-02-009.pdf", "author": [{"shortname": "SP Imberman", "gid": "y3HkhBEAAAAJ"}], "year": 2008}
{"citedby": 2, "type": "Conference Proceedings", "title": "Making nifty assignments niftier and not so nifty assignments nifty with online technologies", "author": ["Imberman, Susan P"], "year": "2008", "publisher": "AI Education Colloquium Workshop", "EndNote": "%0 Conference Proceedings\n%T Making nifty assignments niftier and not so nifty assignments nifty with online technologies\n%A Imberman, Susan P\n%D 2008\n%I AI Education Colloquium Workshop\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:0HVglzaLIzoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk526CW92Qgx-DNf45iAmQMqZ5C3N03&scisf=3&ct=citation&cd=14&hl=en"}
[2018-03-02 14:37:08,086 DEBUG dbutils] Get paper id {"DOI": null, "title": "Making nifty assignments niftier and not so nifty assignments nifty with online technologies", "auth_count": 1, "g_type": "Conference Proceedings", "pages": null, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:37:08,086 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Making nifty assignments niftier and not so nifty assignments nifty with online technologies', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:37:08,086 DEBUG dbutils] Query result: []
[2018-03-02 14:37:08,086 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:08,086 DEBUG dbutils] Add new paper (title='Making nifty assignments niftier and not so nifty assignments nifty with online technologies')
[2018-03-02 14:37:08,086 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Making nifty assignments niftier and not so nifty assignments nifty with online technologies', 'year': 2008, 'publisher': 'AI Education Colloquium Workshop', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Making nifty assignments niftier and not so nifty assignments nifty with online technologies\n%A Imberman, Susan P\n%D 2008\n%I AI Education Colloquium Workshop\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:08,086 DEBUG dbutils] Query result: 15
[2018-03-02 14:37:08,088 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aaai.org/Papers/Workshops/2008/WS-08-02/WS08-02-009.pdf.
[2018-03-02 14:37:08,089 WARNING utils] Download file (url='http://www.aaai.org/Papers/Workshops/2008/WS-08-02/WS08-02-009.pdf') and save (filename='PDF//15.pdf')
[2018-03-02 14:37:08,089 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 14:37:08,089 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:37:08,090 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for otherhost
[2018-03-02 14:37:08,108 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aaai.org
[2018-03-02 14:37:08,876 DEBUG requests.packages.urllib3.connectionpool] "GET /Papers/Workshops/2008/WS-08-02/WS08-02-009.pdf HTTP/1.1" 200 196148
[2018-03-02 14:37:08,877 DEBUG utils] Content-length=196148
[2018-03-02 14:37:08,877 DEBUG utils] Create file PDF//15.pdf, start download.
[2018-03-02 14:37:10,279 DEBUG utils] End download file PDF//15.pdf.
[2018-03-02 14:37:10,280 DEBUG dbutils] Update pdf_transaction for paper id=15.
[2018-03-02 14:37:10,281 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 15'
[2018-03-02 14:37:10,281 DEBUG dbutils] Query result: null
[2018-03-02 14:37:10,287 DEBUG scholar] Handle paper #16 (total 1170)
[2018-03-02 14:37:10,287 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:37:10,296 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:10,296 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:37:10,296 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for scholar.google.com
[2018-03-02 14:37:10,318 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:37:11,833 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:1GZpFITZnn8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk520Dbes-A9U3XqC6FGZRzKktWvLM7&scisf=3&ct=citation&cd=15&hl=en HTTP/1.1" 200 220
[2018-03-02 14:37:11,835 DEBUG scholar] EndNote file:
%0 Journal Article
%T Science fiction is full of bots that hurt people:... but these bots are here now
%A Michael, Katina
%J IEEE Consumer Electronics Magazine
%V 5
%N 4
%P 112-117
%@ 2162-2248
%D 2016
%I IEEE

[2018-03-02 14:37:11,835 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:11,835 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:11,836 DEBUG __main__] Process content of EndNote file #16
{"title": "Science fiction is full of bots that hurt people:... but these bots are here now", "url": "http://ieeexplore.ieee.org/abstract/document/7574440/", "author": [{"shortname": "K Michael", "gid": "0oSenaUAAAAJ"}], "year": 2016}
{"citedby": 3, "type": "Journal Article", "title": "Science fiction is full of bots that hurt people:... but these bots are here now", "author": ["Michael, Katina"], "journal": "IEEE Consumer Electronics Magazine", "volume": 6, "numberorissue": "4", "pages": "112-117", "isbn/issn": "2162-2248", "year": "2016", "publisher": "IEEE", "start_page": 112, "end_page": 117, "EndNote": "%0 Journal Article\n%T Science fiction is full of bots that hurt people:... but these bots are here now\n%A Michael, Katina\n%J IEEE Consumer Electronics Magazine\n%V 5\n%N 4\n%P 112-117\n%@ 2162-2248\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:1GZpFITZnn8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk520Dbes-A9U3XqC6FGZRzKktWvLM7&scisf=3&ct=citation&cd=15&hl=en"}
[2018-03-02 14:37:11,836 DEBUG dbutils] Get paper id {"DOI": null, "title": "Science fiction is full of bots that hurt people:... but these bots are here now", "auth_count": 1, "g_type": "Journal Article", "pages": 6, "year": 2016, "rg_id": null, "start_page": 112, "end_page": 117}.
[2018-03-02 14:37:11,836 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Science fiction is full of bots that hurt people:... but these bots are here now', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 6, 'year': 2016, 'rg_id': None, 'start_page': 112, 'end_page': 117}
[2018-03-02 14:37:11,836 DEBUG dbutils] Query result: []
[2018-03-02 14:37:11,836 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:11,836 DEBUG dbutils] Add new paper (title='Science fiction is full of bots that hurt people:... but these bots are here now')
[2018-03-02 14:37:11,837 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Science fiction is full of bots that hurt people:... but these bots are here now', 'year': 2016, 'publisher': 'IEEE', 'start_page': 112, 'end_page': 117, 'pages': 6, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Science fiction is full of bots that hurt people:... but these bots are here now\n%A Michael, Katina\n%J IEEE Consumer Electronics Magazine\n%V 5\n%N 4\n%P 112-117\n%@ 2162-2248\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:11,838 DEBUG dbutils] Query result: 16
[2018-03-02 14:37:11,844 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7574440/.
[2018-03-02 14:37:11,845 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7574440/.
[2018-03-02 14:37:12,052 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7574440/ HTTP/1.1" 200 None
[2018-03-02 14:37:12,053 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:37:12,053 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:37:12,053 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for sci-hub.tw
[2018-03-02 14:37:12,244 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7574440/ HTTP/1.1" 200 None
[2018-03-02 14:37:12,250 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/fd5b5a9d429b18a2b32b849fec0875da/michael2016.pdf?download=true.
[2018-03-02 14:37:12,250 WARNING utils] Download file (url='http://twin.sci-hub.tw/fd5b5a9d429b18a2b32b849fec0875da/michael2016.pdf?download=true') and save (filename='PDF//16.pdf')
[2018-03-02 14:37:12,265 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 14:37:12,478 DEBUG requests.packages.urllib3.connectionpool] "GET /fd5b5a9d429b18a2b32b849fec0875da/michael2016.pdf?download=true HTTP/1.1" 200 1488393
[2018-03-02 14:37:12,479 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:37:12,479 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:37:12,494 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 14:37:12,706 DEBUG requests.packages.urllib3.connectionpool] "GET /fd5b5a9d429b18a2b32b849fec0875da/michael2016.pdf?download=true HTTP/1.1" 200 1488393
[2018-03-02 14:37:12,707 DEBUG utils] Content-length=1488393
[2018-03-02 14:37:12,707 DEBUG utils] Create file PDF//16.pdf, start download.
[2018-03-02 14:37:14,933 DEBUG utils] End download file PDF//16.pdf.
[2018-03-02 14:37:14,934 DEBUG dbutils] Update pdf_transaction for paper id=16.
[2018-03-02 14:37:14,934 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 16'
[2018-03-02 14:37:14,934 DEBUG dbutils] Query result: null
[2018-03-02 14:37:14,935 DEBUG scholar] Handle paper #17 (total 1170)
[2018-03-02 14:37:14,935 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:37:14,941 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:14,941 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:37:15,236 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:RriYtYJVQfkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5283i5FPWIbLRI4LubBHi0lgTaIQT&scisf=3&ct=citation&cd=16&hl=en HTTP/1.1" 200 138
[2018-03-02 14:37:15,238 DEBUG scholar] EndNote file:
%0 Journal Article
%T The promise of artificial intelligence
%A Castro, Daniel
%A New, Joshua
%J Center for Data Innovation
%D 2016

[2018-03-02 14:37:15,238 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:15,238 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:15,238 DEBUG __main__] Process content of EndNote file #17
{"title": "The promise of artificial intelligence", "url": "http://www2.datainnovation.org/2016-promise-of-ai.pdf", "author": [{"shortname": "D Castro", "gid": ""}, {"shortname": "J New", "gid": ""}], "year": 2016}
{"citedby": 3, "type": "Journal Article", "title": "The promise of artificial intelligence", "author": ["Castro, Daniel", "New, Joshua"], "journal": "Center for Data Innovation", "year": "2016", "EndNote": "%0 Journal Article\n%T The promise of artificial intelligence\n%A Castro, Daniel\n%A New, Joshua\n%J Center for Data Innovation\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:RriYtYJVQfkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk5283i5FPWIbLRI4LubBHi0lgTaIQT&scisf=3&ct=citation&cd=16&hl=en"}
[2018-03-02 14:37:15,238 DEBUG dbutils] Get paper id {"DOI": null, "title": "The promise of artificial intelligence", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:37:15,239 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The promise of artificial intelligence', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:37:15,239 DEBUG dbutils] Query result: []
[2018-03-02 14:37:15,239 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:15,239 DEBUG dbutils] Add new paper (title='The promise of artificial intelligence')
[2018-03-02 14:37:15,239 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The promise of artificial intelligence', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The promise of artificial intelligence\n%A Castro, Daniel\n%A New, Joshua\n%J Center for Data Innovation\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:15,239 DEBUG dbutils] Query result: 17
[2018-03-02 14:37:15,240 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www2.datainnovation.org/2016-promise-of-ai.pdf.
[2018-03-02 14:37:15,241 WARNING utils] Download file (url='http://www2.datainnovation.org/2016-promise-of-ai.pdf') and save (filename='PDF//17.pdf')
[2018-03-02 14:37:15,242 DEBUG utils] Get current proxy for www2.datainnovation.org.
[2018-03-02 14:37:15,242 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:37:15,261 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www2.datainnovation.org
[2018-03-02 14:37:15,942 DEBUG requests.packages.urllib3.connectionpool] "GET /2016-promise-of-ai.pdf HTTP/1.1" 200 3169564
[2018-03-02 14:37:15,942 DEBUG utils] Content-length=3169564
[2018-03-02 14:37:15,943 DEBUG utils] Create file PDF//17.pdf, start download.
[2018-03-02 14:37:20,532 DEBUG utils] End download file PDF//17.pdf.
[2018-03-02 14:37:20,538 DEBUG dbutils] Update pdf_transaction for paper id=17.
[2018-03-02 14:37:20,538 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 17'
[2018-03-02 14:37:20,539 DEBUG dbutils] Query result: null
[2018-03-02 14:37:20,543 DEBUG scholar] Handle paper #18 (total 1170)
[2018-03-02 14:37:20,543 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:37:20,551 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:20,551 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:37:20,551 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for scholar.google.com
[2018-03-02 14:37:20,579 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:37:21,900 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:UEPQKoToRbYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk522rVBbFgBcJNzYzpOajZiENLt5G6&scisf=3&ct=citation&cd=17&hl=en HTTP/1.1" 200 211
[2018-03-02 14:37:21,901 DEBUG scholar] EndNote file:
%0 Journal Article
%T Action research student technology use in a self-access center
%A Castellano, Joachim
%A Mynard, Jo
%A Rubesch, Troy
%J Language Learning & Technology
%V 15
%N 3
%P 12-27
%D 2011

[2018-03-02 14:37:21,901 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:21,901 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:21,902 DEBUG __main__] Process content of EndNote file #18
{"title": "Action research student technology use in a self-access center", "url": "http://www.academia.edu/download/20440893/v15n3.pdf#page=17", "author": [{"shortname": "J Castellano", "gid": "g54D8DEAAAAJ"}, {"shortname": "J Mynard", "gid": "6EIGChsAAAAJ"}, {"shortname": "T Rubesch", "gid": ""}], "year": 2011}
{"citedby": 25, "type": "Journal Article", "title": "Action research student technology use in a self-access center", "author": ["Castellano, Joachim", "Mynard, Jo", "Rubesch, Troy"], "journal": "Language Learning & Technology", "volume": 16, "numberorissue": "3", "pages": "12-27", "year": "2011", "start_page": 12, "end_page": 27, "EndNote": "%0 Journal Article\n%T Action research student technology use in a self-access center\n%A Castellano, Joachim\n%A Mynard, Jo\n%A Rubesch, Troy\n%J Language Learning & Technology\n%V 15\n%N 3\n%P 12-27\n%D 2011\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:UEPQKoToRbYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk522rVBbFgBcJNzYzpOajZiENLt5G6&scisf=3&ct=citation&cd=17&hl=en"}
[2018-03-02 14:37:21,902 DEBUG dbutils] Get paper id {"DOI": null, "title": "Action research student technology use in a self-access center", "auth_count": 3, "g_type": "Journal Article", "pages": 16, "year": 2011, "rg_id": null, "start_page": 12, "end_page": 27}.
[2018-03-02 14:37:21,902 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Action research student technology use in a self-access center', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 16, 'year': 2011, 'rg_id': None, 'start_page': 12, 'end_page': 27}
[2018-03-02 14:37:21,902 DEBUG dbutils] Query result: []
[2018-03-02 14:37:21,902 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:21,903 DEBUG dbutils] Add new paper (title='Action research student technology use in a self-access center')
[2018-03-02 14:37:21,903 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Action research student technology use in a self-access center', 'year': 2011, 'publisher': None, 'start_page': 12, 'end_page': 27, 'pages': 16, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Action research student technology use in a self-access center\n%A Castellano, Joachim\n%A Mynard, Jo\n%A Rubesch, Troy\n%J Language Learning & Technology\n%V 15\n%N 3\n%P 12-27\n%D 2011\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:21,903 DEBUG dbutils] Query result: 18
[2018-03-02 14:37:21,905 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/20440893/v15n3.pdf#page=17.
[2018-03-02 14:37:21,906 WARNING utils] Download file (url='http://www.academia.edu/download/20440893/v15n3.pdf#page=17') and save (filename='PDF//18.pdf')
[2018-03-02 14:37:21,907 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 14:37:21,907 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:37:21,907 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for otherhost
[2018-03-02 14:37:21,934 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.academia.edu
[2018-03-02 14:37:22,269 DEBUG requests.packages.urllib3.connectionpool] "GET /download/20440893/v15n3.pdf HTTP/1.1" 404 None
[2018-03-02 14:37:22,273 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.academia.edu/download/20440893/v15n3.pdf#page=17.
[2018-03-02 14:37:22,274 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.academia.edu/download/20440893/v15n3.pdf#page=17.
[2018-03-02 14:37:22,423 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/20440893/v15n3.pdf HTTP/1.1" 302 None
[2018-03-02 14:37:22,652 DEBUG requests.packages.urllib3.connectionpool] "GET /download/20440893/v15n3.pdf HTTP/1.1" 404 None
[2018-03-02 14:37:22,653 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:37:22,653 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:37:22,653 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for sci-hub.tw
[2018-03-02 14:37:22,801 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/20440893/v15n3.pdf HTTP/1.1" 302 None
[2018-03-02 14:37:23,111 DEBUG requests.packages.urllib3.connectionpool] "GET /download/20440893/v15n3.pdf HTTP/1.1" 404 None
[2018-03-02 14:37:23,117 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:37:23,117 DEBUG __main__] Failed get_pdf from sci-hub for paper #17. URL=17
[2018-03-02 14:37:23,120 DEBUG scholar] Handle paper #19 (total 1170)
[2018-03-02 14:37:23,120 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:37:23,123 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:23,123 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:37:23,352 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:HgmQIjzFdk8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52_kj9dF2oBoFetyEeGle_Tqo-m3T&scisf=3&ct=citation&cd=18&hl=en HTTP/1.1" 200 244
[2018-03-02 14:37:23,353 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Human-like computing and human---computer interaction
%A Dix, Alan
%B Proceedings of the 30th International BCS Human Computer Interaction Conference: Fusion!
%P 52
%D 2016
%I BCS Learning & Development Ltd.

[2018-03-02 14:37:23,353 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:23,354 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:23,354 DEBUG __main__] Process content of EndNote file #19
{"title": "Human-like computing and human---computer interaction", "url": "https://dl.acm.org/citation.cfm?id=3056407", "author": [{"shortname": "A Dix", "gid": "m6AAw9wAAAAJ"}], "year": 2016}
{"citedby": 5, "type": "Conference Proceedings", "title": "Human-like computing and human---computer interaction", "author": ["Dix, Alan"], "secondarytitle": "Proceedings of the 30th International BCS Human Computer Interaction Conference: Fusion!", "pages": "52", "year": "2016", "publisher": "BCS Learning & Development Ltd.", "EndNote": "%0 Conference Proceedings\n%T Human-like computing and human---computer interaction\n%A Dix, Alan\n%B Proceedings of the 30th International BCS Human Computer Interaction Conference: Fusion!\n%P 52\n%D 2016\n%I BCS Learning & Development Ltd.\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:HgmQIjzFdk8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk52_kj9dF2oBoFetyEeGle_Tqo-m3T&scisf=3&ct=citation&cd=18&hl=en"}
[2018-03-02 14:37:23,354 DEBUG dbutils] Get paper id {"DOI": null, "title": "Human-like computing and human---computer interaction", "auth_count": 1, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:37:23,354 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Human-like computing and human---computer interaction', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:37:23,354 DEBUG dbutils] Query result: []
[2018-03-02 14:37:23,354 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:23,354 DEBUG dbutils] Add new paper (title='Human-like computing and human---computer interaction')
[2018-03-02 14:37:23,354 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Human-like computing and human---computer interaction', 'year': 2016, 'publisher': 'BCS Learning & Development Ltd.', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Human-like computing and human---computer interaction\n%A Dix, Alan\n%B Proceedings of the 30th International BCS Human Computer Interaction Conference: Fusion!\n%P 52\n%D 2016\n%I BCS Learning & Development Ltd.\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:23,354 DEBUG dbutils] Query result: 19
[2018-03-02 14:37:23,356 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/4913/f27344f9680123ce33965f624f86b06ea976.pdf.
[2018-03-02 14:37:23,357 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/4913/f27344f9680123ce33965f624f86b06ea976.pdf') and save (filename='PDF//19.pdf')
[2018-03-02 14:37:23,358 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:37:23,358 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:37:23,375 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 14:37:26,951 DEBUG requests.packages.urllib3.connectionpool] "GET /4913/f27344f9680123ce33965f624f86b06ea976.pdf HTTP/1.1" 200 142315
[2018-03-02 14:37:26,952 DEBUG utils] Content-length=142315
[2018-03-02 14:37:26,952 DEBUG utils] Create file PDF//19.pdf, start download.
[2018-03-02 14:37:27,773 DEBUG utils] End download file PDF//19.pdf.
[2018-03-02 14:37:27,774 DEBUG dbutils] Update pdf_transaction for paper id=19.
[2018-03-02 14:37:27,774 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 19'
[2018-03-02 14:37:27,774 DEBUG dbutils] Query result: null
[2018-03-02 14:37:27,775 DEBUG scholar] Handle paper #20 (total 1170)
[2018-03-02 14:37:27,775 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:37:27,783 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:27,783 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:37:27,783 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for scholar.google.com
[2018-03-02 14:37:27,805 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:37:32,942 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:qgFQEEUF-G8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk525oHzOAmEc4uyHteAXPZSFhu9_z9&scisf=3&ct=citation&cd=19&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:qgFQEEUF-G8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk525oHzOAmEc4uyHteAXPZSFhu9_z9&scisf=3&ct=citation&cd=19&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:37:32,942 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for scholar.google.com
[2018-03-02 14:37:32,943 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:37:32,943 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:37:32,957 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:37:34,363 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:qgFQEEUF-G8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk525oHzOAmEc4uyHteAXPZSFhu9_z9&scisf=3&ct=citation&cd=19&hl=en HTTP/1.1" 200 230
[2018-03-02 14:37:34,364 DEBUG scholar] EndNote file:
%0 Journal Article
%T Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots
%A Wu, Yu
%A Wu, Wei
%A Zhou, Ming
%A Li, Zhoujun
%J arXiv preprint arXiv:1612.01627
%D 2016

[2018-03-02 14:37:34,364 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:37:34,364 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:37:34,364 DEBUG __main__] Process content of EndNote file #20
{"title": "Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots", "url": "https://arxiv.org/abs/1612.01627", "author": [{"shortname": "Y Wu", "gid": "aQizmzsAAAAJ"}, {"shortname": "W Wu", "gid": "YtqXSzMAAAAJ"}, {"shortname": "M Zhou", "gid": ""}, {"shortname": "Z Li", "gid": ""}], "year": 1612}
{"citedby": 3, "type": "Journal Article", "title": "Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots", "author": ["Wu, Yu", "Wu, Wei", "Zhou, Ming", "Li, Zhoujun"], "journal": "arXiv preprint arXiv:1612.01627", "year": "2016", "EndNote": "%0 Journal Article\n%T Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots\n%A Wu, Yu\n%A Wu, Wei\n%A Zhou, Ming\n%A Li, Zhoujun\n%J arXiv preprint arXiv:1612.01627\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:qgFQEEUF-G8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk525oHzOAmEc4uyHteAXPZSFhu9_z9&scisf=3&ct=citation&cd=19&hl=en"}
[2018-03-02 14:37:34,364 DEBUG dbutils] Get paper id {"DOI": null, "title": "Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:37:34,364 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:37:34,365 DEBUG dbutils] Query result: []
[2018-03-02 14:37:34,365 DEBUG dbutils] Paper id = None.
[2018-03-02 14:37:34,365 DEBUG dbutils] Add new paper (title='Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots')
[2018-03-02 14:37:34,365 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Sequential match network: A new architecture for multi-turn response selection in retrieval-based chatbots\n%A Wu, Yu\n%A Wu, Wei\n%A Zhou, Ming\n%A Li, Zhoujun\n%J arXiv preprint arXiv:1612.01627\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:37:34,365 DEBUG dbutils] Query result: 20
[2018-03-02 14:37:34,367 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1612.01627.
[2018-03-02 14:37:34,368 WARNING utils] Download file (url='https://arxiv.org/pdf/1612.01627') and save (filename='PDF//20.pdf')
[2018-03-02 14:37:34,368 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:37:34,368 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:37:34,368 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for otherhost
[2018-03-02 14:37:34,384 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:37:35,735 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1612.01627 HTTP/1.1" 302 280
[2018-03-02 14:37:36,573 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1612.01627.pdf HTTP/1.1" 200 1066609
[2018-03-02 14:37:36,573 DEBUG utils] Content-length=1066609
[2018-03-02 14:37:36,573 DEBUG utils] Create file PDF//20.pdf, start download.
[2018-03-02 14:37:40,355 DEBUG utils] End download file PDF//20.pdf.
[2018-03-02 14:37:40,357 DEBUG dbutils] Update pdf_transaction for paper id=20.
[2018-03-02 14:37:40,357 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 20'
[2018-03-02 14:37:40,357 DEBUG dbutils] Query result: null
[2018-03-02 14:37:40,376 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:37:40,376 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:37:40,376 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:37:40,376 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for scholar.google.com
[2018-03-02 14:37:40,392 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:37:41,717 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=20&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:37:41,978 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:37:41,978 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:37:48,023 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:37:48,023 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:37:48,168 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:37:48,168 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:37:48,435 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=20&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:37:48,685 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:38:57,415 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:38:57,415 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:38:57,416 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for scholar.google.com
[2018-03-02 14:38:57,429 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:39:02,224 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=20&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:39:04,467 DEBUG scholar] Find papers on page #3 (max_google_papers = 300)
[2018-03-02 14:39:04,467 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:39:04,467 DEBUG scholar] Handle paper #21 (total 1170)
[2018-03-02 14:39:04,467 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:39:04,470 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:04,470 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:39:04,487 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:06,151 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:mi3VKkKe4lwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctKUa0chLXKF8hoYu2DtXeqDa1uU&scisf=3&ct=citation&cd=20&hl=en HTTP/1.1" 200 232
[2018-03-02 14:39:06,152 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Childrens interactions with inspectable and negotiated learner models
%A Kerly, Alice
%A Bull, Susan
%B International Conference on Intelligent Tutoring Systems
%P 132-141
%D 2008
%I Springer

[2018-03-02 14:39:06,152 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:06,152 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:06,152 DEBUG __main__] Process content of EndNote file #21
{"title": "Children's interactions with inspectable and negotiated learner models", "url": "https://link.springer.com/chapter/10.1007/978-3-540-69132-7_18", "author": [{"shortname": "A Kerly", "gid": ""}, {"shortname": "S Bull", "gid": "TONyepAAAAAJ"}], "year": 2008}
{"citedby": 43, "type": "Conference Proceedings", "title": "Children\u2019s interactions with inspectable and negotiated learner models", "author": ["Kerly, Alice", "Bull, Susan"], "secondarytitle": "International Conference on Intelligent Tutoring Systems", "pages": "132-141", "year": "2008", "publisher": "Springer", "start_page": 132, "end_page": 141, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Children\u2019s interactions with inspectable and negotiated learner models\n%A Kerly, Alice\n%A Bull, Susan\n%B International Conference on Intelligent Tutoring Systems\n%P 132-141\n%D 2008\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:mi3VKkKe4lwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctKUa0chLXKF8hoYu2DtXeqDa1uU&scisf=3&ct=citation&cd=20&hl=en"}
[2018-03-02 14:39:06,152 DEBUG dbutils] Get paper id {"DOI": null, "title": "Children\u2019s interactions with inspectable and negotiated learner models", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2008, "rg_id": null, "start_page": 132, "end_page": 141}.
[2018-03-02 14:39:06,153 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Childrens interactions with inspectable and negotiated learner models', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2008, 'rg_id': None, 'start_page': 132, 'end_page': 141}
[2018-03-02 14:39:06,153 DEBUG dbutils] Query result: []
[2018-03-02 14:39:06,153 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:06,153 DEBUG dbutils] Add new paper (title='Childrens interactions with inspectable and negotiated learner models')
[2018-03-02 14:39:06,153 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Childrens interactions with inspectable and negotiated learner models', 'year': 2008, 'publisher': 'Springer', 'start_page': 132, 'end_page': 141, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Childrens interactions with inspectable and negotiated learner models\n%A Kerly, Alice\n%A Bull, Susan\n%B International Conference on Intelligent Tutoring Systems\n%P 132-141\n%D 2008\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:06,153 DEBUG dbutils] Query result: 21
[2018-03-02 14:39:06,155 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.2385&rep=rep1&type=pdf.
[2018-03-02 14:39:06,155 WARNING utils] Download file (url='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.217.2385&rep=rep1&type=pdf') and save (filename='PDF//21.pdf')
[2018-03-02 14:39:06,156 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:06,156 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:39:06,172 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): citeseerx.ist.psu.edu
[2018-03-02 14:39:07,083 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.217.2385&rep=rep1&type=pdf HTTP/1.1" 200 None
[2018-03-02 14:39:07,083 DEBUG utils] Downloading the entire file.
[2018-03-02 14:39:07,083 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:07,083 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:39:07,083 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for otherhost
[2018-03-02 14:39:07,115 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): citeseerx.ist.psu.edu
[2018-03-02 14:39:07,591 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.217.2385&rep=rep1&type=pdf HTTP/1.1" 302 0
[2018-03-02 14:39:07,860 DEBUG requests.packages.urllib3.connectionpool] "GET /messages/downloadsexceeded.html HTTP/1.1" 200 206
[2018-03-02 14:39:07,864 DEBUG utils] Save file PDF//21.pdf.
[2018-03-02 14:39:07,866 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-540-69132-7_18.
[2018-03-02 14:39:07,866 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-540-69132-7_18.
[2018-03-02 14:39:07,891 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 14:39:08,149 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-540-69132-7_18 HTTP/1.1" 302 None
[2018-03-02 14:39:08,172 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:39:08,541 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D2372F1DF269EED1AA97031349DE57AF HTTP/1.1" 200 13704
[2018-03-02 14:39:08,626 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:08,626 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:39:08,819 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-540-69132-7_18 HTTP/1.1" 302 None
[2018-03-02 14:39:09,072 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D2372F1DF269EED1AA97031349DE57AF HTTP/1.1" 200 13704
[2018-03-02 14:39:09,358 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:39:09,358 DEBUG scholar] Handle paper #22 (total 1170)
[2018-03-02 14:39:09,359 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:39:09,362 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:09,362 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:39:09,362 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for scholar.google.com
[2018-03-02 14:39:09,380 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:10,959 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nd1TAbs_Y9MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6crKmLPCIeE969ayT9IsMzSoJvV6h&scisf=3&ct=citation&cd=21&hl=en HTTP/1.1" 200 293
[2018-03-02 14:39:10,960 DEBUG scholar] EndNote file:
%0 Journal Article
%T C4 (C quad): development of the application for language learning based on social and cognitive presences
%A Yamada, Masanori
%A Goda, Yoshiko
%A Matsukawa, Hideya
%A Hata, Kojiro
%A Yasunami, Seisuke
%J Bradley, L., Thousny, S.(eds.)
%V 20
%P 258-264
%D 2013

[2018-03-02 14:39:10,961 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:10,961 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:10,961 DEBUG __main__] Process content of EndNote file #22
{"title": "C4 (C quad): development of the application for language learning based on social and cognitive presences", "url": "https://books.google.com/books?hl=en&lr=&id=sN9BAgAAQBAJ&oi=fnd&pg=PA258&dq=Use+deep+learning+to+create+a+chatbot&ots=dQNBYHkljc&sig=oneyASfO0rsDNI_OiJ1HXPC6Krg", "author": [{"shortname": "M Yamada", "gid": "4dOyLHAAAAAJ"}, {"shortname": "Y Goda", "gid": "hIk4QDAAAAAJ"}, {"shortname": "H Matsukawa", "gid": ""}], "year": 2013}
{"citedby": 2, "type": "Journal Article", "title": "C4 (C quad): development of the application for language learning based on social and cognitive presences", "author": ["Yamada, Masanori", "Goda, Yoshiko", "Matsukawa, Hideya", "Hata, Kojiro", "Yasunami, Seisuke"], "journal": "Bradley, L., Thousny, S.(eds.)", "volume": 7, "pages": "258-264", "year": "2013", "start_page": 258, "end_page": 264, "EndNote": "%0 Journal Article\n%T C4 (C quad): development of the application for language learning based on social and cognitive presences\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%J Bradley, L., Thousny, S.(eds.)\n%V 20\n%P 258-264\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:nd1TAbs_Y9MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6crKmLPCIeE969ayT9IsMzSoJvV6h&scisf=3&ct=citation&cd=21&hl=en"}
[2018-03-02 14:39:10,961 DEBUG dbutils] Get paper id {"DOI": null, "title": "C4 (C quad): development of the application for language learning based on social and cognitive presences", "auth_count": 5, "g_type": "Journal Article", "pages": 7, "year": 2013, "rg_id": null, "start_page": 258, "end_page": 264}.
[2018-03-02 14:39:10,962 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'C4 (C quad): development of the application for language learning based on social and cognitive presences', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': 7, 'year': 2013, 'rg_id': None, 'start_page': 258, 'end_page': 264}
[2018-03-02 14:39:10,962 DEBUG dbutils] Query result: []
[2018-03-02 14:39:10,962 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:10,962 DEBUG dbutils] Add new paper (title='C4 (C quad): development of the application for language learning based on social and cognitive presences')
[2018-03-02 14:39:10,962 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'C4 (C quad): development of the application for language learning based on social and cognitive presences', 'year': 2013, 'publisher': None, 'start_page': 258, 'end_page': 264, 'pages': 7, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T C4 (C quad): development of the application for language learning based on social and cognitive presences\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%J Bradley, L., Thousny, S.(eds.)\n%V 20\n%P 258-264\n%D 2013\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:10,962 DEBUG dbutils] Query result: 22
[2018-03-02 14:39:10,964 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=sN9BAgAAQBAJ&oi=fnd&pg=PA258&dq=Use+deep+learning+to+create+a+chatbot&ots=dQNBYHkljc&sig=oneyASfO0rsDNI_OiJ1HXPC6Krg.
[2018-03-02 14:39:10,965 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=sN9BAgAAQBAJ&oi=fnd&pg=PA258&dq=Use+deep+learning+to+create+a+chatbot&ots=dQNBYHkljc&sig=oneyASfO0rsDNI_OiJ1HXPC6Krg.
[2018-03-02 14:39:11,200 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=sN9BAgAAQBAJ&oi=fnd&pg=PA258&dq=Use+deep+learning+to+create+a+chatbot&ots=dQNBYHkljc&sig=oneyASfO0rsDNI_OiJ1HXPC6Krg HTTP/1.1" 302 None
[2018-03-02 14:39:11,421 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:39:11,433 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:11,433 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:39:11,433 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for sci-hub.tw
[2018-03-02 14:39:11,609 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=sN9BAgAAQBAJ&oi=fnd&pg=PA258&dq=Use+deep+learning+to+create+a+chatbot&ots=dQNBYHkljc&sig=oneyASfO0rsDNI_OiJ1HXPC6Krg HTTP/1.1" 302 None
[2018-03-02 14:39:11,857 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:39:11,878 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:39:11,879 DEBUG scholar] Handle paper #23 (total 1170)
[2018-03-02 14:39:11,880 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:39:11,883 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:11,883 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:39:12,250 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:PGPRo0BE59cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chGE7nCUTAvthQLpvdS_sb2xWcjd&scisf=3&ct=citation&cd=22&hl=en HTTP/1.1" 200 121
[2018-03-02 14:39:12,250 DEBUG scholar] EndNote file:
%0 Journal Article
%T Emerging technologies for autonomous language learning
%A Warschauer, Mark
%J Reading
%D 2011

[2018-03-02 14:39:12,251 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:12,251 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:12,251 DEBUG __main__] Process content of EndNote file #23
{"title": "Emerging technologies for autonomous language learning", "url": "https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7", "author": [{"shortname": "M Warschauer", "gid": "gexxlUYAAAAJ"}], "year": 2011}
{"citedby": 32, "type": "Journal Article", "title": "Emerging technologies for autonomous language learning", "author": ["Warschauer, Mark"], "journal": "Reading", "year": "2011", "EndNote": "%0 Journal Article\n%T Emerging technologies for autonomous language learning\n%A Warschauer, Mark\n%J Reading\n%D 2011\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:PGPRo0BE59cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chGE7nCUTAvthQLpvdS_sb2xWcjd&scisf=3&ct=citation&cd=22&hl=en"}
[2018-03-02 14:39:12,251 DEBUG dbutils] Get paper id {"DOI": null, "title": "Emerging technologies for autonomous language learning", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:39:12,252 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Emerging technologies for autonomous language learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:39:12,252 DEBUG dbutils] Query result: []
[2018-03-02 14:39:12,252 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:12,252 DEBUG dbutils] Add new paper (title='Emerging technologies for autonomous language learning')
[2018-03-02 14:39:12,252 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Emerging technologies for autonomous language learning', 'year': 2011, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Emerging technologies for autonomous language learning\n%A Warschauer, Mark\n%J Reading\n%D 2011\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:12,253 DEBUG dbutils] Query result: 23
[2018-03-02 14:39:12,254 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7.
[2018-03-02 14:39:12,254 DEBUG scihub] Get page from sci-hub for paper with DOI=https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7.
[2018-03-02 14:39:12,449 DEBUG requests.packages.urllib3.connectionpool] "GET //https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 302 None
[2018-03-02 14:39:12,472 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sisaljournal.org
[2018-03-02 14:39:13,492 DEBUG requests.packages.urllib3.connectionpool] "GET /archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 200 None
[2018-03-02 14:39:13,642 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:13,643 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:39:13,820 DEBUG requests.packages.urllib3.connectionpool] "GET //https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 302 None
[2018-03-02 14:39:13,844 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sisaljournal.org
[2018-03-02 14:39:19,640 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sisaljournal.org', port=443): Max retries exceeded with url: /archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sisaljournal.org', port=443): Max retries exceeded with url: /archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:39:19,640 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for sci-hub.tw
[2018-03-02 14:39:19,829 DEBUG requests.packages.urllib3.connectionpool] "GET //https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 302 None
[2018-03-02 14:39:20,531 DEBUG requests.packages.urllib3.connectionpool] "GET /archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 200 None
[2018-03-02 14:39:20,853 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:20,854 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:39:21,039 DEBUG requests.packages.urllib3.connectionpool] "GET //https://sisaljournal.org/archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 302 None
[2018-03-02 14:39:21,062 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sisaljournal.org
[2018-03-02 14:39:24,344 DEBUG requests.packages.urllib3.connectionpool] "GET /archives/sep11/warschauer_liaw/?like=1&_wpnonce=76232868d7 HTTP/1.1" 200 None
[2018-03-02 14:39:28,104 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:39:28,105 DEBUG scholar] Handle paper #24 (total 1170)
[2018-03-02 14:39:28,106 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:39:28,113 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:28,113 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:39:28,113 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for scholar.google.com
[2018-03-02 14:39:28,135 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:29,894 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KL_qEru5s1cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6crdCAVQ-eL0gWJcNQ9KRkh40ioJO&scisf=3&ct=citation&cd=23&hl=en HTTP/1.1" 200 287
[2018-03-02 14:39:29,895 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners
%A Jia, Jiyou
%A Chen, Weichao
%B Advanced Learning Technologies, 2008. ICALT'08. Eighth IEEE International Conference on
%P 739-743
%@ 0769531679
%D 2008
%I IEEE

[2018-03-02 14:39:29,895 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:29,895 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:29,895 DEBUG __main__] Process content of EndNote file #24
{"title": "Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners", "url": "http://ieeexplore.ieee.org/abstract/document/4561822/", "author": [{"shortname": "J Jia", "gid": ""}, {"shortname": "W Chen", "gid": "BoxpNtkAAAAJ"}], "year": 2008}
{"citedby": 8, "type": "Conference Proceedings", "title": "Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners", "author": ["Jia, Jiyou", "Chen, Weichao"], "secondarytitle": "Advanced Learning Technologies, 2008. ICALT'08. Eighth IEEE International Conference on", "pages": "739-743", "isbn/issn": "0769531679", "year": "2008", "publisher": "IEEE", "start_page": 739, "end_page": 743, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners\n%A Jia, Jiyou\n%A Chen, Weichao\n%B Advanced Learning Technologies, 2008. ICALT'08. Eighth IEEE International Conference on\n%P 739-743\n%@ 0769531679\n%D 2008\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KL_qEru5s1cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6crdCAVQ-eL0gWJcNQ9KRkh40ioJO&scisf=3&ct=citation&cd=23&hl=en"}
[2018-03-02 14:39:29,895 DEBUG dbutils] Get paper id {"DOI": null, "title": "Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 5, "year": 2008, "rg_id": null, "start_page": 739, "end_page": 743}.
[2018-03-02 14:39:29,896 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2008, 'rg_id': None, 'start_page': 739, 'end_page': 743}
[2018-03-02 14:39:29,896 DEBUG dbutils] Query result: []
[2018-03-02 14:39:29,896 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:29,896 DEBUG dbutils] Add new paper (title='Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners')
[2018-03-02 14:39:29,896 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners', 'year': 2008, 'publisher': 'IEEE', 'start_page': 739, 'end_page': 743, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Conference Proceedings\n%T Script-Based Design for Human-Computer Dialog in Given Scenarios for English Learners\n%A Jia, Jiyou\n%A Chen, Weichao\n%B Advanced Learning Technologies, 2008. ICALT'08. Eighth IEEE International Conference on\n%P 739-743\n%@ 0769531679\n%D 2008\n%I IEEE\n", 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:29,896 DEBUG dbutils] Query result: 24
[2018-03-02 14:39:29,899 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/4561822/.
[2018-03-02 14:39:29,899 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/4561822/.
[2018-03-02 14:39:30,089 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/4561822/ HTTP/1.1" 200 None
[2018-03-02 14:39:30,090 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:30,090 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:39:30,090 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for sci-hub.tw
[2018-03-02 14:39:30,239 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/4561822/ HTTP/1.1" 200 None
[2018-03-02 14:39:30,247 DEBUG scihub] URL for PDF: http://dacemirror.sci-hub.tw/proceedings-article/a0e34102e991a03cdb767df8045abb6b/jia2008.pdf?download=true.
[2018-03-02 14:39:30,247 WARNING utils] Download file (url='http://dacemirror.sci-hub.tw/proceedings-article/a0e34102e991a03cdb767df8045abb6b/jia2008.pdf?download=true') and save (filename='PDF//24.pdf')
[2018-03-02 14:39:30,267 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: dacemirror.sci-hub.tw
[2018-03-02 14:39:30,479 DEBUG requests.packages.urllib3.connectionpool] "GET /proceedings-article/a0e34102e991a03cdb767df8045abb6b/jia2008.pdf?download=true HTTP/1.1" 200 242696
[2018-03-02 14:39:30,481 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:39:30,481 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:39:30,499 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): dacemirror.sci-hub.tw
[2018-03-02 14:39:30,727 DEBUG requests.packages.urllib3.connectionpool] "GET /proceedings-article/a0e34102e991a03cdb767df8045abb6b/jia2008.pdf?download=true HTTP/1.1" 200 242696
[2018-03-02 14:39:30,728 DEBUG utils] Content-length=242696
[2018-03-02 14:39:30,729 DEBUG utils] Create file PDF//24.pdf, start download.
[2018-03-02 14:39:35,070 DEBUG utils] End download file PDF//24.pdf.
[2018-03-02 14:39:35,071 DEBUG dbutils] Update pdf_transaction for paper id=24.
[2018-03-02 14:39:35,072 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 24'
[2018-03-02 14:39:35,072 DEBUG dbutils] Query result: null
[2018-03-02 14:39:35,072 DEBUG scholar] Handle paper #25 (total 1170)
[2018-03-02 14:39:35,072 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:39:35,076 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:35,076 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:39:35,399 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GAV66AO6iv4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cguCvq4PJYsmNBDSPlRDpZSWh-x8&scisf=3&ct=citation&cd=24&hl=en HTTP/1.1" 200 321
[2018-03-02 14:39:35,400 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Grid enabled collaborative learning
%A Allison, Colin
%A Nicoll, Ross
%A Purdie, Stuart DJ
%A Eisenstadt, Marc
%A Komzak, Jiri
%A Denham, Chris
%B Advanced Learning Technologies, 2007. ICALT 2007. Seventh IEEE International Conference on
%P 480-484
%@ 076952916X
%D 2007
%I IEEE

[2018-03-02 14:39:35,400 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:35,400 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:35,400 DEBUG __main__] Process content of EndNote file #25
{"title": "Grid enabled collaborative learning", "url": "http://ieeexplore.ieee.org/abstract/document/4281071/", "author": [{"shortname": "C Allison", "gid": "WAcgihMAAAAJ"}, {"shortname": "R Nicoll", "gid": ""}, {"shortname": "SDJ Purdie", "gid": ""}], "year": 2007}
{"citedby": 4, "type": "Conference Proceedings", "title": "Grid enabled collaborative learning", "author": ["Allison, Colin", "Nicoll, Ross", "Purdie, Stuart DJ", "Eisenstadt, Marc", "Komzak, Jiri", "Denham, Chris"], "secondarytitle": "Advanced Learning Technologies, 2007. ICALT 2007. Seventh IEEE International Conference on", "pages": "480-484", "isbn/issn": "076952916X", "year": "2007", "publisher": "IEEE", "start_page": 480, "end_page": 484, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T Grid enabled collaborative learning\n%A Allison, Colin\n%A Nicoll, Ross\n%A Purdie, Stuart DJ\n%A Eisenstadt, Marc\n%A Komzak, Jiri\n%A Denham, Chris\n%B Advanced Learning Technologies, 2007. ICALT 2007. Seventh IEEE International Conference on\n%P 480-484\n%@ 076952916X\n%D 2007\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GAV66AO6iv4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cguCvq4PJYsmNBDSPlRDpZSWh-x8&scisf=3&ct=citation&cd=24&hl=en"}
[2018-03-02 14:39:35,400 DEBUG dbutils] Get paper id {"DOI": null, "title": "Grid enabled collaborative learning", "auth_count": 6, "g_type": "Conference Proceedings", "pages": 5, "year": 2007, "rg_id": null, "start_page": 480, "end_page": 484}.
[2018-03-02 14:39:35,401 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Grid enabled collaborative learning', 'auth_count': 6, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2007, 'rg_id': None, 'start_page': 480, 'end_page': 484}
[2018-03-02 14:39:35,401 DEBUG dbutils] Query result: []
[2018-03-02 14:39:35,401 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:35,401 DEBUG dbutils] Add new paper (title='Grid enabled collaborative learning')
[2018-03-02 14:39:35,401 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Grid enabled collaborative learning', 'year': 2007, 'publisher': 'IEEE', 'start_page': 480, 'end_page': 484, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Grid enabled collaborative learning\n%A Allison, Colin\n%A Nicoll, Ross\n%A Purdie, Stuart DJ\n%A Eisenstadt, Marc\n%A Komzak, Jiri\n%A Denham, Chris\n%B Advanced Learning Technologies, 2007. ICALT 2007. Seventh IEEE International Conference on\n%P 480-484\n%@ 076952916X\n%D 2007\n%I IEEE\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:35,401 DEBUG dbutils] Query result: 25
[2018-03-02 14:39:35,402 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/4281071/.
[2018-03-02 14:39:35,403 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/4281071/.
[2018-03-02 14:39:35,591 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/4281071/ HTTP/1.1" 200 None
[2018-03-02 14:39:35,592 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:35,592 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:39:35,592 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for sci-hub.tw
[2018-03-02 14:39:35,821 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/4281071/ HTTP/1.1" 200 None
[2018-03-02 14:39:35,827 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTEwOS9pY2FsdC4yMDA3LjE1Mw==/allison2007.pdf?download=true.
[2018-03-02 14:39:35,827 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTEwOS9pY2FsdC4yMDA3LjE1Mw==/allison2007.pdf?download=true') and save (filename='PDF//25.pdf')
[2018-03-02 14:39:35,868 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 14:39:36,040 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pY2FsdC4yMDA3LjE1Mw==/allison2007.pdf?download=true HTTP/1.1" 200 637171
[2018-03-02 14:39:36,041 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:39:36,041 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:39:36,056 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (23): cyber.sci-hub.tw
[2018-03-02 14:39:36,255 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pY2FsdC4yMDA3LjE1Mw==/allison2007.pdf?download=true HTTP/1.1" 200 637171
[2018-03-02 14:39:36,256 DEBUG utils] Content-length=637171
[2018-03-02 14:39:36,257 DEBUG utils] Create file PDF//25.pdf, start download.
[2018-03-02 14:39:37,151 DEBUG utils] End download file PDF//25.pdf.
[2018-03-02 14:39:37,153 DEBUG dbutils] Update pdf_transaction for paper id=25.
[2018-03-02 14:39:37,153 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 25'
[2018-03-02 14:39:37,153 DEBUG dbutils] Query result: null
[2018-03-02 14:39:37,154 DEBUG scholar] Handle paper #26 (total 1170)
[2018-03-02 14:39:37,154 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:39:37,157 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:37,157 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:39:37,157 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for scholar.google.com
[2018-03-02 14:39:37,175 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:46,640 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:732: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:qkHHkL85PQMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cnX-R3XLYqYG-tLLqkb8E86tl8j4&scisf=3&ct=citation&cd=25&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:qkHHkL85PQMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cnX-R3XLYqYG-tLLqkb8E86tl8j4&scisf=3&ct=citation&cd=25&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

[2018-03-02 14:39:46,640 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for scholar.google.com
[2018-03-02 14:39:46,642 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:46,643 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:39:46,663 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:49,980 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:qkHHkL85PQMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cnX-R3XLYqYG-tLLqkb8E86tl8j4&scisf=3&ct=citation&cd=25&hl=en HTTP/1.1" 200 222
[2018-03-02 14:39:49,981 DEBUG scholar] EndNote file:
%0 Journal Article
%T CALMsystem: a conversational agent for learner modelling
%A Kerly, Alice
%A Ellis, Richard
%A Bull, Susan
%J Knowledge-Based Systems
%V 21
%N 3
%P 238-246
%@ 0950-7051
%D 2008
%I Elsevier

[2018-03-02 14:39:49,981 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:49,981 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:49,981 DEBUG __main__] Process content of EndNote file #26
{"title": "CALMsystem: a conversational agent for learner modelling", "url": "https://www.sciencedirect.com/science/article/pii/S0950705107001098", "author": [{"shortname": "A Kerly", "gid": ""}, {"shortname": "R Ellis", "gid": ""}, {"shortname": "S Bull", "gid": "TONyepAAAAAJ"}], "year": 2008}
{"citedby": 87, "type": "Journal Article", "title": "CALMsystem: a conversational agent for learner modelling", "author": ["Kerly, Alice", "Ellis, Richard", "Bull, Susan"], "journal": "Knowledge-Based Systems", "volume": 9, "numberorissue": "3", "pages": "238-246", "isbn/issn": "0950-7051", "year": "2008", "publisher": "Elsevier", "start_page": 238, "end_page": 246, "EndNote": "%0 Journal Article\n%T CALMsystem: a conversational agent for learner modelling\n%A Kerly, Alice\n%A Ellis, Richard\n%A Bull, Susan\n%J Knowledge-Based Systems\n%V 21\n%N 3\n%P 238-246\n%@ 0950-7051\n%D 2008\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:qkHHkL85PQMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cnX-R3XLYqYG-tLLqkb8E86tl8j4&scisf=3&ct=citation&cd=25&hl=en"}
[2018-03-02 14:39:49,981 DEBUG dbutils] Get paper id {"DOI": null, "title": "CALMsystem: a conversational agent for learner modelling", "auth_count": 3, "g_type": "Journal Article", "pages": 9, "year": 2008, "rg_id": null, "start_page": 238, "end_page": 246}.
[2018-03-02 14:39:49,981 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'CALMsystem: a conversational agent for learner modelling', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 9, 'year': 2008, 'rg_id': None, 'start_page': 238, 'end_page': 246}
[2018-03-02 14:39:49,981 DEBUG dbutils] Query result: []
[2018-03-02 14:39:49,982 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:49,982 DEBUG dbutils] Add new paper (title='CALMsystem: a conversational agent for learner modelling')
[2018-03-02 14:39:49,982 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'CALMsystem: a conversational agent for learner modelling', 'year': 2008, 'publisher': 'Elsevier', 'start_page': 238, 'end_page': 246, 'pages': 9, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T CALMsystem: a conversational agent for learner modelling\n%A Kerly, Alice\n%A Ellis, Richard\n%A Bull, Susan\n%J Knowledge-Based Systems\n%V 21\n%N 3\n%P 238-246\n%@ 0950-7051\n%D 2008\n%I Elsevier\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:49,982 DEBUG dbutils] Query result: 26
[2018-03-02 14:39:49,983 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.753&rep=rep1&type=pdf.
[2018-03-02 14:39:49,985 WARNING utils] Download file (url='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.753&rep=rep1&type=pdf') and save (filename='PDF//26.pdf')
[2018-03-02 14:39:49,986 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:49,986 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:39:50,007 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: citeseerx.ist.psu.edu
[2018-03-02 14:39:50,476 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.119.753&rep=rep1&type=pdf HTTP/1.1" 200 None
[2018-03-02 14:39:50,477 DEBUG utils] Downloading the entire file.
[2018-03-02 14:39:50,477 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:50,477 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:39:50,477 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for otherhost
[2018-03-02 14:39:50,491 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): citeseerx.ist.psu.edu
[2018-03-02 14:39:50,935 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.119.753&rep=rep1&type=pdf HTTP/1.1" 302 0
[2018-03-02 14:39:51,198 DEBUG requests.packages.urllib3.connectionpool] "GET /messages/downloadsexceeded.html HTTP/1.1" 200 206
[2018-03-02 14:39:51,201 DEBUG utils] Save file PDF//26.pdf.
[2018-03-02 14:39:51,203 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S0950705107001098.
[2018-03-02 14:39:51,203 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S0950705107001098.
[2018-03-02 14:39:51,409 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0950705107001098 HTTP/1.1" 200 None
[2018-03-02 14:39:51,410 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:39:51,410 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:39:51,411 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for sci-hub.tw
[2018-03-02 14:39:51,631 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0950705107001098 HTTP/1.1" 200 None
[2018-03-02 14:39:51,638 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNi9qLmtub3N5cy4yMDA3LjExLjAxNQ==/kerly2008.pdf?download=true.
[2018-03-02 14:39:51,638 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNi9qLmtub3N5cy4yMDA3LjExLjAxNQ==/kerly2008.pdf?download=true') and save (filename='PDF//26.pdf')
[2018-03-02 14:39:51,761 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDA3LjExLjAxNQ==/kerly2008.pdf?download=true HTTP/1.1" 200 739470
[2018-03-02 14:39:51,762 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:39:51,762 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:39:51,779 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (24): cyber.sci-hub.tw
[2018-03-02 14:39:52,089 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDA3LjExLjAxNQ==/kerly2008.pdf?download=true HTTP/1.1" 200 739470
[2018-03-02 14:39:52,090 DEBUG utils] Content-length=739470
[2018-03-02 14:39:52,090 DEBUG utils] Create file PDF//26.pdf, start download.
[2018-03-02 14:39:53,507 DEBUG utils] End download file PDF//26.pdf.
[2018-03-02 14:39:53,508 DEBUG dbutils] Update pdf_transaction for paper id=26.
[2018-03-02 14:39:53,508 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 26'
[2018-03-02 14:39:53,509 DEBUG dbutils] Query result: null
[2018-03-02 14:39:53,509 DEBUG scholar] Handle paper #27 (total 1170)
[2018-03-02 14:39:53,509 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:39:53,513 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:39:53,513 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:39:53,514 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for scholar.google.com
[2018-03-02 14:39:53,546 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:39:55,079 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:-Fas3TUes2YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cmhcD6TIe-LYLDJdWRgvXOqSHJkw&scisf=3&ct=citation&cd=26&hl=en HTTP/1.1" 200 263
[2018-03-02 14:39:55,080 DEBUG scholar] EndNote file:
%0 Journal Article
%T An E-Commerce Website based Chatbot
%A Gupta, Siddharth
%A Borkar, Deep
%A De Mello, Chevelyn
%A Patil, Saurabh
%J International Journal of Computer Science and Information Technologies
%V 6
%N 2
%P 1483-1485
%D 2015
%I Citeseer

[2018-03-02 14:39:55,080 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:39:55,080 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:39:55,080 DEBUG __main__] Process content of EndNote file #27
{"title": "An E-Commerce Website based Chatbot", "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf", "author": [{"shortname": "S Gupta", "gid": "D2QMjGYAAAAJ"}, {"shortname": "D Borkar", "gid": ""}, {"shortname": "C De Mello", "gid": ""}, {"shortname": "S Patil", "gid": ""}], "year": 2015}
{"citedby": 1, "type": "Journal Article", "title": "An E-Commerce Website based Chatbot", "author": ["Gupta, Siddharth", "Borkar, Deep", "De Mello, Chevelyn", "Patil, Saurabh"], "journal": "International Journal of Computer Science and Information Technologies", "volume": 3, "numberorissue": "2", "pages": "1483-1485", "year": "2015", "publisher": "Citeseer", "start_page": 1483, "end_page": 1485, "EndNote": "%0 Journal Article\n%T An E-Commerce Website based Chatbot\n%A Gupta, Siddharth\n%A Borkar, Deep\n%A De Mello, Chevelyn\n%A Patil, Saurabh\n%J International Journal of Computer Science and Information Technologies\n%V 6\n%N 2\n%P 1483-1485\n%D 2015\n%I Citeseer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:-Fas3TUes2YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6cmhcD6TIe-LYLDJdWRgvXOqSHJkw&scisf=3&ct=citation&cd=26&hl=en"}
[2018-03-02 14:39:55,080 DEBUG dbutils] Get paper id {"DOI": null, "title": "An E-Commerce Website based Chatbot", "auth_count": 4, "g_type": "Journal Article", "pages": 3, "year": 2015, "rg_id": null, "start_page": 1483, "end_page": 1485}.
[2018-03-02 14:39:55,080 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An E-Commerce Website based Chatbot', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': 3, 'year': 2015, 'rg_id': None, 'start_page': 1483, 'end_page': 1485}
[2018-03-02 14:39:55,081 DEBUG dbutils] Query result: []
[2018-03-02 14:39:55,081 DEBUG dbutils] Paper id = None.
[2018-03-02 14:39:55,081 DEBUG dbutils] Add new paper (title='An E-Commerce Website based Chatbot')
[2018-03-02 14:39:55,081 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An E-Commerce Website based Chatbot', 'year': 2015, 'publisher': 'Citeseer', 'start_page': 1483, 'end_page': 1485, 'pages': 3, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T An E-Commerce Website based Chatbot\n%A Gupta, Siddharth\n%A Borkar, Deep\n%A De Mello, Chevelyn\n%A Patil, Saurabh\n%J International Journal of Computer Science and Information Technologies\n%V 6\n%N 2\n%P 1483-1485\n%D 2015\n%I Citeseer\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:39:55,081 DEBUG dbutils] Query result: 27
[2018-03-02 14:39:55,083 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf.
[2018-03-02 14:39:55,085 WARNING utils] Download file (url='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf') and save (filename='PDF//27.pdf')
[2018-03-02 14:39:55,085 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:55,086 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:39:55,369 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 200 None
[2018-03-02 14:39:55,369 DEBUG utils] Downloading the entire file.
[2018-03-02 14:39:55,369 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 14:39:55,370 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:39:55,370 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for otherhost
[2018-03-02 14:39:55,385 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): citeseerx.ist.psu.edu
[2018-03-02 14:39:55,853 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 302 0
[2018-03-02 14:39:56,109 DEBUG requests.packages.urllib3.connectionpool] "GET /messages/downloadsexceeded.html HTTP/1.1" 200 206
[2018-03-02 14:39:56,111 DEBUG utils] Save file PDF//27.pdf.
[2018-03-02 14:39:56,114 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf.
[2018-03-02 14:39:56,115 DEBUG scihub] Get page from sci-hub for paper with DOI=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf.
[2018-03-02 14:39:58,218 DEBUG requests.packages.urllib3.connectionpool] "GET //http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:00,438 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:03,238 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:05,358 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 404 None
[2018-03-02 14:40:05,359 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:40:05,359 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:40:05,359 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for sci-hub.tw
[2018-03-02 14:40:07,519 DEBUG requests.packages.urllib3.connectionpool] "GET //http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:09,868 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:14,098 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 14:40:16,238 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf HTTP/1.1" 404 None
[2018-03-02 14:40:16,241 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:40:16,242 DEBUG __main__] Failed get_pdf from sci-hub for paper #26. URL=26
[2018-03-02 14:40:16,243 DEBUG scholar] Handle paper #28 (total 1170)
[2018-03-02 14:40:16,244 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:40:16,250 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:16,250 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 14:40:16,548 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:VY0utUOjOP0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctC2lWCegHLpPvviB3u_XXRb6qDu&scisf=3&ct=citation&cd=27&hl=en HTTP/1.1" 200 226
[2018-03-02 14:40:16,549 DEBUG scholar] EndNote file:
%0 Journal Article
%T Computer Science Workshops from the Villanova Magic School Science Camp
%A Corning, Melissa
%A Way, Thomas
%A Papalaskari, Mary-Angela
%A Nadi, Najib
%J Computer Science
%V 3
%N 6
%P 9
%D 2008

[2018-03-02 14:40:16,549 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:40:16,549 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:40:16,549 DEBUG __main__] Process content of EndNote file #28
{"title": "Computer Science Workshops from the Villanova Magic School Science Camp", "url": "https://www.researchgate.net/profile/Mary-Angela_Papalaskari/publication/242076846_Computer_Science_Workshops_from_the_Villanova_Magic_School_Science_Camp/links/02e7e52a071ce8be13000000/Computer-Science-Workshops-from-the-Villanova-Magic-School-Science-Camp.pdf", "author": [{"shortname": "M Corning", "gid": ""}, {"shortname": "T Way", "gid": ""}, {"shortname": "MA Papalaskari", "gid": ""}, {"shortname": "N Nadi", "gid": ""}], "year": 2008}
{"citedby": 1, "type": "Journal Article", "title": "Computer Science Workshops from the Villanova Magic School Science Camp", "author": ["Corning, Melissa", "Way, Thomas", "Papalaskari, Mary-Angela", "Nadi, Najib"], "journal": "Computer Science", "volume": "3", "numberorissue": "6", "pages": "9", "year": "2008", "EndNote": "%0 Journal Article\n%T Computer Science Workshops from the Villanova Magic School Science Camp\n%A Corning, Melissa\n%A Way, Thomas\n%A Papalaskari, Mary-Angela\n%A Nadi, Najib\n%J Computer Science\n%V 3\n%N 6\n%P 9\n%D 2008\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:VY0utUOjOP0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctC2lWCegHLpPvviB3u_XXRb6qDu&scisf=3&ct=citation&cd=27&hl=en"}
[2018-03-02 14:40:16,550 DEBUG dbutils] Get paper id {"DOI": null, "title": "Computer Science Workshops from the Villanova Magic School Science Camp", "auth_count": 4, "g_type": "Journal Article", "pages": 3, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:40:16,550 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Computer Science Workshops from the Villanova Magic School Science Camp', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': 3, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:40:16,550 DEBUG dbutils] Query result: []
[2018-03-02 14:40:16,550 DEBUG dbutils] Paper id = None.
[2018-03-02 14:40:16,550 DEBUG dbutils] Add new paper (title='Computer Science Workshops from the Villanova Magic School Science Camp')
[2018-03-02 14:40:16,550 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Computer Science Workshops from the Villanova Magic School Science Camp', 'year': 2008, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 3, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Computer Science Workshops from the Villanova Magic School Science Camp\n%A Corning, Melissa\n%A Way, Thomas\n%A Papalaskari, Mary-Angela\n%A Nadi, Najib\n%J Computer Science\n%V 3\n%N 6\n%P 9\n%D 2008\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:40:16,550 DEBUG dbutils] Query result: 28
[2018-03-02 14:40:16,552 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Mary-Angela_Papalaskari/publication/242076846_Computer_Science_Workshops_from_the_Villanova_Magic_School_Science_Camp/links/02e7e52a071ce8be13000000/Computer-Science-Workshops-from-the-Villanova-Magic-School-Science-Camp.pdf.
[2018-03-02 14:40:16,552 WARNING utils] Download file (url='https://www.researchgate.net/profile/Mary-Angela_Papalaskari/publication/242076846_Computer_Science_Workshops_from_the_Villanova_Magic_School_Science_Camp/links/02e7e52a071ce8be13000000/Computer-Science-Workshops-from-the-Villanova-Magic-School-Science-Camp.pdf') and save (filename='PDF//28.pdf')
[2018-03-02 14:40:16,553 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:40:16,553 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:40:16,570 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 14:40:20,491 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:40:20,491 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for www.researchgate.net
[2018-03-02 14:40:20,492 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:40:20,493 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:40:20,508 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 14:40:23,964 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Mary-Angela_Papalaskari/publication/242076846_Computer_Science_Workshops_from_the_Villanova_Magic_School_Science_Camp/links/02e7e52a071ce8be13000000/Computer-Science-Workshops-from-the-Villanova-Magic-School-Science-Camp.pdf HTTP/1.1" 200 54571
[2018-03-02 14:40:23,965 DEBUG utils] Content-length=54571
[2018-03-02 14:40:23,966 DEBUG utils] Create file PDF//28.pdf, start download.
[2018-03-02 14:40:26,487 DEBUG utils] End download file PDF//28.pdf.
[2018-03-02 14:40:26,488 DEBUG dbutils] Update pdf_transaction for paper id=28.
[2018-03-02 14:40:26,488 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 28'
[2018-03-02 14:40:26,489 DEBUG dbutils] Query result: null
[2018-03-02 14:40:26,489 DEBUG scholar] Handle paper #29 (total 1170)
[2018-03-02 14:40:26,489 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:40:26,493 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:26,493 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 14:40:26,493 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for scholar.google.com
[2018-03-02 14:40:26,510 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:40:31,687 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:daXR-Jq1KVUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chY9uEkpOq96fBk4Rv5DrR1UkwWE&scisf=3&ct=citation&cd=28&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:daXR-Jq1KVUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chY9uEkpOq96fBk4Rv5DrR1UkwWE&scisf=3&ct=citation&cd=28&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:40:31,687 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for scholar.google.com
[2018-03-02 14:40:31,687 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:31,687 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 14:40:31,704 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:40:37,027 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:daXR-Jq1KVUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chY9uEkpOq96fBk4Rv5DrR1UkwWE&scisf=3&ct=citation&cd=28&hl=en HTTP/1.1" 200 275
[2018-03-02 14:40:37,028 DEBUG scholar] EndNote file:
%0 Journal Article
%T Towards empathetic human-robot interactions
%A Fung, Pascale
%A Bertero, Dario
%A Wan, Yan
%A Dey, Anik
%A Chan, Ricky Ho Yin
%A Siddique, Farhad Bin
%A Yang, Yang
%A Wu, Chien-Sheng
%A Lin, Ruixi
%J arXiv preprint arXiv:1605.04072
%D 2016

[2018-03-02 14:40:37,028 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:40:37,028 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:40:37,029 DEBUG __main__] Process content of EndNote file #29
{"title": "Towards empathetic human-robot interactions", "url": "https://arxiv.org/abs/1605.04072", "author": [{"shortname": "P Fung", "gid": "QEMJWzEAAAAJ"}, {"shortname": "D Bertero", "gid": "2FdcsZsAAAAJ"}, {"shortname": "Y Wan", "gid": ""}, {"shortname": "A Dey", "gid": "MsQquJ4AAAAJ"}, {"shortname": "RHY Chan", "gid": ""}], "year": 2016}
{"citedby": 9, "type": "Journal Article", "title": "Towards empathetic human-robot interactions", "author": ["Fung, Pascale", "Bertero, Dario", "Wan, Yan", "Dey, Anik", "Chan, Ricky Ho Yin", "Siddique, Farhad Bin", "Yang, Yang", "Wu, Chien-Sheng", "Lin, Ruixi"], "journal": "arXiv preprint arXiv:1605.04072", "year": "2016", "EndNote": "%0 Journal Article\n%T Towards empathetic human-robot interactions\n%A Fung, Pascale\n%A Bertero, Dario\n%A Wan, Yan\n%A Dey, Anik\n%A Chan, Ricky Ho Yin\n%A Siddique, Farhad Bin\n%A Yang, Yang\n%A Wu, Chien-Sheng\n%A Lin, Ruixi\n%J arXiv preprint arXiv:1605.04072\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:daXR-Jq1KVUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6chY9uEkpOq96fBk4Rv5DrR1UkwWE&scisf=3&ct=citation&cd=28&hl=en"}
[2018-03-02 14:40:37,029 DEBUG dbutils] Get paper id {"DOI": null, "title": "Towards empathetic human-robot interactions", "auth_count": 9, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:40:37,029 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Towards empathetic human-robot interactions', 'auth_count': 9, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:40:37,029 DEBUG dbutils] Query result: []
[2018-03-02 14:40:37,029 DEBUG dbutils] Paper id = None.
[2018-03-02 14:40:37,029 DEBUG dbutils] Add new paper (title='Towards empathetic human-robot interactions')
[2018-03-02 14:40:37,029 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Towards empathetic human-robot interactions', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Towards empathetic human-robot interactions\n%A Fung, Pascale\n%A Bertero, Dario\n%A Wan, Yan\n%A Dey, Anik\n%A Chan, Ricky Ho Yin\n%A Siddique, Farhad Bin\n%A Yang, Yang\n%A Wu, Chien-Sheng\n%A Lin, Ruixi\n%J arXiv preprint arXiv:1605.04072\n%D 2016\n', 'RIS': None, 'authors': 9, 'ignore': False, 'transaction': 1}
[2018-03-02 14:40:37,029 DEBUG dbutils] Query result: 29
[2018-03-02 14:40:37,031 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1605.04072.
[2018-03-02 14:40:37,032 WARNING utils] Download file (url='https://arxiv.org/pdf/1605.04072') and save (filename='PDF//29.pdf')
[2018-03-02 14:40:37,032 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:40:37,032 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:40:37,047 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:40:38,287 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.04072 HTTP/1.1" 302 280
[2018-03-02 14:40:38,958 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.04072.pdf HTTP/1.1" 200 2242084
[2018-03-02 14:40:38,958 DEBUG utils] Content-length=2242084
[2018-03-02 14:40:38,959 DEBUG utils] Create file PDF//29.pdf, start download.
[2018-03-02 14:40:44,058 DEBUG utils] End download file PDF//29.pdf.
[2018-03-02 14:40:44,060 DEBUG dbutils] Update pdf_transaction for paper id=29.
[2018-03-02 14:40:44,060 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 29'
[2018-03-02 14:40:44,061 DEBUG dbutils] Query result: null
[2018-03-02 14:40:44,061 DEBUG scholar] Handle paper #30 (total 1170)
[2018-03-02 14:40:44,061 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:40:44,065 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:44,065 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 14:40:44,065 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for scholar.google.com
[2018-03-02 14:40:44,083 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:40:45,737 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EnaoqyMoJ2UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctHbNKRN7sFmn1-lbyj-oRAiRD4w&scisf=3&ct=citation&cd=29&hl=en HTTP/1.1" 200 292
[2018-03-02 14:40:45,738 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Leveraging chatbots to improve self-guided learning through conversational quizzes
%A Pereira, Juanan
%B Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality
%P 911-918
%@ 1450347479
%D 2016
%I ACM

[2018-03-02 14:40:45,738 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:40:45,738 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:40:45,738 DEBUG __main__] Process content of EndNote file #30
{"title": "Leveraging chatbots to improve self-guided learning through conversational quizzes", "url": "https://dl.acm.org/citation.cfm?id=3012625", "author": [{"shortname": "J Pereira", "gid": "2dBvuskAAAAJ"}], "year": 2016}
{"citedby": 4, "type": "Conference Proceedings", "title": "Leveraging chatbots to improve self-guided learning through conversational quizzes", "author": ["Pereira, Juanan"], "secondarytitle": "Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality", "pages": "911-918", "isbn/issn": "1450347479", "year": "2016", "publisher": "ACM", "start_page": 911, "end_page": 918, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Leveraging chatbots to improve self-guided learning through conversational quizzes\n%A Pereira, Juanan\n%B Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality\n%P 911-918\n%@ 1450347479\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:EnaoqyMoJ2UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk6ctHbNKRN7sFmn1-lbyj-oRAiRD4w&scisf=3&ct=citation&cd=29&hl=en"}
[2018-03-02 14:40:45,738 DEBUG dbutils] Get paper id {"DOI": null, "title": "Leveraging chatbots to improve self-guided learning through conversational quizzes", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 8, "year": 2016, "rg_id": null, "start_page": 911, "end_page": 918}.
[2018-03-02 14:40:45,739 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Leveraging chatbots to improve self-guided learning through conversational quizzes', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2016, 'rg_id': None, 'start_page': 911, 'end_page': 918}
[2018-03-02 14:40:45,739 DEBUG dbutils] Query result: []
[2018-03-02 14:40:45,739 DEBUG dbutils] Paper id = None.
[2018-03-02 14:40:45,739 DEBUG dbutils] Add new paper (title='Leveraging chatbots to improve self-guided learning through conversational quizzes')
[2018-03-02 14:40:45,739 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Leveraging chatbots to improve self-guided learning through conversational quizzes', 'year': 2016, 'publisher': 'ACM', 'start_page': 911, 'end_page': 918, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Leveraging chatbots to improve self-guided learning through conversational quizzes\n%A Pereira, Juanan\n%B Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality\n%P 911-918\n%@ 1450347479\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:40:45,739 DEBUG dbutils] Query result: 30
[2018-03-02 14:40:45,741 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=3012625.
[2018-03-02 14:40:45,741 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=3012625.
[2018-03-02 14:40:46,908 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=3012625 HTTP/1.1" 200 None
[2018-03-02 14:40:46,909 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:40:46,909 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:40:47,098 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=3012625 HTTP/1.1" 200 None
[2018-03-02 14:40:47,105 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true.
[2018-03-02 14:40:47,105 WARNING utils] Download file (url='http://twin.sci-hub.tw/536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true') and save (filename='PDF//30.pdf')
[2018-03-02 14:40:47,121 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: twin.sci-hub.tw
[2018-03-02 14:40:47,458 DEBUG requests.packages.urllib3.connectionpool] "GET /536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true HTTP/1.1" 200 501557
[2018-03-02 14:40:47,458 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:40:47,458 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:40:47,458 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for sci-hub.tw
[2018-03-02 14:40:47,479 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): twin.sci-hub.tw
[2018-03-02 14:40:47,648 DEBUG requests.packages.urllib3.connectionpool] "GET /536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:40:47,651 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:40:47,651 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:40:54,059 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:40:54,059 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:40:54,338 DEBUG requests.packages.urllib3.connectionpool] "GET /536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:40:54,339 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:40:54,339 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:40:54,354 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): twin.sci-hub.tw
[2018-03-02 14:40:54,589 DEBUG requests.packages.urllib3.connectionpool] "GET /536f56d54b64ca1bf45b8ea6693c4a3d/pereira2016.pdf?download=true HTTP/1.1" 200 501557
[2018-03-02 14:40:54,590 DEBUG utils] Content-length=501557
[2018-03-02 14:40:54,591 DEBUG utils] Create file PDF//30.pdf, start download.
[2018-03-02 14:40:55,422 DEBUG utils] End download file PDF//30.pdf.
[2018-03-02 14:40:55,423 DEBUG dbutils] Update pdf_transaction for paper id=30.
[2018-03-02 14:40:55,424 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 30'
[2018-03-02 14:40:55,424 DEBUG dbutils] Query result: null
[2018-03-02 14:40:55,424 DEBUG dbutils] Commiting transaction 30.
[2018-03-02 14:40:55,573 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:40:55,573 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:40:55,573 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:40:55,589 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:40:57,549 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=30&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:40:57,895 DEBUG scholar] Find papers on page #4 (max_google_papers = 300)
[2018-03-02 14:40:57,895 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:40:57,896 DEBUG scholar] Handle paper #31 (total 1170)
[2018-03-02 14:40:57,896 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:40:57,899 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:57,899 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:40:57,899 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for scholar.google.com
[2018-03-02 14:40:57,914 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:40:59,317 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:xrlLcJ3ldCgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65fmL5MOuEhzafNSocx_HxixmpJk3&scisf=3&ct=citation&cd=30&hl=en HTTP/1.1" 200 113
[2018-03-02 14:40:59,318 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatboj-Zizek: An Exercise in Automated Ideology
%A Engel, Jonathan Y
%A Garzon, Pedro

[2018-03-02 14:40:59,318 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:40:59,318 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:40:59,318 DEBUG __main__] Skip paper #31, empty year or authors fields.
[2018-03-02 14:40:59,319 DEBUG scholar] Handle paper #32 (total 1170)
[2018-03-02 14:40:59,319 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:40:59,323 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:59,323 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:40:59,587 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:vDDvCs8ubNoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Ra_AlNVvRYq6FmII0L6JbW5YFmT&scisf=3&ct=citation&cd=31&hl=en HTTP/1.1" 200 165
[2018-03-02 14:40:59,588 DEBUG scholar] EndNote file:
%0 Journal Article
%T Learning environments supported by Software Agents and Chat-bot
%A ROSSI, Pier Giuseppe
%A CARLETTI, Simone
%A IMPEDOVO, Maria Antonietta

[2018-03-02 14:40:59,588 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:40:59,588 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:40:59,589 DEBUG __main__] Skip paper #32, empty year or authors fields.
[2018-03-02 14:40:59,589 DEBUG scholar] Handle paper #33 (total 1170)
[2018-03-02 14:40:59,589 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:40:59,593 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:40:59,593 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:40:59,593 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for scholar.google.com
[2018-03-02 14:40:59,609 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:41:02,612 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:NGlqKBzgLGMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65XZUzwCEQseHNPB3ks0EX80CJuaM&scisf=3&ct=citation&cd=32&hl=en HTTP/1.1" 200 72
[2018-03-02 14:41:02,613 DEBUG scholar] EndNote file:
%0 Journal Article
%T Email Client Chatbot
%A Deugo, Dwight
%D 2016

[2018-03-02 14:41:02,613 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:41:02,614 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:41:02,614 DEBUG __main__] Process content of EndNote file #33
{"title": "Email Client Chatbot", "url": "https://drupal.scs.carleton.ca/sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf", "author": [{"shortname": "D Deugo", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Email Client Chatbot", "author": ["Deugo, Dwight"], "year": "2016", "EndNote": "%0 Journal Article\n%T Email Client Chatbot\n%A Deugo, Dwight\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:NGlqKBzgLGMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65XZUzwCEQseHNPB3ks0EX80CJuaM&scisf=3&ct=citation&cd=32&hl=en"}
[2018-03-02 14:41:02,614 DEBUG dbutils] Get paper id {"DOI": null, "title": "Email Client Chatbot", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:41:02,614 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Email Client Chatbot', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:41:02,614 DEBUG dbutils] Query result: []
[2018-03-02 14:41:02,614 DEBUG dbutils] Paper id = None.
[2018-03-02 14:41:02,614 DEBUG dbutils] Add new paper (title='Email Client Chatbot')
[2018-03-02 14:41:02,614 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Email Client Chatbot', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Email Client Chatbot\n%A Deugo, Dwight\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:41:02,615 DEBUG dbutils] Query result: 31
[2018-03-02 14:41:02,616 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://drupal.scs.carleton.ca/sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf.
[2018-03-02 14:41:02,617 WARNING utils] Download file (url='https://drupal.scs.carleton.ca/sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf') and save (filename='PDF//31.pdf')
[2018-03-02 14:41:02,617 DEBUG utils] Get current proxy for drupal.scs.carleton.ca.
[2018-03-02 14:41:02,617 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:41:02,617 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for otherhost
[2018-03-02 14:41:02,637 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): drupal.scs.carleton.ca
[2018-03-02 14:41:03,326 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='drupal.scs.carleton.ca', port=443): Max retries exceeded with url: /sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='drupal.scs.carleton.ca', port=443): Max retries exceeded with url: /sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:41:03,326 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for otherhost
[2018-03-02 14:41:03,326 DEBUG utils] Get current proxy for drupal.scs.carleton.ca.
[2018-03-02 14:41:03,326 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:41:03,342 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): drupal.scs.carleton.ca
[2018-03-02 14:41:04,268 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='drupal.scs.carleton.ca', port=443): Max retries exceeded with url: /sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='drupal.scs.carleton.ca', port=443): Max retries exceeded with url: /sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:41:04,268 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for otherhost
[2018-03-02 14:41:04,268 DEBUG utils] Get current proxy for drupal.scs.carleton.ca.
[2018-03-02 14:41:04,268 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:41:04,283 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): drupal.scs.carleton.ca
[2018-03-02 14:41:05,718 DEBUG requests.packages.urllib3.connectionpool] "GET /sites/default/files/honours_projects/2016/Email%20Client%20Chatbot%20Report.pdf HTTP/1.1" 200 979280
[2018-03-02 14:41:05,718 DEBUG utils] Content-length=979280
[2018-03-02 14:41:05,719 DEBUG utils] Create file PDF//31.pdf, start download.
[2018-03-02 14:41:07,767 DEBUG utils] End download file PDF//31.pdf.
[2018-03-02 14:41:07,768 DEBUG dbutils] Update pdf_transaction for paper id=31.
[2018-03-02 14:41:07,768 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 31'
[2018-03-02 14:41:07,769 DEBUG dbutils] Query result: null
[2018-03-02 14:41:07,771 DEBUG scholar] Handle paper #34 (total 1170)
[2018-03-02 14:41:07,771 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:41:07,777 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:41:07,777 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:41:08,317 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:28aaLUexfRgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65V6bSnWMn3iAKYpeG7do8O1pvWOw&scisf=3&ct=citation&cd=33&hl=en HTTP/1.1" 200 211
[2018-03-02 14:41:08,318 DEBUG scholar] EndNote file:
%0 Journal Article
%T Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom
%A Flynn, Patrice
%J Journal of Social Science Studies
%V 4
%N 1
%P 178
%@ 2329-9150
%D 2016

[2018-03-02 14:41:08,318 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:41:08,318 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:41:08,318 DEBUG __main__] Process content of EndNote file #34
{"title": "Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom", "url": "http://www.macrothink.org/journal/index.php/jsss/article/view/10227", "author": [{"shortname": "P Flynn", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom", "author": ["Flynn, Patrice"], "journal": "Journal of Social Science Studies", "volume": "4", "numberorissue": "1", "pages": "178", "isbn/issn": "2329-9150", "year": "2016", "EndNote": "%0 Journal Article\n%T Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom\n%A Flynn, Patrice\n%J Journal of Social Science Studies\n%V 4\n%N 1\n%P 178\n%@ 2329-9150\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:28aaLUexfRgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65V6bSnWMn3iAKYpeG7do8O1pvWOw&scisf=3&ct=citation&cd=33&hl=en"}
[2018-03-02 14:41:08,319 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom", "auth_count": 1, "g_type": "Journal Article", "pages": 4, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:41:08,319 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 4, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:41:08,319 DEBUG dbutils] Query result: []
[2018-03-02 14:41:08,319 DEBUG dbutils] Paper id = None.
[2018-03-02 14:41:08,319 DEBUG dbutils] Add new paper (title='Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom')
[2018-03-02 14:41:08,319 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 4, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Using an Autonomous Humanoid Robot as a Pedagogical Platform in the Business Classroom\n%A Flynn, Patrice\n%J Journal of Social Science Studies\n%V 4\n%N 1\n%P 178\n%@ 2329-9150\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:41:08,319 DEBUG dbutils] Query result: 32
[2018-03-02 14:41:08,321 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.macrothink.org/journal/index.php/jsss/article/viewFile/10227/8300.
[2018-03-02 14:41:08,321 WARNING utils] Download file (url='http://www.macrothink.org/journal/index.php/jsss/article/viewFile/10227/8300') and save (filename='PDF//32.pdf')
[2018-03-02 14:41:08,322 DEBUG utils] Get current proxy for www.macrothink.org.
[2018-03-02 14:41:08,322 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:41:08,322 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for otherhost
[2018-03-02 14:41:08,338 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.macrothink.org
[2018-03-02 14:41:09,151 DEBUG requests.packages.urllib3.connectionpool] "GET /journal/index.php/jsss/article/viewFile/10227/8300 HTTP/1.1" 200 164638
[2018-03-02 14:41:09,152 DEBUG utils] Content-length=164638
[2018-03-02 14:41:09,152 DEBUG utils] Create file PDF//32.pdf, start download.
[2018-03-02 14:41:10,462 DEBUG utils] End download file PDF//32.pdf.
[2018-03-02 14:41:10,463 DEBUG dbutils] Update pdf_transaction for paper id=32.
[2018-03-02 14:41:10,464 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 32'
[2018-03-02 14:41:10,464 DEBUG dbutils] Query result: null
[2018-03-02 14:41:10,464 DEBUG scholar] Handle paper #35 (total 1170)
[2018-03-02 14:41:10,464 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:41:10,469 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:41:10,469 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:41:10,470 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for scholar.google.com
[2018-03-02 14:41:10,484 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:41:14,677 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:2Hy7USFMBAIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65X6auBeeEBeJ20BjEF3c3XRahRE5&scisf=3&ct=citation&cd=34&hl=en HTTP/1.1" 200 90
[2018-03-02 14:41:14,678 DEBUG scholar] EndNote file:
%0 Journal Article
%T McGill Reasoning & Learning Lab: Research Overview
%A Lowe, Ryan

[2018-03-02 14:41:14,678 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:41:14,678 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:41:14,678 DEBUG __main__] Skip paper #35, empty year or authors fields.
[2018-03-02 14:41:14,679 DEBUG scholar] Handle paper #36 (total 1170)
[2018-03-02 14:41:14,679 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:41:14,682 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:41:14,682 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:41:15,207 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:OKARWlY6A4AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65bbzwl-sI8nvGp4yfXyMpIXco83C&scisf=3&ct=citation&cd=35&hl=en HTTP/1.1" 200 243
[2018-03-02 14:41:15,208 DEBUG scholar] EndNote file:
%0 Journal Article
%T AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS
%A Crown, Stephen
%A Fuentes, Arturo
%A Jones, Robert
%A Nambiar, Rajiv
%A Crown, Deborah
%J age
%V 15
%P 1
%D 2010

[2018-03-02 14:41:15,208 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:41:15,208 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:41:15,208 DEBUG __main__] Process content of EndNote file #36
{"title": "AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS", "url": "https://peer.asee.org/16687.pdf", "author": [{"shortname": "S Crown", "gid": ""}, {"shortname": "A Fuentes", "gid": ""}, {"shortname": "R Jones", "gid": "XEREIo8AAAAJ"}, {"shortname": "R Nambiar", "gid": ""}, {"shortname": "D Crown", "gid": ""}], "year": 2010}
{"type": "Journal Article", "title": "AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS", "author": ["Crown, Stephen", "Fuentes, Arturo", "Jones, Robert", "Nambiar, Rajiv", "Crown, Deborah"], "journal": "age", "volume": "15", "pages": "1", "year": "2010", "EndNote": "%0 Journal Article\n%T AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS\n%A Crown, Stephen\n%A Fuentes, Arturo\n%A Jones, Robert\n%A Nambiar, Rajiv\n%A Crown, Deborah\n%J age\n%V 15\n%P 1\n%D 2010\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:OKARWlY6A4AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65bbzwl-sI8nvGp4yfXyMpIXco83C&scisf=3&ct=citation&cd=35&hl=en"}
[2018-03-02 14:41:15,208 DEBUG dbutils] Get paper id {"DOI": null, "title": "AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS", "auth_count": 5, "g_type": "Journal Article", "pages": 15, "year": 2010, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:41:15,208 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': 15, 'year': 2010, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:41:15,209 DEBUG dbutils] Query result: []
[2018-03-02 14:41:15,209 DEBUG dbutils] Paper id = None.
[2018-03-02 14:41:15,209 DEBUG dbutils] Add new paper (title='AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS')
[2018-03-02 14:41:15,209 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS', 'year': 2010, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 15, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T AC 2010-1726: ANN G. NEERING: INTERACTIVE CHATBOT TO MOTIVATE AND ENGAGE ENGINEERING STUDENTS\n%A Crown, Stephen\n%A Fuentes, Arturo\n%A Jones, Robert\n%A Nambiar, Rajiv\n%A Crown, Deborah\n%J age\n%V 15\n%P 1\n%D 2010\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:41:15,209 DEBUG dbutils] Query result: 33
[2018-03-02 14:41:15,212 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://peer.asee.org/16687.pdf.
[2018-03-02 14:41:15,213 WARNING utils] Download file (url='https://peer.asee.org/16687.pdf') and save (filename='PDF//33.pdf')
[2018-03-02 14:41:15,213 DEBUG utils] Get current proxy for peer.asee.org.
[2018-03-02 14:41:15,213 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:41:15,228 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): peer.asee.org
[2018-03-02 14:41:16,916 DEBUG requests.packages.urllib3.connectionpool] "GET /16687.pdf HTTP/1.1" 200 None
[2018-03-02 14:41:16,917 DEBUG utils] Downloading the entire file.
[2018-03-02 14:41:16,917 DEBUG utils] Get current proxy for peer.asee.org.
[2018-03-02 14:41:16,917 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:41:16,917 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for otherhost
[2018-03-02 14:41:16,932 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): peer.asee.org
[2018-03-02 14:41:18,607 DEBUG requests.packages.urllib3.connectionpool] "GET /16687.pdf HTTP/1.1" 200 None
[2018-03-02 14:41:20,021 DEBUG utils] Save file PDF//33.pdf.
[2018-03-02 14:41:20,023 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://peer.asee.org/16687.pdf.
[2018-03-02 14:41:20,023 DEBUG scihub] Get page from sci-hub for paper with DOI=https://peer.asee.org/16687.pdf.
[2018-03-02 14:41:20,166 DEBUG requests.packages.urllib3.connectionpool] "GET //https://peer.asee.org/16687.pdf HTTP/1.1" 302 None
[2018-03-02 14:41:20,189 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): peer.asee.org
[2018-03-02 14:41:21,478 DEBUG requests.packages.urllib3.connectionpool] "GET /16687.pdf HTTP/1.1" 200 None
[2018-03-02 14:41:23,310 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:23,310 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:41:23,310 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for sci-hub.tw
[2018-03-02 14:41:23,496 DEBUG requests.packages.urllib3.connectionpool] "GET //https://peer.asee.org/16687.pdf HTTP/1.1" 302 None
[2018-03-02 14:41:23,519 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): peer.asee.org
[2018-03-02 14:41:32,671 DEBUG requests.packages.urllib3.connectionpool] "GET /16687.pdf HTTP/1.1" 200 None
[2018-03-02 14:41:40,306 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:41:40,307 DEBUG scholar] Handle paper #37 (total 1170)
[2018-03-02 14:41:40,307 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:41:40,311 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:41:40,311 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:41:40,311 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for scholar.google.com
[2018-03-02 14:41:40,327 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:41:43,376 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:dm_FW1ASkZcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Sp7AiucIfASdkH-hY-ILysXHPWZ&scisf=3&ct=citation&cd=36&hl=en HTTP/1.1" 200 231
[2018-03-02 14:41:43,377 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T The Rise of the Conversational Interface: A New Kid on the Block?
%A McTear, Michael F
%B International Workshop on Future and Emerging Trends in Language Technology
%P 38-49
%D 2016
%I Springer

[2018-03-02 14:41:43,377 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:41:43,377 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:41:43,377 DEBUG __main__] Process content of EndNote file #37
{"title": "The Rise of the Conversational Interface: A New Kid on the Block?", "url": "https://link.springer.com/chapter/10.1007/978-3-319-69365-1_3", "author": [{"shortname": "MF McTear", "gid": "APTzAoIAAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "The Rise of the Conversational Interface: A New Kid on the Block?", "author": ["McTear, Michael F"], "secondarytitle": "International Workshop on Future and Emerging Trends in Language Technology", "pages": "38-49", "year": "2016", "publisher": "Springer", "start_page": 38, "end_page": 49, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T The Rise of the Conversational Interface: A New Kid on the Block?\n%A McTear, Michael F\n%B International Workshop on Future and Emerging Trends in Language Technology\n%P 38-49\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:dm_FW1ASkZcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Sp7AiucIfASdkH-hY-ILysXHPWZ&scisf=3&ct=citation&cd=36&hl=en"}
[2018-03-02 14:41:43,377 DEBUG dbutils] Get paper id {"DOI": null, "title": "The Rise of the Conversational Interface: A New Kid on the Block?", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 12, "year": 2016, "rg_id": null, "start_page": 38, "end_page": 49}.
[2018-03-02 14:41:43,377 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The Rise of the Conversational Interface: A New Kid on the Block?', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 38, 'end_page': 49}
[2018-03-02 14:41:43,377 DEBUG dbutils] Query result: []
[2018-03-02 14:41:43,377 DEBUG dbutils] Paper id = None.
[2018-03-02 14:41:43,378 DEBUG dbutils] Add new paper (title='The Rise of the Conversational Interface: A New Kid on the Block?')
[2018-03-02 14:41:43,378 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The Rise of the Conversational Interface: A New Kid on the Block?', 'year': 2016, 'publisher': 'Springer', 'start_page': 38, 'end_page': 49, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T The Rise of the Conversational Interface: A New Kid on the Block?\n%A McTear, Michael F\n%B International Workshop on Future and Emerging Trends in Language Technology\n%P 38-49\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:41:43,378 DEBUG dbutils] Query result: 34
[2018-03-02 14:41:43,379 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-69365-1_3.
[2018-03-02 14:41:43,379 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-69365-1_3.
[2018-03-02 14:41:43,566 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-69365-1_3 HTTP/1.1" 200 None
[2018-03-02 14:41:43,567 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:43,567 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:41:43,757 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-69365-1_3 HTTP/1.1" 200 None
[2018-03-02 14:41:43,763 DEBUG scihub] URL for PDF: https://sci-hub.tw/saveme/c94d/10.1007@978-3-319-69365-13.pdf.
[2018-03-02 14:41:43,764 WARNING utils] Download file (url='https://sci-hub.tw/saveme/c94d/10.1007@978-3-319-69365-13.pdf') and save (filename='PDF//34.pdf')
[2018-03-02 14:41:43,779 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:44,390 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:44,391 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:44,391 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:41:44,391 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for sci-hub.tw
[2018-03-02 14:41:44,406 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:46,218 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:46,218 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for sci-hub.tw
[2018-03-02 14:41:46,235 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:41:46,983 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:46,984 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:46,984 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 14:41:46,999 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:47,968 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:47,968 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for sci-hub.tw
[2018-03-02 14:41:47,986 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 14:41:48,609 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:48,609 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:48,610 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 14:41:48,624 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:50,982 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:50,982 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for sci-hub.tw
[2018-03-02 14:41:51,002 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): sci-hub.tw
[2018-03-02 14:41:51,645 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:51,646 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:51,646 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:41:51,663 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:52,579 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:52,579 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for sci-hub.tw
[2018-03-02 14:41:52,596 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (5): sci-hub.tw
[2018-03-02 14:41:53,259 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:53,261 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:53,261 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 14:41:53,276 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:54,427 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:54,427 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for sci-hub.tw
[2018-03-02 14:41:54,443 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (6): sci-hub.tw
[2018-03-02 14:41:55,019 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:55,020 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:55,020 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:41:55,036 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:55,584 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:55,584 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for sci-hub.tw
[2018-03-02 14:41:55,600 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (7): sci-hub.tw
[2018-03-02 14:41:56,311 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:56,312 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:56,312 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:41:56,327 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:57,690 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:57,690 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for sci-hub.tw
[2018-03-02 14:41:57,707 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (8): sci-hub.tw
[2018-03-02 14:41:58,353 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:58,354 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:58,354 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:41:58,368 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:41:59,298 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:41:59,298 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for sci-hub.tw
[2018-03-02 14:41:59,314 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (9): sci-hub.tw
[2018-03-02 14:41:59,860 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:41:59,861 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:41:59,861 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:41:59,878 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:01,728 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:01,729 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for sci-hub.tw
[2018-03-02 14:42:01,744 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (10): sci-hub.tw
[2018-03-02 14:42:02,414 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:02,415 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:02,415 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:42:02,430 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:04,837 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:04,837 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for sci-hub.tw
[2018-03-02 14:42:04,852 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (11): sci-hub.tw
[2018-03-02 14:42:05,512 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:05,513 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:05,513 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:42:05,529 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:08,189 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:08,189 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for sci-hub.tw
[2018-03-02 14:42:08,204 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (12): sci-hub.tw
[2018-03-02 14:42:08,881 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:08,882 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:08,882 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 14:42:08,897 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:10,820 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:10,820 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for sci-hub.tw
[2018-03-02 14:42:10,850 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (13): sci-hub.tw
[2018-03-02 14:42:11,440 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:11,441 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:11,441 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 14:42:11,457 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:12,150 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/c94d/10.1007@978-3-319-69365-13.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/c94d/10.1007@978-3-319-69365-13.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:42:12,150 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for sci-hub.tw
[2018-03-02 14:42:12,164 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (14): sci-hub.tw
[2018-03-02 14:42:12,819 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:12,820 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:12,820 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:42:12,835 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:15,380 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:15,380 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for sci-hub.tw
[2018-03-02 14:42:15,396 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (15): sci-hub.tw
[2018-03-02 14:42:16,062 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:16,063 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:16,064 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:42:16,078 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:17,839 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:17,839 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for sci-hub.tw
[2018-03-02 14:42:17,854 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (16): sci-hub.tw
[2018-03-02 14:42:18,531 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:18,533 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:18,533 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:42:18,549 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:19,170 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:19,170 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for sci-hub.tw
[2018-03-02 14:42:19,186 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (17): sci-hub.tw
[2018-03-02 14:42:19,893 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:19,893 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:19,894 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 14:42:19,909 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:20,946 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:20,946 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for sci-hub.tw
[2018-03-02 14:42:20,963 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (18): sci-hub.tw
[2018-03-02 14:42:21,618 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:21,619 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:21,620 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 14:42:21,635 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:22,669 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:22,670 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for sci-hub.tw
[2018-03-02 14:42:22,685 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (19): sci-hub.tw
[2018-03-02 14:42:23,363 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:23,363 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:23,364 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:42:23,383 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:24,349 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:24,349 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for sci-hub.tw
[2018-03-02 14:42:24,365 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (20): sci-hub.tw
[2018-03-02 14:42:25,042 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/c94d/10.1007@978-3-319-69365-13.pdf HTTP/1.1" 200 225121
[2018-03-02 14:42:25,043 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:25,043 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:42:25,059 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:42:29,975 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:42:29,975 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for sci-hub.tw
[2018-03-02 14:42:29,979 DEBUG scholar] Handle paper #38 (total 1170)
[2018-03-02 14:42:29,979 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:42:29,985 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:42:29,985 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:42:30,525 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GJwzYcQTn7wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65X0qfpGOE6aMyRnnC1fjXRjkhsKI&scisf=3&ct=citation&cd=37&hl=en HTTP/1.1" 200 167
[2018-03-02 14:42:30,526 DEBUG scholar] EndNote file:
%0 Journal Article
%T On the ethics of machine learning applications in clinical neuroscience
%A Kellmeyer, Philipp
%J The Neuroethics Blog, November 8th
%D 2016

[2018-03-02 14:42:30,526 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:42:30,526 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:42:30,526 DEBUG __main__] Process content of EndNote file #38
{"title": "On the ethics of machine learning applications in clinical neuroscience", "url": "http://www.theneuroethicsblog.com/2016/11/on-ethics-of-machine-learning.html", "author": [{"shortname": "P Kellmeyer", "gid": "J9E4EogAAAAJ"}], "year": 2016}
{"type": "Journal Article", "title": "On the ethics of machine learning applications in clinical neuroscience", "author": ["Kellmeyer, Philipp"], "journal": "The Neuroethics Blog, November 8th", "year": "2016", "EndNote": "%0 Journal Article\n%T On the ethics of machine learning applications in clinical neuroscience\n%A Kellmeyer, Philipp\n%J The Neuroethics Blog, November 8th\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GJwzYcQTn7wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65X0qfpGOE6aMyRnnC1fjXRjkhsKI&scisf=3&ct=citation&cd=37&hl=en"}
[2018-03-02 14:42:30,526 DEBUG dbutils] Get paper id {"DOI": null, "title": "On the ethics of machine learning applications in clinical neuroscience", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:42:30,527 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'On the ethics of machine learning applications in clinical neuroscience', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:42:30,527 DEBUG dbutils] Query result: []
[2018-03-02 14:42:30,527 DEBUG dbutils] Paper id = None.
[2018-03-02 14:42:30,527 DEBUG dbutils] Add new paper (title='On the ethics of machine learning applications in clinical neuroscience')
[2018-03-02 14:42:30,527 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'On the ethics of machine learning applications in clinical neuroscience', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T On the ethics of machine learning applications in clinical neuroscience\n%A Kellmeyer, Philipp\n%J The Neuroethics Blog, November 8th\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:42:30,527 DEBUG dbutils] Query result: 35
[2018-03-02 14:42:30,529 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.theneuroethicsblog.com/2016/11/on-ethics-of-machine-learning.html.
[2018-03-02 14:42:30,529 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.theneuroethicsblog.com/2016/11/on-ethics-of-machine-learning.html.
[2018-03-02 14:42:30,715 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.theneuroethicsblog.com/2016/11/on-ethics-of-machine-learning.html HTTP/1.1" 302 None
[2018-03-02 14:42:30,739 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.theneuroethicsblog.com
[2018-03-02 14:42:32,076 DEBUG requests.packages.urllib3.connectionpool] "GET /2016/11/on-ethics-of-machine-learning.html HTTP/1.1" 200 21528
[2018-03-02 14:42:32,152 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:32,152 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:42:32,336 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.theneuroethicsblog.com/2016/11/on-ethics-of-machine-learning.html HTTP/1.1" 302 None
[2018-03-02 14:42:32,620 DEBUG requests.packages.urllib3.connectionpool] "GET /2016/11/on-ethics-of-machine-learning.html HTTP/1.1" 200 21528
[2018-03-02 14:42:32,828 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:42:32,830 DEBUG scholar] Handle paper #39 (total 1170)
[2018-03-02 14:42:32,830 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:42:32,834 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:42:32,834 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:42:32,834 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for scholar.google.com
[2018-03-02 14:42:32,850 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:42:35,761 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kNlvcYYRBgEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Rg8m9bJtswyOTlsf8ZiNEz9qBin&scisf=3&ct=citation&cd=38&hl=en HTTP/1.1" 200 293
[2018-03-02 14:42:35,762 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs
%A Suleman, Raja M
%A Mizoguchi, Riichiro
%A Ikeda, Mitsuru
%B International Conference on Intelligent Tutoring Systems
%P 354-360
%D 2016
%I Springer

[2018-03-02 14:42:35,762 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:42:35,762 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:42:35,762 DEBUG __main__] Process content of EndNote file #39
{"title": "NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs", "url": "https://link.springer.com/chapter/10.1007/978-3-319-39583-8_41", "author": [{"shortname": "RM Suleman", "gid": "bLQu4GMAAAAJ"}, {"shortname": "R Mizoguchi", "gid": "8vYF2UIAAAAJ"}, {"shortname": "M Ikeda", "gid": "PCe4CO0AAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs", "author": ["Suleman, Raja M", "Mizoguchi, Riichiro", "Ikeda, Mitsuru"], "secondarytitle": "International Conference on Intelligent Tutoring Systems", "pages": "354-360", "year": "2016", "publisher": "Springer", "start_page": 354, "end_page": 360, "volume": 7, "EndNote": "%0 Conference Proceedings\n%T NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs\n%A Suleman, Raja M\n%A Mizoguchi, Riichiro\n%A Ikeda, Mitsuru\n%B International Conference on Intelligent Tutoring Systems\n%P 354-360\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kNlvcYYRBgEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Rg8m9bJtswyOTlsf8ZiNEz9qBin&scisf=3&ct=citation&cd=38&hl=en"}
[2018-03-02 14:42:35,762 DEBUG dbutils] Get paper id {"DOI": null, "title": "NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 7, "year": 2016, "rg_id": null, "start_page": 354, "end_page": 360}.
[2018-03-02 14:42:35,762 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 7, 'year': 2016, 'rg_id': None, 'start_page': 354, 'end_page': 360}
[2018-03-02 14:42:35,763 DEBUG dbutils] Query result: []
[2018-03-02 14:42:35,763 DEBUG dbutils] Paper id = None.
[2018-03-02 14:42:35,763 DEBUG dbutils] Add new paper (title='NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs')
[2018-03-02 14:42:35,763 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs', 'year': 2016, 'publisher': 'Springer', 'start_page': 354, 'end_page': 360, 'pages': 7, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T NDLtutor: An Automated Conversational Agent to Facilitate Metacognitive Skills in Fully-Negotiated OLMs\n%A Suleman, Raja M\n%A Mizoguchi, Riichiro\n%A Ikeda, Mitsuru\n%B International Conference on Intelligent Tutoring Systems\n%P 354-360\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:42:35,763 DEBUG dbutils] Query result: 36
[2018-03-02 14:42:35,764 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-39583-8_41.
[2018-03-02 14:42:35,765 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-39583-8_41.
[2018-03-02 14:42:35,947 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-39583-8_41 HTTP/1.1" 302 None
[2018-03-02 14:42:35,972 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:42:36,320 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=B05D2B4CDEDBFA4B09550C78BA2BB146 HTTP/1.1" 200 11625
[2018-03-02 14:42:36,416 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:36,416 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:42:36,416 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for sci-hub.tw
[2018-03-02 14:42:36,645 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-39583-8_41 HTTP/1.1" 302 None
[2018-03-02 14:42:36,932 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=B05D2B4CDEDBFA4B09550C78BA2BB146 HTTP/1.1" 200 11625
[2018-03-02 14:42:37,189 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:42:37,190 DEBUG scholar] Handle paper #40 (total 1170)
[2018-03-02 14:42:37,191 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:42:37,195 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:42:37,195 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 14:42:37,700 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Zr8xkVMxC7QJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Wd4OvVW6W4m2lf1p1_s1sFa5B2p&scisf=3&ct=citation&cd=39&hl=en HTTP/1.1" 200 280
[2018-03-02 14:42:37,701 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting
%A Li, Yehao
%A Yao, Ting
%A Hu, Rui
%A Mei, Tao
%A Rui, Yong
%B Proceedings of the 2016 ACM on Multimedia Conference
%P 757-758
%@ 1450336035
%D 2016
%I ACM

[2018-03-02 14:42:37,701 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:42:37,701 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:42:37,701 DEBUG __main__] Process content of EndNote file #40
{"title": "Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting", "url": "https://dl.acm.org/citation.cfm?id=2973835", "author": [{"shortname": "Y Li", "gid": ""}, {"shortname": "T Yao", "gid": "7Yc6yssAAAAJ"}, {"shortname": "R Hu", "gid": ""}, {"shortname": "T Mei", "gid": "7Yq4wf4AAAAJ"}, {"shortname": "Y Rui", "gid": "rCGsLtcAAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting", "author": ["Li, Yehao", "Yao, Ting", "Hu, Rui", "Mei, Tao", "Rui, Yong"], "secondarytitle": "Proceedings of the 2016 ACM on Multimedia Conference", "pages": "757-758", "isbn/issn": "1450336035", "year": "2016", "publisher": "ACM", "start_page": 757, "end_page": 758, "volume": 2, "EndNote": "%0 Conference Proceedings\n%T Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting\n%A Li, Yehao\n%A Yao, Ting\n%A Hu, Rui\n%A Mei, Tao\n%A Rui, Yong\n%B Proceedings of the 2016 ACM on Multimedia Conference\n%P 757-758\n%@ 1450336035\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Zr8xkVMxC7QJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk65Wd4OvVW6W4m2lf1p1_s1sFa5B2p&scisf=3&ct=citation&cd=39&hl=en"}
[2018-03-02 14:42:37,701 DEBUG dbutils] Get paper id {"DOI": null, "title": "Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 2, "year": 2016, "rg_id": null, "start_page": 757, "end_page": 758}.
[2018-03-02 14:42:37,701 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 2, 'year': 2016, 'rg_id': None, 'start_page': 757, 'end_page': 758}
[2018-03-02 14:42:37,701 DEBUG dbutils] Query result: []
[2018-03-02 14:42:37,702 DEBUG dbutils] Paper id = None.
[2018-03-02 14:42:37,702 DEBUG dbutils] Add new paper (title='Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting')
[2018-03-02 14:42:37,702 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting', 'year': 2016, 'publisher': 'ACM', 'start_page': 757, 'end_page': 758, 'pages': 2, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Video ChatBot: Triggering Live Social Interactions by Automatic Video Commenting\n%A Li, Yehao\n%A Yao, Ting\n%A Hu, Rui\n%A Mei, Tao\n%A Rui, Yong\n%B Proceedings of the 2016 ACM on Multimedia Conference\n%P 757-758\n%@ 1450336035\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:42:37,702 DEBUG dbutils] Query result: 37
[2018-03-02 14:42:37,703 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2973835.
[2018-03-02 14:42:37,704 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2973835.
[2018-03-02 14:42:37,882 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2973835 HTTP/1.1" 200 None
[2018-03-02 14:42:37,883 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:42:37,883 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:42:38,066 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2973835 HTTP/1.1" 200 None
[2018-03-02 14:42:38,072 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true.
[2018-03-02 14:42:38,073 WARNING utils] Download file (url='http://twin.sci-hub.tw/eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true') and save (filename='PDF//37.pdf')
[2018-03-02 14:42:38,087 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: twin.sci-hub.tw
[2018-03-02 14:42:38,256 DEBUG requests.packages.urllib3.connectionpool] "GET /eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:42:38,257 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:42:38,257 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:42:38,257 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for sci-hub.tw
[2018-03-02 14:42:38,274 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): twin.sci-hub.tw
[2018-03-02 14:42:38,446 DEBUG requests.packages.urllib3.connectionpool] "GET /eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:42:38,449 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:42:38,449 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:42:45,959 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:42:45,959 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:42:46,229 DEBUG requests.packages.urllib3.connectionpool] "GET /eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:42:46,230 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:42:46,230 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:42:46,245 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): twin.sci-hub.tw
[2018-03-02 14:42:46,405 DEBUG requests.packages.urllib3.connectionpool] "GET /eabb39ec7a6187e572aac491b012b6fe/li2016.pdf?download=true HTTP/1.1" 200 2172117
[2018-03-02 14:42:46,406 DEBUG utils] Content-length=2172117
[2018-03-02 14:42:46,407 DEBUG utils] Create file PDF//37.pdf, start download.
[2018-03-02 14:42:51,382 DEBUG utils] End download file PDF//37.pdf.
[2018-03-02 14:42:51,383 DEBUG dbutils] Update pdf_transaction for paper id=37.
[2018-03-02 14:42:51,383 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 37'
[2018-03-02 14:42:51,383 DEBUG dbutils] Query result: null
[2018-03-02 14:42:51,384 DEBUG dbutils] Commiting transaction 40.
[2018-03-02 14:42:51,521 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:42:51,521 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:42:51,521 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 14:42:51,521 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for scholar.google.com
[2018-03-02 14:42:51,535 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:42:56,100 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=40&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:42:56,676 DEBUG scholar] Find papers on page #5 (max_google_papers = 300)
[2018-03-02 14:42:56,676 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:42:56,677 DEBUG scholar] Handle paper #41 (total 1170)
[2018-03-02 14:42:56,677 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:42:56,680 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:42:56,680 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:42:56,697 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:01,874 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:43:01,874 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for scholar.google.com
[2018-03-02 14:43:01,875 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:01,875 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:43:01,889 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:02,136 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:43:02,136 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for scholar.google.com
[2018-03-02 14:43:02,136 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:02,136 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:43:02,152 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:12,065 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en HTTP/1.1" 200 118
[2018-03-02 14:43:12,065 DEBUG scholar] EndNote file:
%0 Journal Article
%T Creativity in Machine Learning
%A Thoma, Martin
%J arXiv preprint arXiv:1601.03642
%D 2016

[2018-03-02 14:43:12,066 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:12,066 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:12,066 DEBUG __main__] Process content of EndNote file #41
{"title": "Creativity in Machine Learning", "url": "https://arxiv.org/abs/1601.03642", "author": [{"shortname": "M Thoma", "gid": "u52T6MYAAAAJ"}], "year": 1601}
{"type": "Journal Article", "title": "Creativity in Machine Learning", "author": ["Thoma, Martin"], "journal": "arXiv preprint arXiv:1601.03642", "year": "2016", "EndNote": "%0 Journal Article\n%T Creativity in Machine Learning\n%A Thoma, Martin\n%J arXiv preprint arXiv:1601.03642\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:r4vomrbmn0wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XKVUAuiEAjK_kejnURKqqQQsq4Pp&scisf=3&ct=citation&cd=40&hl=en"}
[2018-03-02 14:43:12,066 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creativity in Machine Learning", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:12,066 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creativity in Machine Learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:12,066 DEBUG dbutils] Query result: []
[2018-03-02 14:43:12,066 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:12,066 DEBUG dbutils] Add new paper (title='Creativity in Machine Learning')
[2018-03-02 14:43:12,066 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creativity in Machine Learning', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Creativity in Machine Learning\n%A Thoma, Martin\n%J arXiv preprint arXiv:1601.03642\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:12,067 DEBUG dbutils] Query result: 38
[2018-03-02 14:43:12,070 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1601.03642.
[2018-03-02 14:43:12,071 WARNING utils] Download file (url='https://arxiv.org/pdf/1601.03642') and save (filename='PDF//38.pdf')
[2018-03-02 14:43:12,072 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:43:12,072 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:43:12,093 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:43:13,315 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1601.03642 HTTP/1.1" 302 280
[2018-03-02 14:43:13,976 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1601.03642.pdf HTTP/1.1" 200 1029061
[2018-03-02 14:43:13,976 DEBUG utils] Content-length=1029061
[2018-03-02 14:43:13,977 DEBUG utils] Create file PDF//38.pdf, start download.
[2018-03-02 14:43:16,613 DEBUG utils] End download file PDF//38.pdf.
[2018-03-02 14:43:16,614 DEBUG dbutils] Update pdf_transaction for paper id=38.
[2018-03-02 14:43:16,615 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 38'
[2018-03-02 14:43:16,615 DEBUG dbutils] Query result: null
[2018-03-02 14:43:16,616 DEBUG scholar] Handle paper #42 (total 1170)
[2018-03-02 14:43:16,616 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:43:16,620 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:16,621 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:43:16,621 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for scholar.google.com
[2018-03-02 14:43:16,644 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:18,016 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QIXGnVyC-BEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XBxyNkFvefKZ4Ko-ocOL3D_EkV2z&scisf=3&ct=citation&cd=41&hl=en HTTP/1.1" 200 107
[2018-03-02 14:43:18,017 DEBUG scholar] EndNote file:
%0 Generic
%T Automatic Twitter ResponseGenerator
%A Gunning, Christoffer
%A Forslund, Daniel
%D 2013

[2018-03-02 14:43:18,017 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:18,017 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:18,017 DEBUG __main__] Process content of EndNote file #42
{"title": "Automatic Twitter ResponseGenerator", "url": "http://www.diva-portal.org/smash/get/diva2:668274/FULLTEXT01.pdf", "author": [{"shortname": "C Gunning", "gid": ""}, {"shortname": "D Forslund", "gid": ""}], "year": 2013}
{"type": "Generic", "title": "Automatic Twitter ResponseGenerator", "author": ["Gunning, Christoffer", "Forslund, Daniel"], "year": "2013", "EndNote": "%0 Generic\n%T Automatic Twitter ResponseGenerator\n%A Gunning, Christoffer\n%A Forslund, Daniel\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QIXGnVyC-BEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XBxyNkFvefKZ4Ko-ocOL3D_EkV2z&scisf=3&ct=citation&cd=41&hl=en"}
[2018-03-02 14:43:18,017 DEBUG dbutils] Get paper id {"DOI": null, "title": "Automatic Twitter ResponseGenerator", "auth_count": 2, "g_type": "Generic", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:18,017 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Automatic Twitter ResponseGenerator', 'auth_count': 2, 'g_type': 'Generic', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:18,018 DEBUG dbutils] Query result: []
[2018-03-02 14:43:18,018 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:18,018 DEBUG dbutils] Add new paper (title='Automatic Twitter ResponseGenerator')
[2018-03-02 14:43:18,018 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Automatic Twitter ResponseGenerator', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Automatic Twitter ResponseGenerator\n%A Gunning, Christoffer\n%A Forslund, Daniel\n%D 2013\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:18,018 DEBUG dbutils] Query result: 39
[2018-03-02 14:43:18,022 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.diva-portal.org/smash/get/diva2:668274/FULLTEXT01.pdf.
[2018-03-02 14:43:18,023 WARNING utils] Download file (url='http://www.diva-portal.org/smash/get/diva2:668274/FULLTEXT01.pdf') and save (filename='PDF//39.pdf')
[2018-03-02 14:43:18,024 DEBUG utils] Get current proxy for www.diva-portal.org.
[2018-03-02 14:43:18,024 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:43:18,024 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for otherhost
[2018-03-02 14:43:18,038 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.diva-portal.org
[2018-03-02 14:43:18,287 DEBUG requests.packages.urllib3.connectionpool] "GET /smash/get/diva2:668274/FULLTEXT01.pdf HTTP/1.1" 200 254306
[2018-03-02 14:43:18,287 DEBUG utils] Content-length=254306
[2018-03-02 14:43:18,288 DEBUG utils] Create file PDF//39.pdf, start download.
[2018-03-02 14:43:18,709 DEBUG utils] End download file PDF//39.pdf.
[2018-03-02 14:43:18,710 DEBUG dbutils] Update pdf_transaction for paper id=39.
[2018-03-02 14:43:18,710 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 39'
[2018-03-02 14:43:18,710 DEBUG dbutils] Query result: null
[2018-03-02 14:43:18,710 DEBUG scholar] Handle paper #43 (total 1170)
[2018-03-02 14:43:18,710 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:43:18,713 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:18,713 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 14:43:18,974 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:tnkNn8J2rkkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XBCRIFMbCzRBLMY1fSQFilbCnGw4&scisf=3&ct=citation&cd=42&hl=en HTTP/1.1" 200 75
[2018-03-02 14:43:18,975 DEBUG scholar] EndNote file:
%0 Journal Article
%T in Use for Second Language Learning
%A LEVY, MIKE

[2018-03-02 14:43:18,976 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:18,976 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:18,976 DEBUG __main__] Skip paper #43, empty year or authors fields.
[2018-03-02 14:43:18,976 DEBUG scholar] Handle paper #44 (total 1170)
[2018-03-02 14:43:18,976 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:43:18,980 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:18,980 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 14:43:18,980 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for scholar.google.com
[2018-03-02 14:43:18,995 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:20,565 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:LJiCpdu4iwEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XD5f98Z6eq-8RXqf7ZZHwre5rC2J&scisf=3&ct=citation&cd=43&hl=en HTTP/1.1" 200 292
[2018-03-02 14:43:20,566 DEBUG scholar] EndNote file:
%0 Journal Article
%T C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.
%A Yamada, Masanori
%A Goda, Yoshiko
%A Matsukawa, Hideya
%A Hata, Kojiro
%A Yasunami, Seisuke
%J Research-publishing. net
%D 2013
%I ERIC

[2018-03-02 14:43:20,566 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:20,566 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:20,566 DEBUG __main__] Process content of EndNote file #44
{"title": "C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.", "url": "https://eric.ed.gov/?id=ED565069", "author": [{"shortname": "M Yamada", "gid": "4dOyLHAAAAAJ"}, {"shortname": "Y Goda", "gid": "hIk4QDAAAAAJ"}, {"shortname": "H Matsukawa", "gid": ""}, {"shortname": "K Hata", "gid": ""}], "year": 2013}
{"type": "Journal Article", "title": "C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.", "author": ["Yamada, Masanori", "Goda, Yoshiko", "Matsukawa, Hideya", "Hata, Kojiro", "Yasunami, Seisuke"], "journal": "Research-publishing. net", "year": "2013", "publisher": "ERIC", "EndNote": "%0 Journal Article\n%T C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%J Research-publishing. net\n%D 2013\n%I ERIC\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:LJiCpdu4iwEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XD5f98Z6eq-8RXqf7ZZHwre5rC2J&scisf=3&ct=citation&cd=43&hl=en"}
[2018-03-02 14:43:20,567 DEBUG dbutils] Get paper id {"DOI": null, "title": "C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.", "auth_count": 5, "g_type": "Journal Article", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:20,567 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:20,567 DEBUG dbutils] Query result: []
[2018-03-02 14:43:20,567 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:20,567 DEBUG dbutils] Add new paper (title='C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.')
[2018-03-02 14:43:20,567 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.', 'year': 2013, 'publisher': 'ERIC', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T C [superscript 4](C Quad): Development of the Application for Language Learning Based on Social and Cognitive Presences.\n%A Yamada, Masanori\n%A Goda, Yoshiko\n%A Matsukawa, Hideya\n%A Hata, Kojiro\n%A Yasunami, Seisuke\n%J Research-publishing. net\n%D 2013\n%I ERIC\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:20,567 DEBUG dbutils] Query result: 40
[2018-03-02 14:43:20,569 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://files.eric.ed.gov/fulltext/ED565069.pdf.
[2018-03-02 14:43:20,569 WARNING utils] Download file (url='https://files.eric.ed.gov/fulltext/ED565069.pdf') and save (filename='PDF//40.pdf')
[2018-03-02 14:43:20,569 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 14:43:20,570 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:43:20,584 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 14:43:22,112 DEBUG requests.packages.urllib3.connectionpool] "GET /fulltext/ED565069.pdf HTTP/1.1" 200 1563640
[2018-03-02 14:43:22,113 DEBUG utils] Content-length=1563640
[2018-03-02 14:43:22,114 DEBUG utils] Create file PDF//40.pdf, start download.
[2018-03-02 14:43:27,239 DEBUG utils] End download file PDF//40.pdf.
[2018-03-02 14:43:27,240 DEBUG dbutils] Update pdf_transaction for paper id=40.
[2018-03-02 14:43:27,241 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 40'
[2018-03-02 14:43:27,241 DEBUG dbutils] Query result: null
[2018-03-02 14:43:27,243 DEBUG scholar] Handle paper #45 (total 1170)
[2018-03-02 14:43:27,243 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:43:27,248 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:27,248 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:43:27,524 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:RCBi67xEgwcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XMebcfhUaEUchyp3uLCdO2IbsKsA&scisf=3&ct=citation&cd=44&hl=en HTTP/1.1" 200 118
[2018-03-02 14:43:27,525 DEBUG scholar] EndNote file:
%0 Journal Article
%T Question Answering Using Deep Learning
%A Stroh, Eylon
%A Student, SCPD
%A Mathur, Priyank

[2018-03-02 14:43:27,525 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:27,525 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:27,525 DEBUG __main__] Skip paper #45, empty year or authors fields.
[2018-03-02 14:43:27,526 DEBUG scholar] Handle paper #46 (total 1170)
[2018-03-02 14:43:27,526 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:43:27,531 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:27,531 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:43:27,531 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for scholar.google.com
[2018-03-02 14:43:27,545 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:30,556 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EP1befwt1xIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XBoxj_B9PXCjxq5KN9jX-WXuEns-&scisf=3&ct=citation&cd=45&hl=en HTTP/1.1" 200 179
[2018-03-02 14:43:30,557 DEBUG scholar] EndNote file:
%0 Journal Article
%T The study of the application of a keywords-based chatbot system on the teaching of foreign languages
%A Jia, Jiyou
%J arXiv preprint cs/0310018
%D 2003

[2018-03-02 14:43:30,557 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:30,557 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:30,557 DEBUG __main__] Process content of EndNote file #46
{"title": "The study of the application of a keywords-based chatbot system on the teaching of foreign languages", "url": "https://arxiv.org/abs/cs/0310018", "author": [{"shortname": "J Jia", "gid": ""}], "year": 310}
{"citedby": 21, "type": "Journal Article", "title": "The study of the application of a keywords-based chatbot system on the teaching of foreign languages", "author": ["Jia, Jiyou"], "journal": "arXiv preprint cs/0310018", "year": "2003", "EndNote": "%0 Journal Article\n%T The study of the application of a keywords-based chatbot system on the teaching of foreign languages\n%A Jia, Jiyou\n%J arXiv preprint cs/0310018\n%D 2003\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:EP1befwt1xIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XBoxj_B9PXCjxq5KN9jX-WXuEns-&scisf=3&ct=citation&cd=45&hl=en"}
[2018-03-02 14:43:30,557 DEBUG dbutils] Get paper id {"DOI": null, "title": "The study of the application of a keywords-based chatbot system on the teaching of foreign languages", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2003, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:30,557 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The study of the application of a keywords-based chatbot system on the teaching of foreign languages', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2003, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:30,557 DEBUG dbutils] Query result: []
[2018-03-02 14:43:30,557 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:30,557 DEBUG dbutils] Add new paper (title='The study of the application of a keywords-based chatbot system on the teaching of foreign languages')
[2018-03-02 14:43:30,558 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The study of the application of a keywords-based chatbot system on the teaching of foreign languages', 'year': 2003, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The study of the application of a keywords-based chatbot system on the teaching of foreign languages\n%A Jia, Jiyou\n%J arXiv preprint cs/0310018\n%D 2003\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:30,558 DEBUG dbutils] Query result: 41
[2018-03-02 14:43:30,559 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/cs/0310018.
[2018-03-02 14:43:30,561 WARNING utils] Download file (url='https://arxiv.org/pdf/cs/0310018') and save (filename='PDF//41.pdf')
[2018-03-02 14:43:30,561 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:43:30,561 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:43:30,561 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for otherhost
[2018-03-02 14:43:30,576 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:43:32,585 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/cs/0310018 HTTP/1.1" 302 280
[2018-03-02 14:43:33,372 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/cs/0310018.pdf HTTP/1.1" 200 103524
[2018-03-02 14:43:33,372 DEBUG utils] Content-length=103524
[2018-03-02 14:43:33,373 DEBUG utils] Create file PDF//41.pdf, start download.
[2018-03-02 14:43:34,174 DEBUG utils] End download file PDF//41.pdf.
[2018-03-02 14:43:34,175 DEBUG dbutils] Update pdf_transaction for paper id=41.
[2018-03-02 14:43:34,175 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 41'
[2018-03-02 14:43:34,175 DEBUG dbutils] Query result: null
[2018-03-02 14:43:34,176 DEBUG scholar] Handle paper #47 (total 1170)
[2018-03-02 14:43:34,176 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:43:34,180 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:34,180 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:43:34,714 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:OWV9NcCTYooJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XAyNTD35ExWA4X2osOxck3B0qwrG&scisf=3&ct=citation&cd=46&hl=en HTTP/1.1" 200 261
[2018-03-02 14:43:34,715 DEBUG scholar] EndNote file:
%0 Journal Article
%T Web 2.0: Read, write, create, connect, and learnopportunities for online learning
%A Parscal, Tina J
%J Journal of Psychological Issues in Organizational Culture
%V 1
%N 2
%P 80-89
%@ 2041-8426
%D 2010
%I Wiley Online Library

[2018-03-02 14:43:34,715 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:34,715 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:34,715 DEBUG __main__] Process content of EndNote file #47
{"title": "Web 2.0: Read, write, create, connect, and learn\u2014opportunities for online learning", "url": "http://onlinelibrary.wiley.com/doi/10.1002/jpoc.20016/full", "author": [{"shortname": "TJ Parscal", "gid": ""}], "year": 2010}
{"citedby": 5, "type": "Journal Article", "title": "Web 2.0: Read, write, create, connect, and learn\u2014opportunities for online learning", "author": ["Parscal, Tina J"], "journal": "Journal of Psychological Issues in Organizational Culture", "volume": 10, "numberorissue": "2", "pages": "80-89", "isbn/issn": "2041-8426", "year": "2010", "publisher": "Wiley Online Library", "start_page": 80, "end_page": 89, "EndNote": "%0 Journal Article\n%T Web 2.0: Read, write, create, connect, and learn\u2014opportunities for online learning\n%A Parscal, Tina J\n%J Journal of Psychological Issues in Organizational Culture\n%V 1\n%N 2\n%P 80-89\n%@ 2041-8426\n%D 2010\n%I Wiley Online Library\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:OWV9NcCTYooJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XAyNTD35ExWA4X2osOxck3B0qwrG&scisf=3&ct=citation&cd=46&hl=en"}
[2018-03-02 14:43:34,715 DEBUG dbutils] Get paper id {"DOI": null, "title": "Web 2.0: Read, write, create, connect, and learn\u2014opportunities for online learning", "auth_count": 1, "g_type": "Journal Article", "pages": 10, "year": 2010, "rg_id": null, "start_page": 80, "end_page": 89}.
[2018-03-02 14:43:34,715 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Web 2.0: Read, write, create, connect, and learnopportunities for online learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 10, 'year': 2010, 'rg_id': None, 'start_page': 80, 'end_page': 89}
[2018-03-02 14:43:34,715 DEBUG dbutils] Query result: []
[2018-03-02 14:43:34,716 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:34,716 DEBUG dbutils] Add new paper (title='Web 2.0: Read, write, create, connect, and learnopportunities for online learning')
[2018-03-02 14:43:34,716 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Web 2.0: Read, write, create, connect, and learnopportunities for online learning', 'year': 2010, 'publisher': 'Wiley Online Library', 'start_page': 80, 'end_page': 89, 'pages': 10, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Web 2.0: Read, write, create, connect, and learnopportunities for online learning\n%A Parscal, Tina J\n%J Journal of Psychological Issues in Organizational Culture\n%V 1\n%N 2\n%P 80-89\n%@ 2041-8426\n%D 2010\n%I Wiley Online Library\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:34,716 DEBUG dbutils] Query result: 42
[2018-03-02 14:43:34,717 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://onlinelibrary.wiley.com/doi/10.1002/jpoc.20016/full.
[2018-03-02 14:43:34,717 DEBUG scihub] Get page from sci-hub for paper with DOI=http://onlinelibrary.wiley.com/doi/10.1002/jpoc.20016/full.
[2018-03-02 14:43:34,906 DEBUG requests.packages.urllib3.connectionpool] "GET //http://onlinelibrary.wiley.com/doi/10.1002/jpoc.20016/full HTTP/1.1" 200 None
[2018-03-02 14:43:34,908 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:43:34,908 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:43:34,908 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for sci-hub.tw
[2018-03-02 14:43:35,066 DEBUG requests.packages.urllib3.connectionpool] "GET //http://onlinelibrary.wiley.com/doi/10.1002/jpoc.20016/full HTTP/1.1" 200 None
[2018-03-02 14:43:35,073 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAwMi9qcG9jLjIwMDE2/parscal2010.pdf?download=true.
[2018-03-02 14:43:35,074 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAwMi9qcG9jLjIwMDE2/parscal2010.pdf?download=true') and save (filename='PDF//42.pdf')
[2018-03-02 14:43:35,089 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 14:43:35,317 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAwMi9qcG9jLjIwMDE2/parscal2010.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:43:35,317 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:43:35,318 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:43:35,333 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (25): cyber.sci-hub.tw
[2018-03-02 14:43:35,525 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAwMi9qcG9jLjIwMDE2/parscal2010.pdf?download=true HTTP/1.1" 200 138106
[2018-03-02 14:43:35,526 DEBUG utils] Content-length=138106
[2018-03-02 14:43:35,526 DEBUG utils] Create file PDF//42.pdf, start download.
[2018-03-02 14:43:35,765 DEBUG utils] End download file PDF//42.pdf.
[2018-03-02 14:43:35,766 DEBUG dbutils] Update pdf_transaction for paper id=42.
[2018-03-02 14:43:35,766 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 42'
[2018-03-02 14:43:35,766 DEBUG dbutils] Query result: null
[2018-03-02 14:43:35,767 DEBUG scholar] Handle paper #48 (total 1170)
[2018-03-02 14:43:35,767 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:43:35,773 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:35,774 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:43:35,774 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for scholar.google.com
[2018-03-02 14:43:35,787 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:43:37,554 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:wN-sxvse9JYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XIoL_qQzBgmDGmK-NWkiE2KOPy4B&scisf=3&ct=citation&cd=47&hl=en HTTP/1.1" 200 382
[2018-03-02 14:43:37,555 DEBUG scholar] EndNote file:
%0 Journal Article
%T Innovating pedagogy 2016: Open University innovation report 5
%A Sharples, Mike
%A de Roock, Roberto
%A Ferguson, Rebecca
%A Gaved, Mark
%A Herodotou, Christothea
%A Koh, Elizabeth
%A Kukulska-Hulme, Agnes
%A Looi, Chee-Kit
%A McAndrew, Patrick
%A Rienties, Bart
%@ 1473022819
%D 2016
%I Institute of Educational Technology, The Open University

[2018-03-02 14:43:37,555 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:37,555 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:37,555 DEBUG __main__] Process content of EndNote file #48
{"title": "Innovating pedagogy 2016: Open University innovation report 5", "url": "https://repository.nie.edu.sg/handle/10497/18319", "author": [{"shortname": "M Sharples", "gid": "0KzFF40AAAAJ"}, {"shortname": "R de Roock", "gid": "8C-eFfUAAAAJ"}, {"shortname": "R Ferguson", "gid": "lfxvlmwAAAAJ"}, {"shortname": "M Gaved", "gid": "yAasr00AAAAJ"}], "year": 2016}
{"citedby": 234, "type": "Journal Article", "title": "Innovating pedagogy 2016: Open University innovation report 5", "author": ["Sharples, Mike", "de Roock, Roberto", "Ferguson, Rebecca", "Gaved, Mark", "Herodotou, Christothea", "Koh, Elizabeth", "Kukulska-Hulme, Agnes", "Looi, Chee-Kit", "McAndrew, Patrick", "Rienties, Bart"], "isbn/issn": "1473022819", "year": "2016", "publisher": "Institute of Educational Technology, The Open University", "EndNote": "%0 Journal Article\n%T Innovating pedagogy 2016: Open University innovation report 5\n%A Sharples, Mike\n%A de Roock, Roberto\n%A Ferguson, Rebecca\n%A Gaved, Mark\n%A Herodotou, Christothea\n%A Koh, Elizabeth\n%A Kukulska-Hulme, Agnes\n%A Looi, Chee-Kit\n%A McAndrew, Patrick\n%A Rienties, Bart\n%@ 1473022819\n%D 2016\n%I Institute of Educational Technology, The Open University\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:wN-sxvse9JYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XIoL_qQzBgmDGmK-NWkiE2KOPy4B&scisf=3&ct=citation&cd=47&hl=en"}
[2018-03-02 14:43:37,556 DEBUG dbutils] Get paper id {"DOI": null, "title": "Innovating pedagogy 2016: Open University innovation report 5", "auth_count": 10, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:37,556 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Innovating pedagogy 2016: Open University innovation report 5', 'auth_count': 10, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:37,556 DEBUG dbutils] Query result: []
[2018-03-02 14:43:37,556 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:37,556 DEBUG dbutils] Add new paper (title='Innovating pedagogy 2016: Open University innovation report 5')
[2018-03-02 14:43:37,557 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Innovating pedagogy 2016: Open University innovation report 5', 'year': 2016, 'publisher': 'Institute of Educational Technology, The Open University', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Innovating pedagogy 2016: Open University innovation report 5\n%A Sharples, Mike\n%A de Roock, Roberto\n%A Ferguson, Rebecca\n%A Gaved, Mark\n%A Herodotou, Christothea\n%A Koh, Elizabeth\n%A Kukulska-Hulme, Agnes\n%A Looi, Chee-Kit\n%A McAndrew, Patrick\n%A Rienties, Bart\n%@ 1473022819\n%D 2016\n%I Institute of Educational Technology, The Open University\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:37,557 DEBUG dbutils] Query result: 43
[2018-03-02 14:43:37,558 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://repository.nie.edu.sg/bitstream/10497/18319/3/IP_2016_OUIR5.pdf.
[2018-03-02 14:43:37,559 WARNING utils] Download file (url='https://repository.nie.edu.sg/bitstream/10497/18319/3/IP_2016_OUIR5.pdf') and save (filename='PDF//43.pdf')
[2018-03-02 14:43:37,560 DEBUG utils] Get current proxy for repository.nie.edu.sg.
[2018-03-02 14:43:37,560 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:43:37,574 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): repository.nie.edu.sg
[2018-03-02 14:43:41,039 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10497/18319/3/IP_2016_OUIR5.pdf HTTP/1.1" 200 1879008
[2018-03-02 14:43:41,039 DEBUG utils] Content-length=1879008
[2018-03-02 14:43:41,040 DEBUG utils] Create file PDF//43.pdf, start download.
[2018-03-02 14:43:46,175 DEBUG utils] End download file PDF//43.pdf.
[2018-03-02 14:43:46,176 DEBUG dbutils] Update pdf_transaction for paper id=43.
[2018-03-02 14:43:46,176 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 43'
[2018-03-02 14:43:46,176 DEBUG dbutils] Query result: null
[2018-03-02 14:43:46,176 DEBUG scholar] Handle paper #49 (total 1170)
[2018-03-02 14:43:46,176 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:43:46,183 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:46,183 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:43:46,524 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:RSzeJlSjELEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XIybSGndnXU5I6YXnNRn_AqEr_-C&scisf=3&ct=citation&cd=48&hl=en HTTP/1.1" 200 153
[2018-03-02 14:43:46,525 DEBUG scholar] EndNote file:
%0 Journal Article
%T A disembodied developmental robotic agent called Samu B\'atfai
%A Batfai, Norbert
%J arXiv preprint arXiv:1511.02889
%D 2015

[2018-03-02 14:43:46,525 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:43:46,526 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:43:46,526 DEBUG __main__] Process content of EndNote file #49
{"title": "A disembodied developmental robotic agent called Samu B\\'atfai", "url": "https://arxiv.org/abs/1511.02889", "author": [{"shortname": "N B\u00e1tfai", "gid": "ouiM--QAAAAJ"}], "year": 1511}
{"citedby": 2, "type": "Journal Article", "title": "A disembodied developmental robotic agent called Samu B\\'atfai", "author": ["B\u00e1tfai, Norbert"], "journal": "arXiv preprint arXiv:1511.02889", "year": "2015", "EndNote": "%0 Journal Article\n%T A disembodied developmental robotic agent called Samu B\\'atfai\n%A B\u00e1tfai, Norbert\n%J arXiv preprint arXiv:1511.02889\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:RSzeJlSjELEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XIybSGndnXU5I6YXnNRn_AqEr_-C&scisf=3&ct=citation&cd=48&hl=en"}
[2018-03-02 14:43:46,526 DEBUG dbutils] Get paper id {"DOI": null, "title": "A disembodied developmental robotic agent called Samu B\\'atfai", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:43:46,526 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': "A disembodied developmental robotic agent called Samu B\\'atfai", 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:43:46,526 DEBUG dbutils] Query result: []
[2018-03-02 14:43:46,526 DEBUG dbutils] Paper id = None.
[2018-03-02 14:43:46,526 DEBUG dbutils] Add new paper (title='A disembodied developmental robotic agent called Samu B\'atfai')
[2018-03-02 14:43:46,526 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': "A disembodied developmental robotic agent called Samu B\\'atfai", 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Journal Article\n%T A disembodied developmental robotic agent called Samu B\\'atfai\n%A Batfai, Norbert\n%J arXiv preprint arXiv:1511.02889\n%D 2015\n", 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:43:46,526 DEBUG dbutils] Query result: 44
[2018-03-02 14:43:46,528 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1511.02889.
[2018-03-02 14:43:46,531 WARNING utils] Download file (url='https://arxiv.org/pdf/1511.02889') and save (filename='PDF//44.pdf')
[2018-03-02 14:43:46,531 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:43:46,531 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:43:46,532 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for otherhost
[2018-03-02 14:43:46,547 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:43:51,434 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1511.02889 HTTP/1.1" 302 280
[2018-03-02 14:43:52,135 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1511.02889.pdf HTTP/1.1" 200 739271
[2018-03-02 14:43:52,135 DEBUG utils] Content-length=739271
[2018-03-02 14:43:52,136 DEBUG utils] Create file PDF//44.pdf, start download.
[2018-03-02 14:43:56,075 DEBUG utils] End download file PDF//44.pdf.
[2018-03-02 14:43:56,076 DEBUG dbutils] Update pdf_transaction for paper id=44.
[2018-03-02 14:43:56,076 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 44'
[2018-03-02 14:43:56,077 DEBUG dbutils] Query result: null
[2018-03-02 14:43:56,077 DEBUG scholar] Handle paper #50 (total 1170)
[2018-03-02 14:43:56,077 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:43:56,081 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:43:56,081 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:43:56,081 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for scholar.google.com
[2018-03-02 14:43:56,096 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:00,584 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:DRZfk3pN0t0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XO-pp2wwMVfAGAB2hGC6mD4X7b7q&scisf=3&ct=citation&cd=49&hl=en HTTP/1.1" 200 256
[2018-03-02 14:44:00,585 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T RAIN in indoor rescue training
%A Ulisses, Joao
%A Almeida, Joao Emilio
%A Rossetti, Rosaldo JF
%B Information Systems and Technologies (CISTI), 2015 10th Iberian Conference on
%P 1-6
%@ 9899843458
%D 2015
%I IEEE

[2018-03-02 14:44:00,586 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:00,586 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:00,586 DEBUG __main__] Process content of EndNote file #50
{"title": "RAIN in indoor rescue training", "url": "http://ieeexplore.ieee.org/abstract/document/7170606/", "author": [{"shortname": "J Ulisses", "gid": "XHmrG4cAAAAJ"}, {"shortname": "JE Almeida", "gid": "5qPuxgIAAAAJ"}], "year": 2015}
{"citedby": 2, "type": "Conference Proceedings", "title": "RAIN in indoor rescue training", "author": ["Ulisses, Jo\u00e3o", "Almeida, Jo\u00e3o Em\u00edlio", "Rossetti, Rosaldo JF"], "secondarytitle": "Information Systems and Technologies (CISTI), 2015 10th Iberian Conference on", "pages": "1-6", "isbn/issn": "9899843458", "year": "2015", "publisher": "IEEE", "start_page": 1, "end_page": 6, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T RAIN in indoor rescue training\n%A Ulisses, Jo\u00e3o\n%A Almeida, Jo\u00e3o Em\u00edlio\n%A Rossetti, Rosaldo JF\n%B Information Systems and Technologies (CISTI), 2015 10th Iberian Conference on\n%P 1-6\n%@ 9899843458\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:DRZfk3pN0t0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7XO-pp2wwMVfAGAB2hGC6mD4X7b7q&scisf=3&ct=citation&cd=49&hl=en"}
[2018-03-02 14:44:00,586 DEBUG dbutils] Get paper id {"DOI": null, "title": "RAIN in indoor rescue training", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 6, "year": 2015, "rg_id": null, "start_page": 1, "end_page": 6}.
[2018-03-02 14:44:00,586 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'RAIN in indoor rescue training', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2015, 'rg_id': None, 'start_page': 1, 'end_page': 6}
[2018-03-02 14:44:00,586 DEBUG dbutils] Query result: []
[2018-03-02 14:44:00,586 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:00,586 DEBUG dbutils] Add new paper (title='RAIN in indoor rescue training')
[2018-03-02 14:44:00,586 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'RAIN in indoor rescue training', 'year': 2015, 'publisher': 'IEEE', 'start_page': 1, 'end_page': 6, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T RAIN in indoor rescue training\n%A Ulisses, Joao\n%A Almeida, Joao Emilio\n%A Rossetti, Rosaldo JF\n%B Information Systems and Technologies (CISTI), 2015 10th Iberian Conference on\n%P 1-6\n%@ 9899843458\n%D 2015\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:00,587 DEBUG dbutils] Query result: 45
[2018-03-02 14:44:00,588 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Joao_Ulisses/publication/279289114_RAIN_in_indoor_rescue_training/links/55917bc108ae1e1f9baff509.pdf.
[2018-03-02 14:44:00,590 WARNING utils] Download file (url='https://www.researchgate.net/profile/Joao_Ulisses/publication/279289114_RAIN_in_indoor_rescue_training/links/55917bc108ae1e1f9baff509.pdf') and save (filename='PDF//45.pdf')
[2018-03-02 14:44:00,591 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:44:00,591 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:44:00,591 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for www.researchgate.net
[2018-03-02 14:44:00,608 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 14:44:02,615 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Joao_Ulisses/publication/279289114_RAIN_in_indoor_rescue_training/links/55917bc108ae1e1f9baff509.pdf HTTP/1.1" 200 612088
[2018-03-02 14:44:02,616 DEBUG utils] Content-length=612088
[2018-03-02 14:44:02,616 DEBUG utils] Create file PDF//45.pdf, start download.
[2018-03-02 14:44:04,816 DEBUG utils] End download file PDF//45.pdf.
[2018-03-02 14:44:04,818 DEBUG dbutils] Update pdf_transaction for paper id=45.
[2018-03-02 14:44:04,818 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 45'
[2018-03-02 14:44:04,818 DEBUG dbutils] Query result: null
[2018-03-02 14:44:04,837 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:44:04,837 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:44:04,837 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:44:04,851 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:44:07,276 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=50&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:44:08,184 DEBUG scholar] Find papers on page #6 (max_google_papers = 300)
[2018-03-02 14:44:08,184 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:44:08,184 DEBUG scholar] Handle paper #51 (total 1170)
[2018-03-02 14:44:08,184 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:44:08,187 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:08,188 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:44:08,188 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for scholar.google.com
[2018-03-02 14:44:08,202 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:10,882 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:zU37-DzwNagJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7oz0mYJwsuizJZtyGTdpHCy2gYxO5&scisf=3&ct=citation&cd=50&hl=en HTTP/1.1" 200 98
[2018-03-02 14:44:10,883 DEBUG scholar] EndNote file:
%0 Thesis
%T A chatbot service for use in video game development
%A Larsen, Alec John
%D 2015

[2018-03-02 14:44:10,883 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:10,883 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:10,883 DEBUG __main__] Process content of EndNote file #51
{"title": "A chatbot service for use in video game development", "url": "http://146.141.12.21/handle/10539/17551", "author": [{"shortname": "AJ Larsen", "gid": ""}], "year": 2015}
{"type": "Thesis", "title": "A chatbot service for use in video game development", "author": ["Larsen, Alec John"], "year": "2015", "EndNote": "%0 Thesis\n%T A chatbot service for use in video game development\n%A Larsen, Alec John\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:zU37-DzwNagJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7oz0mYJwsuizJZtyGTdpHCy2gYxO5&scisf=3&ct=citation&cd=50&hl=en"}
[2018-03-02 14:44:10,883 DEBUG dbutils] Get paper id {"DOI": null, "title": "A chatbot service for use in video game development", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:10,883 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A chatbot service for use in video game development', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:10,884 DEBUG dbutils] Query result: []
[2018-03-02 14:44:10,884 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:10,884 DEBUG dbutils] Add new paper (title='A chatbot service for use in video game development')
[2018-03-02 14:44:10,884 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A chatbot service for use in video game development', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T A chatbot service for use in video game development\n%A Larsen, Alec John\n%D 2015\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:10,884 DEBUG dbutils] Query result: 46
[2018-03-02 14:44:10,886 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://146.141.12.21/bitstream/handle/10539/17551/dissertation.pdf?sequence=2.
[2018-03-02 14:44:10,888 WARNING utils] Download file (url='http://146.141.12.21/bitstream/handle/10539/17551/dissertation.pdf?sequence=2') and save (filename='PDF//46.pdf')
[2018-03-02 14:44:10,888 DEBUG utils] Get current proxy for 146.141.12.21.
[2018-03-02 14:44:10,889 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:44:10,927 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): 146.141.12.21
[2018-03-02 14:44:11,735 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/handle/10539/17551/dissertation.pdf?sequence=2 HTTP/1.1" 200 1157651
[2018-03-02 14:44:11,736 DEBUG utils] Content-length=1157651
[2018-03-02 14:44:11,736 DEBUG utils] Create file PDF//46.pdf, start download.
[2018-03-02 14:44:15,996 DEBUG utils] End download file PDF//46.pdf.
[2018-03-02 14:44:15,999 DEBUG dbutils] Update pdf_transaction for paper id=46.
[2018-03-02 14:44:15,999 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 46'
[2018-03-02 14:44:15,999 DEBUG dbutils] Query result: null
[2018-03-02 14:44:16,002 DEBUG scholar] Handle paper #52 (total 1170)
[2018-03-02 14:44:16,002 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:44:16,008 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:16,009 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:44:16,497 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:mhmOh-BUKdYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o7QcL00cKfGphnOHN0MLk5UMeCLK&scisf=3&ct=citation&cd=51&hl=en HTTP/1.1" 200 339
[2018-03-02 14:44:16,498 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies
%A Opel, Simone
%A Brinda, Torsten
%B Proceedings of the 8th Workshop in Primary and Secondary Computing Education
%P 122-131
%@ 145032455X
%D 2013
%I ACM

[2018-03-02 14:44:16,498 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:16,498 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:16,498 DEBUG __main__] Process content of EndNote file #52
{"title": "Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies", "url": "https://dl.acm.org/citation.cfm?id=2532749", "author": [{"shortname": "S Opel", "gid": ""}, {"shortname": "T Brinda", "gid": ""}], "year": 2013}
{"citedby": 7, "type": "Conference Proceedings", "title": "Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies", "author": ["Opel, Simone", "Brinda, Torsten"], "secondarytitle": "Proceedings of the 8th Workshop in Primary and Secondary Computing Education", "pages": "122-131", "isbn/issn": "145032455X", "year": "2013", "publisher": "ACM", "start_page": 122, "end_page": 131, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies\n%A Opel, Simone\n%A Brinda, Torsten\n%B Proceedings of the 8th Workshop in Primary and Secondary Computing Education\n%P 122-131\n%@ 145032455X\n%D 2013\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:mhmOh-BUKdYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o7QcL00cKfGphnOHN0MLk5UMeCLK&scisf=3&ct=citation&cd=51&hl=en"}
[2018-03-02 14:44:16,498 DEBUG dbutils] Get paper id {"DOI": null, "title": "Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2013, "rg_id": null, "start_page": 122, "end_page": 131}.
[2018-03-02 14:44:16,498 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2013, 'rg_id': None, 'start_page': 122, 'end_page': 131}
[2018-03-02 14:44:16,498 DEBUG dbutils] Query result: []
[2018-03-02 14:44:16,499 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:16,499 DEBUG dbutils] Add new paper (title='Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies')
[2018-03-02 14:44:16,499 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies', 'year': 2013, 'publisher': 'ACM', 'start_page': 122, 'end_page': 131, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Arguments for contextual teaching with learning fields in vocational IT schools: results of an interview study among IT and CS training companies\n%A Opel, Simone\n%A Brinda, Torsten\n%B Proceedings of the 8th Workshop in Primary and Secondary Computing Education\n%P 122-131\n%@ 145032455X\n%D 2013\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:16,499 DEBUG dbutils] Query result: 47
[2018-03-02 14:44:16,500 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.wpunco.wiwi.uni-due.de/fileadmin/fileupload/I-DDI/sonstiges/publikationen/wipsce2013.pdf.
[2018-03-02 14:44:16,501 WARNING utils] Download file (url='https://www.wpunco.wiwi.uni-due.de/fileadmin/fileupload/I-DDI/sonstiges/publikationen/wipsce2013.pdf') and save (filename='PDF//47.pdf')
[2018-03-02 14:44:16,501 DEBUG utils] Get current proxy for www.wpunco.wiwi.uni-due.de.
[2018-03-02 14:44:16,502 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:44:16,502 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for otherhost
[2018-03-02 14:44:16,517 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.wpunco.wiwi.uni-due.de
[2018-03-02 14:44:18,026 DEBUG requests.packages.urllib3.connectionpool] "GET /fileadmin/fileupload/I-DDI/sonstiges/publikationen/wipsce2013.pdf HTTP/1.1" 200 982342
[2018-03-02 14:44:18,026 DEBUG utils] Content-length=982342
[2018-03-02 14:44:18,027 DEBUG utils] Create file PDF//47.pdf, start download.
[2018-03-02 14:44:23,144 DEBUG utils] End download file PDF//47.pdf.
[2018-03-02 14:44:23,145 DEBUG dbutils] Update pdf_transaction for paper id=47.
[2018-03-02 14:44:23,145 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 47'
[2018-03-02 14:44:23,146 DEBUG dbutils] Query result: null
[2018-03-02 14:44:23,148 DEBUG scholar] Handle paper #53 (total 1170)
[2018-03-02 14:44:23,148 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:44:23,151 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:23,152 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:44:23,152 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for scholar.google.com
[2018-03-02 14:44:23,170 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:25,964 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:7jTyWoZwAIgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7oytiNv-Ns7GkM0m1-MKk6IBXsFXd&scisf=3&ct=citation&cd=52&hl=en HTTP/1.1" 200 168
[2018-03-02 14:44:25,964 DEBUG scholar] EndNote file:
%0 Journal Article
%T The conversational interface
%A McTear, Michael
%A Callejas, Zoraida
%A Griol, David
%J Springer
%V 6
%N 94
%P 102
%D 2016
%I Springer

[2018-03-02 14:44:25,965 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:25,965 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:25,965 DEBUG __main__] Process content of EndNote file #53
{"title": "The conversational interface", "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-32967-3.pdf", "author": [{"shortname": "M McTear", "gid": "APTzAoIAAAAJ"}, {"shortname": "Z Callejas", "gid": "WE75b8AAAAAJ"}, {"shortname": "D Griol", "gid": ""}], "year": 2016}
{"citedby": 48, "type": "Journal Article", "title": "The conversational interface", "author": ["McTear, Michael", "Callejas, Zoraida", "Griol, David"], "journal": "Springer", "volume": "6", "numberorissue": "94", "pages": "102", "year": "2016", "publisher": "Springer", "EndNote": "%0 Journal Article\n%T The conversational interface\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%J Springer\n%V 6\n%N 94\n%P 102\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:7jTyWoZwAIgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7oytiNv-Ns7GkM0m1-MKk6IBXsFXd&scisf=3&ct=citation&cd=52&hl=en"}
[2018-03-02 14:44:25,965 DEBUG dbutils] Get paper id {"DOI": null, "title": "The conversational interface", "auth_count": 3, "g_type": "Journal Article", "pages": 6, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:25,965 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The conversational interface', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 6, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:25,965 DEBUG dbutils] Query result: []
[2018-03-02 14:44:25,965 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:25,965 DEBUG dbutils] Add new paper (title='The conversational interface')
[2018-03-02 14:44:25,965 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The conversational interface', 'year': 2016, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': 6, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The conversational interface\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%J Springer\n%V 6\n%N 94\n%P 102\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:25,966 DEBUG dbutils] Query result: 48
[2018-03-02 14:44:25,967 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/content/pdf/10.1007/978-3-319-32967-3.pdf.
[2018-03-02 14:44:25,967 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/content/pdf/10.1007/978-3-319-32967-3.pdf.
[2018-03-02 14:44:26,403 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-319-32967-3.pdf HTTP/1.1" 302 None
[2018-03-02 14:44:26,426 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:44:27,262 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=8E39F47C5FAFE43813BFB7A9BB633B35 HTTP/1.1" 200 9406
[2018-03-02 14:44:27,370 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:44:27,370 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:44:27,370 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for sci-hub.tw
[2018-03-02 14:44:27,564 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-319-32967-3.pdf HTTP/1.1" 302 None
[2018-03-02 14:44:27,869 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=8E39F47C5FAFE43813BFB7A9BB633B35 HTTP/1.1" 200 9406
[2018-03-02 14:44:28,071 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:44:28,072 DEBUG scholar] Handle paper #54 (total 1170)
[2018-03-02 14:44:28,072 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:44:28,078 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:28,078 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:44:28,574 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:FOFy8c11xj0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o0BgOByYpetArURTND-Mu42eTj2e&scisf=3&ct=citation&cd=53&hl=en HTTP/1.1" 200 315
[2018-03-02 14:44:28,575 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Towards a game-chatbot: extending the interaction in serious games
%A Van Rosmalen, Peter
%A Eikelboom, Johan
%A Bloemers, Erik
%A Van Winzum, Kees
%A Spronck, Pieter
%B European Conference on Games Based Learning
%P 525
%D 2012
%I Academic Conferences International Limited

[2018-03-02 14:44:28,575 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:28,575 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:28,575 DEBUG __main__] Process content of EndNote file #54
{"title": "Towards a game-chatbot: extending the interaction in serious games", "url": "http://search.proquest.com/openview/dd5077238a059c962d2848702de80b52/1?pq-origsite=gscholar&cbl=396495&casa_token=XZtKLkwcRCsAAAAA:C06qxTNNRIYxR8xZJI7ZDpHk7QD-i0fp48uH4L6S9KERcivvRL1uBwfIFwIhe7AlcLrmP27axJhw", "author": [{"shortname": "P Van Rosmalen", "gid": "0QAY2VQAAAAJ"}, {"shortname": "J Eikelboom", "gid": ""}], "year": 2012}
{"citedby": 3, "type": "Conference Proceedings", "title": "Towards a game-chatbot: extending the interaction in serious games", "author": ["Van Rosmalen, Peter", "Eikelboom, Johan", "Bloemers, Erik", "Van Winzum, Kees", "Spronck, Pieter"], "secondarytitle": "European Conference on Games Based Learning", "pages": "525", "year": "2012", "publisher": "Academic Conferences International Limited", "EndNote": "%0 Conference Proceedings\n%T Towards a game-chatbot: extending the interaction in serious games\n%A Van Rosmalen, Peter\n%A Eikelboom, Johan\n%A Bloemers, Erik\n%A Van Winzum, Kees\n%A Spronck, Pieter\n%B European Conference on Games Based Learning\n%P 525\n%D 2012\n%I Academic Conferences International Limited\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:FOFy8c11xj0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o0BgOByYpetArURTND-Mu42eTj2e&scisf=3&ct=citation&cd=53&hl=en"}
[2018-03-02 14:44:28,575 DEBUG dbutils] Get paper id {"DOI": null, "title": "Towards a game-chatbot: extending the interaction in serious games", "auth_count": 5, "g_type": "Conference Proceedings", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:28,576 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Towards a game-chatbot: extending the interaction in serious games', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:28,576 DEBUG dbutils] Query result: []
[2018-03-02 14:44:28,576 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:28,576 DEBUG dbutils] Add new paper (title='Towards a game-chatbot: extending the interaction in serious games')
[2018-03-02 14:44:28,576 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Towards a game-chatbot: extending the interaction in serious games', 'year': 2012, 'publisher': 'Academic Conferences International Limited', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Towards a game-chatbot: extending the interaction in serious games\n%A Van Rosmalen, Peter\n%A Eikelboom, Johan\n%A Bloemers, Erik\n%A Van Winzum, Kees\n%A Spronck, Pieter\n%B European Conference on Games Based Learning\n%P 525\n%D 2012\n%I Academic Conferences International Limited\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:28,576 DEBUG dbutils] Query result: 49
[2018-03-02 14:44:28,578 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://search.proquest.com/openview/dd5077238a059c962d2848702de80b52/1?pq-origsite=gscholar&cbl=396495&casa_token=XZtKLkwcRCsAAAAA:C06qxTNNRIYxR8xZJI7ZDpHk7QD-i0fp48uH4L6S9KERcivvRL1uBwfIFwIhe7AlcLrmP27axJhw.
[2018-03-02 14:44:28,578 DEBUG scihub] Get page from sci-hub for paper with DOI=http://search.proquest.com/openview/dd5077238a059c962d2848702de80b52/1?pq-origsite=gscholar&cbl=396495&casa_token=XZtKLkwcRCsAAAAA:C06qxTNNRIYxR8xZJI7ZDpHk7QD-i0fp48uH4L6S9KERcivvRL1uBwfIFwIhe7AlcLrmP27axJhw.
[2018-03-02 14:44:30,151 DEBUG requests.packages.urllib3.connectionpool] "GET //http://search.proquest.com/openview/dd5077238a059c962d2848702de80b52/1?pq-origsite=gscholar&cbl=396495&casa_token=XZtKLkwcRCsAAAAA:C06qxTNNRIYxR8xZJI7ZDpHk7QD-i0fp48uH4L6S9KERcivvRL1uBwfIFwIhe7AlcLrmP27axJhw HTTP/1.1" 200 None
[2018-03-02 14:44:30,152 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:44:30,152 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:44:30,973 DEBUG requests.packages.urllib3.connectionpool] "GET //http://search.proquest.com/openview/dd5077238a059c962d2848702de80b52/1?pq-origsite=gscholar&cbl=396495&casa_token=XZtKLkwcRCsAAAAA:C06qxTNNRIYxR8xZJI7ZDpHk7QD-i0fp48uH4L6S9KERcivvRL1uBwfIFwIhe7AlcLrmP27axJhw HTTP/1.1" 200 None
[2018-03-02 14:44:30,990 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:44:30,992 DEBUG scholar] Handle paper #55 (total 1170)
[2018-03-02 14:44:30,992 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:44:30,995 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:30,995 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:44:30,996 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for scholar.google.com
[2018-03-02 14:44:31,010 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:31,763 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QKhErTISoKQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o-eP5ccBWLMeqH4BsqhTn9qr5KN7&scisf=3&ct=citation&cd=54&hl=en HTTP/1.1" 200 323
[2018-03-02 14:44:31,764 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Shall I be your chat companion?: Towards an online human-computer conversation system
%A Yan, Rui
%A Song, Yiping
%A Zhou, Xiangyang
%A Wu, Hua
%B Proceedings of the 25th ACM International on Conference on Information and Knowledge Management
%P 649-658
%@ 1450340733
%D 2016
%I ACM

[2018-03-02 14:44:31,764 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:31,764 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:31,764 DEBUG __main__] Process content of EndNote file #55
{"title": "Shall I be your chat companion?: Towards an online human-computer conversation system", "url": "https://dl.acm.org/citation.cfm?id=2983360", "author": [{"shortname": "R Yan", "gid": "eLw6g-UAAAAJ"}, {"shortname": "Y Song", "gid": "dDZLrFAAAAAJ"}, {"shortname": "X Zhou", "gid": ""}, {"shortname": "H Wu", "gid": "9X2ThuAAAAAJ"}], "year": 2016}
{"citedby": 6, "type": "Conference Proceedings", "title": "Shall I be your chat companion?: Towards an online human-computer conversation system", "author": ["Yan, Rui", "Song, Yiping", "Zhou, Xiangyang", "Wu, Hua"], "secondarytitle": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management", "pages": "649-658", "isbn/issn": "1450340733", "year": "2016", "publisher": "ACM", "start_page": 649, "end_page": 658, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Shall I be your chat companion?: Towards an online human-computer conversation system\n%A Yan, Rui\n%A Song, Yiping\n%A Zhou, Xiangyang\n%A Wu, Hua\n%B Proceedings of the 25th ACM International on Conference on Information and Knowledge Management\n%P 649-658\n%@ 1450340733\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QKhErTISoKQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o-eP5ccBWLMeqH4BsqhTn9qr5KN7&scisf=3&ct=citation&cd=54&hl=en"}
[2018-03-02 14:44:31,765 DEBUG dbutils] Get paper id {"DOI": null, "title": "Shall I be your chat companion?: Towards an online human-computer conversation system", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 649, "end_page": 658}.
[2018-03-02 14:44:31,765 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Shall I be your chat companion?: Towards an online human-computer conversation system', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 649, 'end_page': 658}
[2018-03-02 14:44:31,765 DEBUG dbutils] Query result: []
[2018-03-02 14:44:31,765 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:31,765 DEBUG dbutils] Add new paper (title='Shall I be your chat companion?: Towards an online human-computer conversation system')
[2018-03-02 14:44:31,765 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Shall I be your chat companion?: Towards an online human-computer conversation system', 'year': 2016, 'publisher': 'ACM', 'start_page': 649, 'end_page': 658, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Shall I be your chat companion?: Towards an online human-computer conversation system\n%A Yan, Rui\n%A Song, Yiping\n%A Zhou, Xiangyang\n%A Wu, Hua\n%B Proceedings of the 25th ACM International on Conference on Information and Knowledge Management\n%P 649-658\n%@ 1450340733\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:31,765 DEBUG dbutils] Query result: 50
[2018-03-02 14:44:31,766 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.ruiyan.me/pubs/CIKM2016.pdf.
[2018-03-02 14:44:31,767 WARNING utils] Download file (url='http://www.ruiyan.me/pubs/CIKM2016.pdf') and save (filename='PDF//50.pdf')
[2018-03-02 14:44:31,767 DEBUG utils] Get current proxy for www.ruiyan.me.
[2018-03-02 14:44:31,767 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:44:31,784 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.ruiyan.me
[2018-03-02 14:44:32,775 DEBUG requests.packages.urllib3.connectionpool] "GET /pubs/CIKM2016.pdf HTTP/1.1" 200 None
[2018-03-02 14:44:32,776 DEBUG utils] Downloading the entire file.
[2018-03-02 14:44:32,776 DEBUG utils] Get current proxy for www.ruiyan.me.
[2018-03-02 14:44:32,776 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:44:32,776 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for otherhost
[2018-03-02 14:44:32,792 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.ruiyan.me
[2018-03-02 14:44:33,505 DEBUG requests.packages.urllib3.connectionpool] "GET /pubs/CIKM2016.pdf HTTP/1.1" 200 None
[2018-03-02 14:44:39,601 DEBUG utils] Save file PDF//50.pdf.
[2018-03-02 14:44:39,603 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2983360.
[2018-03-02 14:44:39,603 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2983360.
[2018-03-02 14:44:39,855 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2983360 HTTP/1.1" 200 None
[2018-03-02 14:44:39,856 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:44:39,856 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:44:39,856 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for sci-hub.tw
[2018-03-02 14:44:40,006 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2983360 HTTP/1.1" 200 None
[2018-03-02 14:44:40,014 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:44:40,015 DEBUG scholar] Handle paper #56 (total 1170)
[2018-03-02 14:44:40,015 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:44:40,018 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:40,018 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:44:40,223 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_A00Qk2FGU4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o2PQRzU-cdpAOlp-K7NsVp9qQQkG&scisf=3&ct=citation&cd=55&hl=en HTTP/1.1" 200 76
[2018-03-02 14:44:40,224 DEBUG scholar] EndNote file:
%0 Journal Article
%T Can Computers Think?
%A Aboul-Hosn, Kamal
%D 2004

[2018-03-02 14:44:40,224 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:40,224 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:40,224 DEBUG __main__] Process content of EndNote file #56
{"title": "Can Computers Think?", "url": "http://www.kamal.aboulhosn.org/cct/compthink.pdf", "author": [{"shortname": "K Aboul", "gid": ""}], "year": 2004}
{"type": "Journal Article", "title": "Can Computers Think?", "author": ["Aboul-Hosn, Kamal"], "year": "2004", "EndNote": "%0 Journal Article\n%T Can Computers Think?\n%A Aboul-Hosn, Kamal\n%D 2004\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_A00Qk2FGU4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o2PQRzU-cdpAOlp-K7NsVp9qQQkG&scisf=3&ct=citation&cd=55&hl=en"}
[2018-03-02 14:44:40,224 DEBUG dbutils] Get paper id {"DOI": null, "title": "Can Computers Think?", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2004, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:40,224 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Can Computers Think?', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2004, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:40,225 DEBUG dbutils] Query result: []
[2018-03-02 14:44:40,225 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:40,225 DEBUG dbutils] Add new paper (title='Can Computers Think?')
[2018-03-02 14:44:40,225 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Can Computers Think?', 'year': 2004, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Can Computers Think?\n%A Aboul-Hosn, Kamal\n%D 2004\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:40,225 DEBUG dbutils] Query result: 51
[2018-03-02 14:44:40,226 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.kamal.aboulhosn.org/cct/compthink.pdf.
[2018-03-02 14:44:40,227 WARNING utils] Download file (url='http://www.kamal.aboulhosn.org/cct/compthink.pdf') and save (filename='PDF//51.pdf')
[2018-03-02 14:44:40,228 DEBUG utils] Get current proxy for www.kamal.aboulhosn.org.
[2018-03-02 14:44:40,228 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:44:40,242 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.kamal.aboulhosn.org
[2018-03-02 14:44:40,816 DEBUG requests.packages.urllib3.connectionpool] "GET /cct/compthink.pdf HTTP/1.1" 200 275891
[2018-03-02 14:44:40,816 DEBUG utils] Content-length=275891
[2018-03-02 14:44:40,816 DEBUG utils] Create file PDF//51.pdf, start download.
[2018-03-02 14:44:42,596 DEBUG utils] End download file PDF//51.pdf.
[2018-03-02 14:44:42,597 DEBUG dbutils] Update pdf_transaction for paper id=51.
[2018-03-02 14:44:42,597 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 51'
[2018-03-02 14:44:42,597 DEBUG dbutils] Query result: null
[2018-03-02 14:44:42,598 DEBUG scholar] Handle paper #57 (total 1170)
[2018-03-02 14:44:42,598 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:44:42,601 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:42,602 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:44:42,602 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for scholar.google.com
[2018-03-02 14:44:42,618 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:44,811 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:LFMzpYsnbR8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o3iWHY7_E-myTKwjHgasQp27odp8&scisf=3&ct=citation&cd=56&hl=en HTTP/1.1" 200 226
[2018-03-02 14:44:44,812 DEBUG scholar] EndNote file:
%0 Book
%T Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy
%A Goertzel, Ben
%A Pennachin, Cassio
%A Geisweiller, Nil
%V 5
%@ 9462390274
%D 2014
%I Springer

[2018-03-02 14:44:44,812 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:44,812 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:44,812 DEBUG __main__] Process content of EndNote file #57
{"title": "Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy", "url": "https://books.google.com/books?hl=en&lr=&id=5Wm5BQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=COHyBNeblh&sig=Q6vmz3W3f5n6ud_wgEowTtb-Isc", "author": [{"shortname": "B Goertzel", "gid": ""}, {"shortname": "C Pennachin", "gid": ""}, {"shortname": "N Geisweiller", "gid": ""}], "year": 2014}
{"citedby": 26, "type": "Book", "title": "Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy", "author": ["Goertzel, Ben", "Pennachin, Cassio", "Geisweiller, Nil"], "volume": "5", "isbn/issn": "9462390274", "year": "2014", "publisher": "Springer", "EndNote": "%0 Book\n%T Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy\n%A Goertzel, Ben\n%A Pennachin, Cassio\n%A Geisweiller, Nil\n%V 5\n%@ 9462390274\n%D 2014\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:LFMzpYsnbR8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o3iWHY7_E-myTKwjHgasQp27odp8&scisf=3&ct=citation&cd=56&hl=en"}
[2018-03-02 14:44:44,812 DEBUG dbutils] Get paper id {"DOI": null, "title": "Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy", "auth_count": 3, "g_type": "Book", "pages": 5, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:44,812 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy', 'auth_count': 3, 'g_type': 'Book', 'pages': 5, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:44,812 DEBUG dbutils] Query result: []
[2018-03-02 14:44:44,812 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:44,813 DEBUG dbutils] Add new paper (title='Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy')
[2018-03-02 14:44:44,813 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy', 'year': 2014, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': 5, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Engineering General Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive Synergy\n%A Goertzel, Ben\n%A Pennachin, Cassio\n%A Geisweiller, Nil\n%V 5\n%@ 9462390274\n%D 2014\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:44,813 DEBUG dbutils] Query result: 52
[2018-03-02 14:44:44,814 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=5Wm5BQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=COHyBNeblh&sig=Q6vmz3W3f5n6ud_wgEowTtb-Isc.
[2018-03-02 14:44:44,814 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=5Wm5BQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=COHyBNeblh&sig=Q6vmz3W3f5n6ud_wgEowTtb-Isc.
[2018-03-02 14:44:45,034 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=5Wm5BQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=COHyBNeblh&sig=Q6vmz3W3f5n6ud_wgEowTtb-Isc HTTP/1.1" 302 None
[2018-03-02 14:44:45,223 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:44:45,241 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:44:45,241 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:44:45,423 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=5Wm5BQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=COHyBNeblh&sig=Q6vmz3W3f5n6ud_wgEowTtb-Isc HTTP/1.1" 302 None
[2018-03-02 14:44:45,623 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:44:45,650 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:44:45,651 DEBUG scholar] Handle paper #58 (total 1170)
[2018-03-02 14:44:45,651 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:44:45,655 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:45,655 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:44:46,117 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:8NUZoJva8nAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o65cksCGhTldi7ZB5YIGe0mhtzP1&scisf=3&ct=citation&cd=57&hl=en HTTP/1.1" 200 566
[2018-03-02 14:44:46,118 DEBUG scholar] EndNote file:
%0 Journal Article
%T In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...
%A Panda, Soumya Priyadarsini
%A Nayak, Ajit Kumar
%J International Journal of Speech Technology
%V 19
%N 1
%P 121-134
%D 2016

[2018-03-02 14:44:46,118 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:46,118 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:46,118 DEBUG __main__] Process content of EndNote file #58
{"title": "\u2026\u00a0features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and\u00a0\u2026", "url": "https://www.infona.pl/resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8", "author": [{"shortname": "SP Panda", "gid": ""}, {"shortname": "AK Nayak", "gid": "ZRPZEt4AAAAJ"}], "year": 2016}
{"type": "Journal Article", "title": "In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...", "author": ["Panda, Soumya Priyadarsini", "Nayak, Ajit Kumar"], "journal": "International Journal of Speech Technology", "volume": 14, "numberorissue": "1", "pages": "121-134", "year": "2016", "start_page": 121, "end_page": 134, "EndNote": "%0 Journal Article\n%T In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...\n%A Panda, Soumya Priyadarsini\n%A Nayak, Ajit Kumar\n%J International Journal of Speech Technology\n%V 19\n%N 1\n%P 121-134\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:8NUZoJva8nAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o65cksCGhTldi7ZB5YIGe0mhtzP1&scisf=3&ct=citation&cd=57&hl=en"}
[2018-03-02 14:44:46,118 DEBUG dbutils] Get paper id {"DOI": null, "title": "In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...", "auth_count": 2, "g_type": "Journal Article", "pages": 14, "year": 2016, "rg_id": null, "start_page": 121, "end_page": 134}.
[2018-03-02 14:44:46,119 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 14, 'year': 2016, 'rg_id': None, 'start_page': 121, 'end_page': 134}
[2018-03-02 14:44:46,119 DEBUG dbutils] Query result: []
[2018-03-02 14:44:46,119 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:46,119 DEBUG dbutils] Add new paper (title='In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...')
[2018-03-02 14:44:46,119 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...', 'year': 2016, 'publisher': None, 'start_page': 121, 'end_page': 134, 'pages': 14, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T In our previous works, we have explored articulatory and excitation source features to improve the performance of phone recognition systems (PRSs) using read speech corpora. In this work, we have extended the use of articulatory and excitation source features for developing PRSs of extempore and conversation modes of speech, in addition to the read speech. It is well known that the overall performance...\n%A Panda, Soumya Priyadarsini\n%A Nayak, Ajit Kumar\n%J International Journal of Speech Technology\n%V 19\n%N 1\n%P 121-134\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:46,119 DEBUG dbutils] Query result: 53
[2018-03-02 14:44:46,120 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.infona.pl/resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8.
[2018-03-02 14:44:46,121 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.infona.pl/resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8.
[2018-03-02 14:44:46,333 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.infona.pl/resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8 HTTP/1.1" 302 None
[2018-03-02 14:44:46,355 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.infona.pl
[2018-03-02 14:44:46,963 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8 HTTP/1.1" 302 0
[2018-03-02 14:44:47,148 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-000000010772/tab/jContent/facet?field=%5EjournalYear&value=%5E_02016&resourceId=bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8&tabType=summary&availability=NOT_AVAILABLE&supportedAjaxTabs=references&supportedAjaxTabs=contributors&supportedAjaxTabs=jContent HTTP/1.1" 302 0
[2018-03-02 14:44:47,439 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-000000010772/tab/jContent?q=sc*op*l_0*c_0journalYear_0FACET%3Aeq%3A78152e3a-a0f8-4561-afbc-e13862e03918._002016*p_0cP.1&localeQueryString=field%3D%255EjournalYear%26value%3D%255E_02016%26resourceId%3Dbwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8%26tabType%3Dsummary%26availability%3DNOT_AVAILABLE%26supportedAjaxTabs%3Dreferences%26supportedAjaxTabs%3Dcontributors%26supportedAjaxTabs%3DjContent HTTP/1.1" 200 None
[2018-03-02 14:44:47,685 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:44:47,685 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:44:47,685 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for sci-hub.tw
[2018-03-02 14:44:47,895 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.infona.pl/resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8 HTTP/1.1" 302 None
[2018-03-02 14:44:47,918 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.infona.pl
[2018-03-02 14:44:48,973 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8 HTTP/1.1" 302 0
[2018-03-02 14:44:49,183 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-000000010772/tab/jContent/facet?field=%5EjournalYear&value=%5E_02016&resourceId=bwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8&tabType=summary&availability=NOT_AVAILABLE&supportedAjaxTabs=references&supportedAjaxTabs=contributors&supportedAjaxTabs=jContent HTTP/1.1" 302 0
[2018-03-02 14:44:49,477 DEBUG requests.packages.urllib3.connectionpool] "GET /resource/bwmeta1.element.springer-000000010772/tab/jContent?q=sc*op*l_0*c_0journalYear_0FACET%3Aeq%3Ace9807fc-cafc-4694-832c-e2a6cbb679af._002016*p_0cP.1&localeQueryString=field%3D%255EjournalYear%26value%3D%255E_02016%26resourceId%3Dbwmeta1.element.springer-3022cf9f-b30d-39b7-bace-f5cb922699a8%26tabType%3Dsummary%26availability%3DNOT_AVAILABLE%26supportedAjaxTabs%3Dreferences%26supportedAjaxTabs%3Dcontributors%26supportedAjaxTabs%3DjContent HTTP/1.1" 200 None
[2018-03-02 14:44:49,922 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:44:49,923 DEBUG scholar] Handle paper #59 (total 1170)
[2018-03-02 14:44:49,924 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:44:49,928 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:49,928 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:44:49,928 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for scholar.google.com
[2018-03-02 14:44:49,944 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:44:53,435 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:mO4m-jVV0aIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o54MAqv6DrJfMdHYnjO8D-W90B06&scisf=3&ct=citation&cd=58&hl=en HTTP/1.1" 200 202
[2018-03-02 14:44:53,436 DEBUG scholar] EndNote file:
%0 Journal Article
%T Emulating human conversations using convolutional neural network-based IR
%A Prakash, Abhay
%A Brockett, Chris
%A Agrawal, Puneet
%J arXiv preprint arXiv:1606.07056
%D 2016

[2018-03-02 14:44:53,436 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:53,436 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:53,436 DEBUG __main__] Process content of EndNote file #59
{"title": "Emulating human conversations using convolutional neural network-based IR", "url": "https://arxiv.org/abs/1606.07056", "author": [{"shortname": "A Prakash", "gid": "W6lI59sAAAAJ"}, {"shortname": "C Brockett", "gid": "xBvFANIAAAAJ"}, {"shortname": "P Agrawal", "gid": ""}], "year": 1606}
{"citedby": 6, "type": "Journal Article", "title": "Emulating human conversations using convolutional neural network-based IR", "author": ["Prakash, Abhay", "Brockett, Chris", "Agrawal, Puneet"], "journal": "arXiv preprint arXiv:1606.07056", "year": "2016", "EndNote": "%0 Journal Article\n%T Emulating human conversations using convolutional neural network-based IR\n%A Prakash, Abhay\n%A Brockett, Chris\n%A Agrawal, Puneet\n%J arXiv preprint arXiv:1606.07056\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:mO4m-jVV0aIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o54MAqv6DrJfMdHYnjO8D-W90B06&scisf=3&ct=citation&cd=58&hl=en"}
[2018-03-02 14:44:53,436 DEBUG dbutils] Get paper id {"DOI": null, "title": "Emulating human conversations using convolutional neural network-based IR", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:44:53,436 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Emulating human conversations using convolutional neural network-based IR', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:44:53,436 DEBUG dbutils] Query result: []
[2018-03-02 14:44:53,436 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:53,437 DEBUG dbutils] Add new paper (title='Emulating human conversations using convolutional neural network-based IR')
[2018-03-02 14:44:53,437 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Emulating human conversations using convolutional neural network-based IR', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Emulating human conversations using convolutional neural network-based IR\n%A Prakash, Abhay\n%A Brockett, Chris\n%A Agrawal, Puneet\n%J arXiv preprint arXiv:1606.07056\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:53,437 DEBUG dbutils] Query result: 54
[2018-03-02 14:44:53,438 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1606.07056.
[2018-03-02 14:44:53,438 WARNING utils] Download file (url='https://arxiv.org/pdf/1606.07056') and save (filename='PDF//54.pdf')
[2018-03-02 14:44:53,439 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:44:53,439 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:44:53,439 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for otherhost
[2018-03-02 14:44:53,454 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:44:55,633 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.07056 HTTP/1.1" 302 280
[2018-03-02 14:44:56,445 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.07056.pdf HTTP/1.1" 200 748227
[2018-03-02 14:44:56,446 DEBUG utils] Content-length=748227
[2018-03-02 14:44:56,447 DEBUG utils] Create file PDF//54.pdf, start download.
[2018-03-02 14:44:58,935 DEBUG utils] End download file PDF//54.pdf.
[2018-03-02 14:44:58,936 DEBUG dbutils] Update pdf_transaction for paper id=54.
[2018-03-02 14:44:58,937 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 54'
[2018-03-02 14:44:58,937 DEBUG dbutils] Query result: null
[2018-03-02 14:44:58,937 DEBUG scholar] Handle paper #60 (total 1170)
[2018-03-02 14:44:58,937 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:44:58,941 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:44:58,941 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:44:59,323 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:HwOp-zCMseMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o9nseeATUR3iTr5PiLithvR3iT2i&scisf=3&ct=citation&cd=59&hl=en HTTP/1.1" 200 268
[2018-03-02 14:44:59,324 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Conversational Recommendation System with Unsupervised Learning
%A Sun, Yueming
%A Zhang, Yi
%A Chen, Yunfei
%A Jin, Roger
%B Proceedings of the 10th ACM Conference on Recommender Systems
%P 397-398
%@ 1450340350
%D 2016
%I ACM

[2018-03-02 14:44:59,324 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:44:59,324 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:44:59,325 DEBUG __main__] Process content of EndNote file #60
{"title": "Conversational Recommendation System with Unsupervised Learning", "url": "https://dl.acm.org/citation.cfm?id=2959114", "author": [{"shortname": "Y Sun", "gid": "UOYpBu4AAAAJ"}, {"shortname": "Y Zhang", "gid": ""}, {"shortname": "Y Chen", "gid": ""}, {"shortname": "R Jin", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "Conversational Recommendation System with Unsupervised Learning", "author": ["Sun, Yueming", "Zhang, Yi", "Chen, Yunfei", "Jin, Roger"], "secondarytitle": "Proceedings of the 10th ACM Conference on Recommender Systems", "pages": "397-398", "isbn/issn": "1450340350", "year": "2016", "publisher": "ACM", "start_page": 397, "end_page": 398, "volume": 2, "EndNote": "%0 Conference Proceedings\n%T Conversational Recommendation System with Unsupervised Learning\n%A Sun, Yueming\n%A Zhang, Yi\n%A Chen, Yunfei\n%A Jin, Roger\n%B Proceedings of the 10th ACM Conference on Recommender Systems\n%P 397-398\n%@ 1450340350\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:HwOp-zCMseMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk7o9nseeATUR3iTr5PiLithvR3iT2i&scisf=3&ct=citation&cd=59&hl=en"}
[2018-03-02 14:44:59,325 DEBUG dbutils] Get paper id {"DOI": null, "title": "Conversational Recommendation System with Unsupervised Learning", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 2, "year": 2016, "rg_id": null, "start_page": 397, "end_page": 398}.
[2018-03-02 14:44:59,325 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Conversational Recommendation System with Unsupervised Learning', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 2, 'year': 2016, 'rg_id': None, 'start_page': 397, 'end_page': 398}
[2018-03-02 14:44:59,325 DEBUG dbutils] Query result: []
[2018-03-02 14:44:59,325 DEBUG dbutils] Paper id = None.
[2018-03-02 14:44:59,325 DEBUG dbutils] Add new paper (title='Conversational Recommendation System with Unsupervised Learning')
[2018-03-02 14:44:59,325 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Conversational Recommendation System with Unsupervised Learning', 'year': 2016, 'publisher': 'ACM', 'start_page': 397, 'end_page': 398, 'pages': 2, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Conversational Recommendation System with Unsupervised Learning\n%A Sun, Yueming\n%A Zhang, Yi\n%A Chen, Yunfei\n%A Jin, Roger\n%B Proceedings of the 10th ACM Conference on Recommender Systems\n%P 397-398\n%@ 1450340350\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:44:59,325 DEBUG dbutils] Query result: 55
[2018-03-02 14:44:59,327 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1610.01546.
[2018-03-02 14:44:59,328 WARNING utils] Download file (url='https://arxiv.org/pdf/1610.01546') and save (filename='PDF//55.pdf')
[2018-03-02 14:44:59,328 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:44:59,328 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:44:59,683 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1610.01546 HTTP/1.1" 302 280
[2018-03-02 14:45:00,533 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1610.01546.pdf HTTP/1.1" 200 439205
[2018-03-02 14:45:00,534 DEBUG utils] Content-length=439205
[2018-03-02 14:45:00,534 DEBUG utils] Create file PDF//55.pdf, start download.
[2018-03-02 14:45:01,932 DEBUG utils] End download file PDF//55.pdf.
[2018-03-02 14:45:01,934 DEBUG dbutils] Update pdf_transaction for paper id=55.
[2018-03-02 14:45:01,934 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 55'
[2018-03-02 14:45:01,934 DEBUG dbutils] Query result: null
[2018-03-02 14:45:01,952 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:45:01,952 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:45:01,952 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:45:01,953 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for scholar.google.com
[2018-03-02 14:45:01,967 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:45:04,955 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=60&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:45:05,702 DEBUG scholar] Find papers on page #7 (max_google_papers = 300)
[2018-03-02 14:45:05,703 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:45:05,703 DEBUG scholar] Handle paper #61 (total 1170)
[2018-03-02 14:45:05,703 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:45:05,707 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:05,707 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:45:05,724 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:45:08,102 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Y41JWCVBGSYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73R9ymEoa-YBIhGuuqUsKQMYvlNml&scisf=3&ct=citation&cd=60&hl=en HTTP/1.1" 200 269
[2018-03-02 14:45:08,103 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.
%A Serban, Iulian Vlad
%A Sordoni, Alessandro
%A Bengio, Yoshua
%A Courville, Aaron C
%A Pineau, Joelle
%B AAAI
%V 16
%P 3776-3784
%D 2016

[2018-03-02 14:45:08,103 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:08,103 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:08,103 DEBUG __main__] Process content of EndNote file #61
{"title": "Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.", "url": "http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160", "author": [{"shortname": "IV Serban", "gid": "0g31OfAAAAAJ"}, {"shortname": "A Sordoni", "gid": "DJon7w4AAAAJ"}, {"shortname": "Y Bengio", "gid": "kukA0LcAAAAJ"}, {"shortname": "AC Courville", "gid": "km6CP8cAAAAJ"}, {"shortname": "J Pineau", "gid": "CEt6_mMAAAAJ"}], "year": 2016}
{"citedby": 220, "type": "Conference Proceedings", "title": "Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.", "author": ["Serban, Iulian Vlad", "Sordoni, Alessandro", "Bengio, Yoshua", "Courville, Aaron C", "Pineau, Joelle"], "secondarytitle": "AAAI", "volume": 9, "pages": "3776-3784", "year": "2016", "start_page": 3776, "end_page": 3784, "EndNote": "%0 Conference Proceedings\n%T Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.\n%A Serban, Iulian Vlad\n%A Sordoni, Alessandro\n%A Bengio, Yoshua\n%A Courville, Aaron C\n%A Pineau, Joelle\n%B AAAI\n%V 16\n%P 3776-3784\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Y41JWCVBGSYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73R9ymEoa-YBIhGuuqUsKQMYvlNml&scisf=3&ct=citation&cd=60&hl=en"}
[2018-03-02 14:45:08,103 DEBUG dbutils] Get paper id {"DOI": null, "title": "Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 9, "year": 2016, "rg_id": null, "start_page": 3776, "end_page": 3784}.
[2018-03-02 14:45:08,104 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 9, 'year': 2016, 'rg_id': None, 'start_page': 3776, 'end_page': 3784}
[2018-03-02 14:45:08,104 DEBUG dbutils] Query result: []
[2018-03-02 14:45:08,104 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:08,104 DEBUG dbutils] Add new paper (title='Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.')
[2018-03-02 14:45:08,104 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.', 'year': 2016, 'publisher': None, 'start_page': 3776, 'end_page': 3784, 'pages': 9, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.\n%A Serban, Iulian Vlad\n%A Sordoni, Alessandro\n%A Bengio, Yoshua\n%A Courville, Aaron C\n%A Pineau, Joelle\n%B AAAI\n%V 16\n%P 3776-3784\n%D 2016\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:08,104 DEBUG dbutils] Query result: 56
[2018-03-02 14:45:08,105 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160.
[2018-03-02 14:45:08,109 WARNING utils] Download file (url='http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160') and save (filename='PDF//56.pdf')
[2018-03-02 14:45:08,109 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 14:45:08,109 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:45:08,109 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for otherhost
[2018-03-02 14:45:08,126 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aaai.org
[2018-03-02 14:45:08,922 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/AAAI/AAAI16/paper/download/11957/12160 HTTP/1.1" 200 None
[2018-03-02 14:45:08,932 DEBUG utils] Try get PDF from https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160.
[2018-03-02 14:45:08,932 WARNING utils] Download file (url='https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160') and save (filename='PDF//56.pdf')
[2018-03-02 14:45:08,932 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 14:45:08,932 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:45:08,946 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.aaai.org
[2018-03-02 14:45:11,165 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/AAAI/AAAI16/paper/download/11957/12160 HTTP/1.1" 200 752383
[2018-03-02 14:45:11,165 DEBUG utils] Content-length=752383
[2018-03-02 14:45:11,166 DEBUG utils] Create file PDF//56.pdf, start download.
[2018-03-02 14:45:13,590 DEBUG utils] End download file PDF//56.pdf.
[2018-03-02 14:45:13,591 DEBUG dbutils] Update pdf_transaction for paper id=56.
[2018-03-02 14:45:13,591 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 56'
[2018-03-02 14:45:13,592 DEBUG dbutils] Query result: null
[2018-03-02 14:45:13,592 DEBUG scholar] Handle paper #62 (total 1170)
[2018-03-02 14:45:13,592 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:45:13,596 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:13,596 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:45:13,596 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for scholar.google.com
[2018-03-02 14:45:13,612 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:45:14,926 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ZfPDUDcE--0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73UKQw3H39W1S3vau8IMSSAQQ0rbA&scisf=3&ct=citation&cd=61&hl=en HTTP/1.1" 200 239
[2018-03-02 14:45:14,927 DEBUG scholar] EndNote file:
%0 Journal Article
%T The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems
%A Lowe, Ryan
%A Pow, Nissan
%A Serban, Iulian
%A Pineau, Joelle
%J arXiv preprint arXiv:1506.08909
%D 2015

[2018-03-02 14:45:14,927 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:14,927 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:14,927 DEBUG __main__] Process content of EndNote file #62
{"title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "url": "https://arxiv.org/abs/1506.08909", "author": [{"shortname": "R Lowe", "gid": "iRgYMuEAAAAJ"}, {"shortname": "N Pow", "gid": ""}, {"shortname": "I Serban", "gid": "0g31OfAAAAAJ"}, {"shortname": "J Pineau", "gid": "CEt6_mMAAAAJ"}], "year": 1506}
{"citedby": 119, "type": "Journal Article", "title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "author": ["Lowe, Ryan", "Pow, Nissan", "Serban, Iulian", "Pineau, Joelle"], "journal": "arXiv preprint arXiv:1506.08909", "year": "2015", "EndNote": "%0 Journal Article\n%T The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems\n%A Lowe, Ryan\n%A Pow, Nissan\n%A Serban, Iulian\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1506.08909\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ZfPDUDcE--0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73UKQw3H39W1S3vau8IMSSAQQ0rbA&scisf=3&ct=citation&cd=61&hl=en"}
[2018-03-02 14:45:14,927 DEBUG dbutils] Get paper id {"DOI": null, "title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:45:14,927 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:45:14,928 DEBUG dbutils] Query result: []
[2018-03-02 14:45:14,928 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:14,928 DEBUG dbutils] Add new paper (title='The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems')
[2018-03-02 14:45:14,928 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems\n%A Lowe, Ryan\n%A Pow, Nissan\n%A Serban, Iulian\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1506.08909\n%D 2015\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:14,928 DEBUG dbutils] Query result: 57
[2018-03-02 14:45:14,930 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1506.08909.
[2018-03-02 14:45:14,931 WARNING utils] Download file (url='https://arxiv.org/pdf/1506.08909') and save (filename='PDF//57.pdf')
[2018-03-02 14:45:14,931 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:45:14,931 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:45:14,931 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for otherhost
[2018-03-02 14:45:14,946 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:45:17,093 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1506.08909 HTTP/1.1" 302 280
[2018-03-02 14:45:18,055 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1506.08909.pdf HTTP/1.1" 200 324563
[2018-03-02 14:45:18,055 DEBUG utils] Content-length=324563
[2018-03-02 14:45:18,056 DEBUG utils] Create file PDF//57.pdf, start download.
[2018-03-02 14:45:19,278 DEBUG utils] End download file PDF//57.pdf.
[2018-03-02 14:45:19,279 DEBUG dbutils] Update pdf_transaction for paper id=57.
[2018-03-02 14:45:19,279 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 57'
[2018-03-02 14:45:19,279 DEBUG dbutils] Query result: null
[2018-03-02 14:45:19,280 DEBUG scholar] Handle paper #63 (total 1170)
[2018-03-02 14:45:19,280 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:45:19,284 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:19,284 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 14:45:19,503 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4CTwBkxtnL4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73VHE1wprHT2qUah-jDFXFyrFwgFu&scisf=3&ct=citation&cd=62&hl=en HTTP/1.1" 200 286
[2018-03-02 14:45:19,504 DEBUG scholar] EndNote file:
%0 Journal Article
%T Providing language instructor with artificial intelligence assistant
%A Pietroszek, Krzysztof
%J International Journal of Emerging Technologies in Learning (iJET)
%V 2
%N 4
%P 61-65
%@ 1863-0383
%D 2007
%I International Association of Online Engineering

[2018-03-02 14:45:19,504 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:19,504 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:19,504 DEBUG __main__] Process content of EndNote file #63
{"title": "Providing language instructor with artificial intelligence assistant", "url": "https://www.learntechlib.org/p/45318/", "author": [{"shortname": "K Pietroszek", "gid": "gDAXkq8AAAAJ"}], "year": 2007}
{"citedby": 2, "type": "Journal Article", "title": "Providing language instructor with artificial intelligence assistant", "author": ["Pietroszek, Krzysztof"], "journal": "International Journal of Emerging Technologies in Learning (iJET)", "volume": 5, "numberorissue": "4", "pages": "61-65", "isbn/issn": "1863-0383", "year": "2007", "publisher": "International Association of Online Engineering", "start_page": 61, "end_page": 65, "EndNote": "%0 Journal Article\n%T Providing language instructor with artificial intelligence assistant\n%A Pietroszek, Krzysztof\n%J International Journal of Emerging Technologies in Learning (iJET)\n%V 2\n%N 4\n%P 61-65\n%@ 1863-0383\n%D 2007\n%I International Association of Online Engineering\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4CTwBkxtnL4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73VHE1wprHT2qUah-jDFXFyrFwgFu&scisf=3&ct=citation&cd=62&hl=en"}
[2018-03-02 14:45:19,504 DEBUG dbutils] Get paper id {"DOI": null, "title": "Providing language instructor with artificial intelligence assistant", "auth_count": 1, "g_type": "Journal Article", "pages": 5, "year": 2007, "rg_id": null, "start_page": 61, "end_page": 65}.
[2018-03-02 14:45:19,504 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Providing language instructor with artificial intelligence assistant', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 5, 'year': 2007, 'rg_id': None, 'start_page': 61, 'end_page': 65}
[2018-03-02 14:45:19,505 DEBUG dbutils] Query result: []
[2018-03-02 14:45:19,505 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:19,505 DEBUG dbutils] Add new paper (title='Providing language instructor with artificial intelligence assistant')
[2018-03-02 14:45:19,505 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Providing language instructor with artificial intelligence assistant', 'year': 2007, 'publisher': 'International Association of Online Engineering', 'start_page': 61, 'end_page': 65, 'pages': 5, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Providing language instructor with artificial intelligence assistant\n%A Pietroszek, Krzysztof\n%J International Journal of Emerging Technologies in Learning (iJET)\n%V 2\n%N 4\n%P 61-65\n%@ 1863-0383\n%D 2007\n%I International Association of Online Engineering\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:19,505 DEBUG dbutils] Query result: 58
[2018-03-02 14:45:19,506 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/45318/article_45318.pdf.
[2018-03-02 14:45:19,507 WARNING utils] Download file (url='https://www.learntechlib.org/p/45318/article_45318.pdf') and save (filename='PDF//58.pdf')
[2018-03-02 14:45:19,507 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 14:45:19,507 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:45:19,523 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:45:22,186 DEBUG requests.packages.urllib3.connectionpool] "GET /p/45318/article_45318.pdf HTTP/1.1" 200 None
[2018-03-02 14:45:22,187 DEBUG utils] Downloading the entire file.
[2018-03-02 14:45:22,187 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 14:45:22,187 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:45:22,187 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for otherhost
[2018-03-02 14:45:22,202 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:45:25,055 DEBUG requests.packages.urllib3.connectionpool] "GET /p/45318/article_45318.pdf HTTP/1.1" 200 None
[2018-03-02 14:45:26,004 DEBUG utils] Save file PDF//58.pdf.
[2018-03-02 14:45:26,005 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/45318/.
[2018-03-02 14:45:26,005 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/45318/.
[2018-03-02 14:45:26,202 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/45318/ HTTP/1.1" 302 None
[2018-03-02 14:45:26,225 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.learntechlib.org
[2018-03-02 14:45:27,192 DEBUG requests.packages.urllib3.connectionpool] "GET /p/45318/ HTTP/1.1" 200 16902
[2018-03-02 14:45:27,194 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:45:27,194 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:45:27,382 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/45318/ HTTP/1.1" 302 None
[2018-03-02 14:45:27,406 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 14:45:29,064 DEBUG requests.packages.urllib3.connectionpool] "GET /p/45318/ HTTP/1.1" 200 16904
[2018-03-02 14:45:29,146 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:45:29,147 DEBUG scholar] Handle paper #64 (total 1170)
[2018-03-02 14:45:29,148 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:45:29,151 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:29,151 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 14:45:29,151 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for scholar.google.com
[2018-03-02 14:45:29,168 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:45:32,202 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_VtCL2n3uOIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73TkFCsUwc-o4OvKC_IzSfnwwJWKJ&scisf=3&ct=citation&cd=63&hl=en HTTP/1.1" 200 176
[2018-03-02 14:45:32,204 DEBUG scholar] EndNote file:
%0 Journal Article
%T The Cogs Are Coming: The Cognitive Augmentation Revolution.
%A Fulbright, Ron
%J Association Supporting Computer Users in Education
%D 2016
%I ERIC

[2018-03-02 14:45:32,205 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:32,206 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:32,206 DEBUG __main__] Process content of EndNote file #64
{"title": "The Cogs Are Coming: The Cognitive Augmentation Revolution.", "url": "https://eric.ed.gov/?id=ED570900", "author": [{"shortname": "R Fulbright", "gid": ""}], "year": 2016}
{"citedby": 2, "type": "Journal Article", "title": "The Cogs Are Coming: The Cognitive Augmentation Revolution.", "author": ["Fulbright, Ron"], "journal": "Association Supporting Computer Users in Education", "year": "2016", "publisher": "ERIC", "EndNote": "%0 Journal Article\n%T The Cogs Are Coming: The Cognitive Augmentation Revolution.\n%A Fulbright, Ron\n%J Association Supporting Computer Users in Education\n%D 2016\n%I ERIC\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_VtCL2n3uOIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73TkFCsUwc-o4OvKC_IzSfnwwJWKJ&scisf=3&ct=citation&cd=63&hl=en"}
[2018-03-02 14:45:32,206 DEBUG dbutils] Get paper id {"DOI": null, "title": "The Cogs Are Coming: The Cognitive Augmentation Revolution.", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:45:32,207 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The Cogs Are Coming: The Cognitive Augmentation Revolution.', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:45:32,207 DEBUG dbutils] Query result: []
[2018-03-02 14:45:32,207 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:32,207 DEBUG dbutils] Add new paper (title='The Cogs Are Coming: The Cognitive Augmentation Revolution.')
[2018-03-02 14:45:32,207 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The Cogs Are Coming: The Cognitive Augmentation Revolution.', 'year': 2016, 'publisher': 'ERIC', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The Cogs Are Coming: The Cognitive Augmentation Revolution.\n%A Fulbright, Ron\n%J Association Supporting Computer Users in Education\n%D 2016\n%I ERIC\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:32,207 DEBUG dbutils] Query result: 59
[2018-03-02 14:45:32,209 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://files.eric.ed.gov/fulltext/ED570900.pdf.
[2018-03-02 14:45:32,211 WARNING utils] Download file (url='https://files.eric.ed.gov/fulltext/ED570900.pdf') and save (filename='PDF//59.pdf')
[2018-03-02 14:45:32,211 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 14:45:32,211 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:45:32,230 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 14:45:34,842 DEBUG requests.packages.urllib3.connectionpool] "GET /fulltext/ED570900.pdf HTTP/1.1" 200 115404
[2018-03-02 14:45:34,842 DEBUG utils] Content-length=115404
[2018-03-02 14:45:34,843 DEBUG utils] Create file PDF//59.pdf, start download.
[2018-03-02 14:45:35,492 DEBUG utils] End download file PDF//59.pdf.
[2018-03-02 14:45:35,493 DEBUG dbutils] Update pdf_transaction for paper id=59.
[2018-03-02 14:45:35,493 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 59'
[2018-03-02 14:45:35,493 DEBUG dbutils] Query result: null
[2018-03-02 14:45:35,494 DEBUG scholar] Handle paper #65 (total 1170)
[2018-03-02 14:45:35,494 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:45:35,497 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:35,497 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:45:36,091 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:791oK3wb1jYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73RR-maJUte4mAmXhxGFyCaPfpcdJ&scisf=3&ct=citation&cd=64&hl=en HTTP/1.1" 200 231
[2018-03-02 14:45:36,092 DEBUG scholar] EndNote file:
%0 Journal Article
%T A kst-based system for student tutoring
%A Pilato, Giovanni
%A Pirrone, Roberto
%A Rizzo, Riccardo
%J Applied Artificial Intelligence
%V 22
%N 4
%P 283-308
%@ 0883-9514
%D 2008
%I Taylor & Francis

[2018-03-02 14:45:36,092 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:36,092 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:36,092 DEBUG __main__] Process content of EndNote file #65
{"title": "A kst-based system for student tutoring", "url": "http://www.tandfonline.com/doi/abs/10.1080/08839510801972785", "author": [{"shortname": "G Pilato", "gid": "fAPQPiUAAAAJ"}, {"shortname": "R Pirrone", "gid": "OUXqfHsAAAAJ"}, {"shortname": "R Rizzo", "gid": "Srf4GfwAAAAJ"}], "year": 2008}
{"citedby": 32, "type": "Journal Article", "title": "A kst-based system for student tutoring", "author": ["Pilato, Giovanni", "Pirrone, Roberto", "Rizzo, Riccardo"], "journal": "Applied Artificial Intelligence", "volume": 26, "numberorissue": "4", "pages": "283-308", "isbn/issn": "0883-9514", "year": "2008", "publisher": "Taylor & Francis", "start_page": 283, "end_page": 308, "EndNote": "%0 Journal Article\n%T A kst-based system for student tutoring\n%A Pilato, Giovanni\n%A Pirrone, Roberto\n%A Rizzo, Riccardo\n%J Applied Artificial Intelligence\n%V 22\n%N 4\n%P 283-308\n%@ 0883-9514\n%D 2008\n%I Taylor & Francis\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:791oK3wb1jYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73RR-maJUte4mAmXhxGFyCaPfpcdJ&scisf=3&ct=citation&cd=64&hl=en"}
[2018-03-02 14:45:36,092 DEBUG dbutils] Get paper id {"DOI": null, "title": "A kst-based system for student tutoring", "auth_count": 3, "g_type": "Journal Article", "pages": 26, "year": 2008, "rg_id": null, "start_page": 283, "end_page": 308}.
[2018-03-02 14:45:36,092 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A kst-based system for student tutoring', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 26, 'year': 2008, 'rg_id': None, 'start_page': 283, 'end_page': 308}
[2018-03-02 14:45:36,093 DEBUG dbutils] Query result: []
[2018-03-02 14:45:36,093 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:36,093 DEBUG dbutils] Add new paper (title='A kst-based system for student tutoring')
[2018-03-02 14:45:36,093 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A kst-based system for student tutoring', 'year': 2008, 'publisher': 'Taylor & Francis', 'start_page': 283, 'end_page': 308, 'pages': 26, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A kst-based system for student tutoring\n%A Pilato, Giovanni\n%A Pirrone, Roberto\n%A Rizzo, Riccardo\n%J Applied Artificial Intelligence\n%V 22\n%N 4\n%P 283-308\n%@ 0883-9514\n%D 2008\n%I Taylor & Francis\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:36,093 DEBUG dbutils] Query result: 60
[2018-03-02 14:45:36,095 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.tandfonline.com/doi/abs/10.1080/08839510801972785.
[2018-03-02 14:45:36,095 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.tandfonline.com/doi/abs/10.1080/08839510801972785.
[2018-03-02 14:45:36,271 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.tandfonline.com/doi/abs/10.1080/08839510801972785 HTTP/1.1" 200 None
[2018-03-02 14:45:36,272 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:45:36,272 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:45:36,272 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for sci-hub.tw
[2018-03-02 14:45:36,423 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.tandfonline.com/doi/abs/10.1080/08839510801972785 HTTP/1.1" 200 None
[2018-03-02 14:45:36,429 DEBUG scihub] URL for PDF: http://dacemirror.sci-hub.tw/journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true.
[2018-03-02 14:45:36,429 WARNING utils] Download file (url='http://dacemirror.sci-hub.tw/journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true') and save (filename='PDF//60.pdf')
[2018-03-02 14:45:36,447 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dacemirror.sci-hub.tw
[2018-03-02 14:45:36,646 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:45:36,647 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:45:36,647 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:45:36,662 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dacemirror.sci-hub.tw
[2018-03-02 14:45:36,851 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:45:36,854 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:45:36,855 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:45:41,980 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:45:41,981 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:45:42,272 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:45:42,274 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 14:45:42,274 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:45:42,274 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for sci-hub.tw
[2018-03-02 14:45:42,288 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): dacemirror.sci-hub.tw
[2018-03-02 14:45:42,462 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/8702aaeaea17b8ed6c13b6a6301b3930/pilato2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:45:42,467 DEBUG scholar] Handle paper #66 (total 1170)
[2018-03-02 14:45:42,467 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:45:42,470 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:42,471 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:45:42,471 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for scholar.google.com
[2018-03-02 14:45:42,492 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:45:44,531 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:W7BMQkEqACEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73V2zlG69DtntYimCFkESDxeBYSZm&scisf=3&ct=citation&cd=65&hl=en HTTP/1.1" 200 271
[2018-03-02 14:45:44,532 DEBUG scholar] EndNote file:
%0 Journal Article
%T Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students
%A Liu, Xianghu
%D 2013
%I University of Exeter

[2018-03-02 14:45:44,532 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:44,532 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:44,532 DEBUG __main__] Process content of EndNote file #66
{"title": "Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University\u00a0\u2026", "url": "https://ore.exeter.ac.uk/repository/handle/10871/14067", "author": [{"shortname": "X Liu", "gid": ""}], "year": 2013}
{"citedby": 1, "type": "Journal Article", "title": "Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students", "author": ["Liu, Xianghu"], "year": "2013", "publisher": "University of Exeter", "EndNote": "%0 Journal Article\n%T Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students\n%A Liu, Xianghu\n%D 2013\n%I University of Exeter\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:W7BMQkEqACEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73V2zlG69DtntYimCFkESDxeBYSZm&scisf=3&ct=citation&cd=65&hl=en"}
[2018-03-02 14:45:44,533 DEBUG dbutils] Get paper id {"DOI": null, "title": "Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:45:44,533 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:45:44,533 DEBUG dbutils] Query result: []
[2018-03-02 14:45:44,533 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:44,533 DEBUG dbutils] Add new paper (title='Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students')
[2018-03-02 14:45:44,533 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students', 'year': 2013, 'publisher': 'University of Exeter', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Action Research on the Effects of an Innovative Use of CALL (Computer Assisted Language Learning) on the Listening and Speaking Abilities of Chinese University Intermediate Level English Students\n%A Liu, Xianghu\n%D 2013\n%I University of Exeter\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:44,533 DEBUG dbutils] Query result: 61
[2018-03-02 14:45:44,535 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://ore.exeter.ac.uk/repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1.
[2018-03-02 14:45:44,538 WARNING utils] Download file (url='https://ore.exeter.ac.uk/repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1') and save (filename='PDF//61.pdf')
[2018-03-02 14:45:44,538 DEBUG utils] Get current proxy for ore.exeter.ac.uk.
[2018-03-02 14:45:44,538 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:45:44,538 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for otherhost
[2018-03-02 14:45:44,553 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): ore.exeter.ac.uk
[2018-03-02 14:45:45,283 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ore.exeter.ac.uk', port=443): Max retries exceeded with url: /repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='ore.exeter.ac.uk', port=443): Max retries exceeded with url: /repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:45:45,283 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for otherhost
[2018-03-02 14:45:45,284 DEBUG utils] Get current proxy for ore.exeter.ac.uk.
[2018-03-02 14:45:45,284 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:45:45,300 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): ore.exeter.ac.uk
[2018-03-02 14:45:46,183 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ore.exeter.ac.uk', port=443): Max retries exceeded with url: /repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='ore.exeter.ac.uk', port=443): Max retries exceeded with url: /repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:45:46,183 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for otherhost
[2018-03-02 14:45:46,184 DEBUG utils] Get current proxy for ore.exeter.ac.uk.
[2018-03-02 14:45:46,184 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:45:46,197 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): ore.exeter.ac.uk
[2018-03-02 14:45:48,136 DEBUG requests.packages.urllib3.connectionpool] "GET /repository/bitstream/handle/10871/14067/LiuX.pdf?sequence=1 HTTP/1.1" 200 3163544
[2018-03-02 14:45:48,136 DEBUG utils] Content-length=3163544
[2018-03-02 14:45:48,137 DEBUG utils] Create file PDF//61.pdf, start download.
[2018-03-02 14:45:53,838 DEBUG utils] End download file PDF//61.pdf.
[2018-03-02 14:45:53,839 DEBUG dbutils] Update pdf_transaction for paper id=61.
[2018-03-02 14:45:53,839 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 61'
[2018-03-02 14:45:53,839 DEBUG dbutils] Query result: null
[2018-03-02 14:45:53,840 DEBUG scholar] Handle paper #67 (total 1170)
[2018-03-02 14:45:53,840 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:45:53,844 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:53,845 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:45:54,202 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QNgmLyfHEmIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73UEVPJ0uZ7nZpxplA3vnRI957up9&scisf=3&ct=citation&cd=66&hl=en HTTP/1.1" 200 219
[2018-03-02 14:45:54,203 DEBUG scholar] EndNote file:
%0 Book Section
%T Virtual laboratory for the training of health workers in italy
%A Gorrino, Antonella
%A De Gasperis, Giovanni
%B Distributed Computing and Artificial Intelligence
%P 41-48
%D 2012
%I Springer

[2018-03-02 14:45:54,203 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:54,203 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:54,203 DEBUG __main__] Process content of EndNote file #67
{"title": "Virtual laboratory for the training of health workers in italy", "url": "https://link.springer.com/chapter/10.1007/978-3-642-28765-7_6", "author": [{"shortname": "A Gorrino", "gid": ""}, {"shortname": "G De Gasperis", "gid": "RhXvFdIAAAAJ"}], "year": 2012}
{"citedby": 2, "type": "Book Section", "title": "Virtual laboratory for the training of health workers in italy", "author": ["Gorrino, Antonella", "De Gasperis, Giovanni"], "secondarytitle": "Distributed Computing and Artificial Intelligence", "pages": "41-48", "year": "2012", "publisher": "Springer", "start_page": 41, "end_page": 48, "volume": 8, "EndNote": "%0 Book Section\n%T Virtual laboratory for the training of health workers in italy\n%A Gorrino, Antonella\n%A De Gasperis, Giovanni\n%B Distributed Computing and Artificial Intelligence\n%P 41-48\n%D 2012\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QNgmLyfHEmIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73UEVPJ0uZ7nZpxplA3vnRI957up9&scisf=3&ct=citation&cd=66&hl=en"}
[2018-03-02 14:45:54,203 DEBUG dbutils] Get paper id {"DOI": null, "title": "Virtual laboratory for the training of health workers in italy", "auth_count": 2, "g_type": "Book Section", "pages": 8, "year": 2012, "rg_id": null, "start_page": 41, "end_page": 48}.
[2018-03-02 14:45:54,203 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Virtual laboratory for the training of health workers in italy', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 8, 'year': 2012, 'rg_id': None, 'start_page': 41, 'end_page': 48}
[2018-03-02 14:45:54,203 DEBUG dbutils] Query result: []
[2018-03-02 14:45:54,203 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:54,204 DEBUG dbutils] Add new paper (title='Virtual laboratory for the training of health workers in italy')
[2018-03-02 14:45:54,204 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Virtual laboratory for the training of health workers in italy', 'year': 2012, 'publisher': 'Springer', 'start_page': 41, 'end_page': 48, 'pages': 8, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Virtual laboratory for the training of health workers in italy\n%A Gorrino, Antonella\n%A De Gasperis, Giovanni\n%B Distributed Computing and Artificial Intelligence\n%P 41-48\n%D 2012\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:54,204 DEBUG dbutils] Query result: 62
[2018-03-02 14:45:54,205 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-642-28765-7_6.
[2018-03-02 14:45:54,205 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-642-28765-7_6.
[2018-03-02 14:45:54,412 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-642-28765-7_6 HTTP/1.1" 302 None
[2018-03-02 14:45:54,434 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:45:55,092 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=4EFF9F8CE3DBF232DD5B826440946BF8 HTTP/1.1" 200 13384
[2018-03-02 14:45:55,265 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:45:55,265 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 14:45:55,482 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-642-28765-7_6 HTTP/1.1" 302 None
[2018-03-02 14:45:55,693 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=4EFF9F8CE3DBF232DD5B826440946BF8 HTTP/1.1" 200 13384
[2018-03-02 14:45:55,934 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:45:55,936 DEBUG scholar] Handle paper #68 (total 1170)
[2018-03-02 14:45:55,936 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:45:55,939 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:55,939 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:45:55,939 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for scholar.google.com
[2018-03-02 14:45:55,955 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:45:57,681 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ixdDH1bZ0IwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73dimeqjAaJBgu52l0duA6j_7KZh_&scisf=3&ct=citation&cd=67&hl=en HTTP/1.1" 200 186
[2018-03-02 14:45:57,682 DEBUG scholar] EndNote file:
%0 Book Section
%T The dawn of the conversational interface
%A McTear, Michael
%A Callejas, Zoraida
%A Griol, David
%B The Conversational Interface
%P 11-24
%D 2016
%I Springer

[2018-03-02 14:45:57,682 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:57,682 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:57,682 DEBUG __main__] Process content of EndNote file #68
{"title": "The dawn of the conversational interface", "url": "https://link.springer.com/chapter/10.1007/978-3-319-32967-3_2", "author": [{"shortname": "M McTear", "gid": "APTzAoIAAAAJ"}, {"shortname": "Z Callejas", "gid": "WE75b8AAAAAJ"}, {"shortname": "D Griol", "gid": ""}], "year": 2016}
{"citedby": 4, "type": "Book Section", "title": "The dawn of the conversational interface", "author": ["McTear, Michael", "Callejas, Zoraida", "Griol, David"], "secondarytitle": "The Conversational Interface", "pages": "11-24", "year": "2016", "publisher": "Springer", "start_page": 11, "end_page": 24, "volume": 14, "EndNote": "%0 Book Section\n%T The dawn of the conversational interface\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%B The Conversational Interface\n%P 11-24\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ixdDH1bZ0IwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73dimeqjAaJBgu52l0duA6j_7KZh_&scisf=3&ct=citation&cd=67&hl=en"}
[2018-03-02 14:45:57,683 DEBUG dbutils] Get paper id {"DOI": null, "title": "The dawn of the conversational interface", "auth_count": 3, "g_type": "Book Section", "pages": 14, "year": 2016, "rg_id": null, "start_page": 11, "end_page": 24}.
[2018-03-02 14:45:57,683 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The dawn of the conversational interface', 'auth_count': 3, 'g_type': 'Book Section', 'pages': 14, 'year': 2016, 'rg_id': None, 'start_page': 11, 'end_page': 24}
[2018-03-02 14:45:57,683 DEBUG dbutils] Query result: []
[2018-03-02 14:45:57,683 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:57,683 DEBUG dbutils] Add new paper (title='The dawn of the conversational interface')
[2018-03-02 14:45:57,683 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The dawn of the conversational interface', 'year': 2016, 'publisher': 'Springer', 'start_page': 11, 'end_page': 24, 'pages': 14, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T The dawn of the conversational interface\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%B The Conversational Interface\n%P 11-24\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:57,683 DEBUG dbutils] Query result: 63
[2018-03-02 14:45:57,685 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-32967-3_2.
[2018-03-02 14:45:57,685 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-32967-3_2.
[2018-03-02 14:45:57,852 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-32967-3_2 HTTP/1.1" 302 None
[2018-03-02 14:45:58,122 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=8E39F47C5FAFE43813BFB7A9BB633B35 HTTP/1.1" 200 9406
[2018-03-02 14:45:58,203 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:45:58,203 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 14:45:58,203 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for sci-hub.tw
[2018-03-02 14:45:58,562 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-32967-3_2 HTTP/1.1" 302 None
[2018-03-02 14:45:59,112 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=8E39F47C5FAFE43813BFB7A9BB633B35 HTTP/1.1" 200 9406
[2018-03-02 14:45:59,394 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:45:59,396 DEBUG scholar] Handle paper #69 (total 1170)
[2018-03-02 14:45:59,396 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:45:59,401 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:45:59,401 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:45:59,682 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:sSOFuLA3i0YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73eSIqxsdxYfOoagq1IGmqDp9Ex6B&scisf=3&ct=citation&cd=68&hl=en HTTP/1.1" 200 60
[2018-03-02 14:45:59,683 DEBUG scholar] EndNote file:
%0 Generic
%T Human-Like Computing
%A Dix, Alan
%D 2016

[2018-03-02 14:45:59,683 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:45:59,683 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:45:59,683 DEBUG __main__] Process content of EndNote file #69
{"title": "Human-Like Computing", "url": "http://alandix.com/blog/2016/02/23/human-like-computing/", "author": [{"shortname": "A Dix", "gid": "m6AAw9wAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Generic", "title": "Human-Like Computing", "author": ["Dix, Alan"], "year": "2016", "EndNote": "%0 Generic\n%T Human-Like Computing\n%A Dix, Alan\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:sSOFuLA3i0YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73eSIqxsdxYfOoagq1IGmqDp9Ex6B&scisf=3&ct=citation&cd=68&hl=en"}
[2018-03-02 14:45:59,683 DEBUG dbutils] Get paper id {"DOI": null, "title": "Human-Like Computing", "auth_count": 1, "g_type": "Generic", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:45:59,683 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Human-Like Computing', 'auth_count': 1, 'g_type': 'Generic', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:45:59,684 DEBUG dbutils] Query result: []
[2018-03-02 14:45:59,684 DEBUG dbutils] Paper id = None.
[2018-03-02 14:45:59,684 DEBUG dbutils] Add new paper (title='Human-Like Computing')
[2018-03-02 14:45:59,684 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Human-Like Computing', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Human-Like Computing\n%A Dix, Alan\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:45:59,684 DEBUG dbutils] Query result: 64
[2018-03-02 14:45:59,686 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://alandix.com/blog/2016/02/23/human-like-computing/.
[2018-03-02 14:45:59,686 DEBUG scihub] Get page from sci-hub for paper with DOI=http://alandix.com/blog/2016/02/23/human-like-computing/.
[2018-03-02 14:45:59,872 DEBUG requests.packages.urllib3.connectionpool] "GET //http://alandix.com/blog/2016/02/23/human-like-computing/ HTTP/1.1" 302 None
[2018-03-02 14:45:59,895 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): alandix.com
[2018-03-02 14:46:00,712 DEBUG requests.packages.urllib3.connectionpool] "GET /blog/2016/02/23/human-like-computing/ HTTP/1.1" 200 None
[2018-03-02 14:46:00,955 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:46:00,955 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:46:01,141 DEBUG requests.packages.urllib3.connectionpool] "GET //http://alandix.com/blog/2016/02/23/human-like-computing/ HTTP/1.1" 302 None
[2018-03-02 14:46:01,727 DEBUG requests.packages.urllib3.connectionpool] "GET /blog/2016/02/23/human-like-computing/ HTTP/1.1" 200 None
[2018-03-02 14:46:02,029 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:46:02,031 DEBUG scholar] Handle paper #70 (total 1170)
[2018-03-02 14:46:02,031 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:46:02,035 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:02,035 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:46:02,035 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for scholar.google.com
[2018-03-02 14:46:02,052 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:46:04,202 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:jvUppn5hGTAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73TQxa3cMoKJh8tt9XF3Cpq8RBKrL&scisf=3&ct=citation&cd=69&hl=en HTTP/1.1" 200 222
[2018-03-02 14:46:04,203 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Ethical decision making in robots: Autonomy, trust and responsibility
%A Alaieri, Fahad
%A Vellino, Andre
%B International Conference on Social Robotics
%P 159-168
%D 2016
%I Springer

[2018-03-02 14:46:04,203 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:46:04,203 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:46:04,203 DEBUG __main__] Process content of EndNote file #70
{"title": "Ethical decision making in robots: Autonomy, trust and responsibility", "url": "https://link.springer.com/chapter/10.1007/978-3-319-47437-3_16", "author": [{"shortname": "F Alaieri", "gid": "r0lYM78AAAAJ"}, {"shortname": "A Vellino", "gid": "0ofhSQ4AAAAJ"}], "year": 2016}
{"citedby": 8, "type": "Conference Proceedings", "title": "Ethical decision making in robots: Autonomy, trust and responsibility", "author": ["Alaieri, Fahad", "Vellino, Andr\u00e9"], "secondarytitle": "International Conference on Social Robotics", "pages": "159-168", "year": "2016", "publisher": "Springer", "start_page": 159, "end_page": 168, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Ethical decision making in robots: Autonomy, trust and responsibility\n%A Alaieri, Fahad\n%A Vellino, Andr\u00e9\n%B International Conference on Social Robotics\n%P 159-168\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:jvUppn5hGTAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk73TQxa3cMoKJh8tt9XF3Cpq8RBKrL&scisf=3&ct=citation&cd=69&hl=en"}
[2018-03-02 14:46:04,203 DEBUG dbutils] Get paper id {"DOI": null, "title": "Ethical decision making in robots: Autonomy, trust and responsibility", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 159, "end_page": 168}.
[2018-03-02 14:46:04,203 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Ethical decision making in robots: Autonomy, trust and responsibility', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 159, 'end_page': 168}
[2018-03-02 14:46:04,204 DEBUG dbutils] Query result: []
[2018-03-02 14:46:04,204 DEBUG dbutils] Paper id = None.
[2018-03-02 14:46:04,204 DEBUG dbutils] Add new paper (title='Ethical decision making in robots: Autonomy, trust and responsibility')
[2018-03-02 14:46:04,204 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Ethical decision making in robots: Autonomy, trust and responsibility', 'year': 2016, 'publisher': 'Springer', 'start_page': 159, 'end_page': 168, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Ethical decision making in robots: Autonomy, trust and responsibility\n%A Alaieri, Fahad\n%A Vellino, Andre\n%B International Conference on Social Robotics\n%P 159-168\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:46:04,204 DEBUG dbutils] Query result: 65
[2018-03-02 14:46:04,206 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.ruor.uottawa.ca/bitstream/10393/35163/4/Robots-Paper-Final.pdf.
[2018-03-02 14:46:04,208 WARNING utils] Download file (url='https://www.ruor.uottawa.ca/bitstream/10393/35163/4/Robots-Paper-Final.pdf') and save (filename='PDF//65.pdf')
[2018-03-02 14:46:04,208 DEBUG utils] Get current proxy for www.ruor.uottawa.ca.
[2018-03-02 14:46:04,208 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:46:04,209 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for otherhost
[2018-03-02 14:46:04,224 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ruor.uottawa.ca
[2018-03-02 14:46:05,244 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10393/35163/4/Robots-Paper-Final.pdf HTTP/1.1" 302 0
[2018-03-02 14:46:05,266 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): ruor.uottawa.ca
[2018-03-02 14:46:05,670 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10393/35163/4/Robots-Paper-Final.pdf HTTP/1.1" 302 0
[2018-03-02 14:46:05,692 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): ruor.uottawa.ca
[2018-03-02 14:46:06,902 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10393/35163/4/Robots-Paper-Final.pdf HTTP/1.1" 200 167206
[2018-03-02 14:46:06,903 DEBUG utils] Content-length=167206
[2018-03-02 14:46:06,904 DEBUG utils] Create file PDF//65.pdf, start download.
[2018-03-02 14:46:07,380 DEBUG utils] End download file PDF//65.pdf.
[2018-03-02 14:46:07,381 DEBUG dbutils] Update pdf_transaction for paper id=65.
[2018-03-02 14:46:07,381 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 65'
[2018-03-02 14:46:07,381 DEBUG dbutils] Query result: null
[2018-03-02 14:46:07,399 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:46:07,399 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:46:07,399 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 14:46:07,433 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:46:10,816 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=70&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:46:12,200 DEBUG scholar] Find papers on page #8 (max_google_papers = 300)
[2018-03-02 14:46:12,200 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:46:12,201 DEBUG scholar] Handle paper #71 (total 1170)
[2018-03-02 14:46:12,201 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:46:12,204 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:12,204 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 14:46:12,204 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for scholar.google.com
[2018-03-02 14:46:12,219 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:46:15,093 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:B8873BeBqOwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HyuJzMJYx7UauQV716bTJjgwiPu_&scisf=3&ct=citation&cd=70&hl=en HTTP/1.1" 200 120
[2018-03-02 14:46:15,094 DEBUG scholar] EndNote file:
%0 Book
%T Believable Bots: Can Computers Play Like People?
%A Hingston, Philip
%@ 3642323227
%D 2012
%I Springer

[2018-03-02 14:46:15,094 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:46:15,094 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:46:15,094 DEBUG __main__] Process content of EndNote file #71
{"title": "Believable Bots: Can Computers Play Like People?", "url": "https://link.springer.com/content/pdf/10.1007/978-3-642-32323-2.pdf", "author": [{"shortname": "P Hingston", "gid": "QNcGZdQAAAAJ"}], "year": 2012}
{"citedby": 24, "type": "Book", "title": "Believable Bots: Can Computers Play Like People?", "author": ["Hingston, Philip"], "isbn/issn": "3642323227", "year": "2012", "publisher": "Springer", "EndNote": "%0 Book\n%T Believable Bots: Can Computers Play Like People?\n%A Hingston, Philip\n%@ 3642323227\n%D 2012\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:B8873BeBqOwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HyuJzMJYx7UauQV716bTJjgwiPu_&scisf=3&ct=citation&cd=70&hl=en"}
[2018-03-02 14:46:15,094 DEBUG dbutils] Get paper id {"DOI": null, "title": "Believable Bots: Can Computers Play Like People?", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:46:15,094 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Believable Bots: Can Computers Play Like People?', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:46:15,094 DEBUG dbutils] Query result: []
[2018-03-02 14:46:15,094 DEBUG dbutils] Paper id = None.
[2018-03-02 14:46:15,094 DEBUG dbutils] Add new paper (title='Believable Bots: Can Computers Play Like People?')
[2018-03-02 14:46:15,094 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Believable Bots: Can Computers Play Like People?', 'year': 2012, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Believable Bots: Can Computers Play Like People?\n%A Hingston, Philip\n%@ 3642323227\n%D 2012\n%I Springer\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:46:15,095 DEBUG dbutils] Query result: 66
[2018-03-02 14:46:15,096 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/content/pdf/10.1007/978-3-642-32323-2.pdf.
[2018-03-02 14:46:15,096 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/content/pdf/10.1007/978-3-642-32323-2.pdf.
[2018-03-02 14:46:15,282 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-642-32323-2.pdf HTTP/1.1" 302 None
[2018-03-02 14:46:15,306 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:46:16,022 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=85EC420BCC2FDC15D07AEF6D63DDF4FA HTTP/1.1" 200 9990
[2018-03-02 14:46:16,155 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:46:16,155 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:46:16,155 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for sci-hub.tw
[2018-03-02 14:46:16,342 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-642-32323-2.pdf HTTP/1.1" 302 None
[2018-03-02 14:46:16,602 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=85EC420BCC2FDC15D07AEF6D63DDF4FA HTTP/1.1" 200 9990
[2018-03-02 14:46:16,844 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:46:16,845 DEBUG scholar] Handle paper #72 (total 1170)
[2018-03-02 14:46:16,845 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:46:16,851 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:16,852 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:46:17,352 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kD4MrZ-aIQ0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HwDiE5ioCf4CKJYWE0-jiDD4DP8U&scisf=3&ct=citation&cd=71&hl=en HTTP/1.1" 200 184
[2018-03-02 14:46:17,353 DEBUG scholar] EndNote file:
%0 Thesis
%T Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences
%A Wang, Yifei
%D 2008
%I University of British Columbia

[2018-03-02 14:46:17,353 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:46:17,353 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:46:17,353 DEBUG __main__] Process content of EndNote file #72
{"title": "Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences", "url": "https://open.library.ubc.ca/collections/ubctheses/24/items/1.0066775", "author": [{"shortname": "Y Wang", "gid": ""}], "year": 2008}
{"citedby": 4, "type": "Thesis", "title": "Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences", "author": ["Wang, Yifei"], "year": "2008", "publisher": "University of British Columbia", "EndNote": "%0 Thesis\n%T Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences\n%A Wang, Yifei\n%D 2008\n%I University of British Columbia\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kD4MrZ-aIQ0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HwDiE5ioCf4CKJYWE0-jiDD4DP8U&scisf=3&ct=citation&cd=71&hl=en"}
[2018-03-02 14:46:17,353 DEBUG dbutils] Get paper id {"DOI": null, "title": "Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:46:17,353 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': "Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences", 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:46:17,353 DEBUG dbutils] Query result: []
[2018-03-02 14:46:17,353 DEBUG dbutils] Paper id = None.
[2018-03-02 14:46:17,353 DEBUG dbutils] Add new paper (title='Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences')
[2018-03-02 14:46:17,354 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': "Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences", 'year': 2008, 'publisher': 'University of British Columbia', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Thesis\n%T Designing chatbot interfaces for language learning: ethnographic research into affect and users' experiences\n%A Wang, Yifei\n%D 2008\n%I University of British Columbia\n", 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:46:17,354 DEBUG dbutils] Query result: 67
[2018-03-02 14:46:17,355 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://open.library.ubc.ca/collections/ubctheses/24/items/1.0066775.
[2018-03-02 14:46:17,355 DEBUG scihub] Get page from sci-hub for paper with DOI=https://open.library.ubc.ca/collections/ubctheses/24/items/1.0066775.
[2018-03-02 14:46:17,542 DEBUG requests.packages.urllib3.connectionpool] "GET //https://open.library.ubc.ca/collections/ubctheses/24/items/1.0066775 HTTP/1.1" 302 None
[2018-03-02 14:46:17,563 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): open.library.ubc.ca
[2018-03-02 14:46:18,941 DEBUG requests.packages.urllib3.connectionpool] "GET /collections/ubctheses/24/items/1.0066775 HTTP/1.1" 302 None
[2018-03-02 14:46:20,094 DEBUG requests.packages.urllib3.connectionpool] "GET /cIRcle/collections/ubctheses/24/items/1.0066775 HTTP/1.1" 200 None
[2018-03-02 14:46:21,193 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:46:21,193 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 14:46:21,380 DEBUG requests.packages.urllib3.connectionpool] "GET //https://open.library.ubc.ca/collections/ubctheses/24/items/1.0066775 HTTP/1.1" 302 None
[2018-03-02 14:46:21,402 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): open.library.ubc.ca
[2018-03-02 14:46:23,270 DEBUG requests.packages.urllib3.connectionpool] "GET /collections/ubctheses/24/items/1.0066775 HTTP/1.1" 302 None
[2018-03-02 14:46:24,364 DEBUG requests.packages.urllib3.connectionpool] "GET /cIRcle/collections/ubctheses/24/items/1.0066775 HTTP/1.1" 200 None
[2018-03-02 14:46:25,380 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:46:25,381 DEBUG scholar] Handle paper #73 (total 1170)
[2018-03-02 14:46:25,382 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:46:25,384 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:25,385 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:46:25,385 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for scholar.google.com
[2018-03-02 14:46:25,400 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:46:26,741 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:dT7csu_YE9IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HzpReiNH3kAxvAg674TelBKffc0K&scisf=3&ct=citation&cd=72&hl=en HTTP/1.1" 200 103
[2018-03-02 14:46:26,742 DEBUG scholar] EndNote file:
%0 Journal Article
%T Make friendship with your Machine
%A Anila, M
%J CSI CommunICatIonS
%D 2012

[2018-03-02 14:46:26,742 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:46:26,742 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:46:26,743 DEBUG __main__] Process content of EndNote file #73
{"title": "Make friendship with your Machine", "url": "http://www.csi-india.org/Communications/CSIC/CSIC%20January%202018.pdf#page=25", "author": [{"shortname": "M Anila", "gid": ""}], "year": 2012}
{"type": "Journal Article", "title": "Make friendship with your Machine", "author": ["Anila, M"], "journal": "CSI CommunICatIonS", "year": "2012", "EndNote": "%0 Journal Article\n%T Make friendship with your Machine\n%A Anila, M\n%J CSI CommunICatIonS\n%D 2012\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:dT7csu_YE9IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HzpReiNH3kAxvAg674TelBKffc0K&scisf=3&ct=citation&cd=72&hl=en"}
[2018-03-02 14:46:26,743 DEBUG dbutils] Get paper id {"DOI": null, "title": "Make friendship with your Machine", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:46:26,743 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Make friendship with your Machine', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:46:26,743 DEBUG dbutils] Query result: []
[2018-03-02 14:46:26,743 DEBUG dbutils] Paper id = None.
[2018-03-02 14:46:26,743 DEBUG dbutils] Add new paper (title='Make friendship with your Machine')
[2018-03-02 14:46:26,743 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Make friendship with your Machine', 'year': 2012, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Make friendship with your Machine\n%A Anila, M\n%J CSI CommunICatIonS\n%D 2012\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:46:26,743 DEBUG dbutils] Query result: 68
[2018-03-02 14:46:26,745 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.csi-india.org/Communications/CSIC/CSIC%20January%202018.pdf#page=25.
[2018-03-02 14:46:26,746 WARNING utils] Download file (url='http://www.csi-india.org/Communications/CSIC/CSIC%20January%202018.pdf#page=25') and save (filename='PDF//68.pdf')
[2018-03-02 14:46:26,746 DEBUG utils] Get current proxy for www.csi-india.org.
[2018-03-02 14:46:26,746 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:46:26,762 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.csi-india.org
[2018-03-02 14:46:27,432 DEBUG requests.packages.urllib3.connectionpool] "GET /Communications/CSIC/CSIC%20January%202018.pdf HTTP/1.1" 200 5439375
[2018-03-02 14:46:27,433 DEBUG utils] Content-length=5439375
[2018-03-02 14:46:27,433 DEBUG utils] Create file PDF//68.pdf, start download.
[2018-03-02 14:46:44,454 DEBUG utils] End download file PDF//68.pdf.
[2018-03-02 14:46:44,455 DEBUG dbutils] Update pdf_transaction for paper id=68.
[2018-03-02 14:46:44,455 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 68'
[2018-03-02 14:46:44,455 DEBUG dbutils] Query result: null
[2018-03-02 14:46:44,455 DEBUG scholar] Handle paper #74 (total 1170)
[2018-03-02 14:46:44,456 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:46:44,462 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:44,462 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:46:44,780 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:hz9IB8nt50gJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H7vt3JzyGugxTs4-3_54R-rEv3XX&scisf=3&ct=citation&cd=73&hl=en HTTP/1.1" 200 296
[2018-03-02 14:46:44,781 DEBUG scholar] EndNote file:
%0 Journal Article
%T Conditional generation and snapshot learning in neural dialogue systems
%A Wen, Tsung-Hsien
%A Gasic, Milica
%A Mrksic, Nikola
%A Rojas-Barahona, Lina M
%A Su, Pei-Hao
%A Ultes, Stefan
%A Vandyke, David
%A Young, Steve
%J arXiv preprint arXiv:1606.03352
%D 2016

[2018-03-02 14:46:44,782 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:46:44,782 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:46:44,782 DEBUG __main__] Process content of EndNote file #74
{"title": "Conditional generation and snapshot learning in neural dialogue systems", "url": "https://arxiv.org/abs/1606.03352", "author": [{"shortname": "TH Wen", "gid": "ot6fwsEAAAAJ"}, {"shortname": "M Gasic", "gid": "yDSBDJoAAAAJ"}, {"shortname": "N Mrksic", "gid": "0dGP_JAAAAAJ"}], "year": 2016}
{"citedby": 10, "type": "Journal Article", "title": "Conditional generation and snapshot learning in neural dialogue systems", "author": ["Wen, Tsung-Hsien", "Gasic, Milica", "Mrksic, Nikola", "Rojas-Barahona, Lina M", "Su, Pei-Hao", "Ultes, Stefan", "Vandyke, David", "Young, Steve"], "journal": "arXiv preprint arXiv:1606.03352", "year": "2016", "EndNote": "%0 Journal Article\n%T Conditional generation and snapshot learning in neural dialogue systems\n%A Wen, Tsung-Hsien\n%A Gasic, Milica\n%A Mrksic, Nikola\n%A Rojas-Barahona, Lina M\n%A Su, Pei-Hao\n%A Ultes, Stefan\n%A Vandyke, David\n%A Young, Steve\n%J arXiv preprint arXiv:1606.03352\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:hz9IB8nt50gJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H7vt3JzyGugxTs4-3_54R-rEv3XX&scisf=3&ct=citation&cd=73&hl=en"}
[2018-03-02 14:46:44,782 DEBUG dbutils] Get paper id {"DOI": null, "title": "Conditional generation and snapshot learning in neural dialogue systems", "auth_count": 8, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:46:44,782 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Conditional generation and snapshot learning in neural dialogue systems', 'auth_count': 8, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:46:44,783 DEBUG dbutils] Query result: []
[2018-03-02 14:46:44,783 DEBUG dbutils] Paper id = None.
[2018-03-02 14:46:44,783 DEBUG dbutils] Add new paper (title='Conditional generation and snapshot learning in neural dialogue systems')
[2018-03-02 14:46:44,783 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Conditional generation and snapshot learning in neural dialogue systems', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Conditional generation and snapshot learning in neural dialogue systems\n%A Wen, Tsung-Hsien\n%A Gasic, Milica\n%A Mrksic, Nikola\n%A Rojas-Barahona, Lina M\n%A Su, Pei-Hao\n%A Ultes, Stefan\n%A Vandyke, David\n%A Young, Steve\n%J arXiv preprint arXiv:1606.03352\n%D 2016\n', 'RIS': None, 'authors': 8, 'ignore': False, 'transaction': 1}
[2018-03-02 14:46:44,783 DEBUG dbutils] Query result: 69
[2018-03-02 14:46:44,784 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1606.03352.
[2018-03-02 14:46:44,785 WARNING utils] Download file (url='https://arxiv.org/pdf/1606.03352') and save (filename='PDF//69.pdf')
[2018-03-02 14:46:44,785 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:46:44,785 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:46:44,786 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for otherhost
[2018-03-02 14:46:44,803 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:46:47,272 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.03352 HTTP/1.1" 302 280
[2018-03-02 14:46:48,136 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.03352.pdf HTTP/1.1" 200 1010338
[2018-03-02 14:46:48,136 DEBUG utils] Content-length=1010338
[2018-03-02 14:46:48,137 DEBUG utils] Create file PDF//69.pdf, start download.
[2018-03-02 14:46:58,441 DEBUG utils] End download file PDF//69.pdf.
[2018-03-02 14:46:58,443 DEBUG dbutils] Update pdf_transaction for paper id=69.
[2018-03-02 14:46:58,443 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 69'
[2018-03-02 14:46:58,443 DEBUG dbutils] Query result: null
[2018-03-02 14:46:58,444 DEBUG scholar] Handle paper #75 (total 1170)
[2018-03-02 14:46:58,444 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:46:58,449 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:46:58,449 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:46:58,449 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for scholar.google.com
[2018-03-02 14:46:58,469 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:00,952 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:vcBsOzwm6I4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HyWD1YLv4L9c0-WKQtckptE8HDAv&scisf=3&ct=citation&cd=74&hl=en HTTP/1.1" 200 140
[2018-03-02 14:47:00,953 DEBUG scholar] EndNote file:
%0 Generic
%T Just. Chat-a platform for processing information to be used in chatbots
%A Pereira, Maria Joao
%A Coheur, Lu?sa
%D 2013

[2018-03-02 14:47:00,953 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:00,953 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:00,953 DEBUG __main__] Process content of EndNote file #75
{"title": "Just. Chat-a platform for processing information to be used in chatbots", "url": "https://fenix.tecnico.ulisboa.pt/downloadFile/395145485809/ExtendedAbstract.pdf", "author": [{"shortname": "MJ Pereira", "gid": ""}, {"shortname": "L Coheur", "gid": "dJ5sl_QAAAAJ"}], "year": 2013}
{"citedby": 2, "type": "Generic", "title": "Just. Chat-a platform for processing information to be used in chatbots", "author": ["Pereira, Maria Joao", "Coheur, Lu\u0131sa"], "year": "2013", "EndNote": "%0 Generic\n%T Just. Chat-a platform for processing information to be used in chatbots\n%A Pereira, Maria Joao\n%A Coheur, Lu\u0131sa\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:vcBsOzwm6I4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HyWD1YLv4L9c0-WKQtckptE8HDAv&scisf=3&ct=citation&cd=74&hl=en"}
[2018-03-02 14:47:00,953 DEBUG dbutils] Get paper id {"DOI": null, "title": "Just. Chat-a platform for processing information to be used in chatbots", "auth_count": 2, "g_type": "Generic", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:47:00,953 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Just. Chat-a platform for processing information to be used in chatbots', 'auth_count': 2, 'g_type': 'Generic', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:47:00,953 DEBUG dbutils] Query result: []
[2018-03-02 14:47:00,953 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:00,954 DEBUG dbutils] Add new paper (title='Just. Chat-a platform for processing information to be used in chatbots')
[2018-03-02 14:47:00,954 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Just. Chat-a platform for processing information to be used in chatbots', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Just. Chat-a platform for processing information to be used in chatbots\n%A Pereira, Maria Joao\n%A Coheur, Lu?sa\n%D 2013\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:00,954 DEBUG dbutils] Query result: 70
[2018-03-02 14:47:00,956 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://fenix.tecnico.ulisboa.pt/downloadFile/395145485809/ExtendedAbstract.pdf.
[2018-03-02 14:47:00,957 WARNING utils] Download file (url='https://fenix.tecnico.ulisboa.pt/downloadFile/395145485809/ExtendedAbstract.pdf') and save (filename='PDF//70.pdf')
[2018-03-02 14:47:00,957 DEBUG utils] Get current proxy for fenix.tecnico.ulisboa.pt.
[2018-03-02 14:47:00,957 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:47:00,982 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): fenix.tecnico.ulisboa.pt
[2018-03-02 14:47:01,921 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='fenix.tecnico.ulisboa.pt', port=443): Max retries exceeded with url: /downloadFile/395145485809/ExtendedAbstract.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='fenix.tecnico.ulisboa.pt', port=443): Max retries exceeded with url: /downloadFile/395145485809/ExtendedAbstract.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 14:47:01,921 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for otherhost
[2018-03-02 14:47:01,922 DEBUG utils] Get current proxy for fenix.tecnico.ulisboa.pt.
[2018-03-02 14:47:01,922 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:47:01,935 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): fenix.tecnico.ulisboa.pt
[2018-03-02 14:47:07,181 DEBUG requests.packages.urllib3.connectionpool] "GET /downloadFile/395145485809/ExtendedAbstract.pdf HTTP/1.1" 200 259570
[2018-03-02 14:47:07,182 DEBUG utils] Content-length=259570
[2018-03-02 14:47:07,182 DEBUG utils] Create file PDF//70.pdf, start download.
[2018-03-02 14:47:10,613 DEBUG utils] End download file PDF//70.pdf.
[2018-03-02 14:47:10,614 DEBUG dbutils] Update pdf_transaction for paper id=70.
[2018-03-02 14:47:10,615 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 70'
[2018-03-02 14:47:10,615 DEBUG dbutils] Query result: null
[2018-03-02 14:47:10,615 DEBUG scholar] Handle paper #76 (total 1170)
[2018-03-02 14:47:10,615 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:47:10,621 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:10,621 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:47:11,081 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:gIQoqn38VIUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H6LY6wW97QZUqYDCxcJWC0WtKYaB&scisf=3&ct=citation&cd=75&hl=en HTTP/1.1" 200 264
[2018-03-02 14:47:11,082 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T A Generative Deep Learning for Generating Korean Abbreviations
%A Choi, Su Jeong
%A Kim, A-Yeong
%A Park, Seong-Bae
%A Park, Se-Young
%B Australasian Joint Conference on Artificial Intelligence
%P 113-124
%D 2016
%I Springer

[2018-03-02 14:47:11,082 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:11,082 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:11,082 DEBUG __main__] Process content of EndNote file #76
{"title": "A Generative Deep Learning for Generating Korean Abbreviations", "url": "https://link.springer.com/chapter/10.1007/978-3-319-50127-7_9", "author": [{"shortname": "SJ Choi", "gid": ""}, {"shortname": "AY Kim", "gid": ""}, {"shortname": "SB Park", "gid": ""}, {"shortname": "SY Park", "gid": ""}], "year": 2016}
{"type": "Conference Proceedings", "title": "A Generative Deep Learning for Generating Korean Abbreviations", "author": ["Choi, Su Jeong", "Kim, A-Yeong", "Park, Seong-Bae", "Park, Se-Young"], "secondarytitle": "Australasian Joint Conference on Artificial Intelligence", "pages": "113-124", "year": "2016", "publisher": "Springer", "start_page": 113, "end_page": 124, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T A Generative Deep Learning for Generating Korean Abbreviations\n%A Choi, Su Jeong\n%A Kim, A-Yeong\n%A Park, Seong-Bae\n%A Park, Se-Young\n%B Australasian Joint Conference on Artificial Intelligence\n%P 113-124\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:gIQoqn38VIUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H6LY6wW97QZUqYDCxcJWC0WtKYaB&scisf=3&ct=citation&cd=75&hl=en"}
[2018-03-02 14:47:11,082 DEBUG dbutils] Get paper id {"DOI": null, "title": "A Generative Deep Learning for Generating Korean Abbreviations", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 12, "year": 2016, "rg_id": null, "start_page": 113, "end_page": 124}.
[2018-03-02 14:47:11,082 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A Generative Deep Learning for Generating Korean Abbreviations', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 113, 'end_page': 124}
[2018-03-02 14:47:11,082 DEBUG dbutils] Query result: []
[2018-03-02 14:47:11,082 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:11,082 DEBUG dbutils] Add new paper (title='A Generative Deep Learning for Generating Korean Abbreviations')
[2018-03-02 14:47:11,083 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A Generative Deep Learning for Generating Korean Abbreviations', 'year': 2016, 'publisher': 'Springer', 'start_page': 113, 'end_page': 124, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T A Generative Deep Learning for Generating Korean Abbreviations\n%A Choi, Su Jeong\n%A Kim, A-Yeong\n%A Park, Seong-Bae\n%A Park, Se-Young\n%B Australasian Joint Conference on Artificial Intelligence\n%P 113-124\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:11,083 DEBUG dbutils] Query result: 71
[2018-03-02 14:47:11,084 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-50127-7_9.
[2018-03-02 14:47:11,084 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-50127-7_9.
[2018-03-02 14:47:11,270 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-50127-7_9 HTTP/1.1" 302 None
[2018-03-02 14:47:11,293 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:47:11,633 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D63FB93B03638D44696C633E5D237618 HTTP/1.1" 200 11909
[2018-03-02 14:47:14,941 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:47:14,941 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 14:47:14,941 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for sci-hub.tw
[2018-03-02 14:47:15,120 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-50127-7_9 HTTP/1.1" 302 None
[2018-03-02 14:47:15,410 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D63FB93B03638D44696C633E5D237618 HTTP/1.1" 200 11909
[2018-03-02 14:47:16,652 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:47:16,653 DEBUG scholar] Handle paper #77 (total 1170)
[2018-03-02 14:47:16,654 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:47:16,656 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:16,657 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:47:16,657 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for scholar.google.com
[2018-03-02 14:47:16,673 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:21,675 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770554D0F0>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:-3OEP0QWbJ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H1eZbURBPqSMmR3A_OcDzuyrzJA9&scisf=3&ct=citation&cd=76&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770554D0F0>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:-3OEP0QWbJ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H1eZbURBPqSMmR3A_OcDzuyrzJA9&scisf=3&ct=citation&cd=76&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770554D0F0>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)'))

[2018-03-02 14:47:21,675 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for scholar.google.com
[2018-03-02 14:47:21,676 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:21,676 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:47:21,689 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:26,000 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:-3OEP0QWbJ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H1eZbURBPqSMmR3A_OcDzuyrzJA9&scisf=3&ct=citation&cd=76&hl=en HTTP/1.1" 200 265
[2018-03-02 14:47:26,001 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Intelligence analysis of Tay Twitter bot
%A Mathur, Vinayak
%A Stavrakas, Yannis
%A Singh, Sanjay
%B Contemporary Computing and Informatics (IC3I), 2016 2nd International Conference on
%P 231-236
%@ 1509052569
%D 2016
%I IEEE

[2018-03-02 14:47:26,001 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:26,001 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:26,001 DEBUG __main__] Process content of EndNote file #77
{"title": "Intelligence analysis of Tay Twitter bot", "url": "http://ieeexplore.ieee.org/abstract/document/7917966/", "author": [{"shortname": "V Mathur", "gid": "fyY_F-wAAAAJ"}, {"shortname": "Y Stavrakas", "gid": "Sr3N_a0AAAAJ"}, {"shortname": "S Singh", "gid": "VBj6NyUAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "Intelligence analysis of Tay Twitter bot", "author": ["Mathur, Vinayak", "Stavrakas, Yannis", "Singh, Sanjay"], "secondarytitle": "Contemporary Computing and Informatics (IC3I), 2016 2nd International Conference on", "pages": "231-236", "isbn/issn": "1509052569", "year": "2016", "publisher": "IEEE", "start_page": 231, "end_page": 236, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Intelligence analysis of Tay Twitter bot\n%A Mathur, Vinayak\n%A Stavrakas, Yannis\n%A Singh, Sanjay\n%B Contemporary Computing and Informatics (IC3I), 2016 2nd International Conference on\n%P 231-236\n%@ 1509052569\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:-3OEP0QWbJ8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H1eZbURBPqSMmR3A_OcDzuyrzJA9&scisf=3&ct=citation&cd=76&hl=en"}
[2018-03-02 14:47:26,001 DEBUG dbutils] Get paper id {"DOI": null, "title": "Intelligence analysis of Tay Twitter bot", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 6, "year": 2016, "rg_id": null, "start_page": 231, "end_page": 236}.
[2018-03-02 14:47:26,001 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Intelligence analysis of Tay Twitter bot', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2016, 'rg_id': None, 'start_page': 231, 'end_page': 236}
[2018-03-02 14:47:26,001 DEBUG dbutils] Query result: []
[2018-03-02 14:47:26,001 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:26,002 DEBUG dbutils] Add new paper (title='Intelligence analysis of Tay Twitter bot')
[2018-03-02 14:47:26,002 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Intelligence analysis of Tay Twitter bot', 'year': 2016, 'publisher': 'IEEE', 'start_page': 231, 'end_page': 236, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Intelligence analysis of Tay Twitter bot\n%A Mathur, Vinayak\n%A Stavrakas, Yannis\n%A Singh, Sanjay\n%B Contemporary Computing and Informatics (IC3I), 2016 2nd International Conference on\n%P 231-236\n%@ 1509052569\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:26,002 DEBUG dbutils] Query result: 72
[2018-03-02 14:47:26,004 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7917966/.
[2018-03-02 14:47:26,004 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7917966/.
[2018-03-02 14:47:26,190 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7917966/ HTTP/1.1" 200 None
[2018-03-02 14:47:26,191 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:47:26,191 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:47:26,380 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7917966/ HTTP/1.1" 200 None
[2018-03-02 14:47:26,387 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/1e65479239cce543a8a1cd98eaf8c891/mathur2016.pdf?download=true.
[2018-03-02 14:47:26,388 WARNING utils] Download file (url='http://twin.sci-hub.tw/1e65479239cce543a8a1cd98eaf8c891/mathur2016.pdf?download=true') and save (filename='PDF//72.pdf')
[2018-03-02 14:47:26,404 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 14:47:26,576 DEBUG requests.packages.urllib3.connectionpool] "GET /1e65479239cce543a8a1cd98eaf8c891/mathur2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 14:47:26,576 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:47:26,576 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:47:26,576 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for sci-hub.tw
[2018-03-02 14:47:26,592 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 14:47:26,764 DEBUG requests.packages.urllib3.connectionpool] "GET /1e65479239cce543a8a1cd98eaf8c891/mathur2016.pdf?download=true HTTP/1.1" 200 250150
[2018-03-02 14:47:26,765 DEBUG utils] Content-length=250150
[2018-03-02 14:47:26,766 DEBUG utils] Create file PDF//72.pdf, start download.
[2018-03-02 14:47:27,235 DEBUG utils] End download file PDF//72.pdf.
[2018-03-02 14:47:27,236 DEBUG dbutils] Update pdf_transaction for paper id=72.
[2018-03-02 14:47:27,236 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 72'
[2018-03-02 14:47:27,236 DEBUG dbutils] Query result: null
[2018-03-02 14:47:27,237 DEBUG scholar] Handle paper #78 (total 1170)
[2018-03-02 14:47:27,237 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:47:27,241 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:27,241 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:47:27,241 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for scholar.google.com
[2018-03-02 14:47:27,256 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:28,440 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:wwCoCfNkbOcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HwHExsvnRi1gxJ4TaaBB0phMWo83&scisf=3&ct=citation&cd=77&hl=en HTTP/1.1" 200 221
[2018-03-02 14:47:28,441 DEBUG scholar] EndNote file:
%0 Journal Article
%T Face Alignment With Deep Regression
%A Shi, Baoguang
%A Bai, Xiang
%A Liu, Wenyu
%A Wang, Jingdong
%J IEEE transactions on neural networks and learning systems
%@ 2162-237X
%D 2016
%I IEEE

[2018-03-02 14:47:28,441 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:28,441 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:28,442 DEBUG __main__] Process content of EndNote file #78
{"title": "Face Alignment With Deep Regression", "url": "http://ieeexplore.ieee.org/document/7728148/", "author": [{"shortname": "B Shi", "gid": "zDhPcpUAAAAJ"}, {"shortname": "X Bai", "gid": "UeltiQ4AAAAJ"}, {"shortname": "W Liu", "gid": "hVjCC4AAAAAJ"}, {"shortname": "J Wang", "gid": "z5SPCmgAAAAJ"}], "year": 2016}
{"type": "Journal Article", "title": "Face Alignment With Deep Regression", "author": ["Shi, Baoguang", "Bai, Xiang", "Liu, Wenyu", "Wang, Jingdong"], "journal": "IEEE transactions on neural networks and learning systems", "isbn/issn": "2162-237X", "year": "2016", "publisher": "IEEE", "EndNote": "%0 Journal Article\n%T Face Alignment With Deep Regression\n%A Shi, Baoguang\n%A Bai, Xiang\n%A Liu, Wenyu\n%A Wang, Jingdong\n%J IEEE transactions on neural networks and learning systems\n%@ 2162-237X\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:wwCoCfNkbOcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8HwHExsvnRi1gxJ4TaaBB0phMWo83&scisf=3&ct=citation&cd=77&hl=en"}
[2018-03-02 14:47:28,442 DEBUG dbutils] Get paper id {"DOI": null, "title": "Face Alignment With Deep Regression", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:47:28,442 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Face Alignment With Deep Regression', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:47:28,442 DEBUG dbutils] Query result: []
[2018-03-02 14:47:28,442 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:28,442 DEBUG dbutils] Add new paper (title='Face Alignment With Deep Regression')
[2018-03-02 14:47:28,442 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Face Alignment With Deep Regression', 'year': 2016, 'publisher': 'IEEE', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Face Alignment With Deep Regression\n%A Shi, Baoguang\n%A Bai, Xiang\n%A Liu, Wenyu\n%A Wang, Jingdong\n%J IEEE transactions on neural networks and learning systems\n%@ 2162-237X\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:28,442 DEBUG dbutils] Query result: 73
[2018-03-02 14:47:28,444 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/document/7728148/.
[2018-03-02 14:47:28,444 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/document/7728148/.
[2018-03-02 14:47:28,630 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/document/7728148/ HTTP/1.1" 200 None
[2018-03-02 14:47:28,631 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:47:28,631 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:47:28,821 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/document/7728148/ HTTP/1.1" 200 None
[2018-03-02 14:47:28,826 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/578978a22cee77cb4d23c52755963b05/shi2016.pdf?download=true.
[2018-03-02 14:47:28,827 WARNING utils] Download file (url='http://twin.sci-hub.tw/578978a22cee77cb4d23c52755963b05/shi2016.pdf?download=true') and save (filename='PDF//73.pdf')
[2018-03-02 14:47:28,951 DEBUG requests.packages.urllib3.connectionpool] "GET /578978a22cee77cb4d23c52755963b05/shi2016.pdf?download=true HTTP/1.1" 200 5416073
[2018-03-02 14:47:28,952 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:47:28,952 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:47:28,952 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for sci-hub.tw
[2018-03-02 14:47:28,968 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): twin.sci-hub.tw
[2018-03-02 14:47:29,184 DEBUG requests.packages.urllib3.connectionpool] "GET /578978a22cee77cb4d23c52755963b05/shi2016.pdf?download=true HTTP/1.1" 200 5416073
[2018-03-02 14:47:29,185 DEBUG utils] Content-length=5416073
[2018-03-02 14:47:29,185 DEBUG utils] Create file PDF//73.pdf, start download.
[2018-03-02 14:47:33,445 DEBUG utils] End download file PDF//73.pdf.
[2018-03-02 14:47:33,447 DEBUG dbutils] Update pdf_transaction for paper id=73.
[2018-03-02 14:47:33,447 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 73'
[2018-03-02 14:47:33,448 DEBUG dbutils] Query result: null
[2018-03-02 14:47:33,448 DEBUG scholar] Handle paper #79 (total 1170)
[2018-03-02 14:47:33,448 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:47:33,453 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:33,453 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:47:33,670 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:iZujnydddbAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8Hyv7O5s2ETzhyksbpvzJOrBV0FRF&scisf=3&ct=citation&cd=78&hl=en HTTP/1.1" 200 145
[2018-03-02 14:47:33,670 DEBUG scholar] EndNote file:
%0 Thesis
%T Designing immersive language learning environments in virtual worlds
%A Wang, Yi Fei
%D 2012
%I University of British Columbia

[2018-03-02 14:47:33,670 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:33,670 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:33,670 DEBUG __main__] Process content of EndNote file #79
{"title": "Designing immersive language learning environments in virtual worlds", "url": "https://open.library.ubc.ca/collections/ubctheses/24/items/1.0055363", "author": [{"shortname": "YF Wang", "gid": ""}], "year": 2012}
{"citedby": 2, "type": "Thesis", "title": "Designing immersive language learning environments in virtual worlds", "author": ["Wang, Yi Fei"], "year": "2012", "publisher": "University of British Columbia", "EndNote": "%0 Thesis\n%T Designing immersive language learning environments in virtual worlds\n%A Wang, Yi Fei\n%D 2012\n%I University of British Columbia\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:iZujnydddbAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8Hyv7O5s2ETzhyksbpvzJOrBV0FRF&scisf=3&ct=citation&cd=78&hl=en"}
[2018-03-02 14:47:33,670 DEBUG dbutils] Get paper id {"DOI": null, "title": "Designing immersive language learning environments in virtual worlds", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:47:33,671 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Designing immersive language learning environments in virtual worlds', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:47:33,671 DEBUG dbutils] Query result: []
[2018-03-02 14:47:33,671 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:33,671 DEBUG dbutils] Add new paper (title='Designing immersive language learning environments in virtual worlds')
[2018-03-02 14:47:33,671 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Designing immersive language learning environments in virtual worlds', 'year': 2012, 'publisher': 'University of British Columbia', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T Designing immersive language learning environments in virtual worlds\n%A Wang, Yi Fei\n%D 2012\n%I University of British Columbia\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:33,671 DEBUG dbutils] Query result: 74
[2018-03-02 14:47:33,673 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://open.library.ubc.ca/collections/ubctheses/24/items/1.0055363.
[2018-03-02 14:47:33,673 DEBUG scihub] Get page from sci-hub for paper with DOI=https://open.library.ubc.ca/collections/ubctheses/24/items/1.0055363.
[2018-03-02 14:47:33,820 DEBUG requests.packages.urllib3.connectionpool] "GET //https://open.library.ubc.ca/collections/ubctheses/24/items/1.0055363 HTTP/1.1" 302 None
[2018-03-02 14:47:34,170 DEBUG requests.packages.urllib3.connectionpool] "GET /collections/ubctheses/24/items/1.0055363 HTTP/1.1" 302 None
[2018-03-02 14:47:35,297 DEBUG requests.packages.urllib3.connectionpool] "GET /cIRcle/collections/ubctheses/24/items/1.0055363 HTTP/1.1" 200 None
[2018-03-02 14:47:36,285 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:47:36,285 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:47:36,462 DEBUG requests.packages.urllib3.connectionpool] "GET //https://open.library.ubc.ca/collections/ubctheses/24/items/1.0055363 HTTP/1.1" 302 None
[2018-03-02 14:47:36,485 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): open.library.ubc.ca
[2018-03-02 14:47:38,300 DEBUG requests.packages.urllib3.connectionpool] "GET /collections/ubctheses/24/items/1.0055363 HTTP/1.1" 302 None
[2018-03-02 14:47:39,654 DEBUG requests.packages.urllib3.connectionpool] "GET /cIRcle/collections/ubctheses/24/items/1.0055363 HTTP/1.1" 200 None
[2018-03-02 14:47:44,840 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:47:44,841 DEBUG scholar] Handle paper #80 (total 1170)
[2018-03-02 14:47:44,841 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:47:44,845 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:44,845 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:47:44,846 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for scholar.google.com
[2018-03-02 14:47:44,862 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:46,220 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:W6E_B4pBFucJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H5DNA7HU-3llwEqW5ZokhTZnZnYj&scisf=3&ct=citation&cd=79&hl=en HTTP/1.1" 200 275
[2018-03-02 14:47:46,221 DEBUG scholar] EndNote file:
%0 Journal Article
%T Using a dialogue system based on dialogue maps for computer assisted second language learning
%A Choi, Sung-Kwon
%A Kwon, Oh-Woog
%A Kim, Young-Kil
%A Lee, Yunkeun
%J CALL communities and cultureshort papers from EUROCALL
%P 106-112
%D 2016

[2018-03-02 14:47:46,221 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:46,221 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:46,221 DEBUG __main__] Process content of EndNote file #80
{"title": "Using a dialogue system based on dialogue maps for computer assisted second language learning", "url": "https://books.google.com/books?hl=en&lr=&id=TN6_DQAAQBAJ&oi=fnd&pg=PA106&dq=Use+deep+learning+to+create+a+chatbot&ots=IOLggXB3Ft&sig=xMDkV1b1g0aGo0eMlqervWycRAg", "author": [{"shortname": "SK Choi", "gid": ""}, {"shortname": "OW Kwon", "gid": ""}, {"shortname": "YK Kim", "gid": ""}, {"shortname": "Y Lee", "gid": ""}], "year": 2016}
{"citedby": 2, "type": "Journal Article", "title": "Using a dialogue system based on dialogue maps for computer assisted second language learning", "author": ["Choi, Sung-Kwon", "Kwon, Oh-Woog", "Kim, Young-Kil", "Lee, Yunkeun"], "journal": "CALL communities and culture\u2013short papers from EUROCALL", "pages": "106-112", "year": "2016", "start_page": 106, "end_page": 112, "volume": 7, "EndNote": "%0 Journal Article\n%T Using a dialogue system based on dialogue maps for computer assisted second language learning\n%A Choi, Sung-Kwon\n%A Kwon, Oh-Woog\n%A Kim, Young-Kil\n%A Lee, Yunkeun\n%J CALL communities and culture\u2013short papers from EUROCALL\n%P 106-112\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:W6E_B4pBFucJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8H5DNA7HU-3llwEqW5ZokhTZnZnYj&scisf=3&ct=citation&cd=79&hl=en"}
[2018-03-02 14:47:46,221 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using a dialogue system based on dialogue maps for computer assisted second language learning", "auth_count": 4, "g_type": "Journal Article", "pages": 7, "year": 2016, "rg_id": null, "start_page": 106, "end_page": 112}.
[2018-03-02 14:47:46,221 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using a dialogue system based on dialogue maps for computer assisted second language learning', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': 7, 'year': 2016, 'rg_id': None, 'start_page': 106, 'end_page': 112}
[2018-03-02 14:47:46,222 DEBUG dbutils] Query result: []
[2018-03-02 14:47:46,222 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:46,222 DEBUG dbutils] Add new paper (title='Using a dialogue system based on dialogue maps for computer assisted second language learning')
[2018-03-02 14:47:46,222 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using a dialogue system based on dialogue maps for computer assisted second language learning', 'year': 2016, 'publisher': None, 'start_page': 106, 'end_page': 112, 'pages': 7, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Using a dialogue system based on dialogue maps for computer assisted second language learning\n%A Choi, Sung-Kwon\n%A Kwon, Oh-Woog\n%A Kim, Young-Kil\n%A Lee, Yunkeun\n%J CALL communities and cultureshort papers from EUROCALL\n%P 106-112\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:46,222 DEBUG dbutils] Query result: 75
[2018-03-02 14:47:46,223 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=TN6_DQAAQBAJ&oi=fnd&pg=PA106&dq=Use+deep+learning+to+create+a+chatbot&ots=IOLggXB3Ft&sig=xMDkV1b1g0aGo0eMlqervWycRAg.
[2018-03-02 14:47:46,224 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=TN6_DQAAQBAJ&oi=fnd&pg=PA106&dq=Use+deep+learning+to+create+a+chatbot&ots=IOLggXB3Ft&sig=xMDkV1b1g0aGo0eMlqervWycRAg.
[2018-03-02 14:47:46,439 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=TN6_DQAAQBAJ&oi=fnd&pg=PA106&dq=Use+deep+learning+to+create+a+chatbot&ots=IOLggXB3Ft&sig=xMDkV1b1g0aGo0eMlqervWycRAg HTTP/1.1" 302 None
[2018-03-02 14:47:46,630 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:47:46,643 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:47:46,643 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:47:46,643 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for sci-hub.tw
[2018-03-02 14:47:46,831 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=TN6_DQAAQBAJ&oi=fnd&pg=PA106&dq=Use+deep+learning+to+create+a+chatbot&ots=IOLggXB3Ft&sig=xMDkV1b1g0aGo0eMlqervWycRAg HTTP/1.1" 302 None
[2018-03-02 14:47:47,033 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:47:47,056 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:47:47,056 DEBUG dbutils] Commiting transaction 80.
[2018-03-02 14:47:47,239 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:47:47,239 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:47:47,239 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:47:47,257 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:47:48,639 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=80&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:47:48,855 DEBUG scholar] Find papers on page #9 (max_google_papers = 300)
[2018-03-02 14:47:48,855 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:47:48,856 DEBUG scholar] Handle paper #81 (total 1170)
[2018-03-02 14:47:48,856 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:47:48,859 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:47:48,860 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:47:48,860 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for scholar.google.com
[2018-03-02 14:47:48,877 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:47:51,550 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:uMO__yWbxsgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gZiwKafzv6NLfeSjkbT01IwGm2cU&scisf=3&ct=citation&cd=80&hl=en HTTP/1.1" 200 261
[2018-03-02 14:47:51,551 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Rich image captioning in the wild
%A Tran, Kenneth
%A He, Xiaodong
%A Zhang, Lei
%A Sun, Jian
%B Computer Vision and Pattern Recognition Workshops (CVPRW), 2016 IEEE Conference on
%P 434-441
%@ 1509014373
%D 2016
%I IEEE

[2018-03-02 14:47:51,551 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:47:51,551 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:47:51,551 DEBUG __main__] Process content of EndNote file #81
{"title": "Rich image captioning in the wild", "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf", "author": [{"shortname": "K Tran", "gid": "MhtUDHYAAAAJ"}, {"shortname": "X He", "gid": "W5WbqgoAAAAJ"}, {"shortname": "L Zhang", "gid": "fIlGZToAAAAJ"}, {"shortname": "J Sun", "gid": "7aQ_YLwAAAAJ"}], "year": 2016}
{"citedby": 19, "type": "Conference Proceedings", "title": "Rich image captioning in the wild", "author": ["Tran, Kenneth", "He, Xiaodong", "Zhang, Lei", "Sun, Jian"], "secondarytitle": "Computer Vision and Pattern Recognition Workshops (CVPRW), 2016 IEEE Conference on", "pages": "434-441", "isbn/issn": "1509014373", "year": "2016", "publisher": "IEEE", "start_page": 434, "end_page": 441, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Rich image captioning in the wild\n%A Tran, Kenneth\n%A He, Xiaodong\n%A Zhang, Lei\n%A Sun, Jian\n%B Computer Vision and Pattern Recognition Workshops (CVPRW), 2016 IEEE Conference on\n%P 434-441\n%@ 1509014373\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:uMO__yWbxsgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gZiwKafzv6NLfeSjkbT01IwGm2cU&scisf=3&ct=citation&cd=80&hl=en"}
[2018-03-02 14:47:51,551 DEBUG dbutils] Get paper id {"DOI": null, "title": "Rich image captioning in the wild", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 8, "year": 2016, "rg_id": null, "start_page": 434, "end_page": 441}.
[2018-03-02 14:47:51,551 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Rich image captioning in the wild', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2016, 'rg_id': None, 'start_page': 434, 'end_page': 441}
[2018-03-02 14:47:51,551 DEBUG dbutils] Query result: []
[2018-03-02 14:47:51,552 DEBUG dbutils] Paper id = None.
[2018-03-02 14:47:51,552 DEBUG dbutils] Add new paper (title='Rich image captioning in the wild')
[2018-03-02 14:47:51,552 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Rich image captioning in the wild', 'year': 2016, 'publisher': 'IEEE', 'start_page': 434, 'end_page': 441, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Rich image captioning in the wild\n%A Tran, Kenneth\n%A He, Xiaodong\n%A Zhang, Lei\n%A Sun, Jian\n%B Computer Vision and Pattern Recognition Workshops (CVPRW), 2016 IEEE Conference on\n%P 434-441\n%@ 1509014373\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:47:51,552 DEBUG dbutils] Query result: 76
[2018-03-02 14:47:51,554 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf.
[2018-03-02 14:47:51,555 WARNING utils] Download file (url='https://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf') and save (filename='PDF//76.pdf')
[2018-03-02 14:47:51,555 DEBUG utils] Get current proxy for www.cv-foundation.org.
[2018-03-02 14:47:51,555 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:47:51,556 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for otherhost
[2018-03-02 14:47:51,603 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cv-foundation.org
[2018-03-02 14:47:56,771 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:47:56,772 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for otherhost
[2018-03-02 14:47:56,772 DEBUG utils] Get current proxy for www.cv-foundation.org.
[2018-03-02 14:47:56,772 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 14:47:56,790 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cv-foundation.org
[2018-03-02 14:48:02,110 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:48:02,111 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for otherhost
[2018-03-02 14:48:02,111 DEBUG utils] Get current proxy for www.cv-foundation.org.
[2018-03-02 14:48:02,111 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 14:48:02,125 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cv-foundation.org
[2018-03-02 14:48:07,290 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:48:07,290 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for otherhost
[2018-03-02 14:48:07,290 DEBUG utils] Get current proxy for www.cv-foundation.org.
[2018-03-02 14:48:07,290 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:48:07,304 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cv-foundation.org
[2018-03-02 14:48:12,619 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.cv-foundation.org', port=443): Max retries exceeded with url: /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:48:12,620 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for otherhost
[2018-03-02 14:48:12,620 DEBUG utils] Get current proxy for www.cv-foundation.org.
[2018-03-02 14:48:12,620 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:48:12,635 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cv-foundation.org
[2018-03-02 14:48:15,690 DEBUG requests.packages.urllib3.connectionpool] "GET /openaccess/content_cvpr_2016_workshops/w12/papers/Tran_Rich_Image_Captioning_CVPR_2016_paper.pdf HTTP/1.1" 200 1551570
[2018-03-02 14:48:15,690 DEBUG utils] Content-length=1551570
[2018-03-02 14:48:15,691 DEBUG utils] Create file PDF//76.pdf, start download.
[2018-03-02 14:48:21,391 DEBUG utils] End download file PDF//76.pdf.
[2018-03-02 14:48:21,392 DEBUG dbutils] Update pdf_transaction for paper id=76.
[2018-03-02 14:48:21,393 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 76'
[2018-03-02 14:48:21,393 DEBUG dbutils] Query result: null
[2018-03-02 14:48:21,393 DEBUG scholar] Handle paper #82 (total 1170)
[2018-03-02 14:48:21,393 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:48:21,396 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:21,397 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 14:48:21,889 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:hedHqgYvEJsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gVdzpU63Jn0Arl8DKSlo4vHUi1K2&scisf=3&ct=citation&cd=81&hl=en HTTP/1.1" 200 79
[2018-03-02 14:48:21,890 DEBUG scholar] EndNote file:
%0 Journal Article
%T Judging Chatbots at Turing Test 2014
%A Sloman, Aaron

[2018-03-02 14:48:21,890 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:21,890 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:21,890 DEBUG __main__] Skip paper #82, empty year or authors fields.
[2018-03-02 14:48:21,891 DEBUG scholar] Handle paper #83 (total 1170)
[2018-03-02 14:48:21,891 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:48:21,894 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:21,894 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 14:48:21,894 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for scholar.google.com
[2018-03-02 14:48:21,911 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:48:23,798 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:O4aICuuhpB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gVBq17t35DNClYNDmIZJWLfjGghP&scisf=3&ct=citation&cd=82&hl=en HTTP/1.1" 200 260
[2018-03-02 14:48:23,799 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Experiments on generating questions about facts
%A Rus, Vasile
%A Cai, Zhiqiang
%A Graesser, Arthur C
%B International Conference on Intelligent Text Processing and Computational Linguistics
%P 444-455
%D 2007
%I Springer

[2018-03-02 14:48:23,799 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:23,799 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:23,799 DEBUG __main__] Process content of EndNote file #83
{"title": "Experiments on generating questions about facts", "url": "https://link.springer.com/chapter/10.1007/978-3-540-70939-8_39", "author": [{"shortname": "V Rus", "gid": "k8jqnc8AAAAJ"}, {"shortname": "Z Cai", "gid": "33wi1moAAAAJ"}, {"shortname": "AC Graesser", "gid": "SA-2DGsAAAAJ"}], "year": 2007}
{"citedby": 19, "type": "Conference Proceedings", "title": "Experiments on generating questions about facts", "author": ["Rus, Vasile", "Cai, Zhiqiang", "Graesser, Arthur C"], "secondarytitle": "International Conference on Intelligent Text Processing and Computational Linguistics", "pages": "444-455", "year": "2007", "publisher": "Springer", "start_page": 444, "end_page": 455, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T Experiments on generating questions about facts\n%A Rus, Vasile\n%A Cai, Zhiqiang\n%A Graesser, Arthur C\n%B International Conference on Intelligent Text Processing and Computational Linguistics\n%P 444-455\n%D 2007\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:O4aICuuhpB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gVBq17t35DNClYNDmIZJWLfjGghP&scisf=3&ct=citation&cd=82&hl=en"}
[2018-03-02 14:48:23,799 DEBUG dbutils] Get paper id {"DOI": null, "title": "Experiments on generating questions about facts", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 12, "year": 2007, "rg_id": null, "start_page": 444, "end_page": 455}.
[2018-03-02 14:48:23,799 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Experiments on generating questions about facts', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2007, 'rg_id': None, 'start_page': 444, 'end_page': 455}
[2018-03-02 14:48:23,800 DEBUG dbutils] Query result: []
[2018-03-02 14:48:23,800 DEBUG dbutils] Paper id = None.
[2018-03-02 14:48:23,800 DEBUG dbutils] Add new paper (title='Experiments on generating questions about facts')
[2018-03-02 14:48:23,800 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Experiments on generating questions about facts', 'year': 2007, 'publisher': 'Springer', 'start_page': 444, 'end_page': 455, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Experiments on generating questions about facts\n%A Rus, Vasile\n%A Cai, Zhiqiang\n%A Graesser, Arthur C\n%B International Conference on Intelligent Text Processing and Computational Linguistics\n%P 444-455\n%D 2007\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:48:23,800 DEBUG dbutils] Query result: 77
[2018-03-02 14:48:23,801 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-540-70939-8_39.
[2018-03-02 14:48:23,802 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-540-70939-8_39.
[2018-03-02 14:48:23,989 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-540-70939-8_39 HTTP/1.1" 302 None
[2018-03-02 14:48:24,012 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:48:24,669 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=FE68F7DB3F66FB190CB17BADCE9DB28A HTTP/1.1" 200 11133
[2018-03-02 14:48:24,848 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:48:24,849 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:48:25,005 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-540-70939-8_39 HTTP/1.1" 302 None
[2018-03-02 14:48:25,219 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=FE68F7DB3F66FB190CB17BADCE9DB28A HTTP/1.1" 200 11133
[2018-03-02 14:48:25,447 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:48:25,449 DEBUG scholar] Handle paper #84 (total 1170)
[2018-03-02 14:48:25,449 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:48:25,452 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:25,453 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:48:25,819 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ejSh4FRDYd0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gclayyMTeG9izU3sgAJNzny8ATzg&scisf=3&ct=citation&cd=83&hl=en HTTP/1.1" 200 155
[2018-03-02 14:48:25,820 DEBUG scholar] EndNote file:
%0 Book Section
%T Student services in a networked world
%A Anderson, Terry
%D 2004
%I Bibliotheks-und Informationassystem der Universaitat Oldenburg

[2018-03-02 14:48:25,820 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:25,820 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:25,820 DEBUG __main__] Process content of EndNote file #84
{"title": "Student services in a networked world", "url": "https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1", "author": [{"shortname": "T Anderson", "gid": "19zDF-8AAAAJ"}], "year": 2004}
{"citedby": 17, "type": "Book Section", "title": "Student services in a networked world", "author": ["Anderson, Terry"], "year": "2004", "publisher": "Bibliotheks-und Informationassystem der Universaitat Oldenburg", "EndNote": "%0 Book Section\n%T Student services in a networked world\n%A Anderson, Terry\n%D 2004\n%I Bibliotheks-und Informationassystem der Universaitat Oldenburg\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ejSh4FRDYd0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gclayyMTeG9izU3sgAJNzny8ATzg&scisf=3&ct=citation&cd=83&hl=en"}
[2018-03-02 14:48:25,820 DEBUG dbutils] Get paper id {"DOI": null, "title": "Student services in a networked world", "auth_count": 1, "g_type": "Book Section", "pages": null, "year": 2004, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:48:25,820 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Student services in a networked world', 'auth_count': 1, 'g_type': 'Book Section', 'pages': None, 'year': 2004, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:48:25,820 DEBUG dbutils] Query result: []
[2018-03-02 14:48:25,821 DEBUG dbutils] Paper id = None.
[2018-03-02 14:48:25,821 DEBUG dbutils] Add new paper (title='Student services in a networked world')
[2018-03-02 14:48:25,821 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Student services in a networked world', 'year': 2004, 'publisher': 'Bibliotheks-und Informationassystem der Universaitat Oldenburg', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Student services in a networked world\n%A Anderson, Terry\n%D 2004\n%I Bibliotheks-und Informationassystem der Universaitat Oldenburg\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:48:25,821 DEBUG dbutils] Query result: 78
[2018-03-02 14:48:25,822 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1.
[2018-03-02 14:48:25,823 DEBUG scihub] Get page from sci-hub for paper with DOI=https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1.
[2018-03-02 14:48:26,009 DEBUG requests.packages.urllib3.connectionpool] "GET //https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 302 None
[2018-03-02 14:48:26,031 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): auspace.athabascau.ca
[2018-03-02 14:48:27,180 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 200 152576
[2018-03-02 14:48:28,566 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:48:28,566 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:48:28,567 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for sci-hub.tw
[2018-03-02 14:48:28,760 DEBUG requests.packages.urllib3.connectionpool] "GET //https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 302 None
[2018-03-02 14:48:28,788 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): auspace.athabascau.ca
[2018-03-02 14:48:30,110 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='auspace.athabascau.ca', port=443): Max retries exceeded with url: /bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='auspace.athabascau.ca', port=443): Max retries exceeded with url: /bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 14:48:30,110 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for sci-hub.tw
[2018-03-02 14:48:30,299 DEBUG requests.packages.urllib3.connectionpool] "GET //https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 302 None
[2018-03-02 14:48:30,323 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: auspace.athabascau.ca
[2018-03-02 14:48:31,480 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 200 152576
[2018-03-02 14:48:32,822 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:48:32,823 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:48:33,048 DEBUG requests.packages.urllib3.connectionpool] "GET //https://auspace.athabascau.ca/bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 302 None
[2018-03-02 14:48:33,073 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): auspace.athabascau.ca
[2018-03-02 14:48:35,156 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/handle/2149/412/Student+Services+in+a+Networked+World.doc?sequence=1 HTTP/1.1" 200 152576
[2018-03-02 14:48:36,858 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:48:36,860 DEBUG scholar] Handle paper #85 (total 1170)
[2018-03-02 14:48:36,860 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:48:36,863 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:36,864 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:48:36,864 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for scholar.google.com
[2018-03-02 14:48:36,879 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:48:39,010 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:WPTwigOPiF0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gcYOeP3aYtVNNhZi6NjWoeBUtRxb&scisf=3&ct=citation&cd=84&hl=en HTTP/1.1" 200 420
[2018-03-02 14:48:39,011 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Ask Alice: an artificial retrieval of information agent
%A Valstar, Michel
%A Baur, Tobias
%A Cafaro, Angelo
%A Ghitulescu, Alexandru
%A Potard, Blaise
%A Wagner, Johannes
%A Andre, Elisabeth
%A Durieu, Laurent
%A Aylett, Matthew
%A Dermouche, Soumia
%B Proceedings of the 18th ACM International Conference on Multimodal Interaction
%P 419-420
%@ 1450345565
%D 2016
%I ACM

[2018-03-02 14:48:39,011 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:39,011 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:39,011 DEBUG __main__] Process content of EndNote file #85
{"title": "Ask Alice: an artificial retrieval of information agent", "url": "https://dl.acm.org/citation.cfm?id=2998535", "author": [{"shortname": "M Valstar", "gid": "SRs5RFEAAAAJ"}, {"shortname": "T Baur", "gid": "ZEUW0hIAAAAJ"}, {"shortname": "A Cafaro", "gid": "6yYLAKcAAAAJ"}, {"shortname": "A Ghitulescu", "gid": ""}], "year": 2016}
{"citedby": 4, "type": "Conference Proceedings", "title": "Ask Alice: an artificial retrieval of information agent", "author": ["Valstar, Michel", "Baur, Tobias", "Cafaro, Angelo", "Ghitulescu, Alexandru", "Potard, Blaise", "Wagner, Johannes", "Andr\u00e9, Elisabeth", "Durieu, Laurent", "Aylett, Matthew", "Dermouche, Soumia"], "secondarytitle": "Proceedings of the 18th ACM International Conference on Multimodal Interaction", "pages": "419-420", "isbn/issn": "1450345565", "year": "2016", "publisher": "ACM", "start_page": 419, "end_page": 420, "volume": 2, "EndNote": "%0 Conference Proceedings\n%T Ask Alice: an artificial retrieval of information agent\n%A Valstar, Michel\n%A Baur, Tobias\n%A Cafaro, Angelo\n%A Ghitulescu, Alexandru\n%A Potard, Blaise\n%A Wagner, Johannes\n%A Andr\u00e9, Elisabeth\n%A Durieu, Laurent\n%A Aylett, Matthew\n%A Dermouche, Soumia\n%B Proceedings of the 18th ACM International Conference on Multimodal Interaction\n%P 419-420\n%@ 1450345565\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:WPTwigOPiF0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gcYOeP3aYtVNNhZi6NjWoeBUtRxb&scisf=3&ct=citation&cd=84&hl=en"}
[2018-03-02 14:48:39,011 DEBUG dbutils] Get paper id {"DOI": null, "title": "Ask Alice: an artificial retrieval of information agent", "auth_count": 10, "g_type": "Conference Proceedings", "pages": 2, "year": 2016, "rg_id": null, "start_page": 419, "end_page": 420}.
[2018-03-02 14:48:39,011 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Ask Alice: an artificial retrieval of information agent', 'auth_count': 10, 'g_type': 'Conference Proceedings', 'pages': 2, 'year': 2016, 'rg_id': None, 'start_page': 419, 'end_page': 420}
[2018-03-02 14:48:39,011 DEBUG dbutils] Query result: []
[2018-03-02 14:48:39,011 DEBUG dbutils] Paper id = None.
[2018-03-02 14:48:39,011 DEBUG dbutils] Add new paper (title='Ask Alice: an artificial retrieval of information agent')
[2018-03-02 14:48:39,012 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Ask Alice: an artificial retrieval of information agent', 'year': 2016, 'publisher': 'ACM', 'start_page': 419, 'end_page': 420, 'pages': 2, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Ask Alice: an artificial retrieval of information agent\n%A Valstar, Michel\n%A Baur, Tobias\n%A Cafaro, Angelo\n%A Ghitulescu, Alexandru\n%A Potard, Blaise\n%A Wagner, Johannes\n%A Andre, Elisabeth\n%A Durieu, Laurent\n%A Aylett, Matthew\n%A Dermouche, Soumia\n%B Proceedings of the 18th ACM International Conference on Multimodal Interaction\n%P 419-420\n%@ 1450345565\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 14:48:39,012 DEBUG dbutils] Query result: 79
[2018-03-02 14:48:39,014 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://eprints.nottingham.ac.uk/40953/1/ARIA-demo.pdf.
[2018-03-02 14:48:39,014 WARNING utils] Download file (url='http://eprints.nottingham.ac.uk/40953/1/ARIA-demo.pdf') and save (filename='PDF//79.pdf')
[2018-03-02 14:48:39,015 DEBUG utils] Get current proxy for eprints.nottingham.ac.uk.
[2018-03-02 14:48:39,015 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:48:39,015 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for otherhost
[2018-03-02 14:48:39,030 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): eprints.nottingham.ac.uk
[2018-03-02 14:48:39,958 DEBUG requests.packages.urllib3.connectionpool] "GET /40953/1/ARIA-demo.pdf HTTP/1.1" 200 1753561
[2018-03-02 14:48:39,959 DEBUG utils] Content-length=1753561
[2018-03-02 14:48:39,959 DEBUG utils] Create file PDF//79.pdf, start download.
[2018-03-02 14:48:42,764 DEBUG utils] End download file PDF//79.pdf.
[2018-03-02 14:48:42,765 DEBUG dbutils] Update pdf_transaction for paper id=79.
[2018-03-02 14:48:42,765 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 79'
[2018-03-02 14:48:42,765 DEBUG dbutils] Query result: null
[2018-03-02 14:48:42,765 DEBUG scholar] Handle paper #86 (total 1170)
[2018-03-02 14:48:42,766 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:48:42,771 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:42,772 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:48:43,118 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:j2H2gGm_SmAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gWJnAMAPX5729EBIKk9f9KY0wn0V&scisf=3&ct=citation&cd=85&hl=en HTTP/1.1" 200 104
[2018-03-02 14:48:43,119 DEBUG scholar] EndNote file:
%0 Journal Article
%T Mimicing the Man: a Persona-based Dialogue System
%A Johnson, Michael
%D 2016

[2018-03-02 14:48:43,119 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:43,119 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:43,119 DEBUG __main__] Process content of EndNote file #86
{"title": "Mimicing the Man: a Persona-based Dialogue System", "url": "https://web.stanford.edu/class/cs221/2017/restricted/p-final/mikejohn/final.pdf", "author": [{"shortname": "M Johnson", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Mimicing the Man: a Persona-based Dialogue System", "author": ["Johnson, Michael"], "year": "2016", "EndNote": "%0 Journal Article\n%T Mimicing the Man: a Persona-based Dialogue System\n%A Johnson, Michael\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:j2H2gGm_SmAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gWJnAMAPX5729EBIKk9f9KY0wn0V&scisf=3&ct=citation&cd=85&hl=en"}
[2018-03-02 14:48:43,119 DEBUG dbutils] Get paper id {"DOI": null, "title": "Mimicing the Man: a Persona-based Dialogue System", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:48:43,120 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Mimicing the Man: a Persona-based Dialogue System', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:48:43,120 DEBUG dbutils] Query result: []
[2018-03-02 14:48:43,120 DEBUG dbutils] Paper id = None.
[2018-03-02 14:48:43,120 DEBUG dbutils] Add new paper (title='Mimicing the Man: a Persona-based Dialogue System')
[2018-03-02 14:48:43,120 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Mimicing the Man: a Persona-based Dialogue System', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Mimicing the Man: a Persona-based Dialogue System\n%A Johnson, Michael\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:48:43,120 DEBUG dbutils] Query result: 80
[2018-03-02 14:48:43,122 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://web.stanford.edu/class/cs221/2017/restricted/p-final/mikejohn/final.pdf.
[2018-03-02 14:48:43,123 WARNING utils] Download file (url='https://web.stanford.edu/class/cs221/2017/restricted/p-final/mikejohn/final.pdf') and save (filename='PDF//80.pdf')
[2018-03-02 14:48:43,123 DEBUG utils] Get current proxy for web.stanford.edu.
[2018-03-02 14:48:43,123 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 14:48:43,138 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): web.stanford.edu
[2018-03-02 14:48:46,075 DEBUG requests.packages.urllib3.connectionpool] "GET /class/cs221/2017/restricted/p-final/mikejohn/final.pdf HTTP/1.1" 200 378185
[2018-03-02 14:48:46,076 DEBUG utils] Content-length=378185
[2018-03-02 14:48:46,076 DEBUG utils] Create file PDF//80.pdf, start download.
[2018-03-02 14:48:53,002 DEBUG utils] End download file PDF//80.pdf.
[2018-03-02 14:48:53,003 DEBUG dbutils] Update pdf_transaction for paper id=80.
[2018-03-02 14:48:53,003 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 80'
[2018-03-02 14:48:53,003 DEBUG dbutils] Query result: null
[2018-03-02 14:48:53,004 DEBUG scholar] Handle paper #87 (total 1170)
[2018-03-02 14:48:53,004 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:48:53,007 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:48:53,008 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:48:53,008 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for scholar.google.com
[2018-03-02 14:48:53,026 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:48:53,929 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:lXwaTbN7TRIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gRcxo0EOP3QIvwFJtzd9kvPOaIce&scisf=3&ct=citation&cd=86&hl=en HTTP/1.1" 200 103
[2018-03-02 14:48:53,930 DEBUG scholar] EndNote file:
%0 Journal Article
%T Technology futures
%A Muller, Bertie
%J Securing the future
%P 26
%D 1999

[2018-03-02 14:48:53,930 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:48:53,930 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:48:53,930 DEBUG __main__] Process content of EndNote file #87
{"title": "Technology futures", "url": "https://futurecarecapital.org.uk/wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf#page=28", "author": [{"shortname": "B M\u00fcller", "gid": ""}], "year": 1999}
{"type": "Journal Article", "title": "Technology futures", "author": ["M\u00fcller, Bertie"], "journal": "Securing the future", "pages": "26", "year": "1999", "EndNote": "%0 Journal Article\n%T Technology futures\n%A M\u00fcller, Bertie\n%J Securing the future\n%P 26\n%D 1999\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:lXwaTbN7TRIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gRcxo0EOP3QIvwFJtzd9kvPOaIce&scisf=3&ct=citation&cd=86&hl=en"}
[2018-03-02 14:48:53,931 DEBUG dbutils] Get paper id {"DOI": null, "title": "Technology futures", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 1999, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:48:53,931 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Technology futures', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 1999, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:48:53,931 DEBUG dbutils] Query result: []
[2018-03-02 14:48:53,931 DEBUG dbutils] Paper id = None.
[2018-03-02 14:48:53,931 DEBUG dbutils] Add new paper (title='Technology futures')
[2018-03-02 14:48:53,931 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Technology futures', 'year': 1999, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Technology futures\n%A Muller, Bertie\n%J Securing the future\n%P 26\n%D 1999\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:48:53,931 DEBUG dbutils] Query result: 81
[2018-03-02 14:48:53,933 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://futurecarecapital.org.uk/wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf#page=28.
[2018-03-02 14:48:53,934 WARNING utils] Download file (url='https://futurecarecapital.org.uk/wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf#page=28') and save (filename='PDF//81.pdf')
[2018-03-02 14:48:53,934 DEBUG utils] Get current proxy for futurecarecapital.org.uk.
[2018-03-02 14:48:53,934 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 14:48:53,934 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for otherhost
[2018-03-02 14:48:53,949 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): futurecarecapital.org.uk
[2018-03-02 14:48:59,070 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='futurecarecapital.org.uk', port=443): Max retries exceeded with url: /wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='futurecarecapital.org.uk', port=443): Max retries exceeded with url: /wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:48:59,070 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for otherhost
[2018-03-02 14:48:59,071 DEBUG utils] Get current proxy for futurecarecapital.org.uk.
[2018-03-02 14:48:59,071 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:48:59,086 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): futurecarecapital.org.uk
[2018-03-02 14:49:00,180 DEBUG requests.packages.urllib3.connectionpool] "GET /wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf HTTP/1.1" 403 None
[2018-03-02 14:49:00,186 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 354, in get_request
    if count_try_for_captcha <= settings.PARAMS[_get_name_max_try_to_host(url)]:
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 415, in _get_name_max_try_to_host
    name = dict_host_to_name[host]
KeyError: 'futurecarecapital.org.uk'

[2018-03-02 14:49:00,186 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for otherhost
[2018-03-02 14:49:00,186 DEBUG utils] Get current proxy for futurecarecapital.org.uk.
[2018-03-02 14:49:00,186 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 14:49:00,200 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): futurecarecapital.org.uk
[2018-03-02 14:49:01,274 DEBUG requests.packages.urllib3.connectionpool] "GET /wp-content/uploads/2017/09/FCC-Policy-Securing-The-Future-Full-Report.pdf HTTP/1.1" 200 4716162
[2018-03-02 14:49:01,274 DEBUG utils] Content-length=4716162
[2018-03-02 14:49:01,275 DEBUG utils] Create file PDF//81.pdf, start download.
[2018-03-02 14:49:14,276 DEBUG utils] End download file PDF//81.pdf.
[2018-03-02 14:49:14,277 DEBUG dbutils] Update pdf_transaction for paper id=81.
[2018-03-02 14:49:14,277 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 81'
[2018-03-02 14:49:14,277 DEBUG dbutils] Query result: null
[2018-03-02 14:49:14,278 DEBUG scholar] Handle paper #88 (total 1170)
[2018-03-02 14:49:14,278 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:49:14,281 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:14,281 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:49:14,530 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:zBUxYRO5YzcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gXW85vDammU4J2wvQDPc3hdUBmNS&scisf=3&ct=citation&cd=87&hl=en HTTP/1.1" 200 188
[2018-03-02 14:49:14,531 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Creative Language Learning Projects with Digital Media
%A Chao, Chin-Chi
%B PACLIC 27 Workshop on Computer-Assisted Language Learning
%P 512-519
%D 2013

[2018-03-02 14:49:14,531 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:49:14,531 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:49:14,531 DEBUG __main__] Process content of EndNote file #88
{"title": "Creative Language Learning Projects with Digital Media", "url": "http://www.aclweb.org/anthology/Y13-2001", "author": [{"shortname": "CC Chao", "gid": ""}], "year": 2013}
{"type": "Conference Proceedings", "title": "Creative Language Learning Projects with Digital Media", "author": ["Chao, Chin-Chi"], "secondarytitle": "PACLIC 27 Workshop on Computer-Assisted Language Learning", "pages": "512-519", "year": "2013", "start_page": 512, "end_page": 519, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Creative Language Learning Projects with Digital Media\n%A Chao, Chin-Chi\n%B PACLIC 27 Workshop on Computer-Assisted Language Learning\n%P 512-519\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:zBUxYRO5YzcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gXW85vDammU4J2wvQDPc3hdUBmNS&scisf=3&ct=citation&cd=87&hl=en"}
[2018-03-02 14:49:14,531 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creative Language Learning Projects with Digital Media", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 8, "year": 2013, "rg_id": null, "start_page": 512, "end_page": 519}.
[2018-03-02 14:49:14,531 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creative Language Learning Projects with Digital Media', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2013, 'rg_id': None, 'start_page': 512, 'end_page': 519}
[2018-03-02 14:49:14,532 DEBUG dbutils] Query result: []
[2018-03-02 14:49:14,532 DEBUG dbutils] Paper id = None.
[2018-03-02 14:49:14,532 DEBUG dbutils] Add new paper (title='Creative Language Learning Projects with Digital Media')
[2018-03-02 14:49:14,532 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creative Language Learning Projects with Digital Media', 'year': 2013, 'publisher': None, 'start_page': 512, 'end_page': 519, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Creative Language Learning Projects with Digital Media\n%A Chao, Chin-Chi\n%B PACLIC 27 Workshop on Computer-Assisted Language Learning\n%P 512-519\n%D 2013\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:49:14,532 DEBUG dbutils] Query result: 82
[2018-03-02 14:49:14,535 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/Y13-2001.
[2018-03-02 14:49:14,540 WARNING utils] Download file (url='http://www.aclweb.org/anthology/Y13-2001') and save (filename='PDF//82.pdf')
[2018-03-02 14:49:14,540 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:49:14,540 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 14:49:14,540 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for otherhost
[2018-03-02 14:49:14,555 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 14:49:15,120 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y13-2001 HTTP/1.1" 200 None
[2018-03-02 14:49:15,121 DEBUG utils] Downloading the entire file.
[2018-03-02 14:49:15,121 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:49:15,121 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:49:15,136 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 14:49:15,717 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y13-2001 HTTP/1.1" 200 None
[2018-03-02 14:49:17,235 DEBUG utils] Save file PDF//82.pdf.
[2018-03-02 14:49:17,236 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/Y13-2001.
[2018-03-02 14:49:17,237 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/Y13-2001.
[2018-03-02 14:49:17,439 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/Y13-2001 HTTP/1.1" 302 None
[2018-03-02 14:49:17,758 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y13-2001 HTTP/1.1" 200 None
[2018-03-02 14:49:18,689 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:49:18,689 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:49:18,690 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for sci-hub.tw
[2018-03-02 14:49:18,847 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/Y13-2001 HTTP/1.1" 302 None
[2018-03-02 14:49:19,169 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y13-2001 HTTP/1.1" 200 None
[2018-03-02 14:49:22,803 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:49:22,804 DEBUG scholar] Handle paper #89 (total 1170)
[2018-03-02 14:49:22,805 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:49:22,808 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:22,808 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:49:22,808 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for scholar.google.com
[2018-03-02 14:49:22,825 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:49:23,618 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:cmsaH2t3Q_kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gXZYjH5cLd4lV6ko1EvOF9sqSCQ4&scisf=3&ct=citation&cd=88&hl=en HTTP/1.1" 200 266
[2018-03-02 14:49:23,619 DEBUG scholar] EndNote file:
%0 Journal Article
%T Creative Language Learning Projects with Emerging Digital Media
%A Chao, Chin-chi
%J Sponsors: National Science Council, Executive Yuan, ROC Institute of Linguistics, Academia Sinica NCCU Office of Research and Development
%P 512
%D 2013

[2018-03-02 14:49:23,619 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:49:23,619 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:49:23,620 DEBUG __main__] Process content of EndNote file #89
{"title": "Creative Language Learning Projects with Emerging Digital Media", "url": "http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf", "author": [{"shortname": "C Chao", "gid": ""}], "year": 2013}
{"type": "Journal Article", "title": "Creative Language Learning Projects with Emerging Digital Media", "author": ["Chao, Chin-chi"], "journal": "Sponsors: National Science Council, Executive Yuan, ROC Institute of Linguistics, Academia Sinica NCCU Office of Research and Development", "pages": "512", "year": "2013", "EndNote": "%0 Journal Article\n%T Creative Language Learning Projects with Emerging Digital Media\n%A Chao, Chin-chi\n%J Sponsors: National Science Council, Executive Yuan, ROC Institute of Linguistics, Academia Sinica NCCU Office of Research and Development\n%P 512\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:cmsaH2t3Q_kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gXZYjH5cLd4lV6ko1EvOF9sqSCQ4&scisf=3&ct=citation&cd=88&hl=en"}
[2018-03-02 14:49:23,620 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creative Language Learning Projects with Emerging Digital Media", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:49:23,620 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creative Language Learning Projects with Emerging Digital Media', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:49:23,620 DEBUG dbutils] Query result: []
[2018-03-02 14:49:23,620 DEBUG dbutils] Paper id = None.
[2018-03-02 14:49:23,620 DEBUG dbutils] Add new paper (title='Creative Language Learning Projects with Emerging Digital Media')
[2018-03-02 14:49:23,620 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creative Language Learning Projects with Emerging Digital Media', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Creative Language Learning Projects with Emerging Digital Media\n%A Chao, Chin-chi\n%J Sponsors: National Science Council, Executive Yuan, ROC Institute of Linguistics, Academia Sinica NCCU Office of Research and Development\n%P 512\n%D 2013\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:49:23,620 DEBUG dbutils] Query result: 83
[2018-03-02 14:49:23,622 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf.
[2018-03-02 14:49:23,624 WARNING utils] Download file (url='http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf') and save (filename='PDF//83.pdf')
[2018-03-02 14:49:23,624 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:49:23,624 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:49:23,624 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for otherhost
[2018-03-02 14:49:23,998 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 200 None
[2018-03-02 14:49:23,999 DEBUG utils] Downloading the entire file.
[2018-03-02 14:49:23,999 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:49:23,999 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:49:24,014 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): www.aclweb.org
[2018-03-02 14:49:24,614 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 200 None
[2018-03-02 14:49:26,091 DEBUG utils] Save file PDF//83.pdf.
[2018-03-02 14:49:26,093 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf.
[2018-03-02 14:49:26,093 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf.
[2018-03-02 14:49:26,298 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 302 None
[2018-03-02 14:49:26,618 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 200 None
[2018-03-02 14:49:27,560 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:49:27,560 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:49:27,778 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 302 None
[2018-03-02 14:49:28,151 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/Y/Y13/Y13-2001.pdf HTTP/1.1" 200 None
[2018-03-02 14:49:31,904 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:49:31,905 DEBUG scholar] Handle paper #90 (total 1170)
[2018-03-02 14:49:31,905 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:49:31,909 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:31,909 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:49:32,167 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:aS_B6eTi1yYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gbta2ssXrL2z4lGBHROZa2Vr41hc&scisf=3&ct=citation&cd=89&hl=en HTTP/1.1" 200 146
[2018-03-02 14:49:32,168 DEBUG scholar] EndNote file:
%0 Book
%T India and the Artificial Intelligence Revolution
%A Vempati, Shashi Shekhar
%D 2016
%I Carnegie Endowment for International Peace

[2018-03-02 14:49:32,168 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:49:32,168 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:49:32,168 DEBUG __main__] Process content of EndNote file #90
{"title": "India and the Artificial Intelligence Revolution", "url": "http://www.datascienceassn.org/sites/default/files/India%20and%20the%20Artificial%20Intelligence%20Revolution.pdf", "author": [{"shortname": "SS Vempati", "gid": ""}], "year": 2016}
{"citedby": 2, "type": "Book", "title": "India and the Artificial Intelligence Revolution", "author": ["Vempati, Shashi Shekhar"], "year": "2016", "publisher": "Carnegie Endowment for International Peace", "EndNote": "%0 Book\n%T India and the Artificial Intelligence Revolution\n%A Vempati, Shashi Shekhar\n%D 2016\n%I Carnegie Endowment for International Peace\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:aS_B6eTi1yYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk8gbta2ssXrL2z4lGBHROZa2Vr41hc&scisf=3&ct=citation&cd=89&hl=en"}
[2018-03-02 14:49:32,169 DEBUG dbutils] Get paper id {"DOI": null, "title": "India and the Artificial Intelligence Revolution", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:49:32,169 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'India and the Artificial Intelligence Revolution', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:49:32,169 DEBUG dbutils] Query result: []
[2018-03-02 14:49:32,169 DEBUG dbutils] Paper id = None.
[2018-03-02 14:49:32,169 DEBUG dbutils] Add new paper (title='India and the Artificial Intelligence Revolution')
[2018-03-02 14:49:32,169 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'India and the Artificial Intelligence Revolution', 'year': 2016, 'publisher': 'Carnegie Endowment for International Peace', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T India and the Artificial Intelligence Revolution\n%A Vempati, Shashi Shekhar\n%D 2016\n%I Carnegie Endowment for International Peace\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:49:32,169 DEBUG dbutils] Query result: 84
[2018-03-02 14:49:32,171 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.datascienceassn.org/sites/default/files/India%20and%20the%20Artificial%20Intelligence%20Revolution.pdf.
[2018-03-02 14:49:32,173 WARNING utils] Download file (url='http://www.datascienceassn.org/sites/default/files/India%20and%20the%20Artificial%20Intelligence%20Revolution.pdf') and save (filename='PDF//84.pdf')
[2018-03-02 14:49:32,173 DEBUG utils] Get current proxy for www.datascienceassn.org.
[2018-03-02 14:49:32,173 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:49:32,173 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for otherhost
[2018-03-02 14:49:32,198 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.datascienceassn.org
[2018-03-02 14:49:32,654 DEBUG requests.packages.urllib3.connectionpool] "GET /sites/default/files/India%20and%20the%20Artificial%20Intelligence%20Revolution.pdf HTTP/1.1" 200 1596019
[2018-03-02 14:49:32,654 DEBUG utils] Content-length=1596019
[2018-03-02 14:49:32,655 DEBUG utils] Create file PDF//84.pdf, start download.
[2018-03-02 14:49:35,297 DEBUG utils] End download file PDF//84.pdf.
[2018-03-02 14:49:35,298 DEBUG dbutils] Update pdf_transaction for paper id=84.
[2018-03-02 14:49:35,298 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 84'
[2018-03-02 14:49:35,298 DEBUG dbutils] Query result: null
[2018-03-02 14:49:35,321 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:49:35,321 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:49:35,321 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:49:35,321 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for scholar.google.com
[2018-03-02 14:49:35,337 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:49:46,528 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=90&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:49:49,068 DEBUG scholar] Find papers on page #10 (max_google_papers = 300)
[2018-03-02 14:49:49,069 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:49:49,069 DEBUG scholar] Handle paper #91 (total 1170)
[2018-03-02 14:49:49,069 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:49:49,072 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:49,072 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:49:49,088 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:49:56,967 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:qvk-xpJwnlIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89hIpuWuzJzExDQ1bTaWgUf68zbw2&scisf=3&ct=citation&cd=90&hl=en HTTP/1.1" 200 90
[2018-03-02 14:49:56,968 DEBUG scholar] EndNote file:
%0 Journal Article
%T Paper Author (s)
%A Hu, Baifan
%A Jiang, Xiang
%A Matwin, Stan

[2018-03-02 14:49:56,968 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:49:56,968 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:49:56,968 DEBUG __main__] Skip paper #91, empty year or authors fields.
[2018-03-02 14:49:56,969 DEBUG scholar] Handle paper #92 (total 1170)
[2018-03-02 14:49:56,969 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:49:56,975 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:56,975 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:49:56,975 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for scholar.google.com
[2018-03-02 14:49:56,990 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:49:58,338 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:hxXExths5jAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89rJO1txGrSHD_nBfe8BHcX59WukX&scisf=3&ct=citation&cd=91&hl=en HTTP/1.1" 200 255
[2018-03-02 14:49:58,338 DEBUG scholar] EndNote file:
%0 Journal Article
%T Dialogue-based CALL: a case study on teaching pronouns
%A Vlugter, Peter
%A Knott, Alistair
%A McDonald, J
%A Hall, C
%J Computer Assisted Language Learning
%V 22
%N 2
%P 115-131
%@ 0958-8221
%D 2009
%I Taylor & Francis

[2018-03-02 14:49:58,339 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:49:58,339 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:49:58,339 DEBUG __main__] Process content of EndNote file #92
{"title": "Dialogue-based CALL: a case study on teaching pronouns", "url": "http://www.tandfonline.com/doi/abs/10.1080/09588220902778260", "author": [{"shortname": "P Vlugter", "gid": ""}, {"shortname": "A Knott", "gid": "_4c7Z18AAAAJ"}, {"shortname": "J McDonald", "gid": "xReiljcAAAAJ"}], "year": 2009}
{"citedby": 10, "type": "Journal Article", "title": "Dialogue-based CALL: a case study on teaching pronouns", "author": ["Vlugter, Peter", "Knott, Alistair", "McDonald, J", "Hall, C"], "journal": "Computer Assisted Language Learning", "volume": 17, "numberorissue": "2", "pages": "115-131", "isbn/issn": "0958-8221", "year": "2009", "publisher": "Taylor & Francis", "start_page": 115, "end_page": 131, "EndNote": "%0 Journal Article\n%T Dialogue-based CALL: a case study on teaching pronouns\n%A Vlugter, Peter\n%A Knott, Alistair\n%A McDonald, J\n%A Hall, C\n%J Computer Assisted Language Learning\n%V 22\n%N 2\n%P 115-131\n%@ 0958-8221\n%D 2009\n%I Taylor & Francis\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:hxXExths5jAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89rJO1txGrSHD_nBfe8BHcX59WukX&scisf=3&ct=citation&cd=91&hl=en"}
[2018-03-02 14:49:58,339 DEBUG dbutils] Get paper id {"DOI": null, "title": "Dialogue-based CALL: a case study on teaching pronouns", "auth_count": 4, "g_type": "Journal Article", "pages": 17, "year": 2009, "rg_id": null, "start_page": 115, "end_page": 131}.
[2018-03-02 14:49:58,339 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Dialogue-based CALL: a case study on teaching pronouns', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': 17, 'year': 2009, 'rg_id': None, 'start_page': 115, 'end_page': 131}
[2018-03-02 14:49:58,339 DEBUG dbutils] Query result: []
[2018-03-02 14:49:58,339 DEBUG dbutils] Paper id = None.
[2018-03-02 14:49:58,339 DEBUG dbutils] Add new paper (title='Dialogue-based CALL: a case study on teaching pronouns')
[2018-03-02 14:49:58,339 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Dialogue-based CALL: a case study on teaching pronouns', 'year': 2009, 'publisher': 'Taylor & Francis', 'start_page': 115, 'end_page': 131, 'pages': 17, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Dialogue-based CALL: a case study on teaching pronouns\n%A Vlugter, Peter\n%A Knott, Alistair\n%A McDonald, J\n%A Hall, C\n%J Computer Assisted Language Learning\n%V 22\n%N 2\n%P 115-131\n%@ 0958-8221\n%D 2009\n%I Taylor & Francis\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:49:58,339 DEBUG dbutils] Query result: 85
[2018-03-02 14:49:58,341 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.tandfonline.com/doi/abs/10.1080/09588220902778260.
[2018-03-02 14:49:58,341 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.tandfonline.com/doi/abs/10.1080/09588220902778260.
[2018-03-02 14:49:58,528 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.tandfonline.com/doi/abs/10.1080/09588220902778260 HTTP/1.1" 200 None
[2018-03-02 14:49:58,529 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:49:58,529 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:49:58,529 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for sci-hub.tw
[2018-03-02 14:49:58,678 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.tandfonline.com/doi/abs/10.1080/09588220902778260 HTTP/1.1" 200 None
[2018-03-02 14:49:58,684 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTA4MC8wOTU4ODIyMDkwMjc3ODI2MA==/vlugter2009.pdf?download=true.
[2018-03-02 14:49:58,684 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTA4MC8wOTU4ODIyMDkwMjc3ODI2MA==/vlugter2009.pdf?download=true') and save (filename='PDF//85.pdf')
[2018-03-02 14:49:58,700 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cyber.sci-hub.tw
[2018-03-02 14:49:58,894 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTA4MC8wOTU4ODIyMDkwMjc3ODI2MA==/vlugter2009.pdf?download=true HTTP/1.1" 200 487553
[2018-03-02 14:49:58,895 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:49:58,895 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:49:58,910 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): cyber.sci-hub.tw
[2018-03-02 14:49:59,157 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTA4MC8wOTU4ODIyMDkwMjc3ODI2MA==/vlugter2009.pdf?download=true HTTP/1.1" 200 487553
[2018-03-02 14:49:59,158 DEBUG utils] Content-length=487553
[2018-03-02 14:49:59,159 DEBUG utils] Create file PDF//85.pdf, start download.
[2018-03-02 14:49:59,773 DEBUG utils] End download file PDF//85.pdf.
[2018-03-02 14:49:59,774 DEBUG dbutils] Update pdf_transaction for paper id=85.
[2018-03-02 14:49:59,774 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 85'
[2018-03-02 14:49:59,774 DEBUG dbutils] Query result: null
[2018-03-02 14:49:59,774 DEBUG scholar] Handle paper #93 (total 1170)
[2018-03-02 14:49:59,775 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:49:59,778 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:49:59,778 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:50:00,047 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:S2xHvLqBmqAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89mYk-tnEjbHa3QtK7OKE4Vkrzs7X&scisf=3&ct=citation&cd=92&hl=en HTTP/1.1" 200 121
[2018-03-02 14:50:00,047 DEBUG scholar] EndNote file:
%0 Journal Article
%T What Forms of computational thinking will our children need when they grow up?
%A Sloman, Aaron

[2018-03-02 14:50:00,047 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:50:00,047 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:50:00,048 DEBUG __main__] Skip paper #93, empty year or authors fields.
[2018-03-02 14:50:00,048 DEBUG scholar] Handle paper #94 (total 1170)
[2018-03-02 14:50:00,048 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:50:00,052 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:50:00,052 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:50:00,052 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for scholar.google.com
[2018-03-02 14:50:00,066 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:50:01,477 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:pXZiMsXep-UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89qJA33DGQYzWQxU48Cc-c77wyNzH&scisf=3&ct=citation&cd=93&hl=en HTTP/1.1" 200 208
[2018-03-02 14:50:01,478 DEBUG scholar] EndNote file:
%0 Journal Article
%T Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models
%A Kandasamy, Kirthevasan
%A Bachrach, Yoram
%A Tomioka, Ryota
%A Tarlow, Daniel
%A Carter, David
%D 2016

[2018-03-02 14:50:01,478 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:50:01,478 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:50:01,478 DEBUG __main__] Process content of EndNote file #94
{"title": "Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models", "url": "https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf", "author": [{"shortname": "K Kandasamy", "gid": "kohOJPcAAAAJ"}, {"shortname": "Y Bachrach", "gid": "0W63ivcAAAAJ"}, {"shortname": "R Tomioka", "gid": "TxdeO-UAAAAJ"}, {"shortname": "D Tarlow", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models", "author": ["Kandasamy, Kirthevasan", "Bachrach, Yoram", "Tomioka, Ryota", "Tarlow, Daniel", "Carter, David"], "year": "2016", "EndNote": "%0 Journal Article\n%T Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models\n%A Kandasamy, Kirthevasan\n%A Bachrach, Yoram\n%A Tomioka, Ryota\n%A Tarlow, Daniel\n%A Carter, David\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:pXZiMsXep-UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89qJA33DGQYzWQxU48Cc-c77wyNzH&scisf=3&ct=citation&cd=93&hl=en"}
[2018-03-02 14:50:01,478 DEBUG dbutils] Get paper id {"DOI": null, "title": "Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models", "auth_count": 5, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:50:01,479 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:50:01,479 DEBUG dbutils] Query result: []
[2018-03-02 14:50:01,479 DEBUG dbutils] Paper id = None.
[2018-03-02 14:50:01,479 DEBUG dbutils] Add new paper (title='Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models')
[2018-03-02 14:50:01,479 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Batch Policy Gradient Methods for Improving Seq2Seq Conversation Models\n%A Kandasamy, Kirthevasan\n%A Bachrach, Yoram\n%A Tomioka, Ryota\n%A Tarlow, Daniel\n%A Carter, David\n%D 2016\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:50:01,479 DEBUG dbutils] Query result: 86
[2018-03-02 14:50:01,481 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf.
[2018-03-02 14:50:01,483 WARNING utils] Download file (url='https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf') and save (filename='PDF//86.pdf')
[2018-03-02 14:50:01,483 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:01,483 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:50:01,498 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:06,809 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:50:06,809 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for otherhost
[2018-03-02 14:50:06,809 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:06,810 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:50:06,823 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:07,738 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:07,738 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for otherhost
[2018-03-02 14:50:07,739 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:07,739 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 14:50:07,753 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:08,978 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:08,979 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for otherhost
[2018-03-02 14:50:08,980 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:08,980 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:50:08,993 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:11,608 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:11,609 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for otherhost
[2018-03-02 14:50:11,610 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:11,610 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:50:11,625 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:12,518 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:12,519 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for otherhost
[2018-03-02 14:50:12,520 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:12,520 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:50:12,534 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:13,398 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:13,399 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for otherhost
[2018-03-02 14:50:13,400 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:13,400 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:50:13,414 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:14,358 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:14,358 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for otherhost
[2018-03-02 14:50:14,360 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:14,360 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 14:50:14,373 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:22,617 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:50:22,618 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for otherhost
[2018-03-02 14:50:22,618 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:22,618 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:50:22,632 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:23,469 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:23,469 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for otherhost
[2018-03-02 14:50:23,470 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:23,471 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:50:23,484 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:24,649 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:24,649 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for otherhost
[2018-03-02 14:50:24,650 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:24,650 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 14:50:24,664 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:25,570 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:25,570 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for otherhost
[2018-03-02 14:50:25,572 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:25,572 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 14:50:25,585 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:29,478 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:29,479 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for otherhost
[2018-03-02 14:50:29,480 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:29,480 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:50:29,494 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:32,950 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:32,951 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for otherhost
[2018-03-02 14:50:32,952 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:32,952 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 14:50:32,965 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:33,817 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:33,819 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for otherhost
[2018-03-02 14:50:33,820 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:33,820 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:50:33,835 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:37,218 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:37,218 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for otherhost
[2018-03-02 14:50:37,219 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:37,219 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 14:50:37,233 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:38,331 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:38,331 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for otherhost
[2018-03-02 14:50:38,332 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:38,332 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:50:38,346 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:40,038 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:40,038 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for otherhost
[2018-03-02 14:50:40,039 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:40,039 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:50:40,054 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:45,056 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708CAD1D0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708CAD1D0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708CAD1D0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 14:50:45,056 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for otherhost
[2018-03-02 14:50:45,056 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:45,056 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 14:50:45,070 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:46,267 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:46,267 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for otherhost
[2018-03-02 14:50:46,269 DEBUG utils] Get current proxy for www.ml.cmu.edu.
[2018-03-02 14:50:46,269 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:50:46,282 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:47,848 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:47,848 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for otherhost
[2018-03-02 14:50:47,852 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf.
[2018-03-02 14:50:47,852 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf.
[2018-03-02 14:50:48,047 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:48,069 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:49,776 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:50:51,666 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:50:51,666 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:50:51,666 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for sci-hub.tw
[2018-03-02 14:50:51,927 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:51,948 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:52,848 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:52,848 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for sci-hub.tw
[2018-03-02 14:50:53,037 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:53,317 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:50:54,788 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:50:54,789 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:50:54,976 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:54,999 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:50:56,148 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:56,148 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for sci-hub.tw
[2018-03-02 14:50:56,366 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:56,657 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:50:58,081 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:50:58,081 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 14:50:58,275 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:58,296 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:50:59,308 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:50:59,308 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for sci-hub.tw
[2018-03-02 14:50:59,495 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:50:59,765 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:01,181 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:01,181 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:51:01,366 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:01,389 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:02,208 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:02,208 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for sci-hub.tw
[2018-03-02 14:51:02,396 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:02,638 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:04,073 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:04,074 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 14:51:04,256 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:04,278 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:06,348 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:06,348 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for sci-hub.tw
[2018-03-02 14:51:06,535 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:06,804 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:08,196 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:08,197 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 14:51:08,383 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:08,405 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:51:09,086 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:09,086 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for sci-hub.tw
[2018-03-02 14:51:09,102 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 14:51:09,386 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:09,679 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:11,096 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:11,097 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:51:11,296 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:11,318 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:12,219 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:12,220 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for sci-hub.tw
[2018-03-02 14:51:12,419 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:12,740 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:14,721 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:14,721 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 14:51:14,906 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:14,928 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:16,539 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:16,539 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for sci-hub.tw
[2018-03-02 14:51:16,728 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:17,037 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:18,669 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:18,669 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:51:18,876 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:18,898 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:20,048 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:20,048 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for sci-hub.tw
[2018-03-02 14:51:20,236 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:20,558 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:22,219 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:22,219 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:51:22,440 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:22,463 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:23,225 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:23,226 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for sci-hub.tw
[2018-03-02 14:51:23,376 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:23,687 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:25,301 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:25,303 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:51:25,486 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:25,526 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:26,218 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:51:26,218 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for sci-hub.tw
[2018-03-02 14:51:26,406 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:26,687 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:28,126 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:28,127 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:51:28,286 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:28,311 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:31,407 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:31,407 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for sci-hub.tw
[2018-03-02 14:51:31,705 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:31,986 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:33,744 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:33,744 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:51:33,956 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:33,978 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:35,287 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:35,287 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for sci-hub.tw
[2018-03-02 14:51:35,436 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:35,698 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:37,236 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:37,236 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:51:37,425 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:37,447 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:38,738 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:38,739 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for sci-hub.tw
[2018-03-02 14:51:38,926 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:39,210 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:40,674 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:40,674 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 14:51:40,867 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:40,889 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:51:41,697 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:41,697 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for sci-hub.tw
[2018-03-02 14:51:41,886 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:42,118 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:43,500 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:43,501 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:51:43,685 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:43,706 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:51:44,599 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 14:51:44,599 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for sci-hub.tw
[2018-03-02 14:51:44,786 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:45,075 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:46,544 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:46,544 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 14:51:46,726 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:46,747 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:51:52,096 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.ml.cmu.edu', port=443): Max retries exceeded with url: /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:51:52,096 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for sci-hub.tw
[2018-03-02 14:51:52,299 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:52,599 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:54,231 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:54,231 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:51:54,430 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:54,454 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:51:56,079 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:56,080 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for sci-hub.tw
[2018-03-02 14:51:56,267 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:56,551 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:51:58,113 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:51:58,113 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:51:58,310 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:58,333 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.ml.cmu.edu
[2018-03-02 14:51:59,121 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:51:59,121 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for sci-hub.tw
[2018-03-02 14:51:59,265 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:51:59,548 DEBUG requests.packages.urllib3.connectionpool] "GET /research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 200 440551
[2018-03-02 14:52:01,215 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:52:01,216 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:52:01,413 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf HTTP/1.1" 302 None
[2018-03-02 14:52:01,436 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.ml.cmu.edu
[2018-03-02 14:52:03,088 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:52:03,088 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for sci-hub.tw
[2018-03-02 14:52:03,091 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:52:03,091 DEBUG __main__] Failed get_pdf from sci-hub for paper #85. URL=85
[2018-03-02 14:52:03,093 DEBUG scholar] Handle paper #95 (total 1170)
[2018-03-02 14:52:03,093 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:52:03,101 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:03,101 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 14:52:03,435 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4eKWSuKa0zkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89hpNQlD1e1rU5oxt-eaSSGPxrFAJ&scisf=3&ct=citation&cd=94&hl=en HTTP/1.1" 200 180
[2018-03-02 14:52:03,436 DEBUG scholar] EndNote file:
%0 Journal Article
%T Leveraging Deep Learning for Spatio-Temporal Understanding of Everyday Environments?
%A Kira, Zsolt
%A Li, Wenchen
%A Allen, Robert
%A Wagner, Alan R

[2018-03-02 14:52:03,436 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:03,436 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:03,436 DEBUG __main__] Skip paper #95, empty year or authors fields.
[2018-03-02 14:52:03,437 DEBUG scholar] Handle paper #96 (total 1170)
[2018-03-02 14:52:03,437 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:52:03,440 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:03,440 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 14:52:03,440 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for scholar.google.com
[2018-03-02 14:52:03,456 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:52:06,437 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:pktX7X8UAMAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89o_NcEVvkn-XqvS3WAZQpnvMwyYG&scisf=3&ct=citation&cd=95&hl=en HTTP/1.1" 200 243
[2018-03-02 14:52:06,438 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Improvisational computational storytelling in open worlds
%A Martin, Lara J
%A Harrison, Brent
%A Riedl, Mark O
%B International Conference on Interactive Digital Storytelling
%P 73-84
%D 2016
%I Springer

[2018-03-02 14:52:06,439 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:06,439 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:06,439 DEBUG __main__] Process content of EndNote file #96
{"title": "Improvisational computational storytelling in open worlds", "url": "https://link.springer.com/chapter/10.1007/978-3-319-48279-8_7", "author": [{"shortname": "LJ Martin", "gid": "YjiWURYAAAAJ"}, {"shortname": "B Harrison", "gid": "lgqTsb0AAAAJ"}, {"shortname": "MO Riedl", "gid": "Yg_QjxcAAAAJ"}], "year": 2016}
{"citedby": 5, "type": "Conference Proceedings", "title": "Improvisational computational storytelling in open worlds", "author": ["Martin, Lara J", "Harrison, Brent", "Riedl, Mark O"], "secondarytitle": "International Conference on Interactive Digital Storytelling", "pages": "73-84", "year": "2016", "publisher": "Springer", "start_page": 73, "end_page": 84, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T Improvisational computational storytelling in open worlds\n%A Martin, Lara J\n%A Harrison, Brent\n%A Riedl, Mark O\n%B International Conference on Interactive Digital Storytelling\n%P 73-84\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:pktX7X8UAMAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89o_NcEVvkn-XqvS3WAZQpnvMwyYG&scisf=3&ct=citation&cd=95&hl=en"}
[2018-03-02 14:52:06,439 DEBUG dbutils] Get paper id {"DOI": null, "title": "Improvisational computational storytelling in open worlds", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 12, "year": 2016, "rg_id": null, "start_page": 73, "end_page": 84}.
[2018-03-02 14:52:06,439 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Improvisational computational storytelling in open worlds', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 73, 'end_page': 84}
[2018-03-02 14:52:06,439 DEBUG dbutils] Query result: []
[2018-03-02 14:52:06,439 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:06,439 DEBUG dbutils] Add new paper (title='Improvisational computational storytelling in open worlds')
[2018-03-02 14:52:06,440 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Improvisational computational storytelling in open worlds', 'year': 2016, 'publisher': 'Springer', 'start_page': 73, 'end_page': 84, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Improvisational computational storytelling in open worlds\n%A Martin, Lara J\n%A Harrison, Brent\n%A Riedl, Mark O\n%B International Conference on Interactive Digital Storytelling\n%P 73-84\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:06,440 DEBUG dbutils] Query result: 87
[2018-03-02 14:52:06,441 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.brenteharrison.com/wp-content/uploads/2016/10/Martin_Harrison_Riedl-ICIDS2016.pdf.
[2018-03-02 14:52:06,446 WARNING utils] Download file (url='http://www.brenteharrison.com/wp-content/uploads/2016/10/Martin_Harrison_Riedl-ICIDS2016.pdf') and save (filename='PDF//87.pdf')
[2018-03-02 14:52:06,446 DEBUG utils] Get current proxy for www.brenteharrison.com.
[2018-03-02 14:52:06,446 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:52:06,462 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.brenteharrison.com
[2018-03-02 14:52:06,923 DEBUG requests.packages.urllib3.connectionpool] "GET /wp-content/uploads/2016/10/Martin_Harrison_Riedl-ICIDS2016.pdf HTTP/1.1" 200 431143
[2018-03-02 14:52:06,924 DEBUG utils] Content-length=431143
[2018-03-02 14:52:06,924 DEBUG utils] Create file PDF//87.pdf, start download.
[2018-03-02 14:52:08,433 DEBUG utils] End download file PDF//87.pdf.
[2018-03-02 14:52:08,435 DEBUG dbutils] Update pdf_transaction for paper id=87.
[2018-03-02 14:52:08,435 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 87'
[2018-03-02 14:52:08,435 DEBUG dbutils] Query result: null
[2018-03-02 14:52:08,435 DEBUG scholar] Handle paper #97 (total 1170)
[2018-03-02 14:52:08,436 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:52:08,440 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:08,440 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:52:08,935 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:HutD0zeaz7IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89m3s1mwiMkF6DBwg601kh7uNfwD9&scisf=3&ct=citation&cd=96&hl=en HTTP/1.1" 200 189
[2018-03-02 14:52:08,936 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Beyond virtual tutors: semi-autonomous characters as learning companions
%A Spierling, Ulrike
%B ACM SIGGRAPH 2005 Educators program
%P 5
%D 2005
%I ACM

[2018-03-02 14:52:08,936 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:08,936 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:08,937 DEBUG __main__] Process content of EndNote file #97
{"title": "Beyond virtual tutors: semi-autonomous characters as learning companions", "url": "https://dl.acm.org/citation.cfm?id=1187365", "author": [{"shortname": "U Spierling", "gid": ""}], "year": 2005}
{"citedby": 5, "type": "Conference Proceedings", "title": "Beyond virtual tutors: semi-autonomous characters as learning companions", "author": ["Spierling, Ulrike"], "secondarytitle": "ACM SIGGRAPH 2005 Educators program", "pages": "5", "year": "2005", "publisher": "ACM", "EndNote": "%0 Conference Proceedings\n%T Beyond virtual tutors: semi-autonomous characters as learning companions\n%A Spierling, Ulrike\n%B ACM SIGGRAPH 2005 Educators program\n%P 5\n%D 2005\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:HutD0zeaz7IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89m3s1mwiMkF6DBwg601kh7uNfwD9&scisf=3&ct=citation&cd=96&hl=en"}
[2018-03-02 14:52:08,937 DEBUG dbutils] Get paper id {"DOI": null, "title": "Beyond virtual tutors: semi-autonomous characters as learning companions", "auth_count": 1, "g_type": "Conference Proceedings", "pages": null, "year": 2005, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:08,937 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Beyond virtual tutors: semi-autonomous characters as learning companions', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2005, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:08,937 DEBUG dbutils] Query result: []
[2018-03-02 14:52:08,937 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:08,937 DEBUG dbutils] Add new paper (title='Beyond virtual tutors: semi-autonomous characters as learning companions')
[2018-03-02 14:52:08,937 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Beyond virtual tutors: semi-autonomous characters as learning companions', 'year': 2005, 'publisher': 'ACM', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Beyond virtual tutors: semi-autonomous characters as learning companions\n%A Spierling, Ulrike\n%B ACM SIGGRAPH 2005 Educators program\n%P 5\n%D 2005\n%I ACM\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:08,937 DEBUG dbutils] Query result: 88
[2018-03-02 14:52:08,940 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1187365.
[2018-03-02 14:52:08,940 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1187365.
[2018-03-02 14:52:13,957 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 14:52:13,957 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for sci-hub.tw
[2018-03-02 14:52:13,986 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): sci-hub.tw
[2018-03-02 14:52:15,209 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1187365 HTTP/1.1" 200 None
[2018-03-02 14:52:15,210 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:52:15,210 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:52:15,395 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1187365 HTTP/1.1" 200 None
[2018-03-02 14:52:15,402 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/776a9afb0435a6f41ee36b86b4e92ad4/spierling2005.pdf?download=true.
[2018-03-02 14:52:15,402 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/776a9afb0435a6f41ee36b86b4e92ad4/spierling2005.pdf?download=true') and save (filename='PDF//88.pdf')
[2018-03-02 14:52:15,417 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dabamirror.sci-hub.tw
[2018-03-02 14:52:16,058 DEBUG requests.packages.urllib3.connectionpool] "GET /776a9afb0435a6f41ee36b86b4e92ad4/spierling2005.pdf?download=true HTTP/1.1" 200 288576
[2018-03-02 14:52:16,059 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 14:52:16,059 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 14:52:16,059 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for sci-hub.tw
[2018-03-02 14:52:16,075 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dabamirror.sci-hub.tw
[2018-03-02 14:52:16,275 DEBUG requests.packages.urllib3.connectionpool] "GET /776a9afb0435a6f41ee36b86b4e92ad4/spierling2005.pdf?download=true HTTP/1.1" 200 288576
[2018-03-02 14:52:16,276 DEBUG utils] Content-length=288576
[2018-03-02 14:52:16,277 DEBUG utils] Create file PDF//88.pdf, start download.
[2018-03-02 14:52:16,828 DEBUG utils] End download file PDF//88.pdf.
[2018-03-02 14:52:16,829 DEBUG dbutils] Update pdf_transaction for paper id=88.
[2018-03-02 14:52:16,829 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 88'
[2018-03-02 14:52:16,829 DEBUG dbutils] Query result: null
[2018-03-02 14:52:16,829 DEBUG scholar] Handle paper #98 (total 1170)
[2018-03-02 14:52:16,830 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:52:16,836 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:16,836 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:52:16,836 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for scholar.google.com
[2018-03-02 14:52:16,850 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:52:19,215 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:O3mTF_Bq-pUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89oGPhOwlslEzReyRoLZ1dPrNzSN1&scisf=3&ct=citation&cd=97&hl=en HTTP/1.1" 200 169
[2018-03-02 14:52:19,216 DEBUG scholar] EndNote file:
%0 Journal Article
%T Artificial Intelligence: Uses and Misuses
%A Alzahrani, Hibatullah
%J Global Journal of Computer Science and Technology
%@ 0975-4172
%D 2016

[2018-03-02 14:52:19,216 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:19,217 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:19,217 DEBUG __main__] Process content of EndNote file #98
{"title": "Artificial Intelligence: Uses and Misuses", "url": "http://www.computerresearch.org/index.php/computer/article/view/1481", "author": [{"shortname": "H Alzahrani", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Artificial Intelligence: Uses and Misuses", "author": ["Alzahrani, Hibatullah"], "journal": "Global Journal of Computer Science and Technology", "isbn/issn": "0975-4172", "year": "2016", "EndNote": "%0 Journal Article\n%T Artificial Intelligence: Uses and Misuses\n%A Alzahrani, Hibatullah\n%J Global Journal of Computer Science and Technology\n%@ 0975-4172\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:O3mTF_Bq-pUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89oGPhOwlslEzReyRoLZ1dPrNzSN1&scisf=3&ct=citation&cd=97&hl=en"}
[2018-03-02 14:52:19,217 DEBUG dbutils] Get paper id {"DOI": null, "title": "Artificial Intelligence: Uses and Misuses", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:19,217 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Artificial Intelligence: Uses and Misuses', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:19,217 DEBUG dbutils] Query result: []
[2018-03-02 14:52:19,217 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:19,217 DEBUG dbutils] Add new paper (title='Artificial Intelligence: Uses and Misuses')
[2018-03-02 14:52:19,217 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Artificial Intelligence: Uses and Misuses', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Artificial Intelligence: Uses and Misuses\n%A Alzahrani, Hibatullah\n%J Global Journal of Computer Science and Technology\n%@ 0975-4172\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:19,217 DEBUG dbutils] Query result: 89
[2018-03-02 14:52:19,219 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.computerresearch.org/index.php/computer/article/download/1481/1468.
[2018-03-02 14:52:19,221 WARNING utils] Download file (url='http://www.computerresearch.org/index.php/computer/article/download/1481/1468') and save (filename='PDF//89.pdf')
[2018-03-02 14:52:19,221 DEBUG utils] Get current proxy for www.computerresearch.org.
[2018-03-02 14:52:19,221 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:52:19,221 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for otherhost
[2018-03-02 14:52:19,237 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.computerresearch.org
[2018-03-02 14:52:19,655 DEBUG requests.packages.urllib3.connectionpool] "GET /index.php/computer/article/download/1481/1468 HTTP/1.1" 302 388
[2018-03-02 14:52:19,677 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.computerresearch.org
[2018-03-02 14:52:22,099 DEBUG requests.packages.urllib3.connectionpool] "GET /index.php/computer/article/download/1481/1468 HTTP/1.1" 200 439422
[2018-03-02 14:52:22,100 DEBUG utils] Content-length=439422
[2018-03-02 14:52:22,100 DEBUG utils] Create file PDF//89.pdf, start download.
[2018-03-02 14:52:23,626 DEBUG utils] End download file PDF//89.pdf.
[2018-03-02 14:52:23,627 DEBUG dbutils] Update pdf_transaction for paper id=89.
[2018-03-02 14:52:23,627 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 89'
[2018-03-02 14:52:23,628 DEBUG dbutils] Query result: null
[2018-03-02 14:52:23,630 DEBUG scholar] Handle paper #99 (total 1170)
[2018-03-02 14:52:23,631 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:52:23,634 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:23,634 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:52:24,095 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:JHlxbFJJl1UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89goMND_xOG3I0V5L6hyOfTnn7ble&scisf=3&ct=citation&cd=98&hl=en HTTP/1.1" 200 404
[2018-03-02 14:52:24,096 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor
%A Folsom-Kovarik, Jeremiah T
%A Schatz, Sae
%A Sukthankar, Gita
%A Nicholson, Denise
%B Proceedings of the 2010 Spring Simulation Multiconference
%P 26
%@ 1450300693
%D 2010
%I Society for Computer Simulation International

[2018-03-02 14:52:24,096 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:24,096 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:24,096 DEBUG __main__] Process content of EndNote file #99
{"title": "What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor", "url": "https://dl.acm.org/citation.cfm?id=1878565", "author": [{"shortname": "JT Folsom", "gid": ""}], "year": 2010}
{"citedby": 7, "type": "Conference Proceedings", "title": "What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor", "author": ["Folsom-Kovarik, Jeremiah T", "Schatz, Sae", "Sukthankar, Gita", "Nicholson, Denise"], "secondarytitle": "Proceedings of the 2010 Spring Simulation Multiconference", "pages": "26", "isbn/issn": "1450300693", "year": "2010", "publisher": "Society for Computer Simulation International", "EndNote": "%0 Conference Proceedings\n%T What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor\n%A Folsom-Kovarik, Jeremiah T\n%A Schatz, Sae\n%A Sukthankar, Gita\n%A Nicholson, Denise\n%B Proceedings of the 2010 Spring Simulation Multiconference\n%P 26\n%@ 1450300693\n%D 2010\n%I Society for Computer Simulation International\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:JHlxbFJJl1UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89goMND_xOG3I0V5L6hyOfTnn7ble&scisf=3&ct=citation&cd=98&hl=en"}
[2018-03-02 14:52:24,096 DEBUG dbutils] Get paper id {"DOI": null, "title": "What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor", "auth_count": 4, "g_type": "Conference Proceedings", "pages": null, "year": 2010, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:24,096 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2010, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:24,097 DEBUG dbutils] Query result: []
[2018-03-02 14:52:24,097 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:24,097 DEBUG dbutils] Add new paper (title='What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor')
[2018-03-02 14:52:24,097 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor', 'year': 2010, 'publisher': 'Society for Computer Simulation International', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T What information does this question convey?: Leveraging help-seeking behavior for improved modeling in a simulation-based intelligent tutor\n%A Folsom-Kovarik, Jeremiah T\n%A Schatz, Sae\n%A Sukthankar, Gita\n%A Nicholson, Denise\n%B Proceedings of the 2010 Spring Simulation Multiconference\n%P 26\n%@ 1450300693\n%D 2010\n%I Society for Computer Simulation International\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:24,097 DEBUG dbutils] Query result: 90
[2018-03-02 14:52:24,099 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/39912769/What_information_does_this_question_conv20151111-30318-mfimgn.pdf.
[2018-03-02 14:52:24,101 WARNING utils] Download file (url='http://www.academia.edu/download/39912769/What_information_does_this_question_conv20151111-30318-mfimgn.pdf') and save (filename='PDF//90.pdf')
[2018-03-02 14:52:24,101 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 14:52:24,101 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:52:24,116 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 14:52:24,595 DEBUG requests.packages.urllib3.connectionpool] "GET /download/39912769/What_information_does_this_question_conv20151111-30318-mfimgn.pdf HTTP/1.1" 404 None
[2018-03-02 14:52:24,599 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1878565.
[2018-03-02 14:52:24,599 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1878565.
[2018-03-02 14:52:25,769 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1878565 HTTP/1.1" 200 None
[2018-03-02 14:52:25,771 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:52:25,771 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:52:25,929 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1878565 HTTP/1.1" 200 None
[2018-03-02 14:52:25,935 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/42de5087ed538d6076174afc973bf1d7/folsomkovarik2010.pdf?download=true.
[2018-03-02 14:52:25,935 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/42de5087ed538d6076174afc973bf1d7/folsomkovarik2010.pdf?download=true') and save (filename='PDF//90.pdf')
[2018-03-02 14:52:26,030 DEBUG requests.packages.urllib3.connectionpool] "GET /42de5087ed538d6076174afc973bf1d7/folsomkovarik2010.pdf?download=true HTTP/1.1" 200 866119
[2018-03-02 14:52:26,030 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 14:52:26,031 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 14:52:26,031 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for sci-hub.tw
[2018-03-02 14:52:26,047 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): dabamirror.sci-hub.tw
[2018-03-02 14:52:26,335 DEBUG requests.packages.urllib3.connectionpool] "GET /42de5087ed538d6076174afc973bf1d7/folsomkovarik2010.pdf?download=true HTTP/1.1" 200 866119
[2018-03-02 14:52:26,336 DEBUG utils] Content-length=866119
[2018-03-02 14:52:26,337 DEBUG utils] Create file PDF//90.pdf, start download.
[2018-03-02 14:52:27,274 DEBUG utils] End download file PDF//90.pdf.
[2018-03-02 14:52:27,275 DEBUG dbutils] Update pdf_transaction for paper id=90.
[2018-03-02 14:52:27,276 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 90'
[2018-03-02 14:52:27,276 DEBUG dbutils] Query result: null
[2018-03-02 14:52:27,276 DEBUG scholar] Handle paper #100 (total 1170)
[2018-03-02 14:52:27,276 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:52:27,280 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:27,280 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:52:27,280 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for scholar.google.com
[2018-03-02 14:52:27,296 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:52:29,544 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:sUZSSJnqzMYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89pdUn1pboPF621Xe2pXTXZqHcPVJ&scisf=3&ct=citation&cd=99&hl=en HTTP/1.1" 200 223
[2018-03-02 14:52:29,545 DEBUG scholar] EndNote file:
%0 Journal Article
%T The spring 2009 snapshot of virtual world use in UK higher and further education
%A Kirriemuir, John
%J Bath: Virtual World Watch, for the Eduserv Foundation. Retrieved May
%V 1
%P 2010
%D 2009

[2018-03-02 14:52:29,546 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:29,546 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:29,546 DEBUG __main__] Process content of EndNote file #100
{"title": "The spring 2009 snapshot of virtual world use in UK higher and further education", "url": "http://www.silversprite.com/ss/wp-content/uploads/2014/10/snapshot-five.pdf", "author": [{"shortname": "J Kirriemuir", "gid": "ChedjjEAAAAJ"}], "year": 2009}
{"citedby": 29, "type": "Journal Article", "title": "The spring 2009 snapshot of virtual world use in UK higher and further education", "author": ["Kirriemuir, John"], "journal": "Bath: Virtual World Watch, for the Eduserv Foundation. Retrieved May", "volume": "1", "pages": "2010", "year": "2009", "EndNote": "%0 Journal Article\n%T The spring 2009 snapshot of virtual world use in UK higher and further education\n%A Kirriemuir, John\n%J Bath: Virtual World Watch, for the Eduserv Foundation. Retrieved May\n%V 1\n%P 2010\n%D 2009\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:sUZSSJnqzMYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk89pdUn1pboPF621Xe2pXTXZqHcPVJ&scisf=3&ct=citation&cd=99&hl=en"}
[2018-03-02 14:52:29,546 DEBUG dbutils] Get paper id {"DOI": null, "title": "The spring 2009 snapshot of virtual world use in UK higher and further education", "auth_count": 1, "g_type": "Journal Article", "pages": 1, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:29,546 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The spring 2009 snapshot of virtual world use in UK higher and further education', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 1, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:29,546 DEBUG dbutils] Query result: []
[2018-03-02 14:52:29,546 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:29,546 DEBUG dbutils] Add new paper (title='The spring 2009 snapshot of virtual world use in UK higher and further education')
[2018-03-02 14:52:29,547 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The spring 2009 snapshot of virtual world use in UK higher and further education', 'year': 2009, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 1, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The spring 2009 snapshot of virtual world use in UK higher and further education\n%A Kirriemuir, John\n%J Bath: Virtual World Watch, for the Eduserv Foundation. Retrieved May\n%V 1\n%P 2010\n%D 2009\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:29,547 DEBUG dbutils] Query result: 91
[2018-03-02 14:52:29,548 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.silversprite.com/ss/wp-content/uploads/2014/10/snapshot-five.pdf.
[2018-03-02 14:52:29,550 WARNING utils] Download file (url='http://www.silversprite.com/ss/wp-content/uploads/2014/10/snapshot-five.pdf') and save (filename='PDF//91.pdf')
[2018-03-02 14:52:29,551 DEBUG utils] Get current proxy for www.silversprite.com.
[2018-03-02 14:52:29,551 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 14:52:29,551 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for otherhost
[2018-03-02 14:52:29,566 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.silversprite.com
[2018-03-02 14:52:29,811 DEBUG requests.packages.urllib3.connectionpool] "GET /ss/wp-content/uploads/2014/10/snapshot-five.pdf HTTP/1.1" 200 320843
[2018-03-02 14:52:29,812 DEBUG utils] Content-length=320843
[2018-03-02 14:52:29,813 DEBUG utils] Create file PDF//91.pdf, start download.
[2018-03-02 14:52:30,600 DEBUG utils] End download file PDF//91.pdf.
[2018-03-02 14:52:30,601 DEBUG dbutils] Update pdf_transaction for paper id=91.
[2018-03-02 14:52:30,601 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 91'
[2018-03-02 14:52:30,601 DEBUG dbutils] Query result: null
[2018-03-02 14:52:30,619 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:52:30,619 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:52:30,619 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:52:30,634 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:52:32,900 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=100&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:52:33,845 DEBUG scholar] Find papers on page #11 (max_google_papers = 300)
[2018-03-02 14:52:33,846 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:52:33,846 DEBUG scholar] Handle paper #101 (total 1170)
[2018-03-02 14:52:33,846 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:52:33,850 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:33,850 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 14:52:33,850 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for scholar.google.com
[2018-03-02 14:52:33,865 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:52:35,615 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:l5v6nzDX14oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nVvZTKAXDig-6KisM0pJQBrh4dFj&scisf=3&ct=citation&cd=100&hl=en HTTP/1.1" 200 204
[2018-03-02 14:52:35,616 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatbots' Greetings to Human-Computer Communication
%A Pereira, Maria Joao
%A Coheur, Luisa
%A Fialho, Pedro
%A Ribeiro, Ricardo
%J arXiv preprint arXiv:1609.06479
%D 2016

[2018-03-02 14:52:35,616 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:35,616 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:35,616 DEBUG __main__] Process content of EndNote file #101
{"title": "Chatbots' Greetings to Human-Computer Communication", "url": "https://arxiv.org/abs/1609.06479", "author": [{"shortname": "MJ Pereira", "gid": ""}, {"shortname": "L Coheur", "gid": "dJ5sl_QAAAAJ"}, {"shortname": "P Fialho", "gid": ""}, {"shortname": "R Ribeiro", "gid": "79bZsV4AAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Chatbots' Greetings to Human-Computer Communication", "author": ["Pereira, Maria Jo\u00e3o", "Coheur, Lu\u00edsa", "Fialho, Pedro", "Ribeiro, Ricardo"], "journal": "arXiv preprint arXiv:1609.06479", "year": "2016", "EndNote": "%0 Journal Article\n%T Chatbots' Greetings to Human-Computer Communication\n%A Pereira, Maria Jo\u00e3o\n%A Coheur, Lu\u00edsa\n%A Fialho, Pedro\n%A Ribeiro, Ricardo\n%J arXiv preprint arXiv:1609.06479\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:l5v6nzDX14oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nVvZTKAXDig-6KisM0pJQBrh4dFj&scisf=3&ct=citation&cd=100&hl=en"}
[2018-03-02 14:52:35,617 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots' Greetings to Human-Computer Communication", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:35,617 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': "Chatbots' Greetings to Human-Computer Communication", 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:35,617 DEBUG dbutils] Query result: []
[2018-03-02 14:52:35,617 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:35,617 DEBUG dbutils] Add new paper (title='Chatbots' Greetings to Human-Computer Communication')
[2018-03-02 14:52:35,617 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': "Chatbots' Greetings to Human-Computer Communication", 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Journal Article\n%T Chatbots' Greetings to Human-Computer Communication\n%A Pereira, Maria Joao\n%A Coheur, Luisa\n%A Fialho, Pedro\n%A Ribeiro, Ricardo\n%J arXiv preprint arXiv:1609.06479\n%D 2016\n", 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:35,617 DEBUG dbutils] Query result: 92
[2018-03-02 14:52:35,619 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1609.06479.
[2018-03-02 14:52:35,620 WARNING utils] Download file (url='https://arxiv.org/pdf/1609.06479') and save (filename='PDF//92.pdf')
[2018-03-02 14:52:35,620 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:52:35,620 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:52:35,635 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:52:38,064 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1609.06479 HTTP/1.1" 302 280
[2018-03-02 14:52:38,844 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1609.06479.pdf HTTP/1.1" 200 355243
[2018-03-02 14:52:38,845 DEBUG utils] Content-length=355243
[2018-03-02 14:52:38,846 DEBUG utils] Create file PDF//92.pdf, start download.
[2018-03-02 14:52:41,486 DEBUG utils] End download file PDF//92.pdf.
[2018-03-02 14:52:41,487 DEBUG dbutils] Update pdf_transaction for paper id=92.
[2018-03-02 14:52:41,487 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 92'
[2018-03-02 14:52:41,488 DEBUG dbutils] Query result: null
[2018-03-02 14:52:41,488 DEBUG scholar] Handle paper #102 (total 1170)
[2018-03-02 14:52:41,488 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:52:41,492 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:41,492 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 14:52:41,824 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:dVRKpoFw6UMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nSpgaXbW8FHy_5ilGVdo0thb4IkX&scisf=3&ct=citation&cd=101&hl=en HTTP/1.1" 200 261
[2018-03-02 14:52:41,825 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T An Enhanced Intelligent Agent with Image Description Generation
%A Fielding, Ben
%A Kinghorn, Philip
%A Mistry, Kamlesh
%A Zhang, Li
%B International Conference on Intelligent Virtual Agents
%P 110-119
%D 2016
%I Springer

[2018-03-02 14:52:41,825 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:41,825 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:41,825 DEBUG __main__] Process content of EndNote file #102
{"title": "An Enhanced Intelligent Agent with Image Description Generation", "url": "https://link.springer.com/chapter/10.1007/978-3-319-47665-0_10", "author": [{"shortname": "B Fielding", "gid": "iRSGmTkAAAAJ"}, {"shortname": "P Kinghorn", "gid": "es7Zb3kAAAAJ"}, {"shortname": "K Mistry", "gid": "42pN-FIAAAAJ"}, {"shortname": "L Zhang", "gid": "SNh9qOQAAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "An Enhanced Intelligent Agent with Image Description Generation", "author": ["Fielding, Ben", "Kinghorn, Philip", "Mistry, Kamlesh", "Zhang, Li"], "secondarytitle": "International Conference on Intelligent Virtual Agents", "pages": "110-119", "year": "2016", "publisher": "Springer", "start_page": 110, "end_page": 119, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T An Enhanced Intelligent Agent with Image Description Generation\n%A Fielding, Ben\n%A Kinghorn, Philip\n%A Mistry, Kamlesh\n%A Zhang, Li\n%B International Conference on Intelligent Virtual Agents\n%P 110-119\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:dVRKpoFw6UMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nSpgaXbW8FHy_5ilGVdo0thb4IkX&scisf=3&ct=citation&cd=101&hl=en"}
[2018-03-02 14:52:41,825 DEBUG dbutils] Get paper id {"DOI": null, "title": "An Enhanced Intelligent Agent with Image Description Generation", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 110, "end_page": 119}.
[2018-03-02 14:52:41,825 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An Enhanced Intelligent Agent with Image Description Generation', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 110, 'end_page': 119}
[2018-03-02 14:52:41,825 DEBUG dbutils] Query result: []
[2018-03-02 14:52:41,826 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:41,826 DEBUG dbutils] Add new paper (title='An Enhanced Intelligent Agent with Image Description Generation')
[2018-03-02 14:52:41,826 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An Enhanced Intelligent Agent with Image Description Generation', 'year': 2016, 'publisher': 'Springer', 'start_page': 110, 'end_page': 119, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T An Enhanced Intelligent Agent with Image Description Generation\n%A Fielding, Ben\n%A Kinghorn, Philip\n%A Mistry, Kamlesh\n%A Zhang, Li\n%B International Conference on Intelligent Virtual Agents\n%P 110-119\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:41,826 DEBUG dbutils] Query result: 93
[2018-03-02 14:52:41,828 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/b59c/8b44a568587bc1b61d130f0ca2f7a2ae3b88.pdf.
[2018-03-02 14:52:41,831 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/b59c/8b44a568587bc1b61d130f0ca2f7a2ae3b88.pdf') and save (filename='PDF//93.pdf')
[2018-03-02 14:52:41,831 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:52:41,831 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 14:52:41,831 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for otherhost
[2018-03-02 14:52:41,846 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 14:52:47,296 DEBUG requests.packages.urllib3.connectionpool] "GET /b59c/8b44a568587bc1b61d130f0ca2f7a2ae3b88.pdf HTTP/1.1" 200 875336
[2018-03-02 14:52:47,296 DEBUG utils] Content-length=875336
[2018-03-02 14:52:47,297 DEBUG utils] Create file PDF//93.pdf, start download.
[2018-03-02 14:52:53,165 DEBUG utils] End download file PDF//93.pdf.
[2018-03-02 14:52:53,170 DEBUG dbutils] Update pdf_transaction for paper id=93.
[2018-03-02 14:52:53,170 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 93'
[2018-03-02 14:52:53,170 DEBUG dbutils] Query result: null
[2018-03-02 14:52:53,173 DEBUG scholar] Handle paper #103 (total 1170)
[2018-03-02 14:52:53,173 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:52:53,176 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:53,176 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 14:52:53,176 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for scholar.google.com
[2018-03-02 14:52:53,195 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:52:55,839 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:JBbWqmVLkj4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nRrs9XZKP6_3SLE4Bquw4brWWyrJ&scisf=3&ct=citation&cd=102&hl=en HTTP/1.1" 200 233
[2018-03-02 14:52:55,840 DEBUG scholar] EndNote file:
%0 Journal Article
%T Hierarchical neural network generative models for movie dialogues
%A Serban, Iulian Vlad
%A Sordoni, Alessandro
%A Bengio, Yoshua
%A Courville, Aaron C
%A Pineau, Joelle
%J CoRR, abs/1507.04808
%D 2015

[2018-03-02 14:52:55,840 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:55,840 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:55,840 DEBUG __main__] Process content of EndNote file #103
{"title": "Hierarchical neural network generative models for movie dialogues", "url": "https://pdfs.semanticscholar.org/7df2/2e88a86d7e7e914a9cf3ad5b8fbd62b35cb8.pdf", "author": [{"shortname": "IV Serban", "gid": "0g31OfAAAAAJ"}, {"shortname": "A Sordoni", "gid": "DJon7w4AAAAJ"}, {"shortname": "Y Bengio", "gid": "kukA0LcAAAAJ"}], "year": 2015}
{"citedby": 50, "type": "Journal Article", "title": "Hierarchical neural network generative models for movie dialogues", "author": ["Serban, Iulian Vlad", "Sordoni, Alessandro", "Bengio, Yoshua", "Courville, Aaron C", "Pineau, Joelle"], "journal": "CoRR, abs/1507.04808", "year": "2015", "EndNote": "%0 Journal Article\n%T Hierarchical neural network generative models for movie dialogues\n%A Serban, Iulian Vlad\n%A Sordoni, Alessandro\n%A Bengio, Yoshua\n%A Courville, Aaron C\n%A Pineau, Joelle\n%J CoRR, abs/1507.04808\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:JBbWqmVLkj4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nRrs9XZKP6_3SLE4Bquw4brWWyrJ&scisf=3&ct=citation&cd=102&hl=en"}
[2018-03-02 14:52:55,840 DEBUG dbutils] Get paper id {"DOI": null, "title": "Hierarchical neural network generative models for movie dialogues", "auth_count": 5, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:52:55,840 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Hierarchical neural network generative models for movie dialogues', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:52:55,840 DEBUG dbutils] Query result: []
[2018-03-02 14:52:55,840 DEBUG dbutils] Paper id = None.
[2018-03-02 14:52:55,841 DEBUG dbutils] Add new paper (title='Hierarchical neural network generative models for movie dialogues')
[2018-03-02 14:52:55,841 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Hierarchical neural network generative models for movie dialogues', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Hierarchical neural network generative models for movie dialogues\n%A Serban, Iulian Vlad\n%A Sordoni, Alessandro\n%A Bengio, Yoshua\n%A Courville, Aaron C\n%A Pineau, Joelle\n%J CoRR, abs/1507.04808\n%D 2015\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:52:55,841 DEBUG dbutils] Query result: 94
[2018-03-02 14:52:55,842 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/7df2/2e88a86d7e7e914a9cf3ad5b8fbd62b35cb8.pdf.
[2018-03-02 14:52:55,843 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/7df2/2e88a86d7e7e914a9cf3ad5b8fbd62b35cb8.pdf') and save (filename='PDF//94.pdf')
[2018-03-02 14:52:55,844 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:52:55,844 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:52:56,535 DEBUG requests.packages.urllib3.connectionpool] "GET /7df2/2e88a86d7e7e914a9cf3ad5b8fbd62b35cb8.pdf HTTP/1.1" 200 220930
[2018-03-02 14:52:56,535 DEBUG utils] Content-length=220930
[2018-03-02 14:52:56,536 DEBUG utils] Create file PDF//94.pdf, start download.
[2018-03-02 14:52:58,258 DEBUG utils] End download file PDF//94.pdf.
[2018-03-02 14:52:58,259 DEBUG dbutils] Update pdf_transaction for paper id=94.
[2018-03-02 14:52:58,260 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 94'
[2018-03-02 14:52:58,260 DEBUG dbutils] Query result: null
[2018-03-02 14:52:58,260 DEBUG scholar] Handle paper #104 (total 1170)
[2018-03-02 14:52:58,261 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:52:58,266 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:58,267 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 14:52:58,663 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GsPAVKnpUv0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nbHBTBK_PzwMzX47PdCo1cv9z35x&scisf=3&ct=citation&cd=103&hl=en HTTP/1.1" 200 133
[2018-03-02 14:52:58,664 DEBUG scholar] EndNote file:
%0 Journal Article
%T Ethical Decision Making in Robots: Autonomy, Trust and Responsibility
%A Vellino, Andre
%A Alaieri, Fahad

[2018-03-02 14:52:58,664 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:52:58,664 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:52:58,664 DEBUG __main__] Skip paper #104, empty year or authors fields.
[2018-03-02 14:52:58,664 DEBUG scholar] Handle paper #105 (total 1170)
[2018-03-02 14:52:58,665 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:52:58,667 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:52:58,667 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 14:52:58,668 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for scholar.google.com
[2018-03-02 14:52:58,683 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:53:01,613 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:LXGaB8RdfmEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9ncx_y70NUd61JhwVgAIH_5uIgnM6&scisf=3&ct=citation&cd=104&hl=en HTTP/1.1" 200 100
[2018-03-02 14:53:01,614 DEBUG scholar] EndNote file:
%0 Journal Article
%T Artificial Intelligence: Science and Impact
%A Miller, Michael SP
%D 2015

[2018-03-02 14:53:01,614 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:01,614 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:01,614 DEBUG __main__] Process content of EndNote file #105
{"title": "Artificial Intelligence: Science and Impact", "url": "http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf", "author": [{"shortname": "MSP Miller", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "Artificial Intelligence: Science and Impact", "author": ["Miller, Michael SP"], "year": "2015", "EndNote": "%0 Journal Article\n%T Artificial Intelligence: Science and Impact\n%A Miller, Michael SP\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:LXGaB8RdfmEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9ncx_y70NUd61JhwVgAIH_5uIgnM6&scisf=3&ct=citation&cd=104&hl=en"}
[2018-03-02 14:53:01,614 DEBUG dbutils] Get paper id {"DOI": null, "title": "Artificial Intelligence: Science and Impact", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:53:01,614 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Artificial Intelligence: Science and Impact', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:53:01,614 DEBUG dbutils] Query result: []
[2018-03-02 14:53:01,615 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:01,615 DEBUG dbutils] Add new paper (title='Artificial Intelligence: Science and Impact')
[2018-03-02 14:53:01,615 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Artificial Intelligence: Science and Impact', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Artificial Intelligence: Science and Impact\n%A Miller, Michael SP\n%D 2015\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:01,615 DEBUG dbutils] Query result: 95
[2018-03-02 14:53:01,616 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf.
[2018-03-02 14:53:01,617 WARNING utils] Download file (url='http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf') and save (filename='PDF//95.pdf')
[2018-03-02 14:53:01,618 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 14:53:01,618 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:53:01,618 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for otherhost
[2018-03-02 14:53:01,909 DEBUG requests.packages.urllib3.connectionpool] "GET /download/37589003/AI_Science_Impact_v14_.pdf HTTP/1.1" 404 None
[2018-03-02 14:53:01,914 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf.
[2018-03-02 14:53:01,915 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf.
[2018-03-02 14:53:02,104 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf HTTP/1.1" 302 None
[2018-03-02 14:53:02,377 DEBUG requests.packages.urllib3.connectionpool] "GET /download/37589003/AI_Science_Impact_v14_.pdf HTTP/1.1" 404 None
[2018-03-02 14:53:02,378 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:02,378 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:53:02,564 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf HTTP/1.1" 302 None
[2018-03-02 14:53:02,824 DEBUG requests.packages.urllib3.connectionpool] "GET /download/37589003/AI_Science_Impact_v14_.pdf HTTP/1.1" 404 None
[2018-03-02 14:53:02,829 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:53:02,829 DEBUG __main__] Failed get_pdf from sci-hub for paper #94. URL=94
[2018-03-02 14:53:02,830 DEBUG scholar] Handle paper #106 (total 1170)
[2018-03-02 14:53:02,830 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:53:02,833 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:53:02,833 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:53:03,354 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:U_S3JufjybkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nXXkUAfSg6pVijDsgPbUf9nG4z_N&scisf=3&ct=citation&cd=105&hl=en HTTP/1.1" 200 206
[2018-03-02 14:53:03,355 DEBUG scholar] EndNote file:
%0 Journal Article
%T A turing test for computer game bots
%A Hingston, Philip
%J IEEE Transactions on Computational Intelligence and AI in Games
%V 1
%N 3
%P 169-186
%@ 1943-068X
%D 2009
%I IEEE

[2018-03-02 14:53:03,356 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:03,356 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:03,356 DEBUG __main__] Process content of EndNote file #106
{"title": "A turing test for computer game bots", "url": "http://ieeexplore.ieee.org/abstract/document/5247069/", "author": [{"shortname": "P Hingston", "gid": "QNcGZdQAAAAJ"}], "year": 2009}
{"citedby": 113, "type": "Journal Article", "title": "A turing test for computer game bots", "author": ["Hingston, Philip"], "journal": "IEEE Transactions on Computational Intelligence and AI in Games", "volume": 18, "numberorissue": "3", "pages": "169-186", "isbn/issn": "1943-068X", "year": "2009", "publisher": "IEEE", "start_page": 169, "end_page": 186, "EndNote": "%0 Journal Article\n%T A turing test for computer game bots\n%A Hingston, Philip\n%J IEEE Transactions on Computational Intelligence and AI in Games\n%V 1\n%N 3\n%P 169-186\n%@ 1943-068X\n%D 2009\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:U_S3JufjybkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nXXkUAfSg6pVijDsgPbUf9nG4z_N&scisf=3&ct=citation&cd=105&hl=en"}
[2018-03-02 14:53:03,356 DEBUG dbutils] Get paper id {"DOI": null, "title": "A turing test for computer game bots", "auth_count": 1, "g_type": "Journal Article", "pages": 18, "year": 2009, "rg_id": null, "start_page": 169, "end_page": 186}.
[2018-03-02 14:53:03,356 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A turing test for computer game bots', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 18, 'year': 2009, 'rg_id': None, 'start_page': 169, 'end_page': 186}
[2018-03-02 14:53:03,356 DEBUG dbutils] Query result: []
[2018-03-02 14:53:03,356 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:03,356 DEBUG dbutils] Add new paper (title='A turing test for computer game bots')
[2018-03-02 14:53:03,356 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A turing test for computer game bots', 'year': 2009, 'publisher': 'IEEE', 'start_page': 169, 'end_page': 186, 'pages': 18, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A turing test for computer game bots\n%A Hingston, Philip\n%J IEEE Transactions on Computational Intelligence and AI in Games\n%V 1\n%N 3\n%P 169-186\n%@ 1943-068X\n%D 2009\n%I IEEE\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:03,356 DEBUG dbutils] Query result: 96
[2018-03-02 14:53:03,358 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.cs.ucf.edu/~gitars/cap6671-2010/Presentations/turing.pdf.
[2018-03-02 14:53:03,359 WARNING utils] Download file (url='http://www.cs.ucf.edu/~gitars/cap6671-2010/Presentations/turing.pdf') and save (filename='PDF//96.pdf')
[2018-03-02 14:53:03,359 DEBUG utils] Get current proxy for www.cs.ucf.edu.
[2018-03-02 14:53:03,359 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:53:03,376 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.cs.ucf.edu
[2018-03-02 14:53:03,879 DEBUG requests.packages.urllib3.connectionpool] "GET /~gitars/cap6671-2010/Presentations/turing.pdf HTTP/1.1" 200 1020334
[2018-03-02 14:53:03,879 DEBUG utils] Content-length=1020334
[2018-03-02 14:53:03,881 DEBUG utils] Create file PDF//96.pdf, start download.
[2018-03-02 14:53:07,917 DEBUG utils] End download file PDF//96.pdf.
[2018-03-02 14:53:07,919 DEBUG dbutils] Update pdf_transaction for paper id=96.
[2018-03-02 14:53:07,919 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 96'
[2018-03-02 14:53:07,919 DEBUG dbutils] Query result: null
[2018-03-02 14:53:07,920 DEBUG scholar] Handle paper #107 (total 1170)
[2018-03-02 14:53:07,920 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:53:07,924 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:53:07,925 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:53:07,925 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for scholar.google.com
[2018-03-02 14:53:07,941 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:53:09,233 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nnQ6B_LdV9sJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nd_M5v9uSU04ix1FurI2P2qmvx0h&scisf=3&ct=citation&cd=106&hl=en HTTP/1.1" 200 233
[2018-03-02 14:53:09,235 DEBUG scholar] EndNote file:
%0 Journal Article
%T Advances in natural language processing
%A Hirschberg, Julia
%A Manning, Christopher D
%J Science
%V 349
%N 6245
%P 261-266
%@ 0036-8075
%D 2015
%I American Association for the Advancement of Science

[2018-03-02 14:53:09,235 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:09,235 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:09,235 DEBUG __main__] Process content of EndNote file #107
{"title": "Advances in natural language processing", "url": "http://science.sciencemag.org/content/349/6245/261.short", "author": [{"shortname": "J Hirschberg", "gid": "Qrd7FCoAAAAJ"}, {"shortname": "CD Manning", "gid": "1zmDOdwAAAAJ"}], "year": 2015}
{"citedby": 109, "type": "Journal Article", "title": "Advances in natural language processing", "author": ["Hirschberg, Julia", "Manning, Christopher D"], "journal": "Science", "volume": 6, "numberorissue": "6245", "pages": "261-266", "isbn/issn": "0036-8075", "year": "2015", "publisher": "American Association for the Advancement of Science", "start_page": 261, "end_page": 266, "EndNote": "%0 Journal Article\n%T Advances in natural language processing\n%A Hirschberg, Julia\n%A Manning, Christopher D\n%J Science\n%V 349\n%N 6245\n%P 261-266\n%@ 0036-8075\n%D 2015\n%I American Association for the Advancement of Science\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:nnQ6B_LdV9sJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nd_M5v9uSU04ix1FurI2P2qmvx0h&scisf=3&ct=citation&cd=106&hl=en"}
[2018-03-02 14:53:09,235 DEBUG dbutils] Get paper id {"DOI": null, "title": "Advances in natural language processing", "auth_count": 2, "g_type": "Journal Article", "pages": 6, "year": 2015, "rg_id": null, "start_page": 261, "end_page": 266}.
[2018-03-02 14:53:09,235 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Advances in natural language processing', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 6, 'year': 2015, 'rg_id': None, 'start_page': 261, 'end_page': 266}
[2018-03-02 14:53:09,235 DEBUG dbutils] Query result: []
[2018-03-02 14:53:09,236 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:09,236 DEBUG dbutils] Add new paper (title='Advances in natural language processing')
[2018-03-02 14:53:09,236 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Advances in natural language processing', 'year': 2015, 'publisher': 'American Association for the Advancement of Science', 'start_page': 261, 'end_page': 266, 'pages': 6, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Advances in natural language processing\n%A Hirschberg, Julia\n%A Manning, Christopher D\n%J Science\n%V 349\n%N 6245\n%P 261-266\n%@ 0036-8075\n%D 2015\n%I American Association for the Advancement of Science\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:09,236 DEBUG dbutils] Query result: 97
[2018-03-02 14:53:09,239 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://cs224d.stanford.edu/papers/advances.pdf.
[2018-03-02 14:53:09,240 WARNING utils] Download file (url='http://cs224d.stanford.edu/papers/advances.pdf') and save (filename='PDF//97.pdf')
[2018-03-02 14:53:09,240 DEBUG utils] Get current proxy for cs224d.stanford.edu.
[2018-03-02 14:53:09,240 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:53:09,240 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for otherhost
[2018-03-02 14:53:09,257 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cs224d.stanford.edu
[2018-03-02 14:53:10,128 DEBUG requests.packages.urllib3.connectionpool] "GET /papers/advances.pdf HTTP/1.1" 200 780973
[2018-03-02 14:53:10,129 DEBUG utils] Content-length=780973
[2018-03-02 14:53:10,129 DEBUG utils] Create file PDF//97.pdf, start download.
[2018-03-02 14:53:14,340 DEBUG utils] End download file PDF//97.pdf.
[2018-03-02 14:53:14,341 DEBUG dbutils] Update pdf_transaction for paper id=97.
[2018-03-02 14:53:14,341 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 97'
[2018-03-02 14:53:14,342 DEBUG dbutils] Query result: null
[2018-03-02 14:53:14,342 DEBUG scholar] Handle paper #108 (total 1170)
[2018-03-02 14:53:14,342 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:53:14,346 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:53:14,346 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:53:14,573 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Isk4qvfpBEIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nXPPbojP4lsukyyNaCjHDDTwnW3v&scisf=3&ct=citation&cd=107&hl=en HTTP/1.1" 200 174
[2018-03-02 14:53:14,574 DEBUG scholar] EndNote file:
%0 Book
%T The online learning idea book: Proven ways to enhance technology-based and blended learning
%A Shank, Patti
%V 2
%@ 1118093690
%D 2011
%I John Wiley & Sons

[2018-03-02 14:53:14,574 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:14,574 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:14,574 DEBUG __main__] Process content of EndNote file #108
{"title": "The online learning idea book: Proven ways to enhance technology-based and blended learning", "url": "https://books.google.com/books?hl=en&lr=&id=M-U54g2M1NUC&oi=fnd&pg=PP16&dq=Use+deep+learning+to+create+a+chatbot&ots=4exSpDpGkJ&sig=lV3mkujBZO53YHFqHL-yJUDfHYQ", "author": [{"shortname": "P Shank", "gid": "qCoeDbgAAAAJ"}], "year": 2011}
{"citedby": 67, "type": "Book", "title": "The online learning idea book: Proven ways to enhance technology-based and blended learning", "author": ["Shank, Patti"], "volume": "2", "isbn/issn": "1118093690", "year": "2011", "publisher": "John Wiley & Sons", "EndNote": "%0 Book\n%T The online learning idea book: Proven ways to enhance technology-based and blended learning\n%A Shank, Patti\n%V 2\n%@ 1118093690\n%D 2011\n%I John Wiley & Sons\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Isk4qvfpBEIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nXPPbojP4lsukyyNaCjHDDTwnW3v&scisf=3&ct=citation&cd=107&hl=en"}
[2018-03-02 14:53:14,575 DEBUG dbutils] Get paper id {"DOI": null, "title": "The online learning idea book: Proven ways to enhance technology-based and blended learning", "auth_count": 1, "g_type": "Book", "pages": 2, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:53:14,575 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The online learning idea book: Proven ways to enhance technology-based and blended learning', 'auth_count': 1, 'g_type': 'Book', 'pages': 2, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:53:14,575 DEBUG dbutils] Query result: []
[2018-03-02 14:53:14,575 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:14,575 DEBUG dbutils] Add new paper (title='The online learning idea book: Proven ways to enhance technology-based and blended learning')
[2018-03-02 14:53:14,575 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The online learning idea book: Proven ways to enhance technology-based and blended learning', 'year': 2011, 'publisher': 'John Wiley & Sons', 'start_page': None, 'end_page': None, 'pages': 2, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T The online learning idea book: Proven ways to enhance technology-based and blended learning\n%A Shank, Patti\n%V 2\n%@ 1118093690\n%D 2011\n%I John Wiley & Sons\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:14,575 DEBUG dbutils] Query result: 98
[2018-03-02 14:53:14,577 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=M-U54g2M1NUC&oi=fnd&pg=PP16&dq=Use+deep+learning+to+create+a+chatbot&ots=4exSpDpGkJ&sig=lV3mkujBZO53YHFqHL-yJUDfHYQ.
[2018-03-02 14:53:14,577 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=M-U54g2M1NUC&oi=fnd&pg=PP16&dq=Use+deep+learning+to+create+a+chatbot&ots=4exSpDpGkJ&sig=lV3mkujBZO53YHFqHL-yJUDfHYQ.
[2018-03-02 14:53:14,754 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=M-U54g2M1NUC&oi=fnd&pg=PP16&dq=Use+deep+learning+to+create+a+chatbot&ots=4exSpDpGkJ&sig=lV3mkujBZO53YHFqHL-yJUDfHYQ HTTP/1.1" 302 None
[2018-03-02 14:53:14,906 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:53:14,923 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:14,923 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:53:14,923 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for sci-hub.tw
[2018-03-02 14:53:15,116 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=M-U54g2M1NUC&oi=fnd&pg=PP16&dq=Use+deep+learning+to+create+a+chatbot&ots=4exSpDpGkJ&sig=lV3mkujBZO53YHFqHL-yJUDfHYQ HTTP/1.1" 302 None
[2018-03-02 14:53:15,304 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:53:15,348 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:53:15,349 DEBUG scholar] Handle paper #109 (total 1170)
[2018-03-02 14:53:15,349 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:53:15,352 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:53:15,352 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:53:15,353 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for scholar.google.com
[2018-03-02 14:53:15,369 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:53:15,370 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:53:16,934 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:zObW7OZOUYkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nW_Vd7WHvqQMFZ3n0kzo6-Xl-fiR&scisf=3&ct=citation&cd=108&hl=en HTTP/1.1" 200 296
[2018-03-02 14:53:16,935 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Like having a really bad PA: the gulf between user expectation and experience of conversational agents
%A Luger, Ewa
%A Sellen, Abigail
%B Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems
%P 5286-5297
%@ 1450333621
%D 2016
%I ACM

[2018-03-02 14:53:16,935 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:16,935 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:16,935 DEBUG __main__] Process content of EndNote file #109
{"title": "Like having a really bad PA: the gulf between user expectation and experience of conversational agents", "url": "https://dl.acm.org/citation.cfm?id=2858288", "author": [{"shortname": "E Luger", "gid": "vlaFJs8AAAAJ"}, {"shortname": "A Sellen", "gid": "3UlxG6UAAAAJ"}], "year": 2016}
{"citedby": 41, "type": "Conference Proceedings", "title": "Like having a really bad PA: the gulf between user expectation and experience of conversational agents", "author": ["Luger, Ewa", "Sellen, Abigail"], "secondarytitle": "Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems", "pages": "5286-5297", "isbn/issn": "1450333621", "year": "2016", "publisher": "ACM", "start_page": 5286, "end_page": 5297, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T Like having a really bad PA: the gulf between user expectation and experience of conversational agents\n%A Luger, Ewa\n%A Sellen, Abigail\n%B Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems\n%P 5286-5297\n%@ 1450333621\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:zObW7OZOUYkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nW_Vd7WHvqQMFZ3n0kzo6-Xl-fiR&scisf=3&ct=citation&cd=108&hl=en"}
[2018-03-02 14:53:16,935 DEBUG dbutils] Get paper id {"DOI": null, "title": "Like having a really bad PA: the gulf between user expectation and experience of conversational agents", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 12, "year": 2016, "rg_id": null, "start_page": 5286, "end_page": 5297}.
[2018-03-02 14:53:16,935 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Like having a really bad PA: the gulf between user expectation and experience of conversational agents', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 5286, 'end_page': 5297}
[2018-03-02 14:53:16,935 DEBUG dbutils] Query result: []
[2018-03-02 14:53:16,935 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:16,935 DEBUG dbutils] Add new paper (title='Like having a really bad PA: the gulf between user expectation and experience of conversational agents')
[2018-03-02 14:53:16,936 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Like having a really bad PA: the gulf between user expectation and experience of conversational agents', 'year': 2016, 'publisher': 'ACM', 'start_page': 5286, 'end_page': 5297, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Like having a really bad PA: the gulf between user expectation and experience of conversational agents\n%A Luger, Ewa\n%A Sellen, Abigail\n%B Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems\n%P 5286-5297\n%@ 1450333621\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:16,936 DEBUG dbutils] Query result: 99
[2018-03-02 14:53:16,937 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/814e/62bb4f0ec6facd640fbd3e3fcbd189716d20.pdf.
[2018-03-02 14:53:16,938 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/814e/62bb4f0ec6facd640fbd3e3fcbd189716d20.pdf') and save (filename='PDF//99.pdf')
[2018-03-02 14:53:16,939 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:53:16,939 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:53:16,954 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 14:53:18,268 DEBUG requests.packages.urllib3.connectionpool] "GET /814e/62bb4f0ec6facd640fbd3e3fcbd189716d20.pdf HTTP/1.1" 301 112
[2018-03-02 14:53:18,291 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.semanticscholar.org
[2018-03-02 14:53:19,724 DEBUG requests.packages.urllib3.connectionpool] "GET /paper/814e62bb4f0ec6facd640fbd3e3fcbd189716d20 HTTP/1.1" 301 None
[2018-03-02 14:53:20,168 DEBUG requests.packages.urllib3.connectionpool] "GET /paper/%22Like-Having-a-Really-Bad-PA%22%3A-The-Gulf-between-Us-Luger-Sellen/814e62bb4f0ec6facd640fbd3e3fcbd189716d20 HTTP/1.1" 200 None
[2018-03-02 14:53:21,486 DEBUG utils] Server do not give PDF.
[2018-03-02 14:53:21,487 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2858288.
[2018-03-02 14:53:21,488 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2858288.
[2018-03-02 14:53:22,663 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2858288 HTTP/1.1" 200 None
[2018-03-02 14:53:22,665 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:22,665 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:53:22,817 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2858288 HTTP/1.1" 200 None
[2018-03-02 14:53:22,824 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/cd6e019ad4c1c79c74cbc465acfd7ba0/luger2016.pdf?download=true.
[2018-03-02 14:53:22,824 WARNING utils] Download file (url='http://twin.sci-hub.tw/cd6e019ad4c1c79c74cbc465acfd7ba0/luger2016.pdf?download=true') and save (filename='PDF//99.pdf')
[2018-03-02 14:53:22,839 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 14:53:23,014 DEBUG requests.packages.urllib3.connectionpool] "GET /cd6e019ad4c1c79c74cbc465acfd7ba0/luger2016.pdf?download=true HTTP/1.1" 200 1527150
[2018-03-02 14:53:23,015 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 14:53:23,015 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:53:23,015 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for sci-hub.tw
[2018-03-02 14:53:23,032 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 14:53:23,436 DEBUG requests.packages.urllib3.connectionpool] "GET /cd6e019ad4c1c79c74cbc465acfd7ba0/luger2016.pdf?download=true HTTP/1.1" 200 1527150
[2018-03-02 14:53:23,437 DEBUG utils] Content-length=1527150
[2018-03-02 14:53:23,438 DEBUG utils] Create file PDF//99.pdf, start download.
[2018-03-02 14:53:25,658 DEBUG utils] End download file PDF//99.pdf.
[2018-03-02 14:53:25,660 DEBUG dbutils] Update pdf_transaction for paper id=99.
[2018-03-02 14:53:25,660 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 99'
[2018-03-02 14:53:25,661 DEBUG dbutils] Query result: null
[2018-03-02 14:53:25,661 DEBUG scholar] Handle paper #110 (total 1170)
[2018-03-02 14:53:25,661 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:53:25,664 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:53:25,664 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:53:26,024 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:oC4N_t-VePIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nZBwBJ1YWJo3LocZkvjZw0J6_tBc&scisf=3&ct=citation&cd=109&hl=en HTTP/1.1" 200 357
[2018-03-02 14:53:26,025 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Modeling semantic relevance for question-answer pairs in web social communities
%A Wang, Baoxun
%A Wang, Xiaolong
%A Sun, Chengjie
%A Liu, Bingquan
%A Sun, Lin
%B Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics
%P 1230-1238
%D 2010
%I Association for Computational Linguistics

[2018-03-02 14:53:26,025 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:53:26,025 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:53:26,025 DEBUG __main__] Process content of EndNote file #110
{"title": "Modeling semantic relevance for question-answer pairs in web social communities", "url": "https://dl.acm.org/citation.cfm?id=1858806", "author": [{"shortname": "B Wang", "gid": "HPFpDpoAAAAJ"}, {"shortname": "X Wang", "gid": "Q2-9VWsAAAAJ"}, {"shortname": "C Sun", "gid": ""}, {"shortname": "B Liu", "gid": ""}, {"shortname": "L Sun", "gid": ""}], "year": 2010}
{"citedby": 44, "type": "Conference Proceedings", "title": "Modeling semantic relevance for question-answer pairs in web social communities", "author": ["Wang, Baoxun", "Wang, Xiaolong", "Sun, Chengjie", "Liu, Bingquan", "Sun, Lin"], "secondarytitle": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics", "pages": "1230-1238", "year": "2010", "publisher": "Association for Computational Linguistics", "start_page": 1230, "end_page": 1238, "volume": 9, "EndNote": "%0 Conference Proceedings\n%T Modeling semantic relevance for question-answer pairs in web social communities\n%A Wang, Baoxun\n%A Wang, Xiaolong\n%A Sun, Chengjie\n%A Liu, Bingquan\n%A Sun, Lin\n%B Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics\n%P 1230-1238\n%D 2010\n%I Association for Computational Linguistics\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:oC4N_t-VePIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk9nZBwBJ1YWJo3LocZkvjZw0J6_tBc&scisf=3&ct=citation&cd=109&hl=en"}
[2018-03-02 14:53:26,026 DEBUG dbutils] Get paper id {"DOI": null, "title": "Modeling semantic relevance for question-answer pairs in web social communities", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 9, "year": 2010, "rg_id": null, "start_page": 1230, "end_page": 1238}.
[2018-03-02 14:53:26,026 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Modeling semantic relevance for question-answer pairs in web social communities', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 9, 'year': 2010, 'rg_id': None, 'start_page': 1230, 'end_page': 1238}
[2018-03-02 14:53:26,026 DEBUG dbutils] Query result: []
[2018-03-02 14:53:26,026 DEBUG dbutils] Paper id = None.
[2018-03-02 14:53:26,026 DEBUG dbutils] Add new paper (title='Modeling semantic relevance for question-answer pairs in web social communities')
[2018-03-02 14:53:26,026 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Modeling semantic relevance for question-answer pairs in web social communities', 'year': 2010, 'publisher': 'Association for Computational Linguistics', 'start_page': 1230, 'end_page': 1238, 'pages': 9, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Modeling semantic relevance for question-answer pairs in web social communities\n%A Wang, Baoxun\n%A Wang, Xiaolong\n%A Sun, Chengjie\n%A Liu, Bingquan\n%A Sun, Lin\n%B Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics\n%P 1230-1238\n%D 2010\n%I Association for Computational Linguistics\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 14:53:26,026 DEBUG dbutils] Query result: 100
[2018-03-02 14:53:26,028 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/P10-1125.
[2018-03-02 14:53:26,028 WARNING utils] Download file (url='http://www.aclweb.org/anthology/P10-1125') and save (filename='PDF//100.pdf')
[2018-03-02 14:53:26,028 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:53:26,028 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 14:53:26,028 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for otherhost
[2018-03-02 14:53:26,046 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 14:53:26,654 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P10-1125 HTTP/1.1" 200 None
[2018-03-02 14:53:26,654 DEBUG utils] Downloading the entire file.
[2018-03-02 14:53:26,655 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 14:53:26,655 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:53:26,669 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 14:53:27,411 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/P10-1125 HTTP/1.1" 200 None
[2018-03-02 14:53:29,259 DEBUG utils] Save file PDF//100.pdf.
[2018-03-02 14:53:29,261 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1858806.
[2018-03-02 14:53:29,261 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1858806.
[2018-03-02 14:53:30,442 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1858806 HTTP/1.1" 200 None
[2018-03-02 14:53:30,446 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:30,446 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:53:30,610 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1858806 HTTP/1.1" 200 None
[2018-03-02 14:53:30,615 DEBUG scihub] URL for PDF: https://sci-hub.tw/saveme/3fab/10.0000@dl.acm.org@1858806.pdf.
[2018-03-02 14:53:30,616 WARNING utils] Download file (url='https://sci-hub.tw/saveme/3fab/10.0000@dl.acm.org@1858806.pdf') and save (filename='PDF//100.pdf')
[2018-03-02 14:53:30,631 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (21): sci-hub.tw
[2018-03-02 14:53:31,253 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:31,254 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:31,254 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:53:31,254 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for sci-hub.tw
[2018-03-02 14:53:31,269 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:53:36,270 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708BDE908>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708BDE908>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708BDE908>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 14:53:36,272 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for sci-hub.tw
[2018-03-02 14:53:36,287 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (22): sci-hub.tw
[2018-03-02 14:53:36,916 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:36,917 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:36,917 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:53:36,932 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:53:38,067 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:38,067 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for sci-hub.tw
[2018-03-02 14:53:38,082 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (23): sci-hub.tw
[2018-03-02 14:53:38,769 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:38,770 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:38,770 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 14:53:38,787 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 14:53:42,074 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:42,075 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for sci-hub.tw
[2018-03-02 14:53:42,092 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (24): sci-hub.tw
[2018-03-02 14:53:42,585 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:42,586 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:42,586 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:53:42,601 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:47,907 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:53:47,908 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for sci-hub.tw
[2018-03-02 14:53:47,923 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (25): sci-hub.tw
[2018-03-02 14:53:48,552 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:48,554 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:48,554 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 14:53:48,569 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:49,624 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:49,624 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for sci-hub.tw
[2018-03-02 14:53:49,640 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (26): sci-hub.tw
[2018-03-02 14:53:50,326 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:50,327 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:50,327 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 14:53:50,343 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:51,064 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:51,065 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for sci-hub.tw
[2018-03-02 14:53:51,087 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (27): sci-hub.tw
[2018-03-02 14:53:51,771 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:51,772 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:51,772 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:53:51,804 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:52,305 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:52,305 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for sci-hub.tw
[2018-03-02 14:53:52,334 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (28): sci-hub.tw
[2018-03-02 14:53:53,055 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:53,056 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:53,056 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 14:53:53,080 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:53,794 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:53,795 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for sci-hub.tw
[2018-03-02 14:53:53,815 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (29): sci-hub.tw
[2018-03-02 14:53:54,466 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:54,485 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:54,485 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:53:54,510 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:54,944 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:54,944 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for sci-hub.tw
[2018-03-02 14:53:54,973 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (30): sci-hub.tw
[2018-03-02 14:53:55,625 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:55,626 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:55,626 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:53:55,642 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:57,025 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:57,025 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for sci-hub.tw
[2018-03-02 14:53:57,040 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (31): sci-hub.tw
[2018-03-02 14:53:57,619 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:57,620 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:57,620 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:53:57,636 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:53:58,514 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:53:58,514 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for sci-hub.tw
[2018-03-02 14:53:58,529 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (32): sci-hub.tw
[2018-03-02 14:53:59,145 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:53:59,146 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:53:59,146 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:53:59,161 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:01,064 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:01,064 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for sci-hub.tw
[2018-03-02 14:54:01,083 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (33): sci-hub.tw
[2018-03-02 14:54:01,707 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:01,708 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:01,708 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 14:54:01,727 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:03,694 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:03,694 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for sci-hub.tw
[2018-03-02 14:54:03,710 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (34): sci-hub.tw
[2018-03-02 14:54:04,287 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:04,288 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:04,288 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 14:54:04,303 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:06,895 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:06,895 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for sci-hub.tw
[2018-03-02 14:54:06,929 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (35): sci-hub.tw
[2018-03-02 14:54:07,510 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:07,511 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:07,511 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 14:54:07,526 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:09,564 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:09,564 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for sci-hub.tw
[2018-03-02 14:54:09,580 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (36): sci-hub.tw
[2018-03-02 14:54:10,194 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:10,194 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:10,195 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 14:54:10,213 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:11,054 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/3fab/10.0000@dl.acm.org@1858806.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:54:11,054 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for sci-hub.tw
[2018-03-02 14:54:11,069 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (37): sci-hub.tw
[2018-03-02 14:54:11,647 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:11,648 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:11,648 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:54:11,677 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:13,956 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:13,956 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for sci-hub.tw
[2018-03-02 14:54:13,972 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (38): sci-hub.tw
[2018-03-02 14:54:14,520 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:14,521 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:14,521 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:54:14,536 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:17,096 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:17,096 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for sci-hub.tw
[2018-03-02 14:54:17,113 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (39): sci-hub.tw
[2018-03-02 14:54:17,625 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:17,626 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:17,626 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:54:17,641 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:18,566 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:18,566 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for sci-hub.tw
[2018-03-02 14:54:18,582 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (40): sci-hub.tw
[2018-03-02 14:54:19,175 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/3fab/10.0000@dl.acm.org@1858806.pdf HTTP/1.1" 200 362312
[2018-03-02 14:54:19,176 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:19,176 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 14:54:19,191 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 14:54:20,164 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:54:20,164 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for sci-hub.tw
[2018-03-02 14:54:20,168 DEBUG dbutils] Commiting transaction 110.
[2018-03-02 14:54:20,316 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:54:20,316 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:54:20,316 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:54:20,316 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for scholar.google.com
[2018-03-02 14:54:20,331 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:54:22,513 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=110&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:54:23,973 DEBUG scholar] Find papers on page #12 (max_google_papers = 300)
[2018-03-02 14:54:23,973 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:54:23,974 DEBUG scholar] Handle paper #111 (total 1170)
[2018-03-02 14:54:23,974 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:54:23,977 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:54:23,977 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:54:23,995 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:54:23,996 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:54:26,113 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:CUNu3zBWU-sJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C9Ihoz8is7ppJhXXb9Wd0bLpEqmy&scisf=3&ct=citation&cd=110&hl=en HTTP/1.1" 200 161
[2018-03-02 14:54:26,114 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Using data mining to automate addie
%A Ray, Fritz
%A Brawner, Keith
%A Robson, Robby
%B Educational Data Mining 2014
%D 2014

[2018-03-02 14:54:26,114 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:54:26,114 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:54:26,114 DEBUG __main__] Process content of EndNote file #111
{"title": "Using data mining to automate addie", "url": "http://eduworks.com/documents/105_EDM-2014-Poster.pdf", "author": [{"shortname": "F Ray", "gid": ""}, {"shortname": "K Brawner", "gid": "SuI1kAQAAAAJ"}, {"shortname": "R Robson", "gid": ""}], "year": 2014}
{"citedby": 6, "type": "Conference Proceedings", "title": "Using data mining to automate addie", "author": ["Ray, Fritz", "Brawner, Keith", "Robson, Robby"], "secondarytitle": "Educational Data Mining 2014", "year": "2014", "EndNote": "%0 Conference Proceedings\n%T Using data mining to automate addie\n%A Ray, Fritz\n%A Brawner, Keith\n%A Robson, Robby\n%B Educational Data Mining 2014\n%D 2014\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:CUNu3zBWU-sJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C9Ihoz8is7ppJhXXb9Wd0bLpEqmy&scisf=3&ct=citation&cd=110&hl=en"}
[2018-03-02 14:54:26,115 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using data mining to automate addie", "auth_count": 3, "g_type": "Conference Proceedings", "pages": null, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:54:26,115 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using data mining to automate addie', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:54:26,115 DEBUG dbutils] Query result: []
[2018-03-02 14:54:26,115 DEBUG dbutils] Paper id = None.
[2018-03-02 14:54:26,115 DEBUG dbutils] Add new paper (title='Using data mining to automate addie')
[2018-03-02 14:54:26,115 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using data mining to automate addie', 'year': 2014, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Using data mining to automate addie\n%A Ray, Fritz\n%A Brawner, Keith\n%A Robson, Robby\n%B Educational Data Mining 2014\n%D 2014\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:54:26,116 DEBUG dbutils] Query result: 101
[2018-03-02 14:54:26,117 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://eduworks.com/documents/105_EDM-2014-Poster.pdf.
[2018-03-02 14:54:26,118 WARNING utils] Download file (url='http://eduworks.com/documents/105_EDM-2014-Poster.pdf') and save (filename='PDF//101.pdf')
[2018-03-02 14:54:26,118 DEBUG utils] Get current proxy for eduworks.com.
[2018-03-02 14:54:26,118 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:54:26,118 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for otherhost
[2018-03-02 14:54:26,135 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): eduworks.com
[2018-03-02 14:54:26,722 DEBUG requests.packages.urllib3.connectionpool] "GET /documents/105_EDM-2014-Poster.pdf HTTP/1.1" 301 340
[2018-03-02 14:54:26,746 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): eduworks.com
[2018-03-02 14:54:30,043 DEBUG requests.packages.urllib3.connectionpool] "GET /documents/105_EDM-2014-Poster.pdf HTTP/1.1" 200 582768
[2018-03-02 14:54:30,043 DEBUG utils] Content-length=582768
[2018-03-02 14:54:30,044 DEBUG utils] Create file PDF//101.pdf, start download.
[2018-03-02 14:54:39,036 DEBUG utils] End download file PDF//101.pdf.
[2018-03-02 14:54:39,037 DEBUG dbutils] Update pdf_transaction for paper id=101.
[2018-03-02 14:54:39,038 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 101'
[2018-03-02 14:54:39,038 DEBUG dbutils] Query result: null
[2018-03-02 14:54:39,038 DEBUG scholar] Handle paper #112 (total 1170)
[2018-03-02 14:54:39,039 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:54:39,045 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:54:39,045 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 14:54:39,045 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for scholar.google.com
[2018-03-02 14:54:39,063 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:54:39,065 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:54:40,176 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:DAfpFmBuoXEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C1QUYsynnaxYjoaTPTlkIO-X_olS&scisf=3&ct=citation&cd=111&hl=en HTTP/1.1" 200 250
[2018-03-02 14:54:40,177 DEBUG scholar] EndNote file:
%0 Journal Article
%T Topic augmented neural response generation with a joint attention mechanism
%A Xing, Chen
%A Wu, Wei
%A Wu, Yu
%A Liu, Jie
%A Huang, Yalou
%A Zhou, Ming
%A Ma, Wei-Ying
%J URL http://arxiv. org/abs/1606.08340
%D 2016

[2018-03-02 14:54:40,177 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:54:40,177 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:54:40,177 DEBUG __main__] Process content of EndNote file #112
{"title": "Topic augmented neural response generation with a joint attention mechanism", "url": "https://pdfs.semanticscholar.org/f5c1/a53daef462ce1120d64c13aa11ed88702547.pdf", "author": [{"shortname": "C Xing", "gid": ""}, {"shortname": "W Wu", "gid": "YtqXSzMAAAAJ"}, {"shortname": "Y Wu", "gid": "aQizmzsAAAAJ"}, {"shortname": "J Liu", "gid": "VmLrvTIAAAAJ"}, {"shortname": "Y Huang", "gid": ""}], "year": 2016}
{"citedby": 13, "type": "Journal Article", "title": "Topic augmented neural response generation with a joint attention mechanism", "author": ["Xing, Chen", "Wu, Wei", "Wu, Yu", "Liu, Jie", "Huang, Yalou", "Zhou, Ming", "Ma, Wei-Ying"], "journal": "URL http://arxiv. org/abs/1606.08340", "year": "2016", "EndNote": "%0 Journal Article\n%T Topic augmented neural response generation with a joint attention mechanism\n%A Xing, Chen\n%A Wu, Wei\n%A Wu, Yu\n%A Liu, Jie\n%A Huang, Yalou\n%A Zhou, Ming\n%A Ma, Wei-Ying\n%J URL http://arxiv. org/abs/1606.08340\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:DAfpFmBuoXEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C1QUYsynnaxYjoaTPTlkIO-X_olS&scisf=3&ct=citation&cd=111&hl=en"}
[2018-03-02 14:54:40,177 DEBUG dbutils] Get paper id {"DOI": null, "title": "Topic augmented neural response generation with a joint attention mechanism", "auth_count": 7, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:54:40,177 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Topic augmented neural response generation with a joint attention mechanism', 'auth_count': 7, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:54:40,178 DEBUG dbutils] Query result: []
[2018-03-02 14:54:40,178 DEBUG dbutils] Paper id = None.
[2018-03-02 14:54:40,178 DEBUG dbutils] Add new paper (title='Topic augmented neural response generation with a joint attention mechanism')
[2018-03-02 14:54:40,178 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Topic augmented neural response generation with a joint attention mechanism', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Topic augmented neural response generation with a joint attention mechanism\n%A Xing, Chen\n%A Wu, Wei\n%A Wu, Yu\n%A Liu, Jie\n%A Huang, Yalou\n%A Zhou, Ming\n%A Ma, Wei-Ying\n%J URL http://arxiv. org/abs/1606.08340\n%D 2016\n', 'RIS': None, 'authors': 7, 'ignore': False, 'transaction': 1}
[2018-03-02 14:54:40,178 DEBUG dbutils] Query result: 102
[2018-03-02 14:54:40,180 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/f5c1/a53daef462ce1120d64c13aa11ed88702547.pdf.
[2018-03-02 14:54:40,181 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/f5c1/a53daef462ce1120d64c13aa11ed88702547.pdf') and save (filename='PDF//102.pdf')
[2018-03-02 14:54:40,181 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:54:40,181 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:54:40,196 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 14:54:40,197 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 14:54:44,152 DEBUG requests.packages.urllib3.connectionpool] "GET /f5c1/a53daef462ce1120d64c13aa11ed88702547.pdf HTTP/1.1" 200 241187
[2018-03-02 14:54:44,152 DEBUG utils] Content-length=241187
[2018-03-02 14:54:44,153 DEBUG utils] Create file PDF//102.pdf, start download.
[2018-03-02 14:54:46,647 DEBUG utils] End download file PDF//102.pdf.
[2018-03-02 14:54:46,648 DEBUG dbutils] Update pdf_transaction for paper id=102.
[2018-03-02 14:54:46,648 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 102'
[2018-03-02 14:54:46,648 DEBUG dbutils] Query result: null
[2018-03-02 14:54:46,649 DEBUG scholar] Handle paper #113 (total 1170)
[2018-03-02 14:54:46,649 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:54:46,654 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:54:46,655 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:54:46,942 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4ddEMDZfRu4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C7wg_zZbK4AsjqxFnwcd9ff1ywTY&scisf=3&ct=citation&cd=112&hl=en HTTP/1.1" 200 271
[2018-03-02 14:54:46,943 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Exploratory and Collaborative Learning Experience in Immersive Environments
%A Gutl, Christian
%A Tomes, Lisa Maria
%A Pirker, Johanna
%A Chang, Vanessa
%B International Conference on Immersive Learning
%P 3-16
%D 2016
%I Springer

[2018-03-02 14:54:46,943 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:54:46,943 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:54:46,943 DEBUG __main__] Process content of EndNote file #113
{"title": "Exploratory and Collaborative Learning Experience in Immersive Environments", "url": "https://link.springer.com/chapter/10.1007/978-3-319-41769-1_1", "author": [{"shortname": "C G\u00fctl", "gid": "NoAiKpcAAAAJ"}, {"shortname": "LM Tomes", "gid": ""}, {"shortname": "J Pirker", "gid": "ta4FNOkAAAAJ"}, {"shortname": "V Chang", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "Exploratory and Collaborative Learning Experience in Immersive Environments", "author": ["G\u00fctl, Christian", "Tomes, Lisa Maria", "Pirker, Johanna", "Chang, Vanessa"], "secondarytitle": "International Conference on Immersive Learning", "pages": "3-16", "year": "2016", "publisher": "Springer", "start_page": 3, "end_page": 16, "volume": 14, "EndNote": "%0 Conference Proceedings\n%T Exploratory and Collaborative Learning Experience in Immersive Environments\n%A G\u00fctl, Christian\n%A Tomes, Lisa Maria\n%A Pirker, Johanna\n%A Chang, Vanessa\n%B International Conference on Immersive Learning\n%P 3-16\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4ddEMDZfRu4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C7wg_zZbK4AsjqxFnwcd9ff1ywTY&scisf=3&ct=citation&cd=112&hl=en"}
[2018-03-02 14:54:46,944 DEBUG dbutils] Get paper id {"DOI": null, "title": "Exploratory and Collaborative Learning Experience in Immersive Environments", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 14, "year": 2016, "rg_id": null, "start_page": 3, "end_page": 16}.
[2018-03-02 14:54:46,944 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Exploratory and Collaborative Learning Experience in Immersive Environments', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 14, 'year': 2016, 'rg_id': None, 'start_page': 3, 'end_page': 16}
[2018-03-02 14:54:46,944 DEBUG dbutils] Query result: []
[2018-03-02 14:54:46,944 DEBUG dbutils] Paper id = None.
[2018-03-02 14:54:46,944 DEBUG dbutils] Add new paper (title='Exploratory and Collaborative Learning Experience in Immersive Environments')
[2018-03-02 14:54:46,944 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Exploratory and Collaborative Learning Experience in Immersive Environments', 'year': 2016, 'publisher': 'Springer', 'start_page': 3, 'end_page': 16, 'pages': 14, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Exploratory and Collaborative Learning Experience in Immersive Environments\n%A Gutl, Christian\n%A Tomes, Lisa Maria\n%A Pirker, Johanna\n%A Chang, Vanessa\n%B International Conference on Immersive Learning\n%P 3-16\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:54:46,944 DEBUG dbutils] Query result: 103
[2018-03-02 14:54:46,946 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-41769-1_1.
[2018-03-02 14:54:46,946 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-41769-1_1.
[2018-03-02 14:54:46,962 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 14:54:47,222 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-41769-1_1 HTTP/1.1" 302 None
[2018-03-02 14:54:47,245 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): libgen.io
[2018-03-02 14:54:47,758 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=A867AEB5D8EA2F2BAF5605DAE97DA9B8 HTTP/1.1" 200 9776
[2018-03-02 14:54:47,807 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:54:47,807 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 14:54:47,993 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-41769-1_1 HTTP/1.1" 302 None
[2018-03-02 14:54:48,213 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=A867AEB5D8EA2F2BAF5605DAE97DA9B8 HTTP/1.1" 200 9776
[2018-03-02 14:54:48,452 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:54:48,453 DEBUG scholar] Handle paper #114 (total 1170)
[2018-03-02 14:54:48,453 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:54:48,456 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:54:48,456 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:54:48,456 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for scholar.google.com
[2018-03-02 14:54:48,471 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:54:48,472 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:54:50,831 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:tGqEYZcpcAoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C9xy11OXyscjrkDbWP7mSKkjUhY0&scisf=3&ct=citation&cd=113&hl=en HTTP/1.1" 200 225
[2018-03-02 14:54:50,832 DEBUG scholar] EndNote file:
%0 Journal Article
%T Requirements for artificial companions: Its harder than you think
%A Sloman, Aaron
%J Close Engagements with Artificial Companions. J. Benjamins Publishing Company, Amsterdam
%P 179-200
%D 2010

[2018-03-02 14:54:50,832 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:54:50,832 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:54:50,832 DEBUG __main__] Process content of EndNote file #114
{"title": "Requirements for artificial companions: It's harder than you think", "url": "https://www.cs.bham.ac.uk/research/projects/cogaff/sloman-oii-2009.pdf", "author": [{"shortname": "A Sloman", "gid": "lTc3UwsAAAAJ"}], "year": 2010}
{"citedby": 8, "type": "Journal Article", "title": "Requirements for artificial companions: It\u2019s harder than you think", "author": ["Sloman, Aaron"], "journal": "Close Engagements with Artificial Companions. J. Benjamins Publishing Company, Amsterdam", "pages": "179-200", "year": "2010", "start_page": 179, "end_page": 200, "volume": 22, "EndNote": "%0 Journal Article\n%T Requirements for artificial companions: It\u2019s harder than you think\n%A Sloman, Aaron\n%J Close Engagements with Artificial Companions. J. Benjamins Publishing Company, Amsterdam\n%P 179-200\n%D 2010\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:tGqEYZcpcAoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C9xy11OXyscjrkDbWP7mSKkjUhY0&scisf=3&ct=citation&cd=113&hl=en"}
[2018-03-02 14:54:50,833 DEBUG dbutils] Get paper id {"DOI": null, "title": "Requirements for artificial companions: It\u2019s harder than you think", "auth_count": 1, "g_type": "Journal Article", "pages": 22, "year": 2010, "rg_id": null, "start_page": 179, "end_page": 200}.
[2018-03-02 14:54:50,833 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Requirements for artificial companions: Its harder than you think', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 22, 'year': 2010, 'rg_id': None, 'start_page': 179, 'end_page': 200}
[2018-03-02 14:54:50,833 DEBUG dbutils] Query result: []
[2018-03-02 14:54:50,833 DEBUG dbutils] Paper id = None.
[2018-03-02 14:54:50,833 DEBUG dbutils] Add new paper (title='Requirements for artificial companions: Its harder than you think')
[2018-03-02 14:54:50,833 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Requirements for artificial companions: Its harder than you think', 'year': 2010, 'publisher': None, 'start_page': 179, 'end_page': 200, 'pages': 22, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Requirements for artificial companions: Its harder than you think\n%A Sloman, Aaron\n%J Close Engagements with Artificial Companions. J. Benjamins Publishing Company, Amsterdam\n%P 179-200\n%D 2010\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:54:50,833 DEBUG dbutils] Query result: 104
[2018-03-02 14:54:50,836 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.cs.bham.ac.uk/research/projects/cogaff/sloman-oii-2009.pdf.
[2018-03-02 14:54:50,839 WARNING utils] Download file (url='https://www.cs.bham.ac.uk/research/projects/cogaff/sloman-oii-2009.pdf') and save (filename='PDF//104.pdf')
[2018-03-02 14:54:50,840 DEBUG utils] Get current proxy for www.cs.bham.ac.uk.
[2018-03-02 14:54:50,840 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:54:50,840 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for otherhost
[2018-03-02 14:54:50,854 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cs.bham.ac.uk
[2018-03-02 14:54:56,563 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.cs.bham.ac.uk', port=443): Max retries exceeded with url: /research/projects/cogaff/sloman-oii-2009.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.cs.bham.ac.uk', port=443): Max retries exceeded with url: /research/projects/cogaff/sloman-oii-2009.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:54:56,563 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for otherhost
[2018-03-02 14:54:56,563 DEBUG utils] Get current proxy for www.cs.bham.ac.uk.
[2018-03-02 14:54:56,563 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:54:56,577 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cs.bham.ac.uk
[2018-03-02 14:54:58,802 DEBUG requests.packages.urllib3.connectionpool] "GET /research/projects/cogaff/sloman-oii-2009.pdf HTTP/1.1" 200 184721
[2018-03-02 14:54:58,802 DEBUG utils] Content-length=184721
[2018-03-02 14:54:58,803 DEBUG utils] Create file PDF//104.pdf, start download.
[2018-03-02 14:55:00,853 DEBUG utils] End download file PDF//104.pdf.
[2018-03-02 14:55:00,854 DEBUG dbutils] Update pdf_transaction for paper id=104.
[2018-03-02 14:55:00,854 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 104'
[2018-03-02 14:55:00,854 DEBUG dbutils] Query result: null
[2018-03-02 14:55:00,855 DEBUG scholar] Handle paper #115 (total 1170)
[2018-03-02 14:55:00,855 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:55:00,860 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:55:00,861 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:55:01,422 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:yCK1HezZN88J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C8Fc_lAGYoh33_4uCl241b-uhMRO&scisf=3&ct=citation&cd=114&hl=en HTTP/1.1" 200 146
[2018-03-02 14:55:01,423 DEBUG scholar] EndNote file:
%0 Journal Article
%T AI amusements: the tragic tale of Tay the chatbot
%A Davis, Ernest
%J AI Matters
%V 2
%N 4
%P 20-24
%D 2016
%I ACM

[2018-03-02 14:55:01,423 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:55:01,423 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:55:01,423 DEBUG __main__] Process content of EndNote file #115
{"title": "AI amusements: the tragic tale of Tay the chatbot", "url": "http://sigai.acm.org/static/aimatters/2-4/AIMatters-2-4-09-Davis.pdf", "author": [{"shortname": "E Davis", "gid": "tLO-x-IAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "AI amusements: the tragic tale of Tay the chatbot", "author": ["Davis, Ernest"], "journal": "AI Matters", "volume": 5, "numberorissue": "4", "pages": "20-24", "year": "2016", "publisher": "ACM", "start_page": 20, "end_page": 24, "EndNote": "%0 Journal Article\n%T AI amusements: the tragic tale of Tay the chatbot\n%A Davis, Ernest\n%J AI Matters\n%V 2\n%N 4\n%P 20-24\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:yCK1HezZN88J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C8Fc_lAGYoh33_4uCl241b-uhMRO&scisf=3&ct=citation&cd=114&hl=en"}
[2018-03-02 14:55:01,423 DEBUG dbutils] Get paper id {"DOI": null, "title": "AI amusements: the tragic tale of Tay the chatbot", "auth_count": 1, "g_type": "Journal Article", "pages": 5, "year": 2016, "rg_id": null, "start_page": 20, "end_page": 24}.
[2018-03-02 14:55:01,423 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'AI amusements: the tragic tale of Tay the chatbot', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 5, 'year': 2016, 'rg_id': None, 'start_page': 20, 'end_page': 24}
[2018-03-02 14:55:01,424 DEBUG dbutils] Query result: []
[2018-03-02 14:55:01,424 DEBUG dbutils] Paper id = None.
[2018-03-02 14:55:01,424 DEBUG dbutils] Add new paper (title='AI amusements: the tragic tale of Tay the chatbot')
[2018-03-02 14:55:01,424 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'AI amusements: the tragic tale of Tay the chatbot', 'year': 2016, 'publisher': 'ACM', 'start_page': 20, 'end_page': 24, 'pages': 5, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T AI amusements: the tragic tale of Tay the chatbot\n%A Davis, Ernest\n%J AI Matters\n%V 2\n%N 4\n%P 20-24\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:55:01,424 DEBUG dbutils] Query result: 105
[2018-03-02 14:55:01,425 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://sigai.acm.org/static/aimatters/2-4/AIMatters-2-4-09-Davis.pdf.
[2018-03-02 14:55:01,426 WARNING utils] Download file (url='http://sigai.acm.org/static/aimatters/2-4/AIMatters-2-4-09-Davis.pdf') and save (filename='PDF//105.pdf')
[2018-03-02 14:55:01,426 DEBUG utils] Get current proxy for sigai.acm.org.
[2018-03-02 14:55:01,426 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 14:55:01,426 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for otherhost
[2018-03-02 14:55:01,442 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): sigai.acm.org
[2018-03-02 14:55:02,002 DEBUG requests.packages.urllib3.connectionpool] "GET /static/aimatters/2-4/AIMatters-2-4-09-Davis.pdf HTTP/1.1" 200 68966
[2018-03-02 14:55:02,003 DEBUG utils] Content-length=68966
[2018-03-02 14:55:02,004 DEBUG utils] Create file PDF//105.pdf, start download.
[2018-03-02 14:55:02,600 DEBUG utils] End download file PDF//105.pdf.
[2018-03-02 14:55:02,602 DEBUG dbutils] Update pdf_transaction for paper id=105.
[2018-03-02 14:55:02,602 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 105'
[2018-03-02 14:55:02,602 DEBUG dbutils] Query result: null
[2018-03-02 14:55:02,603 DEBUG scholar] Handle paper #116 (total 1170)
[2018-03-02 14:55:02,603 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:55:02,608 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:55:02,608 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:55:02,608 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for scholar.google.com
[2018-03-02 14:55:02,623 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:55:02,625 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:55:03,682 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:HVCFtFkFE6UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C6Y4kKMa6wejiOduhZfnU53_fDwN&scisf=3&ct=citation&cd=115&hl=en HTTP/1.1" 200 218
[2018-03-02 14:55:03,683 DEBUG scholar] EndNote file:
%0 Thesis
%T Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system
%A Latham, Annabel Marie
%D 2011
%I Manchester Metropolitan University

[2018-03-02 14:55:03,683 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:55:03,683 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:55:03,683 DEBUG __main__] Process content of EndNote file #116
{"title": "Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system", "url": "https://e-space.mmu.ac.uk/313169/", "author": [{"shortname": "AM Latham", "gid": "aOHksqcAAAAJ"}], "year": 2011}
{"citedby": 9, "type": "Thesis", "title": "Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system", "author": ["Latham, Annabel Marie"], "year": "2011", "publisher": "Manchester Metropolitan University", "EndNote": "%0 Thesis\n%T Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system\n%A Latham, Annabel Marie\n%D 2011\n%I Manchester Metropolitan University\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:HVCFtFkFE6UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C6Y4kKMa6wejiOduhZfnU53_fDwN&scisf=3&ct=citation&cd=115&hl=en"}
[2018-03-02 14:55:03,684 DEBUG dbutils] Get paper id {"DOI": null, "title": "Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:55:03,684 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:55:03,684 DEBUG dbutils] Query result: []
[2018-03-02 14:55:03,684 DEBUG dbutils] Paper id = None.
[2018-03-02 14:55:03,684 DEBUG dbutils] Add new paper (title='Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system')
[2018-03-02 14:55:03,684 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system', 'year': 2011, 'publisher': 'Manchester Metropolitan University', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T Personalising learning with dynamic prediction and adaptation to learning styles in a conversational intelligent tutoring system\n%A Latham, Annabel Marie\n%D 2011\n%I Manchester Metropolitan University\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:55:03,684 DEBUG dbutils] Query result: 106
[2018-03-02 14:55:03,685 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://e-space.mmu.ac.uk/313169/1/ALatham%20PhD%20thesis.pdf.
[2018-03-02 14:55:03,687 WARNING utils] Download file (url='http://e-space.mmu.ac.uk/313169/1/ALatham%20PhD%20thesis.pdf') and save (filename='PDF//106.pdf')
[2018-03-02 14:55:03,687 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:03,688 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:55:03,706 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:04,052 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:04,075 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:05,126 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:05,126 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for otherhost
[2018-03-02 14:55:05,128 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:05,128 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 14:55:05,362 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:05,384 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:06,548 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:06,548 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for otherhost
[2018-03-02 14:55:06,550 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:06,550 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 14:55:06,762 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:06,785 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:07,753 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/1/ALatham%20PhD%20thesis.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/1/ALatham%20PhD%20thesis.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:55:07,753 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for otherhost
[2018-03-02 14:55:07,753 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:07,754 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 14:55:07,991 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:08,014 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:09,247 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:09,247 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for otherhost
[2018-03-02 14:55:09,249 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:09,250 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:55:09,472 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:09,497 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:11,985 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:11,985 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for otherhost
[2018-03-02 14:55:11,986 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:11,986 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 14:55:12,232 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:12,254 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:12,823 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:12,823 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for otherhost
[2018-03-02 14:55:12,825 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:12,825 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 14:55:13,051 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:13,073 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:13,657 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:13,657 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for otherhost
[2018-03-02 14:55:13,659 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:13,659 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 14:55:13,886 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:13,908 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:15,228 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:15,228 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for otherhost
[2018-03-02 14:55:15,229 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:15,229 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:55:15,421 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:15,442 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:16,407 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/1/ALatham%20PhD%20thesis.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/1/ALatham%20PhD%20thesis.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:55:16,407 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for otherhost
[2018-03-02 14:55:16,408 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:16,408 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:55:16,634 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:16,662 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:17,257 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:17,258 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for otherhost
[2018-03-02 14:55:17,259 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:17,259 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:55:17,497 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:17,520 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:18,595 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:18,595 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for otherhost
[2018-03-02 14:55:18,597 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:18,597 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:55:18,821 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:18,845 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:19,925 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:19,925 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for otherhost
[2018-03-02 14:55:19,926 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:19,926 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 14:55:20,142 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:20,165 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:20,785 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:20,785 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for otherhost
[2018-03-02 14:55:20,786 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:20,787 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 14:55:21,011 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:21,036 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:22,442 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:22,442 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for otherhost
[2018-03-02 14:55:22,444 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:22,445 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:55:22,672 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:22,694 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:23,362 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:23,363 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for otherhost
[2018-03-02 14:55:23,364 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:23,364 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:55:23,602 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:23,623 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:24,102 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:24,102 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for otherhost
[2018-03-02 14:55:24,105 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:24,105 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:55:24,331 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:24,353 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:27,588 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:27,588 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for otherhost
[2018-03-02 14:55:27,590 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:27,590 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 14:55:27,811 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:27,833 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:29,587 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:29,587 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for otherhost
[2018-03-02 14:55:29,588 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:29,588 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:55:29,812 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:29,834 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:30,311 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:30,311 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for otherhost
[2018-03-02 14:55:30,313 DEBUG utils] Get current proxy for e-space.mmu.ac.uk.
[2018-03-02 14:55:30,313 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 14:55:30,510 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/1/ALatham%20PhD%20thesis.pdf HTTP/1.1" 302 312
[2018-03-02 14:55:30,533 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:31,892 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:31,892 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for otherhost
[2018-03-02 14:55:31,896 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://e-space.mmu.ac.uk/313169/.
[2018-03-02 14:55:31,896 DEBUG scihub] Get page from sci-hub for paper with DOI=https://e-space.mmu.ac.uk/313169/.
[2018-03-02 14:55:32,091 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:32,112 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:32,632 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:32,761 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:32,761 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 14:55:32,761 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for sci-hub.tw
[2018-03-02 14:55:32,951 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:32,976 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:34,005 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:34,005 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for sci-hub.tw
[2018-03-02 14:55:34,191 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:34,433 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:34,582 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:34,582 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 14:55:34,785 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:34,808 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:38,513 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:38,513 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for sci-hub.tw
[2018-03-02 14:55:38,712 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:38,922 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:39,042 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:39,042 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 14:55:39,231 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:39,254 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:55:41,267 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:41,267 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for sci-hub.tw
[2018-03-02 14:55:41,450 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:41,674 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:41,784 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:41,784 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 14:55:41,971 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:41,995 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:55:42,921 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:55:42,921 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for sci-hub.tw
[2018-03-02 14:55:43,100 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:43,271 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:43,389 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:43,389 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 14:55:43,563 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:43,585 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:44,724 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:44,724 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for sci-hub.tw
[2018-03-02 14:55:44,912 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:45,094 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:45,210 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:45,210 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:55:45,411 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:45,435 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:46,742 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:46,743 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for sci-hub.tw
[2018-03-02 14:55:46,931 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:47,164 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:47,351 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:47,351 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 14:55:47,541 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:47,563 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:55:48,553 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:48,553 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for sci-hub.tw
[2018-03-02 14:55:48,741 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:48,961 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:49,114 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:49,114 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:55:49,300 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:49,324 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:50,206 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 14:55:50,207 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for sci-hub.tw
[2018-03-02 14:55:50,391 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:50,593 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:50,766 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:50,766 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:55:50,950 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:50,972 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:55:51,511 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:51,511 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for sci-hub.tw
[2018-03-02 14:55:51,706 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:51,927 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:52,125 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:52,125 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 14:55:52,331 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:52,353 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:53,191 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 14:55:53,191 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for sci-hub.tw
[2018-03-02 14:55:53,381 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:53,598 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:53,777 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:53,777 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 14:55:53,961 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:53,982 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:55,705 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:55,705 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for sci-hub.tw
[2018-03-02 14:55:55,891 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:56,091 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:56,260 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:56,260 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 14:55:56,401 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:56,422 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:55:57,417 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:57,417 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for sci-hub.tw
[2018-03-02 14:55:57,616 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:57,801 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:57,958 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:57,958 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 14:55:58,180 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:58,203 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:55:59,098 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:55:59,098 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for sci-hub.tw
[2018-03-02 14:55:59,279 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:59,485 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:55:59,709 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:55:59,709 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:55:59,888 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:55:59,910 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:56:01,031 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:56:01,031 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for sci-hub.tw
[2018-03-02 14:56:01,220 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:01,443 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:01,617 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:01,617 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 14:56:01,851 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:01,873 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:56:07,190 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:56:07,191 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for sci-hub.tw
[2018-03-02 14:56:07,380 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:07,404 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: e-space.mmu.ac.uk
[2018-03-02 14:56:08,065 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:08,235 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:08,235 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 14:56:08,461 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:08,491 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:56:10,020 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:56:10,021 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for sci-hub.tw
[2018-03-02 14:56:10,220 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:10,445 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:10,609 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:10,609 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:56:10,800 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:10,828 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:56:12,652 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:56:12,653 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for sci-hub.tw
[2018-03-02 14:56:12,844 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:13,075 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:13,196 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:13,197 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 14:56:13,390 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:13,414 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:56:14,281 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='e-space.mmu.ac.uk', port=443): Max retries exceeded with url: /313169/ (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 14:56:14,281 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for sci-hub.tw
[2018-03-02 14:56:14,470 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:14,693 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:14,862 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:14,862 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:56:15,050 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:15,073 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): e-space.mmu.ac.uk
[2018-03-02 14:56:15,648 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:56:15,648 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for sci-hub.tw
[2018-03-02 14:56:15,870 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:16,091 DEBUG requests.packages.urllib3.connectionpool] "GET /313169/ HTTP/1.1" 200 None
[2018-03-02 14:56:16,217 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:16,217 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 14:56:16,411 DEBUG requests.packages.urllib3.connectionpool] "GET //https://e-space.mmu.ac.uk/313169/ HTTP/1.1" 302 None
[2018-03-02 14:56:16,432 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): e-space.mmu.ac.uk
[2018-03-02 14:56:17,041 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 14:56:17,041 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for sci-hub.tw
[2018-03-02 14:56:17,044 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 14:56:17,044 DEBUG __main__] Failed get_pdf from sci-hub for paper #105. URL=105
[2018-03-02 14:56:17,045 DEBUG scholar] Handle paper #117 (total 1170)
[2018-03-02 14:56:17,045 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:56:17,050 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:56:17,051 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:56:17,370 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QFbPZg1x8HEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-CzY64EratmQRvxelCdXuTJP4SosP&scisf=3&ct=citation&cd=116&hl=en HTTP/1.1" 200 154
[2018-03-02 14:56:17,371 DEBUG scholar] EndNote file:
%0 Journal Article
%T Whatever happened to machines that think?
%A Mullins, Justin
%J New Scientist
%V 186
%N 2496
%P 32-37
%@ 0262-4079
%D 2005

[2018-03-02 14:56:17,371 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:56:17,371 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:56:17,371 DEBUG __main__] Process content of EndNote file #117
{"title": "Whatever happened to machines that think?", "url": "http://mce.ucoz.ru/_ld/0/85_Whatever_happen.doc", "author": [{"shortname": "J Mullins", "gid": ""}], "year": 2005}
{"citedby": 15, "type": "Journal Article", "title": "Whatever happened to machines that think?", "author": ["Mullins, Justin"], "journal": "New Scientist", "volume": 6, "numberorissue": "2496", "pages": "32-37", "isbn/issn": "0262-4079", "year": "2005", "start_page": 32, "end_page": 37, "EndNote": "%0 Journal Article\n%T Whatever happened to machines that think?\n%A Mullins, Justin\n%J New Scientist\n%V 186\n%N 2496\n%P 32-37\n%@ 0262-4079\n%D 2005\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QFbPZg1x8HEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-CzY64EratmQRvxelCdXuTJP4SosP&scisf=3&ct=citation&cd=116&hl=en"}
[2018-03-02 14:56:17,371 DEBUG dbutils] Get paper id {"DOI": null, "title": "Whatever happened to machines that think?", "auth_count": 1, "g_type": "Journal Article", "pages": 6, "year": 2005, "rg_id": null, "start_page": 32, "end_page": 37}.
[2018-03-02 14:56:17,371 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Whatever happened to machines that think?', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 6, 'year': 2005, 'rg_id': None, 'start_page': 32, 'end_page': 37}
[2018-03-02 14:56:17,372 DEBUG dbutils] Query result: []
[2018-03-02 14:56:17,372 DEBUG dbutils] Paper id = None.
[2018-03-02 14:56:17,372 DEBUG dbutils] Add new paper (title='Whatever happened to machines that think?')
[2018-03-02 14:56:17,372 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Whatever happened to machines that think?', 'year': 2005, 'publisher': None, 'start_page': 32, 'end_page': 37, 'pages': 6, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Whatever happened to machines that think?\n%A Mullins, Justin\n%J New Scientist\n%V 186\n%N 2496\n%P 32-37\n%@ 0262-4079\n%D 2005\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:56:17,372 DEBUG dbutils] Query result: 107
[2018-03-02 14:56:17,373 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://mce.ucoz.ru/_ld/0/85_Whatever_happen.doc.
[2018-03-02 14:56:17,374 DEBUG scihub] Get page from sci-hub for paper with DOI=http://mce.ucoz.ru/_ld/0/85_Whatever_happen.doc.
[2018-03-02 14:56:17,560 DEBUG requests.packages.urllib3.connectionpool] "GET //http://mce.ucoz.ru/_ld/0/85_Whatever_happen.doc HTTP/1.1" 302 None
[2018-03-02 14:56:17,583 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): mce.ucoz.ru
[2018-03-02 14:56:17,701 DEBUG requests.packages.urllib3.connectionpool] "GET /_ld/0/85_Whatever_happen.doc HTTP/1.1" 200 57856
[2018-03-02 14:56:17,931 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:17,932 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:56:18,120 DEBUG requests.packages.urllib3.connectionpool] "GET //http://mce.ucoz.ru/_ld/0/85_Whatever_happen.doc HTTP/1.1" 302 None
[2018-03-02 14:56:18,230 DEBUG requests.packages.urllib3.connectionpool] "GET /_ld/0/85_Whatever_happen.doc HTTP/1.1" 200 57856
[2018-03-02 14:56:18,778 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:56:18,779 DEBUG scholar] Handle paper #118 (total 1170)
[2018-03-02 14:56:18,780 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:56:18,783 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:56:18,783 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 14:56:18,783 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for scholar.google.com
[2018-03-02 14:56:18,798 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:56:18,799 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:56:21,781 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:UbWfO4triMEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C5vFpQRYNLYRQrdpGCmPqUcmSt_U&scisf=3&ct=citation&cd=117&hl=en HTTP/1.1" 200 338
[2018-03-02 14:56:21,782 DEBUG scholar] EndNote file:
%0 Journal Article
%T We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics
%A Can, What Social Robots
%A Do, Should
%A Seibt, J
%J What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016
%V 290
%P 48
%@ 161499708X
%D 2016
%I IOS Press

[2018-03-02 14:56:21,782 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:56:21,782 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:56:21,782 DEBUG __main__] Process content of EndNote file #118
{"title": "We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics", "url": "https://books.google.com/books?hl=en&lr=&id=QxKhDQAAQBAJ&oi=fnd&pg=PA48&dq=Use+deep+learning+to+create+a+chatbot&ots=ESDV5jIx4m&sig=tax4a8QOQE7ce0qUYmquiePVjxM", "author": [{"shortname": "WSR Can", "gid": ""}, {"shortname": "S Do", "gid": ""}, {"shortname": "J Seibt", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics", "author": ["Can, What Social Robots", "Do, Should", "Seibt, J"], "journal": "What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016", "volume": "290", "pages": "48", "isbn/issn": "161499708X", "year": "2016", "publisher": "IOS Press", "EndNote": "%0 Journal Article\n%T We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics\n%A Can, What Social Robots\n%A Do, Should\n%A Seibt, J\n%J What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016\n%V 290\n%P 48\n%@ 161499708X\n%D 2016\n%I IOS Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:UbWfO4triMEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C5vFpQRYNLYRQrdpGCmPqUcmSt_U&scisf=3&ct=citation&cd=117&hl=en"}
[2018-03-02 14:56:21,782 DEBUG dbutils] Get paper id {"DOI": null, "title": "We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics", "auth_count": 3, "g_type": "Journal Article", "pages": 290, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:56:21,783 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 290, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:56:21,783 DEBUG dbutils] Query result: []
[2018-03-02 14:56:21,783 DEBUG dbutils] Paper id = None.
[2018-03-02 14:56:21,783 DEBUG dbutils] Add new paper (title='We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics')
[2018-03-02 14:56:21,783 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics', 'year': 2016, 'publisher': 'IOS Press', 'start_page': None, 'end_page': None, 'pages': 290, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T We, Anthrobot: Learning from Human Forms of Interaction and Esprit de Corps to Develop More Plural Social Robotics\n%A Can, What Social Robots\n%A Do, Should\n%A Seibt, J\n%J What Social Robots Can and Should Do: Proceedings of Robophilosophy 2016/TRANSOR 2016\n%V 290\n%P 48\n%@ 161499708X\n%D 2016\n%I IOS Press\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:56:21,783 DEBUG dbutils] Query result: 108
[2018-03-02 14:56:21,785 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=QxKhDQAAQBAJ&oi=fnd&pg=PA48&dq=Use+deep+learning+to+create+a+chatbot&ots=ESDV5jIx4m&sig=tax4a8QOQE7ce0qUYmquiePVjxM.
[2018-03-02 14:56:21,785 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=QxKhDQAAQBAJ&oi=fnd&pg=PA48&dq=Use+deep+learning+to+create+a+chatbot&ots=ESDV5jIx4m&sig=tax4a8QOQE7ce0qUYmquiePVjxM.
[2018-03-02 14:56:21,980 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=QxKhDQAAQBAJ&oi=fnd&pg=PA48&dq=Use+deep+learning+to+create+a+chatbot&ots=ESDV5jIx4m&sig=tax4a8QOQE7ce0qUYmquiePVjxM HTTP/1.1" 302 None
[2018-03-02 14:56:22,185 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:56:22,189 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:56:22,189 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 14:56:22,189 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for sci-hub.tw
[2018-03-02 14:56:22,370 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=QxKhDQAAQBAJ&oi=fnd&pg=PA48&dq=Use+deep+learning+to+create+a+chatbot&ots=ESDV5jIx4m&sig=tax4a8QOQE7ce0qUYmquiePVjxM HTTP/1.1" 302 None
[2018-03-02 14:56:22,573 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:56:22,620 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:56:22,621 DEBUG scholar] Handle paper #119 (total 1170)
[2018-03-02 14:56:22,622 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:56:22,625 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:56:22,625 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:56:23,110 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ypblwBclYIQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C4U9p6uAEnmuLyHxeNrKEkohXzL4&scisf=3&ct=citation&cd=118&hl=en HTTP/1.1" 200 163
[2018-03-02 14:56:23,111 DEBUG scholar] EndNote file:
%0 Journal Article
%T Living in cyn: mating aiml and cyc together with program n
%A Coursey, Kino
%J Resources avalaible at: http://www. daxtron. com
%D 2004

[2018-03-02 14:56:23,111 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:56:23,112 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:56:23,112 DEBUG __main__] Process content of EndNote file #119
{"title": "Living in cyn: mating aiml and cyc together with program n", "url": "http://www.daxtron.com/pdf/CYN_Description.pdf", "author": [{"shortname": "K Coursey", "gid": ""}], "year": 2004}
{"citedby": 13, "type": "Journal Article", "title": "Living in cyn: mating aiml and cyc together with program n", "author": ["Coursey, Kino"], "journal": "Resources avalaible at: http://www. daxtron. com", "year": "2004", "EndNote": "%0 Journal Article\n%T Living in cyn: mating aiml and cyc together with program n\n%A Coursey, Kino\n%J Resources avalaible at: http://www. daxtron. com\n%D 2004\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ypblwBclYIQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C4U9p6uAEnmuLyHxeNrKEkohXzL4&scisf=3&ct=citation&cd=118&hl=en"}
[2018-03-02 14:56:23,112 DEBUG dbutils] Get paper id {"DOI": null, "title": "Living in cyn: mating aiml and cyc together with program n", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2004, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:56:23,112 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Living in cyn: mating aiml and cyc together with program n', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2004, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:56:23,112 DEBUG dbutils] Query result: []
[2018-03-02 14:56:23,112 DEBUG dbutils] Paper id = None.
[2018-03-02 14:56:23,112 DEBUG dbutils] Add new paper (title='Living in cyn: mating aiml and cyc together with program n')
[2018-03-02 14:56:23,112 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Living in cyn: mating aiml and cyc together with program n', 'year': 2004, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Living in cyn: mating aiml and cyc together with program n\n%A Coursey, Kino\n%J Resources avalaible at: http://www. daxtron. com\n%D 2004\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:56:23,112 DEBUG dbutils] Query result: 109
[2018-03-02 14:56:23,113 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.daxtron.com/pdf/CYN_Description.pdf.
[2018-03-02 14:56:23,114 WARNING utils] Download file (url='http://www.daxtron.com/pdf/CYN_Description.pdf') and save (filename='PDF//109.pdf')
[2018-03-02 14:56:23,114 DEBUG utils] Get current proxy for www.daxtron.com.
[2018-03-02 14:56:23,114 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:56:23,131 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.daxtron.com
[2018-03-02 14:56:23,513 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/CYN_Description.pdf HTTP/1.1" 200 464443
[2018-03-02 14:56:23,513 DEBUG utils] Content-length=464443
[2018-03-02 14:56:23,514 DEBUG utils] Create file PDF//109.pdf, start download.
[2018-03-02 14:56:26,008 DEBUG utils] End download file PDF//109.pdf.
[2018-03-02 14:56:26,009 DEBUG dbutils] Update pdf_transaction for paper id=109.
[2018-03-02 14:56:26,009 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 109'
[2018-03-02 14:56:26,010 DEBUG dbutils] Query result: null
[2018-03-02 14:56:26,010 DEBUG scholar] Handle paper #120 (total 1170)
[2018-03-02 14:56:26,010 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:56:26,014 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:56:26,014 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 14:56:26,014 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for scholar.google.com
[2018-03-02 14:56:26,030 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:56:26,031 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:56:27,230 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:g9D4JbMZohcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C0WKitRaYytie7zRzCKCoAKdNlex&scisf=3&ct=citation&cd=119&hl=en HTTP/1.1" 200 225
[2018-03-02 14:56:27,231 DEBUG scholar] EndNote file:
%0 Journal Article
%T Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents
%A Asghar, Nabiha
%A Poupart, Pascal
%A Xin, Jiang
%A Li, Hang
%J arXiv preprint arXiv:1612.03929
%D 2016

[2018-03-02 14:56:27,231 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:56:27,231 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:56:27,231 DEBUG __main__] Process content of EndNote file #120
{"title": "Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents", "url": "https://arxiv.org/abs/1612.03929", "author": [{"shortname": "N Asghar", "gid": "xYFNj60AAAAJ"}, {"shortname": "P Poupart", "gid": "KhAJWroAAAAJ"}, {"shortname": "J Xin", "gid": ""}, {"shortname": "H Li", "gid": "nTl5mSwAAAAJ"}], "year": 1612}
{"citedby": 4, "type": "Journal Article", "title": "Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents", "author": ["Asghar, Nabiha", "Poupart, Pascal", "Xin, Jiang", "Li, Hang"], "journal": "arXiv preprint arXiv:1612.03929", "year": "2016", "EndNote": "%0 Journal Article\n%T Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents\n%A Asghar, Nabiha\n%A Poupart, Pascal\n%A Xin, Jiang\n%A Li, Hang\n%J arXiv preprint arXiv:1612.03929\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:g9D4JbMZohcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-C0WKitRaYytie7zRzCKCoAKdNlex&scisf=3&ct=citation&cd=119&hl=en"}
[2018-03-02 14:56:27,231 DEBUG dbutils] Get paper id {"DOI": null, "title": "Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:56:27,232 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:56:27,232 DEBUG dbutils] Query result: []
[2018-03-02 14:56:27,232 DEBUG dbutils] Paper id = None.
[2018-03-02 14:56:27,232 DEBUG dbutils] Add new paper (title='Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents')
[2018-03-02 14:56:27,232 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Online Sequence-to-Sequence Reinforcement Learning for Open-Domain Conversational Agents\n%A Asghar, Nabiha\n%A Poupart, Pascal\n%A Xin, Jiang\n%A Li, Hang\n%J arXiv preprint arXiv:1612.03929\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:56:27,232 DEBUG dbutils] Query result: 110
[2018-03-02 14:56:27,234 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1612.03929.
[2018-03-02 14:56:27,234 WARNING utils] Download file (url='https://arxiv.org/pdf/1612.03929') and save (filename='PDF//110.pdf')
[2018-03-02 14:56:27,235 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:56:27,235 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 14:56:27,235 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for otherhost
[2018-03-02 14:56:27,250 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:56:29,300 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1612.03929 HTTP/1.1" 302 280
[2018-03-02 14:56:30,207 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1612.03929.pdf HTTP/1.1" 200 124218
[2018-03-02 14:56:30,207 DEBUG utils] Content-length=124218
[2018-03-02 14:56:30,208 DEBUG utils] Create file PDF//110.pdf, start download.
[2018-03-02 14:56:31,945 DEBUG utils] End download file PDF//110.pdf.
[2018-03-02 14:56:31,946 DEBUG dbutils] Update pdf_transaction for paper id=110.
[2018-03-02 14:56:31,947 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 110'
[2018-03-02 14:56:31,947 DEBUG dbutils] Query result: null
[2018-03-02 14:56:31,965 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:56:31,966 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:56:31,966 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:56:31,980 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:56:33,343 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=120&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:56:33,553 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:56:33,554 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:57:49,758 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 14:57:49,758 DEBUG utils] Load cookie from chrome.
[2018-03-02 14:57:49,900 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:57:49,900 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 14:57:49,900 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for scholar.google.com
[2018-03-02 14:57:49,914 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:57:51,374 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=120&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:57:51,682 DEBUG scholar] Find papers on page #13 (max_google_papers = 300)
[2018-03-02 14:57:51,683 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:57:51,683 DEBUG scholar] Handle paper #121 (total 1170)
[2018-03-02 14:57:51,683 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:57:51,686 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:57:51,686 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:57:51,702 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:57:51,703 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:57:53,409 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:8q91aHAFz00J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-23pI3fsFHN3dHbps2TjKkZPsbth0&scisf=3&ct=citation&cd=120&hl=en HTTP/1.1" 200 258
[2018-03-02 14:57:53,410 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles
%A Banerjee, Siddhartha
%A Biyani, Prakhar
%A Tsioutsiouliklis, Kostas
%B Second Workshop on Chatbots and Conversational Agent Technologies
%D 2016

[2018-03-02 14:57:53,410 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:57:53,410 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:57:53,410 DEBUG __main__] Process content of EndNote file #121
{"title": "Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles", "url": "http://workshop.colips.org/wochat/@iva2016/documents/RP-262.pdf", "author": [{"shortname": "S Banerjee", "gid": "69fATowAAAAJ"}, {"shortname": "P Biyani", "gid": "4ZRy-BMAAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles", "author": ["Banerjee, Siddhartha", "Biyani, Prakhar", "Tsioutsiouliklis, Kostas"], "secondarytitle": "Second Workshop on Chatbots and Conversational Agent Technologies", "year": "2016", "EndNote": "%0 Conference Proceedings\n%T Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles\n%A Banerjee, Siddhartha\n%A Biyani, Prakhar\n%A Tsioutsiouliklis, Kostas\n%B Second Workshop on Chatbots and Conversational Agent Technologies\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:8q91aHAFz00J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-23pI3fsFHN3dHbps2TjKkZPsbth0&scisf=3&ct=citation&cd=120&hl=en"}
[2018-03-02 14:57:53,410 DEBUG dbutils] Get paper id {"DOI": null, "title": "Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles", "auth_count": 3, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:57:53,410 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:57:53,411 DEBUG dbutils] Query result: []
[2018-03-02 14:57:53,411 DEBUG dbutils] Paper id = None.
[2018-03-02 14:57:53,411 DEBUG dbutils] Add new paper (title='Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles')
[2018-03-02 14:57:53,411 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Transforming Chatbot Responses to Mimic Domain-specific Linguistic Styles\n%A Banerjee, Siddhartha\n%A Biyani, Prakhar\n%A Tsioutsiouliklis, Kostas\n%B Second Workshop on Chatbots and Conversational Agent Technologies\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:57:53,411 DEBUG dbutils] Query result: 111
[2018-03-02 14:57:53,412 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://workshop.colips.org/wochat/@iva2016/documents/RP-262.pdf.
[2018-03-02 14:57:53,414 WARNING utils] Download file (url='http://workshop.colips.org/wochat/@iva2016/documents/RP-262.pdf') and save (filename='PDF//111.pdf')
[2018-03-02 14:57:53,414 DEBUG utils] Get current proxy for workshop.colips.org.
[2018-03-02 14:57:53,414 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:57:53,430 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): workshop.colips.org
[2018-03-02 14:57:54,159 DEBUG requests.packages.urllib3.connectionpool] "GET /wochat/@iva2016/documents/RP-262.pdf HTTP/1.1" 200 325193
[2018-03-02 14:57:54,159 DEBUG utils] Content-length=325193
[2018-03-02 14:57:54,160 DEBUG utils] Create file PDF//111.pdf, start download.
[2018-03-02 14:57:56,725 DEBUG utils] End download file PDF//111.pdf.
[2018-03-02 14:57:56,726 DEBUG dbutils] Update pdf_transaction for paper id=111.
[2018-03-02 14:57:56,726 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 111'
[2018-03-02 14:57:56,726 DEBUG dbutils] Query result: null
[2018-03-02 14:57:56,727 DEBUG scholar] Handle paper #122 (total 1170)
[2018-03-02 14:57:56,727 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:57:56,730 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:57:56,731 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 14:57:56,731 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for scholar.google.com
[2018-03-02 14:57:56,750 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:57:56,751 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:57:58,198 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:84n_nLszn8MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2x00uo3nAtAO6TJrMHC5DCneS7sp&scisf=3&ct=citation&cd=121&hl=en HTTP/1.1" 200 250
[2018-03-02 14:57:58,199 DEBUG scholar] EndNote file:
%0 Journal Article
%T CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics
%A Summerville, Adam James
%A Ryan, James
%A Mateas, Michael
%A Wardrip-Fruin, Noah
%J arXiv preprint arXiv:1607.06852
%D 2016

[2018-03-02 14:57:58,199 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:57:58,199 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:57:58,199 DEBUG __main__] Process content of EndNote file #122
{"title": "CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics", "url": "https://arxiv.org/abs/1607.06852", "author": [{"shortname": "AJ Summerville", "gid": "rJ2D_7QAAAAJ"}, {"shortname": "J Ryan", "gid": "_9lw-0oAAAAJ"}, {"shortname": "M Mateas", "gid": ""}], "year": 2016}
{"citedby": 3, "type": "Journal Article", "title": "CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics", "author": ["Summerville, Adam James", "Ryan, James", "Mateas, Michael", "Wardrip-Fruin, Noah"], "journal": "arXiv preprint arXiv:1607.06852", "year": "2016", "EndNote": "%0 Journal Article\n%T CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics\n%A Summerville, Adam James\n%A Ryan, James\n%A Mateas, Michael\n%A Wardrip-Fruin, Noah\n%J arXiv preprint arXiv:1607.06852\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:84n_nLszn8MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2x00uo3nAtAO6TJrMHC5DCneS7sp&scisf=3&ct=citation&cd=121&hl=en"}
[2018-03-02 14:57:58,200 DEBUG dbutils] Get paper id {"DOI": null, "title": "CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:57:58,200 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:57:58,200 DEBUG dbutils] Query result: []
[2018-03-02 14:57:58,200 DEBUG dbutils] Paper id = None.
[2018-03-02 14:57:58,200 DEBUG dbutils] Add new paper (title='CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics')
[2018-03-02 14:57:58,200 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T CFGs-2-NLU: Sequence-to-sequence learning for mapping utterances to semantics and pragmatics\n%A Summerville, Adam James\n%A Ryan, James\n%A Mateas, Michael\n%A Wardrip-Fruin, Noah\n%J arXiv preprint arXiv:1607.06852\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:57:58,200 DEBUG dbutils] Query result: 112
[2018-03-02 14:57:58,204 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1607.06852.
[2018-03-02 14:57:58,205 WARNING utils] Download file (url='https://arxiv.org/pdf/1607.06852') and save (filename='PDF//112.pdf')
[2018-03-02 14:57:58,205 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 14:57:58,205 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 14:57:58,205 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for otherhost
[2018-03-02 14:57:58,221 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 14:58:00,798 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1607.06852 HTTP/1.1" 302 280
[2018-03-02 14:58:01,709 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1607.06852.pdf HTTP/1.1" 200 412817
[2018-03-02 14:58:01,709 DEBUG utils] Content-length=412817
[2018-03-02 14:58:01,710 DEBUG utils] Create file PDF//112.pdf, start download.
[2018-03-02 14:58:04,455 DEBUG utils] End download file PDF//112.pdf.
[2018-03-02 14:58:04,456 DEBUG dbutils] Update pdf_transaction for paper id=112.
[2018-03-02 14:58:04,456 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 112'
[2018-03-02 14:58:04,457 DEBUG dbutils] Query result: null
[2018-03-02 14:58:04,457 DEBUG scholar] Handle paper #123 (total 1170)
[2018-03-02 14:58:04,457 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:58:04,461 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:04,461 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:58:04,778 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:oWPvAWDNMqAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-20p-xUv7qaOI5XJ7OaqZJTT9Q6XK&scisf=3&ct=citation&cd=122&hl=en HTTP/1.1" 200 226
[2018-03-02 14:58:04,779 DEBUG scholar] EndNote file:
%0 Book Section
%T Using problem-based learning within 3D virtual worlds
%A Parson, Vanessa
%A Bignell, Simon
%B Transforming Virtual World Learning
%P 241-261
%@ 2044-9968
%D 2011
%I Emerald Group Publishing Limited

[2018-03-02 14:58:04,779 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:04,779 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:04,780 DEBUG __main__] Process content of EndNote file #123
{"title": "Using problem-based learning within 3D virtual worlds", "url": "http://www.emeraldinsight.com/doi/abs/10.1108/S2044-9968(2011)0000004014", "author": [{"shortname": "V Parson", "gid": ""}, {"shortname": "S Bignell", "gid": "jRNVSM4AAAAJ"}], "year": 2011}
{"citedby": 9, "type": "Book Section", "title": "Using problem-based learning within 3D virtual worlds", "author": ["Parson, Vanessa", "Bignell, Simon"], "secondarytitle": "Transforming Virtual World Learning", "pages": "241-261", "isbn/issn": "2044-9968", "year": "2011", "publisher": "Emerald Group Publishing Limited", "start_page": 241, "end_page": 261, "volume": 21, "EndNote": "%0 Book Section\n%T Using problem-based learning within 3D virtual worlds\n%A Parson, Vanessa\n%A Bignell, Simon\n%B Transforming Virtual World Learning\n%P 241-261\n%@ 2044-9968\n%D 2011\n%I Emerald Group Publishing Limited\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:oWPvAWDNMqAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-20p-xUv7qaOI5XJ7OaqZJTT9Q6XK&scisf=3&ct=citation&cd=122&hl=en"}
[2018-03-02 14:58:04,780 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using problem-based learning within 3D virtual worlds", "auth_count": 2, "g_type": "Book Section", "pages": 21, "year": 2011, "rg_id": null, "start_page": 241, "end_page": 261}.
[2018-03-02 14:58:04,780 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using problem-based learning within 3D virtual worlds', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 21, 'year': 2011, 'rg_id': None, 'start_page': 241, 'end_page': 261}
[2018-03-02 14:58:04,780 DEBUG dbutils] Query result: []
[2018-03-02 14:58:04,780 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:04,780 DEBUG dbutils] Add new paper (title='Using problem-based learning within 3D virtual worlds')
[2018-03-02 14:58:04,780 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using problem-based learning within 3D virtual worlds', 'year': 2011, 'publisher': 'Emerald Group Publishing Limited', 'start_page': 241, 'end_page': 261, 'pages': 21, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Using problem-based learning within 3D virtual worlds\n%A Parson, Vanessa\n%A Bignell, Simon\n%B Transforming Virtual World Learning\n%P 241-261\n%@ 2044-9968\n%D 2011\n%I Emerald Group Publishing Limited\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:04,780 DEBUG dbutils] Query result: 113
[2018-03-02 14:58:04,782 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.emeraldinsight.com/doi/abs/10.1108/S2044-9968(2011)0000004014.
[2018-03-02 14:58:04,782 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.emeraldinsight.com/doi/abs/10.1108/S2044-9968(2011)0000004014.
[2018-03-02 14:58:04,795 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 14:58:05,079 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.emeraldinsight.com/doi/abs/10.1108/S2044-9968(2011)0000004014 HTTP/1.1" 200 None
[2018-03-02 14:58:05,080 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:58:05,080 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:58:05,228 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.emeraldinsight.com/doi/abs/10.1108/S2044-9968(2011)0000004014 HTTP/1.1" 200 None
[2018-03-02 14:58:05,235 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTEwOC9zMjA0NC05OTY4KDIwMTEpMDAwMDAwNDAxNA==/parson2011.pdf?download=true.
[2018-03-02 14:58:05,235 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTEwOC9zMjA0NC05OTY4KDIwMTEpMDAwMDAwNDAxNA==/parson2011.pdf?download=true') and save (filename='PDF//113.pdf')
[2018-03-02 14:58:05,252 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cyber.sci-hub.tw
[2018-03-02 14:58:05,429 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOC9zMjA0NC05OTY4KDIwMTEpMDAwMDAwNDAxNA==/parson2011.pdf?download=true HTTP/1.1" 200 341990
[2018-03-02 14:58:05,430 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 14:58:05,430 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:58:05,430 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for sci-hub.tw
[2018-03-02 14:58:05,443 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): cyber.sci-hub.tw
[2018-03-02 14:58:05,627 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOC9zMjA0NC05OTY4KDIwMTEpMDAwMDAwNDAxNA==/parson2011.pdf?download=true HTTP/1.1" 200 341990
[2018-03-02 14:58:05,628 DEBUG utils] Content-length=341990
[2018-03-02 14:58:05,629 DEBUG utils] Create file PDF//113.pdf, start download.
[2018-03-02 14:58:06,159 DEBUG utils] End download file PDF//113.pdf.
[2018-03-02 14:58:06,159 DEBUG dbutils] Update pdf_transaction for paper id=113.
[2018-03-02 14:58:06,161 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 113'
[2018-03-02 14:58:06,161 DEBUG dbutils] Query result: null
[2018-03-02 14:58:06,161 DEBUG scholar] Handle paper #124 (total 1170)
[2018-03-02 14:58:06,161 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:58:06,165 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:06,165 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 14:58:06,165 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for scholar.google.com
[2018-03-02 14:58:06,181 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:58:06,183 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:58:07,542 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Po5RbR2-LggJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2xDvAXlkItsxa3rW_cDDEPk_E48m&scisf=3&ct=citation&cd=123&hl=en HTTP/1.1" 200 232
[2018-03-02 14:58:07,543 DEBUG scholar] EndNote file:
%0 Journal Article
%T Lifelong machine learning
%A Chen, Zhiyuan
%A Liu, Bing
%J Synthesis Lectures on Artificial Intelligence and Machine Learning
%V 10
%N 3
%P 1-145
%@ 1939-4608
%D 2016
%I Morgan & Claypool Publishers

[2018-03-02 14:58:07,543 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:07,543 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:07,544 DEBUG __main__] Process content of EndNote file #124
{"title": "Lifelong machine learning", "url": "http://www.morganclaypool.com/doi/abs/10.2200/S00737ED1V01Y201610AIM033", "author": [{"shortname": "Z Chen", "gid": "tCitBzMAAAAJ"}, {"shortname": "B Liu", "gid": "Kt1bjZoAAAAJ"}], "year": 2016}
{"citedby": 16, "type": "Journal Article", "title": "Lifelong machine learning", "author": ["Chen, Zhiyuan", "Liu, Bing"], "journal": "Synthesis Lectures on Artificial Intelligence and Machine Learning", "volume": 145, "numberorissue": "3", "pages": "1-145", "isbn/issn": "1939-4608", "year": "2016", "publisher": "Morgan & Claypool Publishers", "start_page": 1, "end_page": 145, "EndNote": "%0 Journal Article\n%T Lifelong machine learning\n%A Chen, Zhiyuan\n%A Liu, Bing\n%J Synthesis Lectures on Artificial Intelligence and Machine Learning\n%V 10\n%N 3\n%P 1-145\n%@ 1939-4608\n%D 2016\n%I Morgan & Claypool Publishers\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Po5RbR2-LggJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2xDvAXlkItsxa3rW_cDDEPk_E48m&scisf=3&ct=citation&cd=123&hl=en"}
[2018-03-02 14:58:07,544 DEBUG dbutils] Get paper id {"DOI": null, "title": "Lifelong machine learning", "auth_count": 2, "g_type": "Journal Article", "pages": 145, "year": 2016, "rg_id": null, "start_page": 1, "end_page": 145}.
[2018-03-02 14:58:07,544 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Lifelong machine learning', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 145, 'year': 2016, 'rg_id': None, 'start_page': 1, 'end_page': 145}
[2018-03-02 14:58:07,544 DEBUG dbutils] Query result: []
[2018-03-02 14:58:07,544 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:07,544 DEBUG dbutils] Add new paper (title='Lifelong machine learning')
[2018-03-02 14:58:07,544 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Lifelong machine learning', 'year': 2016, 'publisher': 'Morgan & Claypool Publishers', 'start_page': 1, 'end_page': 145, 'pages': 145, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Lifelong machine learning\n%A Chen, Zhiyuan\n%A Liu, Bing\n%J Synthesis Lectures on Artificial Intelligence and Machine Learning\n%V 10\n%N 3\n%P 1-145\n%@ 1939-4608\n%D 2016\n%I Morgan & Claypool Publishers\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:07,544 DEBUG dbutils] Query result: 114
[2018-03-02 14:58:07,546 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.cs.uic.edu/~liub/lifelong-machine-learning-draft.pdf.
[2018-03-02 14:58:07,547 WARNING utils] Download file (url='https://www.cs.uic.edu/~liub/lifelong-machine-learning-draft.pdf') and save (filename='PDF//114.pdf')
[2018-03-02 14:58:07,547 DEBUG utils] Get current proxy for www.cs.uic.edu.
[2018-03-02 14:58:07,547 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:58:07,564 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.cs.uic.edu
[2018-03-02 14:58:10,401 DEBUG requests.packages.urllib3.connectionpool] "GET /~liub/lifelong-machine-learning-draft.pdf HTTP/1.1" 200 1869405
[2018-03-02 14:58:10,401 DEBUG utils] Content-length=1869405
[2018-03-02 14:58:10,402 DEBUG utils] Create file PDF//114.pdf, start download.
[2018-03-02 14:58:17,541 DEBUG utils] End download file PDF//114.pdf.
[2018-03-02 14:58:17,542 DEBUG dbutils] Update pdf_transaction for paper id=114.
[2018-03-02 14:58:17,542 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 114'
[2018-03-02 14:58:17,542 DEBUG dbutils] Query result: null
[2018-03-02 14:58:17,542 DEBUG scholar] Handle paper #125 (total 1170)
[2018-03-02 14:58:17,543 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:58:17,546 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:17,546 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:58:17,788 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:OHryj3hBpzMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2wgDzZBJUviiZv1RGDerBAd7KuAm&scisf=3&ct=citation&cd=124&hl=en HTTP/1.1" 200 234
[2018-03-02 14:58:17,789 DEBUG scholar] EndNote file:
%0 Journal Article
%T Artificial general intelligence: concept, state of the art, and future prospects
%A Goertzel, Ben
%J Journal of Artificial General Intelligence
%V 5
%N 1
%P 1-48
%@ 1946-0163
%D 2014
%I De Gruyter Open

[2018-03-02 14:58:17,789 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:17,789 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:17,789 DEBUG __main__] Process content of EndNote file #125
{"title": "Artificial general intelligence: concept, state of the art, and future prospects", "url": "https://www.degruyter.com/view/j/jagi.2014.5.issue-1/jagi-2014-0001/jagi-2014-0001.xml", "author": [{"shortname": "B Goertzel", "gid": ""}], "year": 2014}
{"citedby": 23, "type": "Journal Article", "title": "Artificial general intelligence: concept, state of the art, and future prospects", "author": ["Goertzel, Ben"], "journal": "Journal of Artificial General Intelligence", "volume": 48, "numberorissue": "1", "pages": "1-48", "isbn/issn": "1946-0163", "year": "2014", "publisher": "De Gruyter Open", "start_page": 1, "end_page": 48, "EndNote": "%0 Journal Article\n%T Artificial general intelligence: concept, state of the art, and future prospects\n%A Goertzel, Ben\n%J Journal of Artificial General Intelligence\n%V 5\n%N 1\n%P 1-48\n%@ 1946-0163\n%D 2014\n%I De Gruyter Open\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:OHryj3hBpzMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2wgDzZBJUviiZv1RGDerBAd7KuAm&scisf=3&ct=citation&cd=124&hl=en"}
[2018-03-02 14:58:17,789 DEBUG dbutils] Get paper id {"DOI": null, "title": "Artificial general intelligence: concept, state of the art, and future prospects", "auth_count": 1, "g_type": "Journal Article", "pages": 48, "year": 2014, "rg_id": null, "start_page": 1, "end_page": 48}.
[2018-03-02 14:58:17,789 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Artificial general intelligence: concept, state of the art, and future prospects', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 48, 'year': 2014, 'rg_id': None, 'start_page': 1, 'end_page': 48}
[2018-03-02 14:58:17,790 DEBUG dbutils] Query result: []
[2018-03-02 14:58:17,790 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:17,790 DEBUG dbutils] Add new paper (title='Artificial general intelligence: concept, state of the art, and future prospects')
[2018-03-02 14:58:17,790 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Artificial general intelligence: concept, state of the art, and future prospects', 'year': 2014, 'publisher': 'De Gruyter Open', 'start_page': 1, 'end_page': 48, 'pages': 48, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Artificial general intelligence: concept, state of the art, and future prospects\n%A Goertzel, Ben\n%J Journal of Artificial General Intelligence\n%V 5\n%N 1\n%P 1-48\n%@ 1946-0163\n%D 2014\n%I De Gruyter Open\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:17,790 DEBUG dbutils] Query result: 115
[2018-03-02 14:58:17,791 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.degruyter.com/downloadpdf/j/jagi.2014.5.issue-1/jagi-2014-0001/jagi-2014-0001.xml.
[2018-03-02 14:58:17,792 WARNING utils] Download file (url='https://www.degruyter.com/downloadpdf/j/jagi.2014.5.issue-1/jagi-2014-0001/jagi-2014-0001.xml') and save (filename='PDF//115.pdf')
[2018-03-02 14:58:17,793 DEBUG utils] Get current proxy for www.degruyter.com.
[2018-03-02 14:58:17,793 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 14:58:17,793 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for otherhost
[2018-03-02 14:58:17,809 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.degruyter.com
[2018-03-02 14:58:19,838 DEBUG requests.packages.urllib3.connectionpool] "GET /downloadpdf/j/jagi.2014.5.issue-1/jagi-2014-0001/jagi-2014-0001.xml HTTP/1.1" 302 0
[2018-03-02 14:58:20,510 DEBUG requests.packages.urllib3.connectionpool] "GET /downloadpdf/j/jagi.2014.5.issue-1/jagi-2014-0001/jagi-2014-0001.pdf HTTP/1.1" 200 765177
[2018-03-02 14:58:20,510 DEBUG utils] Content-length=765177
[2018-03-02 14:58:20,511 DEBUG utils] Create file PDF//115.pdf, start download.
[2018-03-02 14:58:23,475 DEBUG utils] End download file PDF//115.pdf.
[2018-03-02 14:58:23,476 DEBUG dbutils] Update pdf_transaction for paper id=115.
[2018-03-02 14:58:23,476 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 115'
[2018-03-02 14:58:23,477 DEBUG dbutils] Query result: null
[2018-03-02 14:58:23,477 DEBUG scholar] Handle paper #126 (total 1170)
[2018-03-02 14:58:23,477 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 14:58:23,484 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:23,484 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 14:58:23,484 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for scholar.google.com
[2018-03-02 14:58:23,504 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:58:28,629 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:QX8RWXqBJB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-24MVcJyXcnhb51k-Pry3LNWGCvBR&scisf=3&ct=citation&cd=125&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:QX8RWXqBJB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-24MVcJyXcnhb51k-Pry3LNWGCvBR&scisf=3&ct=citation&cd=125&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 14:58:28,629 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for scholar.google.com
[2018-03-02 14:58:28,629 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:28,629 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:58:28,643 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:58:28,644 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:58:30,015 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QX8RWXqBJB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-24MVcJyXcnhb51k-Pry3LNWGCvBR&scisf=3&ct=citation&cd=125&hl=en HTTP/1.1" 200 287
[2018-03-02 14:58:30,016 DEBUG scholar] EndNote file:
%0 Journal Article
%T Animated pedagogical agents: The effect of visual information on a historical figure application
%A Heller, Robert
%A Procter, Mike
%J International Journal of Web-Based Learning and Teaching Technologies (IJWLTT)
%V 4
%N 1
%P 54-65
%D 2009
%I IGI Global

[2018-03-02 14:58:30,016 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:30,016 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:30,016 DEBUG __main__] Process content of EndNote file #126
{"title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "url": "https://www.igi-global.com/article/animated-pedagogical-agents/3022", "author": [{"shortname": "R Heller", "gid": ""}, {"shortname": "M Procter", "gid": "6DeEyb0AAAAJ"}], "year": 2009}
{"citedby": 12, "type": "Journal Article", "title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "author": ["Heller, Robert", "Procter, Mike"], "journal": "International Journal of Web-Based Learning and Teaching Technologies (IJWLTT)", "volume": 12, "numberorissue": "1", "pages": "54-65", "year": "2009", "publisher": "IGI Global", "start_page": 54, "end_page": 65, "EndNote": "%0 Journal Article\n%T Animated pedagogical agents: The effect of visual information on a historical figure application\n%A Heller, Robert\n%A Procter, Mike\n%J International Journal of Web-Based Learning and Teaching Technologies (IJWLTT)\n%V 4\n%N 1\n%P 54-65\n%D 2009\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QX8RWXqBJB4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-24MVcJyXcnhb51k-Pry3LNWGCvBR&scisf=3&ct=citation&cd=125&hl=en"}
[2018-03-02 14:58:30,016 DEBUG dbutils] Get paper id {"DOI": null, "title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "auth_count": 2, "g_type": "Journal Article", "pages": 12, "year": 2009, "rg_id": null, "start_page": 54, "end_page": 65}.
[2018-03-02 14:58:30,017 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Animated pedagogical agents: The effect of visual information on a historical figure application', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 12, 'year': 2009, 'rg_id': None, 'start_page': 54, 'end_page': 65}
[2018-03-02 14:58:30,017 DEBUG dbutils] Query result: []
[2018-03-02 14:58:30,017 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:30,017 DEBUG dbutils] Add new paper (title='Animated pedagogical agents: The effect of visual information on a historical figure application')
[2018-03-02 14:58:30,017 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Animated pedagogical agents: The effect of visual information on a historical figure application', 'year': 2009, 'publisher': 'IGI Global', 'start_page': 54, 'end_page': 65, 'pages': 12, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Animated pedagogical agents: The effect of visual information on a historical figure application\n%A Heller, Robert\n%A Procter, Mike\n%J International Journal of Web-Based Learning and Teaching Technologies (IJWLTT)\n%V 4\n%N 1\n%P 54-65\n%D 2009\n%I IGI Global\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:30,017 DEBUG dbutils] Query result: 116
[2018-03-02 14:58:30,019 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.igi-global.com/article/animated-pedagogical-agents/3022.
[2018-03-02 14:58:30,019 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.igi-global.com/article/animated-pedagogical-agents/3022.
[2018-03-02 14:58:32,458 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.igi-global.com/article/animated-pedagogical-agents/3022 HTTP/1.1" 200 None
[2018-03-02 14:58:32,460 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:58:32,460 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 14:58:32,678 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.igi-global.com/article/animated-pedagogical-agents/3022 HTTP/1.1" 200 None
[2018-03-02 14:58:32,686 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:58:32,687 DEBUG scholar] Handle paper #127 (total 1170)
[2018-03-02 14:58:32,687 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 14:58:32,692 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:32,692 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 14:58:32,692 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for scholar.google.com
[2018-03-02 14:58:32,708 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.googleusercontent.com
[2018-03-02 14:58:34,010 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:pKcvUhCuQIEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-26TthmLTDoXNpgYfrBHRiD8gFs8Q&scisf=3&ct=citation&cd=126&hl=en HTTP/1.1" 200 315
[2018-03-02 14:58:34,011 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Automatic ranking of swear words using word embeddings and pseudo-relevance feedback
%A D'Haro, Luis Fernando
%A Banchs, Rafael E
%B Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2015 Asia-Pacific
%P 815-820
%@ 9881476801
%D 2015
%I IEEE

[2018-03-02 14:58:34,011 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:34,011 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:34,011 DEBUG __main__] Process content of EndNote file #127
{"title": "Automatic ranking of swear words using word embeddings and pseudo-relevance feedback", "url": "http://ieeexplore.ieee.org/abstract/document/7415386/", "author": [{"shortname": "LF D'Haro", "gid": "SCFRL80AAAAJ"}, {"shortname": "RE Banchs", "gid": "V5ou5AMAAAAJ"}], "year": 2015}
{"citedby": 1, "type": "Conference Proceedings", "title": "Automatic ranking of swear words using word embeddings and pseudo-relevance feedback", "author": ["D'Haro, Luis Fernando", "Banchs, Rafael E"], "secondarytitle": "Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2015 Asia-Pacific", "pages": "815-820", "isbn/issn": "9881476801", "year": "2015", "publisher": "IEEE", "start_page": 815, "end_page": 820, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Automatic ranking of swear words using word embeddings and pseudo-relevance feedback\n%A D'Haro, Luis Fernando\n%A Banchs, Rafael E\n%B Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2015 Asia-Pacific\n%P 815-820\n%@ 9881476801\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:pKcvUhCuQIEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-26TthmLTDoXNpgYfrBHRiD8gFs8Q&scisf=3&ct=citation&cd=126&hl=en"}
[2018-03-02 14:58:34,012 DEBUG dbutils] Get paper id {"DOI": null, "title": "Automatic ranking of swear words using word embeddings and pseudo-relevance feedback", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 6, "year": 2015, "rg_id": null, "start_page": 815, "end_page": 820}.
[2018-03-02 14:58:34,012 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Automatic ranking of swear words using word embeddings and pseudo-relevance feedback', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2015, 'rg_id': None, 'start_page': 815, 'end_page': 820}
[2018-03-02 14:58:34,012 DEBUG dbutils] Query result: []
[2018-03-02 14:58:34,012 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:34,012 DEBUG dbutils] Add new paper (title='Automatic ranking of swear words using word embeddings and pseudo-relevance feedback')
[2018-03-02 14:58:34,012 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Automatic ranking of swear words using word embeddings and pseudo-relevance feedback', 'year': 2015, 'publisher': 'IEEE', 'start_page': 815, 'end_page': 820, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Conference Proceedings\n%T Automatic ranking of swear words using word embeddings and pseudo-relevance feedback\n%A D'Haro, Luis Fernando\n%A Banchs, Rafael E\n%B Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2015 Asia-Pacific\n%P 815-820\n%@ 9881476801\n%D 2015\n%I IEEE\n", 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:34,012 DEBUG dbutils] Query result: 117
[2018-03-02 14:58:34,014 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.apsipa.org/proceedings_2015/pdf/232.pdf.
[2018-03-02 14:58:34,014 WARNING utils] Download file (url='http://www.apsipa.org/proceedings_2015/pdf/232.pdf') and save (filename='PDF//117.pdf')
[2018-03-02 14:58:34,014 DEBUG utils] Get current proxy for www.apsipa.org.
[2018-03-02 14:58:34,015 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:58:34,032 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.apsipa.org
[2018-03-02 14:58:34,748 DEBUG requests.packages.urllib3.connectionpool] "GET /proceedings_2015/pdf/232.pdf HTTP/1.1" 200 1726380
[2018-03-02 14:58:34,749 DEBUG utils] Content-length=1726380
[2018-03-02 14:58:34,749 DEBUG utils] Create file PDF//117.pdf, start download.
[2018-03-02 14:58:54,464 DEBUG utils] End download file PDF//117.pdf.
[2018-03-02 14:58:54,466 DEBUG dbutils] Update pdf_transaction for paper id=117.
[2018-03-02 14:58:54,466 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 117'
[2018-03-02 14:58:54,466 DEBUG dbutils] Query result: null
[2018-03-02 14:58:54,466 DEBUG scholar] Handle paper #128 (total 1170)
[2018-03-02 14:58:54,466 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 14:58:54,472 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:54,472 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:58:54,727 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:hqAQIMkRsqgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2xdUjigf0j7d2ov0BNhFxvlUsJ6d&scisf=3&ct=citation&cd=127&hl=en HTTP/1.1" 200 235
[2018-03-02 14:58:54,728 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Accessing an information system by chatting
%A Shawar, Bayan Abu
%A Atwell, Eric
%B International Conference on Application of Natural Language to Information Systems
%P 407-412
%D 2004
%I Springer

[2018-03-02 14:58:54,728 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:54,728 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:54,728 DEBUG __main__] Process content of EndNote file #128
{"title": "Accessing an information system by chatting", "url": "https://link.springer.com/chapter/10.1007/978-3-540-27779-8_39", "author": [{"shortname": "BA Shawar", "gid": ""}, {"shortname": "E Atwell", "gid": "Iu5WFskAAAAJ"}], "year": 2004}
{"citedby": 16, "type": "Conference Proceedings", "title": "Accessing an information system by chatting", "author": ["Shawar, Bayan Abu", "Atwell, Eric"], "secondarytitle": "International Conference on Application of Natural Language to Information Systems", "pages": "407-412", "year": "2004", "publisher": "Springer", "start_page": 407, "end_page": 412, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Accessing an information system by chatting\n%A Shawar, Bayan Abu\n%A Atwell, Eric\n%B International Conference on Application of Natural Language to Information Systems\n%P 407-412\n%D 2004\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:hqAQIMkRsqgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-2xdUjigf0j7d2ov0BNhFxvlUsJ6d&scisf=3&ct=citation&cd=127&hl=en"}
[2018-03-02 14:58:54,728 DEBUG dbutils] Get paper id {"DOI": null, "title": "Accessing an information system by chatting", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 6, "year": 2004, "rg_id": null, "start_page": 407, "end_page": 412}.
[2018-03-02 14:58:54,728 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Accessing an information system by chatting', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2004, 'rg_id': None, 'start_page': 407, 'end_page': 412}
[2018-03-02 14:58:54,729 DEBUG dbutils] Query result: []
[2018-03-02 14:58:54,729 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:54,729 DEBUG dbutils] Add new paper (title='Accessing an information system by chatting')
[2018-03-02 14:58:54,729 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Accessing an information system by chatting', 'year': 2004, 'publisher': 'Springer', 'start_page': 407, 'end_page': 412, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Accessing an information system by chatting\n%A Shawar, Bayan Abu\n%A Atwell, Eric\n%B International Conference on Application of Natural Language to Information Systems\n%P 407-412\n%D 2004\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:54,729 DEBUG dbutils] Query result: 118
[2018-03-02 14:58:54,730 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/2a76/dadd1bbfd82c05cfd7a70e5aa750c5372e29.pdf.
[2018-03-02 14:58:54,731 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/2a76/dadd1bbfd82c05cfd7a70e5aa750c5372e29.pdf') and save (filename='PDF//118.pdf')
[2018-03-02 14:58:54,732 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:58:54,732 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 14:58:54,732 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for otherhost
[2018-03-02 14:58:54,748 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 14:58:55,983 DEBUG requests.packages.urllib3.connectionpool] "GET /2a76/dadd1bbfd82c05cfd7a70e5aa750c5372e29.pdf HTTP/1.1" 200 226698
[2018-03-02 14:58:55,983 DEBUG utils] Content-length=226698
[2018-03-02 14:58:55,984 DEBUG utils] Create file PDF//118.pdf, start download.
[2018-03-02 14:58:56,546 DEBUG utils] End download file PDF//118.pdf.
[2018-03-02 14:58:56,547 DEBUG dbutils] Update pdf_transaction for paper id=118.
[2018-03-02 14:58:56,547 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 118'
[2018-03-02 14:58:56,547 DEBUG dbutils] Query result: null
[2018-03-02 14:58:56,547 DEBUG scholar] Handle paper #129 (total 1170)
[2018-03-02 14:58:56,548 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 14:58:56,551 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:58:56,551 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 14:58:56,551 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for scholar.google.com
[2018-03-02 14:58:56,571 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:58:56,572 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:58:58,236 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GCPO6JXP3osJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-25dMQcM_J3_9-E57-wKdwrcxpiMe&scisf=3&ct=citation&cd=128&hl=en HTTP/1.1" 200 182
[2018-03-02 14:58:58,237 DEBUG scholar] EndNote file:
%0 Journal Article
%T Humanism and artificial intelligence
%A Cosgrove, Mary-Anne
%J Australian Humanist, The
%N 124
%P 7
%D 2016
%I Council of Australian Humanist Societies

[2018-03-02 14:58:58,237 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:58:58,237 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:58:58,237 DEBUG __main__] Process content of EndNote file #129
{"title": "Humanism and artificial intelligence", "url": "https://search.informit.com.au/documentSummary;dn=655096447721392;res=IELHSS", "author": [{"shortname": "MA Cosgrove", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Humanism and artificial intelligence", "author": ["Cosgrove, Mary-Anne"], "journal": "Australian Humanist, The", "numberorissue": "124", "pages": "7", "year": "2016", "publisher": "Council of Australian Humanist Societies", "EndNote": "%0 Journal Article\n%T Humanism and artificial intelligence\n%A Cosgrove, Mary-Anne\n%J Australian Humanist, The\n%N 124\n%P 7\n%D 2016\n%I Council of Australian Humanist Societies\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GCPO6JXP3osJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-25dMQcM_J3_9-E57-wKdwrcxpiMe&scisf=3&ct=citation&cd=128&hl=en"}
[2018-03-02 14:58:58,237 DEBUG dbutils] Get paper id {"DOI": null, "title": "Humanism and artificial intelligence", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:58:58,237 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Humanism and artificial intelligence', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:58:58,237 DEBUG dbutils] Query result: []
[2018-03-02 14:58:58,238 DEBUG dbutils] Paper id = None.
[2018-03-02 14:58:58,238 DEBUG dbutils] Add new paper (title='Humanism and artificial intelligence')
[2018-03-02 14:58:58,238 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Humanism and artificial intelligence', 'year': 2016, 'publisher': 'Council of Australian Humanist Societies', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Humanism and artificial intelligence\n%A Cosgrove, Mary-Anne\n%J Australian Humanist, The\n%N 124\n%P 7\n%D 2016\n%I Council of Australian Humanist Societies\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:58:58,238 DEBUG dbutils] Query result: 119
[2018-03-02 14:58:58,240 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://search.informit.com.au/documentSummary;dn=655096447721392;res=IELHSS.
[2018-03-02 14:58:58,240 DEBUG scihub] Get page from sci-hub for paper with DOI=https://search.informit.com.au/documentSummary;dn=655096447721392;res=IELHSS.
[2018-03-02 14:59:03,256 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 14:59:03,256 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for sci-hub.tw
[2018-03-02 14:59:03,272 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): sci-hub.tw
[2018-03-02 14:59:08,399 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 14:59:08,399 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for sci-hub.tw
[2018-03-02 14:59:08,415 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): sci-hub.tw
[2018-03-02 14:59:13,511 DEBUG requests.packages.urllib3.connectionpool] "GET //https://search.informit.com.au/documentSummary;dn=655096447721392;res=IELHSS HTTP/1.1" 200 None
[2018-03-02 14:59:13,517 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:59:13,517 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:59:13,717 DEBUG requests.packages.urllib3.connectionpool] "GET //https://search.informit.com.au/documentSummary;dn=655096447721392;res=IELHSS HTTP/1.1" 200 None
[2018-03-02 14:59:13,783 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:59:13,784 DEBUG scholar] Handle paper #130 (total 1170)
[2018-03-02 14:59:13,784 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 14:59:13,789 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:13,789 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:59:14,137 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:zHhQo2hE-yYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-27ettA3C6T6ReXW9kpOwp8IaJwwZ&scisf=3&ct=citation&cd=129&hl=en HTTP/1.1" 200 150
[2018-03-02 14:59:14,138 DEBUG scholar] EndNote file:
%0 Book
%T A practical guide to using Second Life in higher education
%A Savin-Baden, Maggi
%@ 0335242154
%D 2010
%I McGraw-Hill Education (UK)

[2018-03-02 14:59:14,138 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:14,139 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:14,139 DEBUG __main__] Process content of EndNote file #130
{"title": "A practical guide to using Second Life in higher education", "url": "https://books.google.com/books?hl=en&lr=&id=0yZFBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=mwAT-7Q7zA&sig=Myx6eih5Rts_GriFgj68_xjafmw", "author": [{"shortname": "M Savin", "gid": ""}], "year": 2010}
{"citedby": 83, "type": "Book", "title": "A practical guide to using Second Life in higher education", "author": ["Savin-Baden, Maggi"], "isbn/issn": "0335242154", "year": "2010", "publisher": "McGraw-Hill Education (UK)", "EndNote": "%0 Book\n%T A practical guide to using Second Life in higher education\n%A Savin-Baden, Maggi\n%@ 0335242154\n%D 2010\n%I McGraw-Hill Education (UK)\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:zHhQo2hE-yYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk-27ettA3C6T6ReXW9kpOwp8IaJwwZ&scisf=3&ct=citation&cd=129&hl=en"}
[2018-03-02 14:59:14,139 DEBUG dbutils] Get paper id {"DOI": null, "title": "A practical guide to using Second Life in higher education", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2010, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:59:14,139 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A practical guide to using Second Life in higher education', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2010, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:59:14,139 DEBUG dbutils] Query result: []
[2018-03-02 14:59:14,139 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:14,139 DEBUG dbutils] Add new paper (title='A practical guide to using Second Life in higher education')
[2018-03-02 14:59:14,139 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A practical guide to using Second Life in higher education', 'year': 2010, 'publisher': 'McGraw-Hill Education (UK)', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T A practical guide to using Second Life in higher education\n%A Savin-Baden, Maggi\n%@ 0335242154\n%D 2010\n%I McGraw-Hill Education (UK)\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:14,140 DEBUG dbutils] Query result: 120
[2018-03-02 14:59:14,141 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=0yZFBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=mwAT-7Q7zA&sig=Myx6eih5Rts_GriFgj68_xjafmw.
[2018-03-02 14:59:14,141 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=0yZFBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=mwAT-7Q7zA&sig=Myx6eih5Rts_GriFgj68_xjafmw.
[2018-03-02 14:59:14,357 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=0yZFBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=mwAT-7Q7zA&sig=Myx6eih5Rts_GriFgj68_xjafmw HTTP/1.1" 302 None
[2018-03-02 14:59:14,563 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:59:14,566 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:59:14,566 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 14:59:14,566 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for sci-hub.tw
[2018-03-02 14:59:14,757 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=0yZFBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=mwAT-7Q7zA&sig=Myx6eih5Rts_GriFgj68_xjafmw HTTP/1.1" 302 None
[2018-03-02 14:59:14,947 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 14:59:14,979 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:59:14,979 DEBUG dbutils] Commiting transaction 130.
[2018-03-02 14:59:15,129 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 14:59:15,130 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 14:59:15,130 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 14:59:15,130 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for scholar.google.com
[2018-03-02 14:59:15,144 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 14:59:16,687 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=130&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 14:59:17,012 DEBUG scholar] Find papers on page #14 (max_google_papers = 300)
[2018-03-02 14:59:17,012 DEBUG scholar] Total 10 papers on page.
[2018-03-02 14:59:17,013 DEBUG scholar] Handle paper #131 (total 1170)
[2018-03-02 14:59:17,013 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 14:59:17,020 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:17,021 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:59:17,038 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:59:17,040 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:59:19,067 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:mPtbs5jFaX4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MRMFA9_YC8WbmbKYawTgX-u_Siqz&scisf=3&ct=citation&cd=130&hl=en HTTP/1.1" 200 208
[2018-03-02 14:59:19,068 DEBUG scholar] EndNote file:
%0 Journal Article
%T Emerging technologies looking back and ahead: 20 years of technologies for language learning
%A Godwin-Jones, Robert
%J Language Learning & Technology
%V 20
%N 2
%P 5-12
%D 2016

[2018-03-02 14:59:19,068 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:19,068 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:19,068 DEBUG __main__] Process content of EndNote file #131
{"title": "Emerging technologies looking back and ahead: 20 years of technologies for language learning", "url": "https://www.researchgate.net/profile/Greg_Kessler/publication/304043746_SPECIAL_ISSUE_OF_SPECIAL_ISSUES_20_YEARS_OF_LANGUAGE_LEARNING_TECHNOLOGY/links/579a1aae08ae2e0b31b14873/SPECIAL-ISSUE-OF-SPECIAL-ISSUES-20-YEARS-OF-LANGUAGE-LEARNING-TECHNOLOGY.pdf#page=10", "author": [{"shortname": "R Godwin", "gid": ""}], "year": 2016}
{"citedby": 6, "type": "Journal Article", "title": "Emerging technologies looking back and ahead: 20 years of technologies for language learning", "author": ["Godwin-Jones, Robert"], "journal": "Language Learning & Technology", "volume": 8, "numberorissue": "2", "pages": "5-12", "year": "2016", "start_page": 5, "end_page": 12, "EndNote": "%0 Journal Article\n%T Emerging technologies looking back and ahead: 20 years of technologies for language learning\n%A Godwin-Jones, Robert\n%J Language Learning & Technology\n%V 20\n%N 2\n%P 5-12\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:mPtbs5jFaX4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MRMFA9_YC8WbmbKYawTgX-u_Siqz&scisf=3&ct=citation&cd=130&hl=en"}
[2018-03-02 14:59:19,068 DEBUG dbutils] Get paper id {"DOI": null, "title": "Emerging technologies looking back and ahead: 20 years of technologies for language learning", "auth_count": 1, "g_type": "Journal Article", "pages": 8, "year": 2016, "rg_id": null, "start_page": 5, "end_page": 12}.
[2018-03-02 14:59:19,069 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Emerging technologies looking back and ahead: 20 years of technologies for language learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 8, 'year': 2016, 'rg_id': None, 'start_page': 5, 'end_page': 12}
[2018-03-02 14:59:19,069 DEBUG dbutils] Query result: []
[2018-03-02 14:59:19,069 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:19,069 DEBUG dbutils] Add new paper (title='Emerging technologies looking back and ahead: 20 years of technologies for language learning')
[2018-03-02 14:59:19,069 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Emerging technologies looking back and ahead: 20 years of technologies for language learning', 'year': 2016, 'publisher': None, 'start_page': 5, 'end_page': 12, 'pages': 8, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Emerging technologies looking back and ahead: 20 years of technologies for language learning\n%A Godwin-Jones, Robert\n%J Language Learning & Technology\n%V 20\n%N 2\n%P 5-12\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:19,070 DEBUG dbutils] Query result: 121
[2018-03-02 14:59:19,072 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Greg_Kessler/publication/304043746_SPECIAL_ISSUE_OF_SPECIAL_ISSUES_20_YEARS_OF_LANGUAGE_LEARNING_TECHNOLOGY/links/579a1aae08ae2e0b31b14873/SPECIAL-ISSUE-OF-SPECIAL-ISSUES-20-YEARS-OF-LANGUAGE-LEARNING-TECHNOLOGY.pdf#page=10.
[2018-03-02 14:59:19,072 WARNING utils] Download file (url='https://www.researchgate.net/profile/Greg_Kessler/publication/304043746_SPECIAL_ISSUE_OF_SPECIAL_ISSUES_20_YEARS_OF_LANGUAGE_LEARNING_TECHNOLOGY/links/579a1aae08ae2e0b31b14873/SPECIAL-ISSUE-OF-SPECIAL-ISSUES-20-YEARS-OF-LANGUAGE-LEARNING-TECHNOLOGY.pdf#page=10') and save (filename='PDF//121.pdf')
[2018-03-02 14:59:19,073 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:59:19,073 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:59:24,094 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1002, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 865, in read
    return self._sslobj.read(len, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 625, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.researchgate.net', port=443): Read timed out. (read timeout=5)

[2018-03-02 14:59:24,094 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for www.researchgate.net
[2018-03-02 14:59:24,094 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:59:24,094 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 14:59:24,110 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 14:59:25,122 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Greg_Kessler/publication/304043746_SPECIAL_ISSUE_OF_SPECIAL_ISSUES_20_YEARS_OF_LANGUAGE_LEARNING_TECHNOLOGY/links/579a1aae08ae2e0b31b14873/SPECIAL-ISSUE-OF-SPECIAL-ISSUES-20-YEARS-OF-LANGUAGE-LEARNING-TECHNOLOGY.pdf HTTP/1.1" 429 None
[2018-03-02 14:59:25,274 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for www.researchgate.net
[2018-03-02 14:59:25,275 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 14:59:25,275 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 14:59:25,290 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 14:59:26,297 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Greg_Kessler/publication/304043746_SPECIAL_ISSUE_OF_SPECIAL_ISSUES_20_YEARS_OF_LANGUAGE_LEARNING_TECHNOLOGY/links/579a1aae08ae2e0b31b14873/SPECIAL-ISSUE-OF-SPECIAL-ISSUES-20-YEARS-OF-LANGUAGE-LEARNING-TECHNOLOGY.pdf HTTP/1.1" 200 3161298
[2018-03-02 14:59:26,298 DEBUG utils] Content-length=3161298
[2018-03-02 14:59:26,298 DEBUG utils] Create file PDF//121.pdf, start download.
[2018-03-02 14:59:32,998 DEBUG utils] End download file PDF//121.pdf.
[2018-03-02 14:59:32,999 DEBUG dbutils] Update pdf_transaction for paper id=121.
[2018-03-02 14:59:32,999 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 121'
[2018-03-02 14:59:32,999 DEBUG dbutils] Query result: null
[2018-03-02 14:59:33,000 DEBUG scholar] Handle paper #132 (total 1170)
[2018-03-02 14:59:33,000 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 14:59:33,005 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:33,005 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 14:59:33,005 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for scholar.google.com
[2018-03-02 14:59:33,023 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:59:33,024 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:59:34,646 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:bbYTBKETBk8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQaN3CyhA7Hp_1ZHQreXyzV7O1_v&scisf=3&ct=citation&cd=131&hl=en HTTP/1.1" 200 181
[2018-03-02 14:59:34,647 DEBUG scholar] EndNote file:
%0 Journal Article
%T Innovating Language Education: An NMC Horizon Project Strategic Brief
%A Adams Becker, Samantha
%A Rodriguez, Julio C
%A Estrada, V
%A Davis, A
%D 2016

[2018-03-02 14:59:34,647 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:34,647 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:34,648 DEBUG __main__] Process content of EndNote file #132
{"title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "url": "https://scholarspace.manoa.hawaii.edu/handle/10125/49406", "author": [{"shortname": "S Adams Becker", "gid": ""}, {"shortname": "JC Rodriguez", "gid": ""}, {"shortname": "V Estrada", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "author": ["Adams Becker, Samantha", "Rodriguez, Julio C", "Estrada, V", "Davis, A"], "year": "2016", "EndNote": "%0 Journal Article\n%T Innovating Language Education: An NMC Horizon Project Strategic Brief\n%A Adams Becker, Samantha\n%A Rodriguez, Julio C\n%A Estrada, V\n%A Davis, A\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:bbYTBKETBk8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQaN3CyhA7Hp_1ZHQreXyzV7O1_v&scisf=3&ct=citation&cd=131&hl=en"}
[2018-03-02 14:59:34,648 DEBUG dbutils] Get paper id {"DOI": null, "title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:59:34,648 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Innovating Language Education: An NMC Horizon Project Strategic Brief', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:59:34,648 DEBUG dbutils] Query result: []
[2018-03-02 14:59:34,648 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:34,648 DEBUG dbutils] Add new paper (title='Innovating Language Education: An NMC Horizon Project Strategic Brief')
[2018-03-02 14:59:34,648 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Innovating Language Education: An NMC Horizon Project Strategic Brief', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Innovating Language Education: An NMC Horizon Project Strategic Brief\n%A Adams Becker, Samantha\n%A Rodriguez, Julio C\n%A Estrada, V\n%A Davis, A\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:34,648 DEBUG dbutils] Query result: 122
[2018-03-02 14:59:34,650 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://scholarspace.manoa.hawaii.edu/bitstream/10125/49406/1/2016-nmc-strategic-brief-language_ed-1.pdf.
[2018-03-02 14:59:34,651 WARNING utils] Download file (url='https://scholarspace.manoa.hawaii.edu/bitstream/10125/49406/1/2016-nmc-strategic-brief-language_ed-1.pdf') and save (filename='PDF//122.pdf')
[2018-03-02 14:59:34,652 DEBUG utils] Get current proxy for scholarspace.manoa.hawaii.edu.
[2018-03-02 14:59:34,652 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:59:34,667 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholarspace.manoa.hawaii.edu
[2018-03-02 14:59:38,026 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10125/49406/1/2016-nmc-strategic-brief-language_ed-1.pdf HTTP/1.1" 200 889912
[2018-03-02 14:59:38,027 DEBUG utils] Content-length=889912
[2018-03-02 14:59:38,028 DEBUG utils] Create file PDF//122.pdf, start download.
[2018-03-02 14:59:46,587 DEBUG utils] End download file PDF//122.pdf.
[2018-03-02 14:59:46,588 DEBUG dbutils] Update pdf_transaction for paper id=122.
[2018-03-02 14:59:46,588 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 122'
[2018-03-02 14:59:46,588 DEBUG dbutils] Query result: null
[2018-03-02 14:59:46,589 DEBUG scholar] Handle paper #133 (total 1170)
[2018-03-02 14:59:46,589 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 14:59:46,593 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:46,593 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 14:59:46,594 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for scholar.google.com
[2018-03-02 14:59:46,611 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:59:51,816 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:732: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:ZJkjPmxuRZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MeLvyXGBSWEWny64skZl9r8LIvfF&scisf=3&ct=citation&cd=132&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:ZJkjPmxuRZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MeLvyXGBSWEWny64skZl9r8LIvfF&scisf=3&ct=citation&cd=132&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

[2018-03-02 14:59:51,816 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for scholar.google.com
[2018-03-02 14:59:51,817 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:51,817 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:59:51,831 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:59:51,833 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:59:54,856 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ZJkjPmxuRZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MeLvyXGBSWEWny64skZl9r8LIvfF&scisf=3&ct=citation&cd=132&hl=en HTTP/1.1" 200 91
[2018-03-02 14:59:54,857 DEBUG scholar] EndNote file:
%0 Generic
%T A sentiment-based chat bot
%A BLOM, ALEXANDER
%A THORSEN, SOFIE
%D 2013

[2018-03-02 14:59:54,857 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:54,857 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:54,858 DEBUG __main__] Process content of EndNote file #133
{"title": "A sentiment-based chat bot", "url": "http://www.diva-portal.org/smash/get/diva2:670679/FULLTEXT01.pdf", "author": [{"shortname": "A BLOM", "gid": ""}, {"shortname": "S THORSEN", "gid": ""}], "year": 2013}
{"citedby": 1, "type": "Generic", "title": "A sentiment-based chat bot", "author": ["BLOM, ALEXANDER", "THORSEN, SOFIE"], "year": "2013", "EndNote": "%0 Generic\n%T A sentiment-based chat bot\n%A BLOM, ALEXANDER\n%A THORSEN, SOFIE\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ZJkjPmxuRZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MeLvyXGBSWEWny64skZl9r8LIvfF&scisf=3&ct=citation&cd=132&hl=en"}
[2018-03-02 14:59:54,858 DEBUG dbutils] Get paper id {"DOI": null, "title": "A sentiment-based chat bot", "auth_count": 2, "g_type": "Generic", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 14:59:54,858 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A sentiment-based chat bot', 'auth_count': 2, 'g_type': 'Generic', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 14:59:54,858 DEBUG dbutils] Query result: []
[2018-03-02 14:59:54,858 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:54,858 DEBUG dbutils] Add new paper (title='A sentiment-based chat bot')
[2018-03-02 14:59:54,858 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A sentiment-based chat bot', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T A sentiment-based chat bot\n%A BLOM, ALEXANDER\n%A THORSEN, SOFIE\n%D 2013\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:54,858 DEBUG dbutils] Query result: 123
[2018-03-02 14:59:54,860 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.diva-portal.org/smash/get/diva2:670679/FULLTEXT01.pdf.
[2018-03-02 14:59:54,861 WARNING utils] Download file (url='http://www.diva-portal.org/smash/get/diva2:670679/FULLTEXT01.pdf') and save (filename='PDF//123.pdf')
[2018-03-02 14:59:54,861 DEBUG utils] Get current proxy for www.diva-portal.org.
[2018-03-02 14:59:54,861 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:59:54,877 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.diva-portal.org
[2018-03-02 14:59:55,346 DEBUG requests.packages.urllib3.connectionpool] "GET /smash/get/diva2:670679/FULLTEXT01.pdf HTTP/1.1" 200 376061
[2018-03-02 14:59:55,346 DEBUG utils] Content-length=376061
[2018-03-02 14:59:55,347 DEBUG utils] Create file PDF//123.pdf, start download.
[2018-03-02 14:59:56,110 DEBUG utils] End download file PDF//123.pdf.
[2018-03-02 14:59:56,111 DEBUG dbutils] Update pdf_transaction for paper id=123.
[2018-03-02 14:59:56,112 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 123'
[2018-03-02 14:59:56,112 DEBUG dbutils] Query result: null
[2018-03-02 14:59:56,112 DEBUG scholar] Handle paper #134 (total 1170)
[2018-03-02 14:59:56,112 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 14:59:56,118 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:56,118 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 14:59:56,118 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for scholar.google.com
[2018-03-02 14:59:56,132 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 14:59:56,135 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 14:59:57,786 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_FOglQxwNzkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQrWzPZhoBQvE-3Q3NJzYVgS-DgU&scisf=3&ct=citation&cd=133&hl=en HTTP/1.1" 200 265
[2018-03-02 14:59:57,787 DEBUG scholar] EndNote file:
%0 Book Section
%T Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture
%A Griol, D
%A Callejas, Z
%B Formative Assessment, Learning Data Analytics and Gamification
%P 313-331
%D 2016
%I Elsevier

[2018-03-02 14:59:57,787 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:57,787 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:57,787 DEBUG __main__] Process content of EndNote file #134
{"title": "Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture", "url": "https://www.sciencedirect.com/science/article/pii/B9780128036372000154", "author": [{"shortname": "D Griol", "gid": ""}, {"shortname": "Z Callejas", "gid": "WE75b8AAAAAJ"}], "year": 2016}
{"type": "Book Section", "title": "Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture", "author": ["Griol, D", "Callejas, Z"], "secondarytitle": "Formative Assessment, Learning Data Analytics and Gamification", "pages": "313-331", "year": "2016", "publisher": "Elsevier", "start_page": 313, "end_page": 331, "volume": 19, "EndNote": "%0 Book Section\n%T Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture\n%A Griol, D\n%A Callejas, Z\n%B Formative Assessment, Learning Data Analytics and Gamification\n%P 313-331\n%D 2016\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_FOglQxwNzkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQrWzPZhoBQvE-3Q3NJzYVgS-DgU&scisf=3&ct=citation&cd=133&hl=en"}
[2018-03-02 14:59:57,787 DEBUG dbutils] Get paper id {"DOI": null, "title": "Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture", "auth_count": 2, "g_type": "Book Section", "pages": 19, "year": 2016, "rg_id": null, "start_page": 313, "end_page": 331}.
[2018-03-02 14:59:57,787 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 19, 'year': 2016, 'rg_id': None, 'start_page': 313, 'end_page': 331}
[2018-03-02 14:59:57,787 DEBUG dbutils] Query result: []
[2018-03-02 14:59:57,787 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:57,787 DEBUG dbutils] Add new paper (title='Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture')
[2018-03-02 14:59:57,787 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture', 'year': 2016, 'publisher': 'Elsevier', 'start_page': 313, 'end_page': 331, 'pages': 19, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Conversational Agents as Learning Facilitators: Experiences With a Mobile Multimodal Dialogue System Architecture\n%A Griol, D\n%A Callejas, Z\n%B Formative Assessment, Learning Data Analytics and Gamification\n%P 313-331\n%D 2016\n%I Elsevier\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:57,788 DEBUG dbutils] Query result: 124
[2018-03-02 14:59:57,789 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/B9780128036372000154.
[2018-03-02 14:59:57,789 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/B9780128036372000154.
[2018-03-02 14:59:58,016 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/B9780128036372000154 HTTP/1.1" 302 None
[2018-03-02 14:59:58,039 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 14:59:58,459 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=38040D0D1A55180F031BA6D739709174 HTTP/1.1" 200 10100
[2018-03-02 14:59:58,959 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 14:59:58,959 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 14:59:59,176 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/B9780128036372000154 HTTP/1.1" 302 None
[2018-03-02 14:59:59,422 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=38040D0D1A55180F031BA6D739709174 HTTP/1.1" 200 10100
[2018-03-02 14:59:59,634 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 14:59:59,635 DEBUG scholar] Handle paper #135 (total 1170)
[2018-03-02 14:59:59,635 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 14:59:59,638 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 14:59:59,639 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 14:59:59,955 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:cxe_5Xp2l1AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MT_uFMdOs4nnqCq5WjUSrGzWgroY&scisf=3&ct=citation&cd=134&hl=en HTTP/1.1" 200 287
[2018-03-02 14:59:59,956 DEBUG scholar] EndNote file:
%0 Journal Article
%T We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics
%A De Miranda, Luis
%A Rovatsos, M
%A Ramamoorthy, S
%J What social robots can and should do: Proceedings of Robo-Philosophy
%P 48-59
%D 2016

[2018-03-02 14:59:59,956 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 14:59:59,956 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 14:59:59,956 DEBUG __main__] Process content of EndNote file #135
{"title": "We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics", "url": "https://pdfs.semanticscholar.org/804e/89a50aadc2eb4555f322756be33b1f78b179.pdf", "author": [{"shortname": "L De Miranda", "gid": "lJQdKhwAAAAJ"}, {"shortname": "M Rovatsos", "gid": "xQGbSfMAAAAJ"}], "year": 2016}
{"citedby": 2, "type": "Journal Article", "title": "We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics", "author": ["De Miranda, Luis", "Rovatsos, M", "Ramamoorthy, S"], "journal": "What social robots can and should do: Proceedings of Robo-Philosophy", "pages": "48-59", "year": "2016", "start_page": 48, "end_page": 59, "volume": 12, "EndNote": "%0 Journal Article\n%T We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics\n%A De Miranda, Luis\n%A Rovatsos, M\n%A Ramamoorthy, S\n%J What social robots can and should do: Proceedings of Robo-Philosophy\n%P 48-59\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:cxe_5Xp2l1AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MT_uFMdOs4nnqCq5WjUSrGzWgroY&scisf=3&ct=citation&cd=134&hl=en"}
[2018-03-02 14:59:59,957 DEBUG dbutils] Get paper id {"DOI": null, "title": "We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics", "auth_count": 3, "g_type": "Journal Article", "pages": 12, "year": 2016, "rg_id": null, "start_page": 48, "end_page": 59}.
[2018-03-02 14:59:59,957 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 48, 'end_page': 59}
[2018-03-02 14:59:59,957 DEBUG dbutils] Query result: []
[2018-03-02 14:59:59,957 DEBUG dbutils] Paper id = None.
[2018-03-02 14:59:59,957 DEBUG dbutils] Add new paper (title='We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics')
[2018-03-02 14:59:59,957 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics', 'year': 2016, 'publisher': None, 'start_page': 48, 'end_page': 59, 'pages': 12, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T We, anthrobot: Learning from human forms of interaction and esprit de corps to develop more plural social robotics\n%A De Miranda, Luis\n%A Rovatsos, M\n%A Ramamoorthy, S\n%J What social robots can and should do: Proceedings of Robo-Philosophy\n%P 48-59\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 14:59:59,957 DEBUG dbutils] Query result: 125
[2018-03-02 14:59:59,959 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/804e/89a50aadc2eb4555f322756be33b1f78b179.pdf.
[2018-03-02 14:59:59,959 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/804e/89a50aadc2eb4555f322756be33b1f78b179.pdf') and save (filename='PDF//125.pdf')
[2018-03-02 14:59:59,959 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 14:59:59,960 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 14:59:59,960 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for otherhost
[2018-03-02 14:59:59,976 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:00:03,373 DEBUG requests.packages.urllib3.connectionpool] "GET /804e/89a50aadc2eb4555f322756be33b1f78b179.pdf HTTP/1.1" 200 454232
[2018-03-02 15:00:03,374 DEBUG utils] Content-length=454232
[2018-03-02 15:00:03,374 DEBUG utils] Create file PDF//125.pdf, start download.
[2018-03-02 15:00:08,787 DEBUG utils] End download file PDF//125.pdf.
[2018-03-02 15:00:08,788 DEBUG dbutils] Update pdf_transaction for paper id=125.
[2018-03-02 15:00:08,788 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 125'
[2018-03-02 15:00:08,788 DEBUG dbutils] Query result: null
[2018-03-02 15:00:08,790 DEBUG scholar] Handle paper #136 (total 1170)
[2018-03-02 15:00:08,791 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:00:08,795 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:08,795 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:00:08,795 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for scholar.google.com
[2018-03-02 15:00:08,813 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:00:13,998 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:uBU93G3tX1YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MVadgm4ePxtxdd_4_TSOS_noAxer&scisf=3&ct=citation&cd=135&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:uBU93G3tX1YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MVadgm4ePxtxdd_4_TSOS_noAxer&scisf=3&ct=citation&cd=135&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:00:13,998 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for scholar.google.com
[2018-03-02 15:00:13,999 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:13,999 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:00:14,017 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:00:14,018 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:00:16,000 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:uBU93G3tX1YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MVadgm4ePxtxdd_4_TSOS_noAxer&scisf=3&ct=citation&cd=135&hl=en HTTP/1.1" 200 298
[2018-03-02 15:00:16,001 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land
%A Masmuzidin, Masyarah Zulhaida
%A Wan, Taoran
%B Proceedings of the 11th International Conference on Interaction Design and Children
%P 280-283
%@ 1450310079
%D 2012
%I ACM

[2018-03-02 15:00:16,001 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:16,001 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:16,001 DEBUG __main__] Process content of EndNote file #136
{"title": "V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land", "url": "https://dl.acm.org/citation.cfm?id=2307145", "author": [{"shortname": "MZ Masmuzidin", "gid": "3_RbwgoAAAAJ"}, {"shortname": "T Wan", "gid": ""}], "year": 2012}
{"citedby": 1, "type": "Conference Proceedings", "title": "V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land", "author": ["Masmuzidin, Masyarah Zulhaida", "Wan, Taoran"], "secondarytitle": "Proceedings of the 11th International Conference on Interaction Design and Children", "pages": "280-283", "isbn/issn": "1450310079", "year": "2012", "publisher": "ACM", "start_page": 280, "end_page": 283, "volume": 4, "EndNote": "%0 Conference Proceedings\n%T V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land\n%A Masmuzidin, Masyarah Zulhaida\n%A Wan, Taoran\n%B Proceedings of the 11th International Conference on Interaction Design and Children\n%P 280-283\n%@ 1450310079\n%D 2012\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:uBU93G3tX1YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MVadgm4ePxtxdd_4_TSOS_noAxer&scisf=3&ct=citation&cd=135&hl=en"}
[2018-03-02 15:00:16,001 DEBUG dbutils] Get paper id {"DOI": null, "title": "V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 4, "year": 2012, "rg_id": null, "start_page": 280, "end_page": 283}.
[2018-03-02 15:00:16,002 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 4, 'year': 2012, 'rg_id': None, 'start_page': 280, 'end_page': 283}
[2018-03-02 15:00:16,002 DEBUG dbutils] Query result: []
[2018-03-02 15:00:16,002 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:16,002 DEBUG dbutils] Add new paper (title='V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land')
[2018-03-02 15:00:16,002 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land', 'year': 2012, 'publisher': 'ACM', 'start_page': 280, 'end_page': 283, 'pages': 4, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T V-Penglipur Lara: The development of a pedagogical agent in Malaysian folktales land\n%A Masmuzidin, Masyarah Zulhaida\n%A Wan, Taoran\n%B Proceedings of the 11th International Conference on Interaction Design and Children\n%P 280-283\n%@ 1450310079\n%D 2012\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:16,002 DEBUG dbutils] Query result: 126
[2018-03-02 15:00:16,004 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2307145.
[2018-03-02 15:00:16,004 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2307145.
[2018-03-02 15:00:19,232 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2307145 HTTP/1.1" 200 None
[2018-03-02 15:00:19,233 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:00:19,233 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:00:19,233 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for sci-hub.tw
[2018-03-02 15:00:19,418 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2307145 HTTP/1.1" 200 None
[2018-03-02 15:00:19,424 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/9cfbb7b2774f3094f208023dbbe211a9/masmuzidin2012.pdf?download=true.
[2018-03-02 15:00:19,424 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/9cfbb7b2774f3094f208023dbbe211a9/masmuzidin2012.pdf?download=true') and save (filename='PDF//126.pdf')
[2018-03-02 15:00:19,439 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dabamirror.sci-hub.tw
[2018-03-02 15:00:19,696 DEBUG requests.packages.urllib3.connectionpool] "GET /9cfbb7b2774f3094f208023dbbe211a9/masmuzidin2012.pdf?download=true HTTP/1.1" 200 425000
[2018-03-02 15:00:19,697 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:00:19,697 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:00:19,713 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dabamirror.sci-hub.tw
[2018-03-02 15:00:19,908 DEBUG requests.packages.urllib3.connectionpool] "GET /9cfbb7b2774f3094f208023dbbe211a9/masmuzidin2012.pdf?download=true HTTP/1.1" 200 425000
[2018-03-02 15:00:19,909 DEBUG utils] Content-length=425000
[2018-03-02 15:00:19,909 DEBUG utils] Create file PDF//126.pdf, start download.
[2018-03-02 15:00:20,519 DEBUG utils] End download file PDF//126.pdf.
[2018-03-02 15:00:20,520 DEBUG dbutils] Update pdf_transaction for paper id=126.
[2018-03-02 15:00:20,520 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 126'
[2018-03-02 15:00:20,520 DEBUG dbutils] Query result: null
[2018-03-02 15:00:20,521 DEBUG scholar] Handle paper #137 (total 1170)
[2018-03-02 15:00:20,521 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:00:20,524 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:20,524 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:00:20,525 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for scholar.google.com
[2018-03-02 15:00:20,541 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:00:20,542 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:00:21,945 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AwHmQr0lh9oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQK_9vmmk0AJ6ubjrPyKKzESYeOg&scisf=3&ct=citation&cd=136&hl=en HTTP/1.1" 200 328
[2018-03-02 15:00:21,946 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Humorist bot: Bringing computational humour in a chat-bot system
%A Augello, Agnese
%A Saccone, Gaetano
%A Gaglio, Salvatore
%A Pilato, Giovanni
%B Complex, Intelligent and Software Intensive Systems, 2008. CISIS 2008. International Conference on
%P 703-708
%@ 0769531091
%D 2008
%I IEEE

[2018-03-02 15:00:21,946 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:21,946 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:21,946 DEBUG __main__] Process content of EndNote file #137
{"title": "Humorist bot: Bringing computational humour in a chat-bot system", "url": "http://ieeexplore.ieee.org/abstract/document/4606756/", "author": [{"shortname": "A Augello", "gid": "vPJnw0AAAAAJ"}, {"shortname": "G Saccone", "gid": ""}, {"shortname": "S Gaglio", "gid": "UcUoEdAAAAAJ"}], "year": 2008}
{"citedby": 33, "type": "Conference Proceedings", "title": "Humorist bot: Bringing computational humour in a chat-bot system", "author": ["Augello, Agnese", "Saccone, Gaetano", "Gaglio, Salvatore", "Pilato, Giovanni"], "secondarytitle": "Complex, Intelligent and Software Intensive Systems, 2008. CISIS 2008. International Conference on", "pages": "703-708", "isbn/issn": "0769531091", "year": "2008", "publisher": "IEEE", "start_page": 703, "end_page": 708, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Humorist bot: Bringing computational humour in a chat-bot system\n%A Augello, Agnese\n%A Saccone, Gaetano\n%A Gaglio, Salvatore\n%A Pilato, Giovanni\n%B Complex, Intelligent and Software Intensive Systems, 2008. CISIS 2008. International Conference on\n%P 703-708\n%@ 0769531091\n%D 2008\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:AwHmQr0lh9oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MQK_9vmmk0AJ6ubjrPyKKzESYeOg&scisf=3&ct=citation&cd=136&hl=en"}
[2018-03-02 15:00:21,947 DEBUG dbutils] Get paper id {"DOI": null, "title": "Humorist bot: Bringing computational humour in a chat-bot system", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 6, "year": 2008, "rg_id": null, "start_page": 703, "end_page": 708}.
[2018-03-02 15:00:21,947 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Humorist bot: Bringing computational humour in a chat-bot system', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2008, 'rg_id': None, 'start_page': 703, 'end_page': 708}
[2018-03-02 15:00:21,947 DEBUG dbutils] Query result: []
[2018-03-02 15:00:21,947 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:21,947 DEBUG dbutils] Add new paper (title='Humorist bot: Bringing computational humour in a chat-bot system')
[2018-03-02 15:00:21,947 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Humorist bot: Bringing computational humour in a chat-bot system', 'year': 2008, 'publisher': 'IEEE', 'start_page': 703, 'end_page': 708, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Humorist bot: Bringing computational humour in a chat-bot system\n%A Augello, Agnese\n%A Saccone, Gaetano\n%A Gaglio, Salvatore\n%A Pilato, Giovanni\n%B Complex, Intelligent and Software Intensive Systems, 2008. CISIS 2008. International Conference on\n%P 703-708\n%@ 0769531091\n%D 2008\n%I IEEE\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:21,947 DEBUG dbutils] Query result: 127
[2018-03-02 15:00:21,949 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Giovanni_Pilato2/publication/4369405_Humorist_Bot_Bringing_Computational_Humour_in_a_Chat-Bot_System/links/54885b940cf268d28f08dbce.pdf.
[2018-03-02 15:00:21,949 WARNING utils] Download file (url='https://www.researchgate.net/profile/Giovanni_Pilato2/publication/4369405_Humorist_Bot_Bringing_Computational_Humour_in_a_Chat-Bot_System/links/54885b940cf268d28f08dbce.pdf') and save (filename='PDF//127.pdf')
[2018-03-02 15:00:21,950 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:00:21,950 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:00:21,950 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for www.researchgate.net
[2018-03-02 15:00:21,966 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:00:23,551 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Giovanni_Pilato2/publication/4369405_Humorist_Bot_Bringing_Computational_Humour_in_a_Chat-Bot_System/links/54885b940cf268d28f08dbce.pdf HTTP/1.1" 200 491278
[2018-03-02 15:00:23,552 DEBUG utils] Content-length=491278
[2018-03-02 15:00:23,552 DEBUG utils] Create file PDF//127.pdf, start download.
[2018-03-02 15:00:24,603 DEBUG utils] End download file PDF//127.pdf.
[2018-03-02 15:00:24,606 DEBUG dbutils] Update pdf_transaction for paper id=127.
[2018-03-02 15:00:24,606 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 127'
[2018-03-02 15:00:24,606 DEBUG dbutils] Query result: null
[2018-03-02 15:00:24,606 DEBUG scholar] Handle paper #138 (total 1170)
[2018-03-02 15:00:24,606 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:00:24,612 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:24,612 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:00:24,886 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:g14X3k6BOO8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MdT43XZGwOYHXb4OV2BWqr8OK6if&scisf=3&ct=citation&cd=137&hl=en HTTP/1.1" 200 263
[2018-03-02 15:00:24,887 DEBUG scholar] EndNote file:
%0 Journal Article
%T End-to-end reinforcement learning of dialogue agents for information access
%A Dhingra, Bhuwan
%A Li, Lihong
%A Li, Xiujun
%A Gao, Jianfeng
%A Chen, Yun-Nung
%A Ahmed, Faisal
%A Deng, Li
%J arXiv preprint arXiv:1609.00777
%D 2016

[2018-03-02 15:00:24,887 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:24,887 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:24,887 DEBUG __main__] Process content of EndNote file #138
{"title": "End-to-end reinforcement learning of dialogue agents for information access", "url": "https://arxiv.org/abs/1609.00777", "author": [{"shortname": "B Dhingra", "gid": "2W2ttrQAAAAJ"}, {"shortname": "L Li", "gid": "Rqy5KDEAAAAJ"}, {"shortname": "X Li", "gid": "SW_WaQ0AAAAJ"}, {"shortname": "J Gao", "gid": "CQ1cqKkAAAAJ"}, {"shortname": "YN Chen", "gid": "jQLg-_UAAAAJ"}, {"shortname": "F Ahmed", "gid": "laKl8acAAAAJ"}], "year": 2016}
{"citedby": 26, "type": "Journal Article", "title": "End-to-end reinforcement learning of dialogue agents for information access", "author": ["Dhingra, Bhuwan", "Li, Lihong", "Li, Xiujun", "Gao, Jianfeng", "Chen, Yun-Nung", "Ahmed, Faisal", "Deng, Li"], "journal": "arXiv preprint arXiv:1609.00777", "year": "2016", "EndNote": "%0 Journal Article\n%T End-to-end reinforcement learning of dialogue agents for information access\n%A Dhingra, Bhuwan\n%A Li, Lihong\n%A Li, Xiujun\n%A Gao, Jianfeng\n%A Chen, Yun-Nung\n%A Ahmed, Faisal\n%A Deng, Li\n%J arXiv preprint arXiv:1609.00777\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:g14X3k6BOO8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MdT43XZGwOYHXb4OV2BWqr8OK6if&scisf=3&ct=citation&cd=137&hl=en"}
[2018-03-02 15:00:24,887 DEBUG dbutils] Get paper id {"DOI": null, "title": "End-to-end reinforcement learning of dialogue agents for information access", "auth_count": 7, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:00:24,887 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'End-to-end reinforcement learning of dialogue agents for information access', 'auth_count': 7, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:00:24,888 DEBUG dbutils] Query result: []
[2018-03-02 15:00:24,888 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:24,888 DEBUG dbutils] Add new paper (title='End-to-end reinforcement learning of dialogue agents for information access')
[2018-03-02 15:00:24,888 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'End-to-end reinforcement learning of dialogue agents for information access', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T End-to-end reinforcement learning of dialogue agents for information access\n%A Dhingra, Bhuwan\n%A Li, Lihong\n%A Li, Xiujun\n%A Gao, Jianfeng\n%A Chen, Yun-Nung\n%A Ahmed, Faisal\n%A Deng, Li\n%J arXiv preprint arXiv:1609.00777\n%D 2016\n', 'RIS': None, 'authors': 7, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:24,888 DEBUG dbutils] Query result: 128
[2018-03-02 15:00:24,889 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1609.00777.
[2018-03-02 15:00:24,890 WARNING utils] Download file (url='https://arxiv.org/pdf/1609.00777') and save (filename='PDF//128.pdf')
[2018-03-02 15:00:24,890 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:00:24,890 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:00:24,905 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: arxiv.org
[2018-03-02 15:00:24,906 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): arxiv.org
[2018-03-02 15:00:27,416 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1609.00777 HTTP/1.1" 302 280
[2018-03-02 15:00:28,391 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1609.00777.pdf HTTP/1.1" 200 1315070
[2018-03-02 15:00:28,391 DEBUG utils] Content-length=1315070
[2018-03-02 15:00:28,392 DEBUG utils] Create file PDF//128.pdf, start download.
[2018-03-02 15:00:36,826 DEBUG utils] End download file PDF//128.pdf.
[2018-03-02 15:00:36,827 DEBUG dbutils] Update pdf_transaction for paper id=128.
[2018-03-02 15:00:36,828 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 128'
[2018-03-02 15:00:36,828 DEBUG dbutils] Query result: null
[2018-03-02 15:00:36,828 DEBUG scholar] Handle paper #139 (total 1170)
[2018-03-02 15:00:36,829 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:00:36,833 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:36,833 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:00:36,833 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for scholar.google.com
[2018-03-02 15:00:36,852 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:00:36,853 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:00:38,196 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:P--HpfLVQBEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MbF0TfdAPA8f5wKs0mir1XDVxSwn&scisf=3&ct=citation&cd=138&hl=en HTTP/1.1" 200 256
[2018-03-02 15:00:38,197 DEBUG scholar] EndNote file:
%0 Journal Article
%T Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues
%A Niculescu, Andreea I
%A Banchs, Rafael E
%J Proceedings of ERRARE, Sinaia, Romania
%D 2015

[2018-03-02 15:00:38,197 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:38,197 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:38,197 DEBUG __main__] Process content of EndNote file #139
{"title": "Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues", "url": "http://errare2015.racai.ro/pdf/Niculescu%20et%20Banchs.pdf", "author": [{"shortname": "AI Niculescu", "gid": "Iyyq8vMAAAAJ"}, {"shortname": "RE Banchs", "gid": "V5ou5AMAAAAJ"}], "year": 2015}
{"citedby": 4, "type": "Journal Article", "title": "Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues", "author": ["Niculescu, Andreea I", "Banchs, Rafael E"], "journal": "Proceedings of ERRARE, Sinaia, Romania", "year": "2015", "EndNote": "%0 Journal Article\n%T Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues\n%A Niculescu, Andreea I\n%A Banchs, Rafael E\n%J Proceedings of ERRARE, Sinaia, Romania\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:P--HpfLVQBEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MbF0TfdAPA8f5wKs0mir1XDVxSwn&scisf=3&ct=citation&cd=138&hl=en"}
[2018-03-02 15:00:38,197 DEBUG dbutils] Get paper id {"DOI": null, "title": "Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:00:38,197 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:00:38,197 DEBUG dbutils] Query result: []
[2018-03-02 15:00:38,197 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:38,197 DEBUG dbutils] Add new paper (title='Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues')
[2018-03-02 15:00:38,197 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Strategies to cope with errors in human-machine spoken interactions: using chatbots as back-off mechanism for task-oriented dialogues\n%A Niculescu, Andreea I\n%A Banchs, Rafael E\n%J Proceedings of ERRARE, Sinaia, Romania\n%D 2015\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:38,197 DEBUG dbutils] Query result: 129
[2018-03-02 15:00:38,199 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://errare2015.racai.ro/pdf/Niculescu%20et%20Banchs.pdf.
[2018-03-02 15:00:38,200 WARNING utils] Download file (url='http://errare2015.racai.ro/pdf/Niculescu%20et%20Banchs.pdf') and save (filename='PDF//129.pdf')
[2018-03-02 15:00:38,200 DEBUG utils] Get current proxy for errare2015.racai.ro.
[2018-03-02 15:00:38,200 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:00:38,200 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for otherhost
[2018-03-02 15:00:38,217 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): errare2015.racai.ro
[2018-03-02 15:00:38,715 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/Niculescu%20et%20Banchs.pdf HTTP/1.1" 200 170657
[2018-03-02 15:00:38,716 DEBUG utils] Content-length=170657
[2018-03-02 15:00:38,717 DEBUG utils] Create file PDF//129.pdf, start download.
[2018-03-02 15:00:39,402 DEBUG utils] End download file PDF//129.pdf.
[2018-03-02 15:00:39,404 DEBUG dbutils] Update pdf_transaction for paper id=129.
[2018-03-02 15:00:39,404 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 129'
[2018-03-02 15:00:39,405 DEBUG dbutils] Query result: null
[2018-03-02 15:00:39,405 DEBUG scholar] Handle paper #140 (total 1170)
[2018-03-02 15:00:39,405 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:00:39,408 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:39,408 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:00:39,686 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:K4Si5GRp3XMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MRXL6TJI4qpGWkPdQeOAItIBxrqG&scisf=3&ct=citation&cd=139&hl=en HTTP/1.1" 200 183
[2018-03-02 15:00:39,686 DEBUG scholar] EndNote file:
%0 Journal Article
%T Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.
%A Boiano, Stefania
%A Gaia, Giuliano
%A Caldarini, Morgana
%D 2003
%I ERIC

[2018-03-02 15:00:39,686 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:39,686 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:39,687 DEBUG __main__] Process content of EndNote file #140
{"title": "Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.", "url": "https://eric.ed.gov/?id=ED482150", "author": [{"shortname": "S Boiano", "gid": "nWbM1V4AAAAJ"}, {"shortname": "G Gaia", "gid": "tjUQUIIAAAAJ"}, {"shortname": "M Caldarini", "gid": ""}], "year": 2003}
{"citedby": 1, "type": "Journal Article", "title": "Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.", "author": ["Boiano, Stefania", "Gaia, Giuliano", "Caldarini, Morgana"], "year": "2003", "publisher": "ERIC", "EndNote": "%0 Journal Article\n%T Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.\n%A Boiano, Stefania\n%A Gaia, Giuliano\n%A Caldarini, Morgana\n%D 2003\n%I ERIC\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:K4Si5GRp3XMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_MRXL6TJI4qpGWkPdQeOAItIBxrqG&scisf=3&ct=citation&cd=139&hl=en"}
[2018-03-02 15:00:39,687 DEBUG dbutils] Get paper id {"DOI": null, "title": "Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2003, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:00:39,687 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2003, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:00:39,687 DEBUG dbutils] Query result: []
[2018-03-02 15:00:39,687 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:39,687 DEBUG dbutils] Add new paper (title='Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.')
[2018-03-02 15:00:39,687 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.', 'year': 2003, 'publisher': 'ERIC', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Make Your Museum Talk: Natural Language Interfaces for Cultural Institutions.\n%A Boiano, Stefania\n%A Gaia, Giuliano\n%A Caldarini, Morgana\n%D 2003\n%I ERIC\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:39,687 DEBUG dbutils] Query result: 130
[2018-03-02 15:00:39,689 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://files.eric.ed.gov/fulltext/ED482150.pdf.
[2018-03-02 15:00:39,689 WARNING utils] Download file (url='https://files.eric.ed.gov/fulltext/ED482150.pdf') and save (filename='PDF//130.pdf')
[2018-03-02 15:00:39,690 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 15:00:39,690 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:00:39,708 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 15:00:42,646 DEBUG requests.packages.urllib3.connectionpool] "GET /fulltext/ED482150.pdf HTTP/1.1" 200 222846
[2018-03-02 15:00:42,646 DEBUG utils] Content-length=222846
[2018-03-02 15:00:42,647 DEBUG utils] Create file PDF//130.pdf, start download.
[2018-03-02 15:00:45,743 DEBUG utils] End download file PDF//130.pdf.
[2018-03-02 15:00:45,744 DEBUG dbutils] Update pdf_transaction for paper id=130.
[2018-03-02 15:00:45,744 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 130'
[2018-03-02 15:00:45,745 DEBUG dbutils] Query result: null
[2018-03-02 15:00:45,768 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:00:45,768 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:00:45,768 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:00:45,768 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for scholar.google.com
[2018-03-02 15:00:45,783 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:00:49,050 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=140&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:00:49,462 DEBUG scholar] Find papers on page #15 (max_google_papers = 300)
[2018-03-02 15:00:49,462 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:00:49,463 DEBUG scholar] Handle paper #141 (total 1170)
[2018-03-02 15:00:49,463 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:00:49,466 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:00:49,467 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:00:49,483 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:00:49,484 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:00:52,425 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:0L7lYxgM0SAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZ4OZsOgTZnlxUCyGfGBbPguGk0S&scisf=3&ct=citation&cd=140&hl=en HTTP/1.1" 200 273
[2018-03-02 15:00:52,426 DEBUG scholar] EndNote file:
%0 Journal Article
%T Natural language processing tools
%A Brunelle, Justin F
%A Boonthum-Denecke, Chutima
%J Cross-Disciplinary Advances in Applied Natural Language Processing: Issues and Approaches: Issues and Approaches
%P 9
%@ 1613504489
%D 2011
%I IGI Global

[2018-03-02 15:00:52,426 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:00:52,426 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:00:52,426 DEBUG __main__] Process content of EndNote file #141
{"title": "Natural language processing tools", "url": "https://books.google.com/books?hl=en&lr=&id=6aom9gQuWR8C&oi=fnd&pg=PA9&dq=Use+deep+learning+to+create+a+chatbot&ots=xerRtnVsqI&sig=A6w8UcQ01YYHHFQQ5M9X4KOcPGs", "author": [{"shortname": "JF Brunelle", "gid": "O_Fdci8AAAAJ"}, {"shortname": "C Boonthum", "gid": ""}], "year": 2011}
{"citedby": 3, "type": "Journal Article", "title": "Natural language processing tools", "author": ["Brunelle, Justin F", "Boonthum-Denecke, Chutima"], "journal": "Cross-Disciplinary Advances in Applied Natural Language Processing: Issues and Approaches: Issues and Approaches", "pages": "9", "isbn/issn": "1613504489", "year": "2011", "publisher": "IGI Global", "EndNote": "%0 Journal Article\n%T Natural language processing tools\n%A Brunelle, Justin F\n%A Boonthum-Denecke, Chutima\n%J Cross-Disciplinary Advances in Applied Natural Language Processing: Issues and Approaches: Issues and Approaches\n%P 9\n%@ 1613504489\n%D 2011\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:0L7lYxgM0SAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZ4OZsOgTZnlxUCyGfGBbPguGk0S&scisf=3&ct=citation&cd=140&hl=en"}
[2018-03-02 15:00:52,426 DEBUG dbutils] Get paper id {"DOI": null, "title": "Natural language processing tools", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:00:52,427 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Natural language processing tools', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:00:52,427 DEBUG dbutils] Query result: []
[2018-03-02 15:00:52,427 DEBUG dbutils] Paper id = None.
[2018-03-02 15:00:52,427 DEBUG dbutils] Add new paper (title='Natural language processing tools')
[2018-03-02 15:00:52,427 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Natural language processing tools', 'year': 2011, 'publisher': 'IGI Global', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Natural language processing tools\n%A Brunelle, Justin F\n%A Boonthum-Denecke, Chutima\n%J Cross-Disciplinary Advances in Applied Natural Language Processing: Issues and Approaches: Issues and Approaches\n%P 9\n%@ 1613504489\n%D 2011\n%I IGI Global\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:00:52,427 DEBUG dbutils] Query result: 131
[2018-03-02 15:00:52,429 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf.
[2018-03-02 15:00:52,431 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf') and save (filename='PDF//131.pdf')
[2018-03-02 15:00:52,431 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:00:52,431 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:00:52,431 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for otherhost
[2018-03-02 15:00:52,448 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:00:54,134 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:00:54,167 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:00:54,167 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for otherhost
[2018-03-02 15:00:54,169 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:00:54,169 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:00:54,184 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:00:57,585 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:00:57,586 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:00:57,586 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for otherhost
[2018-03-02 15:00:57,587 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:00:57,587 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:00:57,602 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:00:59,815 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:00:59,816 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:00:59,816 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for otherhost
[2018-03-02 15:00:59,817 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:00:59,818 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:00:59,834 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:02,754 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:02,755 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:02,755 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for otherhost
[2018-03-02 15:01:02,756 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:02,756 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:01:02,772 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:05,455 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:05,456 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:05,456 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for otherhost
[2018-03-02 15:01:05,457 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:05,457 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:01:05,471 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:10,766 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:01:10,766 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for otherhost
[2018-03-02 15:01:10,766 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:10,767 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:01:10,782 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:11,935 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:11,935 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:11,936 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for otherhost
[2018-03-02 15:01:11,937 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:11,937 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:01:11,952 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:13,295 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:13,296 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:13,296 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for otherhost
[2018-03-02 15:01:13,297 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:13,298 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:01:13,312 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:14,305 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:14,306 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:14,306 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for otherhost
[2018-03-02 15:01:14,307 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:14,307 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:01:14,323 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:15,595 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:15,595 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:15,596 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for otherhost
[2018-03-02 15:01:15,597 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:15,597 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:01:15,611 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:23,344 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:23,345 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:23,345 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for otherhost
[2018-03-02 15:01:23,347 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:23,347 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:01:23,361 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:26,044 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:26,045 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:26,045 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for otherhost
[2018-03-02 15:01:26,047 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:26,047 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:01:26,060 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:27,515 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:27,516 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:27,516 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for otherhost
[2018-03-02 15:01:27,517 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:27,517 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:01:27,532 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:28,774 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:28,776 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:28,776 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for otherhost
[2018-03-02 15:01:28,777 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:28,778 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:01:28,792 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:32,183 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:32,183 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:32,184 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for otherhost
[2018-03-02 15:01:32,185 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:32,185 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:01:32,202 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:33,974 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:33,975 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:33,975 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for otherhost
[2018-03-02 15:01:33,976 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:33,977 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:01:33,990 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:35,234 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:35,235 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:35,235 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for otherhost
[2018-03-02 15:01:35,237 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:35,237 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:01:35,252 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:36,104 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:36,105 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:36,105 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for otherhost
[2018-03-02 15:01:36,106 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:36,106 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:01:36,121 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:41,124 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770570C780>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770570C780>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770570C780>, 'Connection to 190.7.112.18 timed out. (connect timeout=5)'))

[2018-03-02 15:01:41,124 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for otherhost
[2018-03-02 15:01:41,124 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:01:41,124 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:01:41,140 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:01:42,594 DEBUG requests.packages.urllib3.connectionpool] "GET /bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf HTTP/1.1" 404 None
[2018-03-02 15:01:42,595 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:01:42,595 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for otherhost
[2018-03-02 15:01:42,598 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=6aom9gQuWR8C&oi=fnd&pg=PA9&dq=Use+deep+learning+to+create+a+chatbot&ots=xerRtnVsqI&sig=A6w8UcQ01YYHHFQQ5M9X4KOcPGs.
[2018-03-02 15:01:42,599 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=6aom9gQuWR8C&oi=fnd&pg=PA9&dq=Use+deep+learning+to+create+a+chatbot&ots=xerRtnVsqI&sig=A6w8UcQ01YYHHFQQ5M9X4KOcPGs.
[2018-03-02 15:01:42,617 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:01:42,873 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=6aom9gQuWR8C&oi=fnd&pg=PA9&dq=Use+deep+learning+to+create+a+chatbot&ots=xerRtnVsqI&sig=A6w8UcQ01YYHHFQQ5M9X4KOcPGs HTTP/1.1" 302 None
[2018-03-02 15:01:43,064 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:01:43,078 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:01:43,078 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:01:43,078 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for sci-hub.tw
[2018-03-02 15:01:43,254 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=6aom9gQuWR8C&oi=fnd&pg=PA9&dq=Use+deep+learning+to+create+a+chatbot&ots=xerRtnVsqI&sig=A6w8UcQ01YYHHFQQ5M9X4KOcPGs HTTP/1.1" 302 None
[2018-03-02 15:01:43,469 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:01:43,503 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:01:43,504 DEBUG scholar] Handle paper #142 (total 1170)
[2018-03-02 15:01:43,504 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:01:43,509 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:01:43,510 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:01:43,510 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for scholar.google.com
[2018-03-02 15:01:43,525 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:01:43,528 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:01:47,326 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5Ep4y1xRrIwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_je0u20fc-HWhAmMHESmrVzu6rLKp&scisf=3&ct=citation&cd=141&hl=en HTTP/1.1" 200 313
[2018-03-02 15:01:47,327 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Design of chatbot with 3D avatar, voice interface, and facial expression
%A Angga, P Antonius
%A Fachri, W Edwin
%A Elevanita, A
%A Agushinta, R Dewi
%B Science in Information Technology (ICSITech), 2015 International Conference on
%P 326-330
%@ 1479983861
%D 2015
%I IEEE

[2018-03-02 15:01:47,327 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:01:47,327 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:01:47,327 DEBUG __main__] Process content of EndNote file #142
{"title": "Design of chatbot with 3D avatar, voice interface, and facial expression", "url": "http://ieeexplore.ieee.org/abstract/document/7407826/", "author": [{"shortname": "PA Angga", "gid": ""}, {"shortname": "WE Fachri", "gid": ""}, {"shortname": "A Elevanita", "gid": ""}], "year": 2015}
{"citedby": 2, "type": "Conference Proceedings", "title": "Design of chatbot with 3D avatar, voice interface, and facial expression", "author": ["Angga, P Antonius", "Fachri, W Edwin", "Elevanita, A", "Agushinta, R Dewi"], "secondarytitle": "Science in Information Technology (ICSITech), 2015 International Conference on", "pages": "326-330", "isbn/issn": "1479983861", "year": "2015", "publisher": "IEEE", "start_page": 326, "end_page": 330, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T Design of chatbot with 3D avatar, voice interface, and facial expression\n%A Angga, P Antonius\n%A Fachri, W Edwin\n%A Elevanita, A\n%A Agushinta, R Dewi\n%B Science in Information Technology (ICSITech), 2015 International Conference on\n%P 326-330\n%@ 1479983861\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5Ep4y1xRrIwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_je0u20fc-HWhAmMHESmrVzu6rLKp&scisf=3&ct=citation&cd=141&hl=en"}
[2018-03-02 15:01:47,327 DEBUG dbutils] Get paper id {"DOI": null, "title": "Design of chatbot with 3D avatar, voice interface, and facial expression", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 5, "year": 2015, "rg_id": null, "start_page": 326, "end_page": 330}.
[2018-03-02 15:01:47,327 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Design of chatbot with 3D avatar, voice interface, and facial expression', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2015, 'rg_id': None, 'start_page': 326, 'end_page': 330}
[2018-03-02 15:01:47,327 DEBUG dbutils] Query result: []
[2018-03-02 15:01:47,328 DEBUG dbutils] Paper id = None.
[2018-03-02 15:01:47,328 DEBUG dbutils] Add new paper (title='Design of chatbot with 3D avatar, voice interface, and facial expression')
[2018-03-02 15:01:47,328 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Design of chatbot with 3D avatar, voice interface, and facial expression', 'year': 2015, 'publisher': 'IEEE', 'start_page': 326, 'end_page': 330, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Design of chatbot with 3D avatar, voice interface, and facial expression\n%A Angga, P Antonius\n%A Fachri, W Edwin\n%A Elevanita, A\n%A Agushinta, R Dewi\n%B Science in Information Technology (ICSITech), 2015 International Conference on\n%P 326-330\n%@ 1479983861\n%D 2015\n%I IEEE\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:01:47,328 DEBUG dbutils] Query result: 132
[2018-03-02 15:01:47,329 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7407826/.
[2018-03-02 15:01:47,330 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7407826/.
[2018-03-02 15:01:47,568 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7407826/ HTTP/1.1" 200 None
[2018-03-02 15:01:47,569 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:01:47,569 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:01:47,758 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7407826/ HTTP/1.1" 200 None
[2018-03-02 15:01:47,765 DEBUG scihub] URL for PDF: http://zeze.sci-hub.tw/b256824b7f8afc12406f333c6a34486b/angga2015.pdf?download=true.
[2018-03-02 15:01:47,765 WARNING utils] Download file (url='http://zeze.sci-hub.tw/b256824b7f8afc12406f333c6a34486b/angga2015.pdf?download=true') and save (filename='PDF//132.pdf')
[2018-03-02 15:01:47,780 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): zeze.sci-hub.tw
[2018-03-02 15:01:48,695 DEBUG requests.packages.urllib3.connectionpool] "GET /b256824b7f8afc12406f333c6a34486b/angga2015.pdf?download=true HTTP/1.1" 200 314845
[2018-03-02 15:01:48,696 DEBUG utils] Get current proxy for zeze.sci-hub.tw.
[2018-03-02 15:01:48,696 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:01:48,696 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for sci-hub.tw
[2018-03-02 15:01:48,713 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): zeze.sci-hub.tw
[2018-03-02 15:01:49,001 DEBUG requests.packages.urllib3.connectionpool] "GET /b256824b7f8afc12406f333c6a34486b/angga2015.pdf?download=true HTTP/1.1" 200 314845
[2018-03-02 15:01:49,002 DEBUG utils] Content-length=314845
[2018-03-02 15:01:49,002 DEBUG utils] Create file PDF//132.pdf, start download.
[2018-03-02 15:01:49,799 DEBUG utils] End download file PDF//132.pdf.
[2018-03-02 15:01:49,800 DEBUG dbutils] Update pdf_transaction for paper id=132.
[2018-03-02 15:01:49,800 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 132'
[2018-03-02 15:01:49,800 DEBUG dbutils] Query result: null
[2018-03-02 15:01:49,801 DEBUG scholar] Handle paper #143 (total 1170)
[2018-03-02 15:01:49,801 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:01:49,804 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:01:49,804 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:01:50,554 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AL_PtWU_WIkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jbIx56cADgJf-gYBBVH5-y6kONcX&scisf=3&ct=citation&cd=142&hl=en HTTP/1.1" 200 347
[2018-03-02 15:01:50,555 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Real-time speech emotion and sentiment recognition for interactive dialogue systems
%A Bertero, Dario
%A Siddique, Farhad Bin
%A Wu, Chien-Sheng
%A Wan, Yan
%A Chan, Ricky Ho Yin
%A Fung, Pascale
%B Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing
%P 1042-1047
%D 2016

[2018-03-02 15:01:50,555 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:01:50,556 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:01:50,556 DEBUG __main__] Process content of EndNote file #143
{"title": "Real-time speech emotion and sentiment recognition for interactive dialogue systems", "url": "http://www.aclweb.org/anthology/D16-1110", "author": [{"shortname": "D Bertero", "gid": "2FdcsZsAAAAJ"}, {"shortname": "FB Siddique", "gid": "2po4Y8UAAAAJ"}, {"shortname": "CS Wu", "gid": "1G4GV2EAAAAJ"}, {"shortname": "Y Wan", "gid": ""}], "year": 2016}
{"citedby": 5, "type": "Conference Proceedings", "title": "Real-time speech emotion and sentiment recognition for interactive dialogue systems", "author": ["Bertero, Dario", "Siddique, Farhad Bin", "Wu, Chien-Sheng", "Wan, Yan", "Chan, Ricky Ho Yin", "Fung, Pascale"], "secondarytitle": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing", "pages": "1042-1047", "year": "2016", "start_page": 1042, "end_page": 1047, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Real-time speech emotion and sentiment recognition for interactive dialogue systems\n%A Bertero, Dario\n%A Siddique, Farhad Bin\n%A Wu, Chien-Sheng\n%A Wan, Yan\n%A Chan, Ricky Ho Yin\n%A Fung, Pascale\n%B Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\n%P 1042-1047\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:AL_PtWU_WIkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jbIx56cADgJf-gYBBVH5-y6kONcX&scisf=3&ct=citation&cd=142&hl=en"}
[2018-03-02 15:01:50,556 DEBUG dbutils] Get paper id {"DOI": null, "title": "Real-time speech emotion and sentiment recognition for interactive dialogue systems", "auth_count": 6, "g_type": "Conference Proceedings", "pages": 6, "year": 2016, "rg_id": null, "start_page": 1042, "end_page": 1047}.
[2018-03-02 15:01:50,556 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Real-time speech emotion and sentiment recognition for interactive dialogue systems', 'auth_count': 6, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2016, 'rg_id': None, 'start_page': 1042, 'end_page': 1047}
[2018-03-02 15:01:50,556 DEBUG dbutils] Query result: []
[2018-03-02 15:01:50,556 DEBUG dbutils] Paper id = None.
[2018-03-02 15:01:50,556 DEBUG dbutils] Add new paper (title='Real-time speech emotion and sentiment recognition for interactive dialogue systems')
[2018-03-02 15:01:50,556 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Real-time speech emotion and sentiment recognition for interactive dialogue systems', 'year': 2016, 'publisher': None, 'start_page': 1042, 'end_page': 1047, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Real-time speech emotion and sentiment recognition for interactive dialogue systems\n%A Bertero, Dario\n%A Siddique, Farhad Bin\n%A Wu, Chien-Sheng\n%A Wan, Yan\n%A Chan, Ricky Ho Yin\n%A Fung, Pascale\n%B Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing\n%P 1042-1047\n%D 2016\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 15:01:50,557 DEBUG dbutils] Query result: 133
[2018-03-02 15:01:50,558 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/D16-1110.
[2018-03-02 15:01:50,559 WARNING utils] Download file (url='http://www.aclweb.org/anthology/D16-1110') and save (filename='PDF//133.pdf')
[2018-03-02 15:01:50,559 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:01:50,559 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:01:50,576 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 15:01:51,235 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/D16-1110 HTTP/1.1" 200 None
[2018-03-02 15:01:51,235 DEBUG utils] Downloading the entire file.
[2018-03-02 15:01:51,236 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:01:51,236 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:01:51,236 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for otherhost
[2018-03-02 15:01:51,251 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 15:01:52,174 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/D16-1110 HTTP/1.1" 200 None
[2018-03-02 15:01:53,879 DEBUG utils] Save file PDF//133.pdf.
[2018-03-02 15:01:53,881 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/D16-1110.
[2018-03-02 15:01:53,881 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/D16-1110.
[2018-03-02 15:01:54,094 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/D16-1110 HTTP/1.1" 302 None
[2018-03-02 15:01:54,444 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/D16-1110 HTTP/1.1" 200 None
[2018-03-02 15:01:55,627 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:01:55,627 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:01:55,774 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/D16-1110 HTTP/1.1" 302 None
[2018-03-02 15:01:56,044 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/D16-1110 HTTP/1.1" 200 None
[2018-03-02 15:02:00,009 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:02:00,010 DEBUG scholar] Handle paper #144 (total 1170)
[2018-03-02 15:02:00,010 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:02:00,013 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:00,013 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:02:00,014 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for scholar.google.com
[2018-03-02 15:02:00,030 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:02:00,031 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:02:03,264 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:F-Yj_xo6eZcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jbZ2V6a7IB-0xzi52IiI8e78o3Z-&scisf=3&ct=citation&cd=143&hl=en HTTP/1.1" 200 207
[2018-03-02 15:02:03,265 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.
%A Boiano, Stefania
%A Cuomo, Pietro
%A Gaia, Giuliano
%B EVA
%D 2016

[2018-03-02 15:02:03,265 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:02:03,265 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:02:03,265 DEBUG __main__] Process content of EndNote file #144
{"title": "Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.", "url": "https://www.researchgate.net/profile/Giuliano_Gaia/publication/305315721_Real-time_Messaging_Platforms_for_Storytelling_and_Gamification_in_Museums_A_Case_History_in_Milan/links/58401b5708ae2d21755ec30b/Real-time-Messaging-Platforms-for-Storytelling-and-Gamification-in-Museums-A-Case-History-in-Milan.pdf", "author": [{"shortname": "S Boiano", "gid": "nWbM1V4AAAAJ"}, {"shortname": "P Cuomo", "gid": ""}, {"shortname": "G Gaia", "gid": "tjUQUIIAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.", "author": ["Boiano, Stefania", "Cuomo, Pietro", "Gaia, Giuliano"], "secondarytitle": "EVA", "year": "2016", "EndNote": "%0 Conference Proceedings\n%T Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.\n%A Boiano, Stefania\n%A Cuomo, Pietro\n%A Gaia, Giuliano\n%B EVA\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:F-Yj_xo6eZcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jbZ2V6a7IB-0xzi52IiI8e78o3Z-&scisf=3&ct=citation&cd=143&hl=en"}
[2018-03-02 15:02:03,265 DEBUG dbutils] Get paper id {"DOI": null, "title": "Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.", "auth_count": 3, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:02:03,266 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:02:03,266 DEBUG dbutils] Query result: []
[2018-03-02 15:02:03,266 DEBUG dbutils] Paper id = None.
[2018-03-02 15:02:03,266 DEBUG dbutils] Add new paper (title='Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.')
[2018-03-02 15:02:03,266 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Real-time Messaging Platforms for Storytelling and Gamification in Museums: A case history in Milan.\n%A Boiano, Stefania\n%A Cuomo, Pietro\n%A Gaia, Giuliano\n%B EVA\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:02:03,266 DEBUG dbutils] Query result: 134
[2018-03-02 15:02:03,268 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Giuliano_Gaia/publication/305315721_Real-time_Messaging_Platforms_for_Storytelling_and_Gamification_in_Museums_A_Case_History_in_Milan/links/58401b5708ae2d21755ec30b/Real-time-Messaging-Platforms-for-Storytelling-and-Gamification-in-Museums-A-Case-History-in-Milan.pdf.
[2018-03-02 15:02:03,269 WARNING utils] Download file (url='https://www.researchgate.net/profile/Giuliano_Gaia/publication/305315721_Real-time_Messaging_Platforms_for_Storytelling_and_Gamification_in_Museums_A_Case_History_in_Milan/links/58401b5708ae2d21755ec30b/Real-time-Messaging-Platforms-for-Storytelling-and-Gamification-in-Museums-A-Case-History-in-Milan.pdf') and save (filename='PDF//134.pdf')
[2018-03-02 15:02:03,269 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:02:03,269 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:02:03,287 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.researchgate.net
[2018-03-02 15:02:03,288 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.researchgate.net
[2018-03-02 15:02:05,110 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Giuliano_Gaia/publication/305315721_Real-time_Messaging_Platforms_for_Storytelling_and_Gamification_in_Museums_A_Case_History_in_Milan/links/58401b5708ae2d21755ec30b/Real-time-Messaging-Platforms-for-Storytelling-and-Gamification-in-Museums-A-Case-History-in-Milan.pdf HTTP/1.1" 200 199823
[2018-03-02 15:02:05,111 DEBUG utils] Content-length=199823
[2018-03-02 15:02:05,111 DEBUG utils] Create file PDF//134.pdf, start download.
[2018-03-02 15:02:05,725 DEBUG utils] End download file PDF//134.pdf.
[2018-03-02 15:02:05,726 DEBUG dbutils] Update pdf_transaction for paper id=134.
[2018-03-02 15:02:05,726 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 134'
[2018-03-02 15:02:05,726 DEBUG dbutils] Query result: null
[2018-03-02 15:02:05,727 DEBUG scholar] Handle paper #145 (total 1170)
[2018-03-02 15:02:05,727 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:02:05,729 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:05,730 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:02:06,274 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4a3R_wOyM58J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jdxug4BM4KLFl9o_uS6T7X3ib1vx&scisf=3&ct=citation&cd=144&hl=en HTTP/1.1" 200 170
[2018-03-02 15:02:06,275 DEBUG scholar] EndNote file:
%0 Journal Article
%T Topic augmented neural network for short text conversation
%A Wu, Yu
%A Wu, Wei
%A Li, Zhoujun
%A Zhou, Ming
%J CoRR abs/1605.00090
%D 2016

[2018-03-02 15:02:06,275 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:02:06,275 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:02:06,275 DEBUG __main__] Process content of EndNote file #145
{"title": "Topic augmented neural network for short text conversation", "url": "https://pdfs.semanticscholar.org/6d18/ab89181c24385f6d1f0fcccd7d2e54ed400c.pdf", "author": [{"shortname": "Y Wu", "gid": "aQizmzsAAAAJ"}, {"shortname": "W Wu", "gid": "YtqXSzMAAAAJ"}, {"shortname": "Z Li", "gid": ""}, {"shortname": "M Zhou", "gid": ""}], "year": 1605}
{"citedby": 2, "type": "Journal Article", "title": "Topic augmented neural network for short text conversation", "author": ["Wu, Yu", "Wu, Wei", "Li, Zhoujun", "Zhou, Ming"], "journal": "CoRR abs/1605.00090", "year": "2016", "EndNote": "%0 Journal Article\n%T Topic augmented neural network for short text conversation\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J CoRR abs/1605.00090\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4a3R_wOyM58J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jdxug4BM4KLFl9o_uS6T7X3ib1vx&scisf=3&ct=citation&cd=144&hl=en"}
[2018-03-02 15:02:06,275 DEBUG dbutils] Get paper id {"DOI": null, "title": "Topic augmented neural network for short text conversation", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:02:06,275 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Topic augmented neural network for short text conversation', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:02:06,276 DEBUG dbutils] Query result: []
[2018-03-02 15:02:06,276 DEBUG dbutils] Paper id = None.
[2018-03-02 15:02:06,276 DEBUG dbutils] Add new paper (title='Topic augmented neural network for short text conversation')
[2018-03-02 15:02:06,276 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Topic augmented neural network for short text conversation', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Topic augmented neural network for short text conversation\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J CoRR abs/1605.00090\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:02:06,276 DEBUG dbutils] Query result: 135
[2018-03-02 15:02:06,277 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/6d18/ab89181c24385f6d1f0fcccd7d2e54ed400c.pdf.
[2018-03-02 15:02:06,277 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/6d18/ab89181c24385f6d1f0fcccd7d2e54ed400c.pdf') and save (filename='PDF//135.pdf')
[2018-03-02 15:02:06,278 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:02:06,278 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:02:06,295 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:02:08,006 DEBUG requests.packages.urllib3.connectionpool] "GET /6d18/ab89181c24385f6d1f0fcccd7d2e54ed400c.pdf HTTP/1.1" 200 645638
[2018-03-02 15:02:08,007 DEBUG utils] Content-length=645638
[2018-03-02 15:02:08,007 DEBUG utils] Create file PDF//135.pdf, start download.
[2018-03-02 15:02:09,882 DEBUG utils] End download file PDF//135.pdf.
[2018-03-02 15:02:09,883 DEBUG dbutils] Update pdf_transaction for paper id=135.
[2018-03-02 15:02:09,883 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 135'
[2018-03-02 15:02:09,883 DEBUG dbutils] Query result: null
[2018-03-02 15:02:09,884 DEBUG scholar] Handle paper #146 (total 1170)
[2018-03-02 15:02:09,884 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:02:09,887 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:09,887 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:02:09,887 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for scholar.google.com
[2018-03-02 15:02:09,904 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:02:09,905 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:02:12,704 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kKbKco7OEIsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jUxt_HQzdqV0DzZURj2RkdvNvAEN&scisf=3&ct=citation&cd=145&hl=en HTTP/1.1" 200 223
[2018-03-02 15:02:12,705 DEBUG scholar] EndNote file:
%0 Book
%T Innovating Language Education: An NMC Horizon Project Strategic Brief
%A Becker, Samantha Adams
%A Rodriguez, Julio C
%A Estrada, Victoria
%A Davis, Ann
%@ 0997259957
%D 2016
%I The New Media Consortium

[2018-03-02 15:02:12,705 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:02:12,705 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:02:12,705 DEBUG __main__] Process content of EndNote file #146
{"title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "url": "https://www.learntechlib.org/p/171514/", "author": [{"shortname": "SA Becker", "gid": ""}, {"shortname": "JC Rodriguez", "gid": ""}, {"shortname": "V Estrada", "gid": ""}, {"shortname": "A Davis", "gid": "HLk684EAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Book", "title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "author": ["Becker, Samantha Adams", "Rodriguez, Julio C", "Estrada, Victoria", "Davis, Ann"], "isbn/issn": "0997259957", "year": "2016", "publisher": "The New Media Consortium", "EndNote": "%0 Book\n%T Innovating Language Education: An NMC Horizon Project Strategic Brief\n%A Becker, Samantha Adams\n%A Rodriguez, Julio C\n%A Estrada, Victoria\n%A Davis, Ann\n%@ 0997259957\n%D 2016\n%I The New Media Consortium\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kKbKco7OEIsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jUxt_HQzdqV0DzZURj2RkdvNvAEN&scisf=3&ct=citation&cd=145&hl=en"}
[2018-03-02 15:02:12,705 DEBUG dbutils] Get paper id {"DOI": null, "title": "Innovating Language Education: An NMC Horizon Project Strategic Brief", "auth_count": 4, "g_type": "Book", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:02:12,705 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Innovating Language Education: An NMC Horizon Project Strategic Brief', 'auth_count': 4, 'g_type': 'Book', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:02:12,705 DEBUG dbutils] Query result: []
[2018-03-02 15:02:12,705 DEBUG dbutils] Paper id = None.
[2018-03-02 15:02:12,706 DEBUG dbutils] Add new paper (title='Innovating Language Education: An NMC Horizon Project Strategic Brief')
[2018-03-02 15:02:12,706 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Innovating Language Education: An NMC Horizon Project Strategic Brief', 'year': 2016, 'publisher': 'The New Media Consortium', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Innovating Language Education: An NMC Horizon Project Strategic Brief\n%A Becker, Samantha Adams\n%A Rodriguez, Julio C\n%A Estrada, Victoria\n%A Davis, Ann\n%@ 0997259957\n%D 2016\n%I The New Media Consortium\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:02:12,706 DEBUG dbutils] Query result: 136
[2018-03-02 15:02:12,707 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/171514/report_171514.pdf.
[2018-03-02 15:02:12,708 WARNING utils] Download file (url='https://www.learntechlib.org/p/171514/report_171514.pdf') and save (filename='PDF//136.pdf')
[2018-03-02 15:02:12,708 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 15:02:12,709 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:02:12,709 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for otherhost
[2018-03-02 15:02:12,724 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 15:02:17,340 DEBUG requests.packages.urllib3.connectionpool] "GET /p/171514/report_171514.pdf HTTP/1.1" 200 None
[2018-03-02 15:02:17,341 DEBUG utils] Downloading the entire file.
[2018-03-02 15:02:17,341 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 15:02:17,341 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:02:17,356 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.learntechlib.org
[2018-03-02 15:02:20,820 DEBUG requests.packages.urllib3.connectionpool] "GET /p/171514/report_171514.pdf HTTP/1.1" 200 None
[2018-03-02 15:02:27,735 DEBUG utils] Save file PDF//136.pdf.
[2018-03-02 15:02:27,738 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/171514/.
[2018-03-02 15:02:27,738 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/171514/.
[2018-03-02 15:02:27,983 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/171514/ HTTP/1.1" 302 None
[2018-03-02 15:02:28,007 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.learntechlib.org
[2018-03-02 15:02:28,966 DEBUG requests.packages.urllib3.connectionpool] "GET /p/171514/ HTTP/1.1" 200 17403
[2018-03-02 15:02:28,967 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:02:28,968 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:02:28,968 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for sci-hub.tw
[2018-03-02 15:02:29,183 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/171514/ HTTP/1.1" 302 None
[2018-03-02 15:02:29,205 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 15:02:30,572 DEBUG requests.packages.urllib3.connectionpool] "GET /p/171514/ HTTP/1.1" 200 15652
[2018-03-02 15:02:30,661 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:02:30,662 DEBUG scholar] Handle paper #147 (total 1170)
[2018-03-02 15:02:30,662 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:02:30,668 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:30,668 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:02:31,164 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:zM-tFg7QR8cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jStxo1vkCetw9khnb3RxxiCMChBq&scisf=3&ct=citation&cd=146&hl=en HTTP/1.1" 200 185
[2018-03-02 15:02:31,165 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatbots in the library: is it time?
%A Allison, DeeAnn
%J Library Hi Tech
%V 30
%N 1
%P 95-107
%@ 0737-8831
%D 2012
%I Emerald Group Publishing Limited

[2018-03-02 15:02:31,165 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:02:31,165 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:02:31,165 DEBUG __main__] Process content of EndNote file #147
{"title": "Chatbots in the library: is it time?", "url": "http://www.emeraldinsight.com/doi/abs/10.1108/07378831211213238", "author": [{"shortname": "DA Allison", "gid": "7rW0N9YAAAAJ"}], "year": 2012}
{"citedby": 14, "type": "Journal Article", "title": "Chatbots in the library: is it time?", "author": ["Allison, DeeAnn"], "journal": "Library Hi Tech", "volume": 13, "numberorissue": "1", "pages": "95-107", "isbn/issn": "0737-8831", "year": "2012", "publisher": "Emerald Group Publishing Limited", "start_page": 95, "end_page": 107, "EndNote": "%0 Journal Article\n%T Chatbots in the library: is it time?\n%A Allison, DeeAnn\n%J Library Hi Tech\n%V 30\n%N 1\n%P 95-107\n%@ 0737-8831\n%D 2012\n%I Emerald Group Publishing Limited\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:zM-tFg7QR8cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jStxo1vkCetw9khnb3RxxiCMChBq&scisf=3&ct=citation&cd=146&hl=en"}
[2018-03-02 15:02:31,165 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots in the library: is it time?", "auth_count": 1, "g_type": "Journal Article", "pages": 13, "year": 2012, "rg_id": null, "start_page": 95, "end_page": 107}.
[2018-03-02 15:02:31,165 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbots in the library: is it time?', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 13, 'year': 2012, 'rg_id': None, 'start_page': 95, 'end_page': 107}
[2018-03-02 15:02:31,166 DEBUG dbutils] Query result: []
[2018-03-02 15:02:31,166 DEBUG dbutils] Paper id = None.
[2018-03-02 15:02:31,166 DEBUG dbutils] Add new paper (title='Chatbots in the library: is it time?')
[2018-03-02 15:02:31,166 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbots in the library: is it time?', 'year': 2012, 'publisher': 'Emerald Group Publishing Limited', 'start_page': 95, 'end_page': 107, 'pages': 13, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Chatbots in the library: is it time?\n%A Allison, DeeAnn\n%J Library Hi Tech\n%V 30\n%N 1\n%P 95-107\n%@ 0737-8831\n%D 2012\n%I Emerald Group Publishing Limited\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:02:31,166 DEBUG dbutils] Query result: 137
[2018-03-02 15:02:31,167 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1294&context=libraryscience.
[2018-03-02 15:02:31,168 WARNING utils] Download file (url='http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1294&context=libraryscience') and save (filename='PDF//137.pdf')
[2018-03-02 15:02:31,168 DEBUG utils] Get current proxy for digitalcommons.unl.edu.
[2018-03-02 15:02:31,168 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:02:31,169 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for otherhost
[2018-03-02 15:02:31,187 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): digitalcommons.unl.edu
[2018-03-02 15:02:32,053 DEBUG requests.packages.urllib3.connectionpool] "GET /cgi/viewcontent.cgi?article=1294&context=libraryscience HTTP/1.1" 302 None
[2018-03-02 15:02:32,075 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): digitalcommons.unl.edu
[2018-03-02 15:02:36,324 DEBUG requests.packages.urllib3.connectionpool] "GET /cgi/viewcontent.cgi?referer=&httpsredir=1&article=1294&context=libraryscience HTTP/1.1" 200 393756
[2018-03-02 15:02:36,325 DEBUG utils] Content-length=393756
[2018-03-02 15:02:36,326 DEBUG utils] Create file PDF//137.pdf, start download.
[2018-03-02 15:02:54,931 DEBUG utils] End download file PDF//137.pdf.
[2018-03-02 15:02:54,933 DEBUG dbutils] Update pdf_transaction for paper id=137.
[2018-03-02 15:02:54,933 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 137'
[2018-03-02 15:02:54,933 DEBUG dbutils] Query result: null
[2018-03-02 15:02:54,933 DEBUG scholar] Handle paper #148 (total 1170)
[2018-03-02 15:02:54,934 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:02:54,937 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:54,937 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:02:54,937 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for scholar.google.com
[2018-03-02 15:02:54,954 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:02:59,957 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000077040706D8>, 'Connection to 72.10.162.250 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000077040706D8>, 'Connection to 72.10.162.250 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x00000077040706D8>, 'Connection to 72.10.162.250 timed out. (connect timeout=5)'))

[2018-03-02 15:02:59,957 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for scholar.google.com
[2018-03-02 15:02:59,957 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:02:59,957 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:02:59,972 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:00,254 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:03:00,254 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for scholar.google.com
[2018-03-02 15:03:00,254 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:00,254 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:03:00,270 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:03:00,271 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:04,282 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en HTTP/1.1" 200 232
[2018-03-02 15:03:04,283 DEBUG scholar] EndNote file:
%0 Book Section
%T Application of the Multiple Perspectives Model in an Undergraduate Course
%A Marques, Celio Goncalo
%A Carvalho, Ana Amelia A
%B Key competencies in the knowledge society
%P 269-280
%D 2010
%I Springer

[2018-03-02 15:03:04,283 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:04,283 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:04,284 DEBUG __main__] Process content of EndNote file #148
{"title": "Application of the Multiple Perspectives Model in an Undergraduate Course", "url": "https://link.springer.com/chapter/10.1007/978-3-642-15378-5_26", "author": [{"shortname": "CG Marques", "gid": ""}, {"shortname": "AAA Carvalho", "gid": "_qjCA5sAAAAJ"}], "year": 2010}
{"citedby": 1, "type": "Book Section", "title": "Application of the Multiple Perspectives Model in an Undergraduate Course", "author": ["Marques, C\u00e9lio Gon\u00e7alo", "Carvalho, Ana Am\u00e9lia A"], "secondarytitle": "Key competencies in the knowledge society", "pages": "269-280", "year": "2010", "publisher": "Springer", "start_page": 269, "end_page": 280, "volume": 12, "EndNote": "%0 Book Section\n%T Application of the Multiple Perspectives Model in an Undergraduate Course\n%A Marques, C\u00e9lio Gon\u00e7alo\n%A Carvalho, Ana Am\u00e9lia A\n%B Key competencies in the knowledge society\n%P 269-280\n%D 2010\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:JNHtOC6Xg0AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jZPGCJwdW0XrkcpB3cks8s6wYO_V&scisf=3&ct=citation&cd=147&hl=en"}
[2018-03-02 15:03:04,284 DEBUG dbutils] Get paper id {"DOI": null, "title": "Application of the Multiple Perspectives Model in an Undergraduate Course", "auth_count": 2, "g_type": "Book Section", "pages": 12, "year": 2010, "rg_id": null, "start_page": 269, "end_page": 280}.
[2018-03-02 15:03:04,284 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Application of the Multiple Perspectives Model in an Undergraduate Course', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 12, 'year': 2010, 'rg_id': None, 'start_page': 269, 'end_page': 280}
[2018-03-02 15:03:04,284 DEBUG dbutils] Query result: []
[2018-03-02 15:03:04,284 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:04,284 DEBUG dbutils] Add new paper (title='Application of the Multiple Perspectives Model in an Undergraduate Course')
[2018-03-02 15:03:04,284 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Application of the Multiple Perspectives Model in an Undergraduate Course', 'year': 2010, 'publisher': 'Springer', 'start_page': 269, 'end_page': 280, 'pages': 12, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Application of the Multiple Perspectives Model in an Undergraduate Course\n%A Marques, Celio Goncalo\n%A Carvalho, Ana Amelia A\n%B Key competencies in the knowledge society\n%P 269-280\n%D 2010\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:04,284 DEBUG dbutils] Query result: 138
[2018-03-02 15:03:04,286 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://link.springer.com/content/pdf/10.1007/978-3-642-15378-5_26.pdf.
[2018-03-02 15:03:04,289 WARNING utils] Download file (url='https://link.springer.com/content/pdf/10.1007/978-3-642-15378-5_26.pdf') and save (filename='PDF//138.pdf')
[2018-03-02 15:03:04,289 DEBUG utils] Get current proxy for link.springer.com.
[2018-03-02 15:03:04,289 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:03:04,305 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): link.springer.com
[2018-03-02 15:03:08,440 DEBUG requests.packages.urllib3.connectionpool] "GET /content/pdf/10.1007/978-3-642-15378-5_26.pdf HTTP/1.1" 200 223215
[2018-03-02 15:03:08,440 DEBUG utils] Content-length=223215
[2018-03-02 15:03:08,441 DEBUG utils] Create file PDF//138.pdf, start download.
[2018-03-02 15:03:19,728 DEBUG utils] End download file PDF//138.pdf.
[2018-03-02 15:03:19,730 DEBUG dbutils] Update pdf_transaction for paper id=138.
[2018-03-02 15:03:19,730 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 138'
[2018-03-02 15:03:19,730 DEBUG dbutils] Query result: null
[2018-03-02 15:03:19,730 DEBUG scholar] Handle paper #149 (total 1170)
[2018-03-02 15:03:19,731 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:03:19,734 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:19,734 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:03:19,735 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for scholar.google.com
[2018-03-02 15:03:24,754 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1002, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 865, in read
    return self._sslobj.read(len, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 625, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Read timed out. (read timeout=5)

[2018-03-02 15:03:24,754 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for scholar.google.com
[2018-03-02 15:03:24,754 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:24,754 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:03:24,769 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:03:24,772 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:26,541 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:gO4BfTH0Z_YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jT--nDmGb77WTuHMovlnnL0BeZaY&scisf=3&ct=citation&cd=148&hl=en HTTP/1.1" 200 255
[2018-03-02 15:03:26,542 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Arabic question-answering via instance based learning from an FAQ corpus
%A Abu Shawar, B
%A Atwell, ES
%B Proceedings of the CL2009 International Conference on Corpus Linguistics
%D 2009
%I UCREL, Lancaster University

[2018-03-02 15:03:26,542 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:26,542 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:26,542 DEBUG __main__] Process content of EndNote file #149
{"title": "Arabic question-answering via instance based learning from an FAQ corpus", "url": "http://eprints.whiterose.ac.uk/82302/", "author": [{"shortname": "B Abu Shawar", "gid": ""}, {"shortname": "ES Atwell", "gid": "Iu5WFskAAAAJ"}], "year": 2009}
{"citedby": 1, "type": "Conference Proceedings", "title": "Arabic question-answering via instance based learning from an FAQ corpus", "author": ["Abu Shawar, B", "Atwell, ES"], "secondarytitle": "Proceedings of the CL2009 International Conference on Corpus Linguistics", "year": "2009", "publisher": "UCREL, Lancaster University", "EndNote": "%0 Conference Proceedings\n%T Arabic question-answering via instance based learning from an FAQ corpus\n%A Abu Shawar, B\n%A Atwell, ES\n%B Proceedings of the CL2009 International Conference on Corpus Linguistics\n%D 2009\n%I UCREL, Lancaster University\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:gO4BfTH0Z_YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jT--nDmGb77WTuHMovlnnL0BeZaY&scisf=3&ct=citation&cd=148&hl=en"}
[2018-03-02 15:03:26,542 DEBUG dbutils] Get paper id {"DOI": null, "title": "Arabic question-answering via instance based learning from an FAQ corpus", "auth_count": 2, "g_type": "Conference Proceedings", "pages": null, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:03:26,542 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Arabic question-answering via instance based learning from an FAQ corpus', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:03:26,543 DEBUG dbutils] Query result: []
[2018-03-02 15:03:26,543 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:26,543 DEBUG dbutils] Add new paper (title='Arabic question-answering via instance based learning from an FAQ corpus')
[2018-03-02 15:03:26,543 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Arabic question-answering via instance based learning from an FAQ corpus', 'year': 2009, 'publisher': 'UCREL, Lancaster University', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Arabic question-answering via instance based learning from an FAQ corpus\n%A Abu Shawar, B\n%A Atwell, ES\n%B Proceedings of the CL2009 International Conference on Corpus Linguistics\n%D 2009\n%I UCREL, Lancaster University\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:26,543 DEBUG dbutils] Query result: 139
[2018-03-02 15:03:26,544 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://eprints.whiterose.ac.uk/82302/1/ArabicQuestionAnswering.pdf.
[2018-03-02 15:03:26,545 WARNING utils] Download file (url='http://eprints.whiterose.ac.uk/82302/1/ArabicQuestionAnswering.pdf') and save (filename='PDF//139.pdf')
[2018-03-02 15:03:26,546 DEBUG utils] Get current proxy for eprints.whiterose.ac.uk.
[2018-03-02 15:03:26,546 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:03:26,546 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for otherhost
[2018-03-02 15:03:26,564 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): eprints.whiterose.ac.uk
[2018-03-02 15:03:27,432 DEBUG requests.packages.urllib3.connectionpool] "GET /82302/1/ArabicQuestionAnswering.pdf HTTP/1.1" 200 311997
[2018-03-02 15:03:27,432 DEBUG utils] Content-length=311997
[2018-03-02 15:03:27,433 DEBUG utils] Create file PDF//139.pdf, start download.
[2018-03-02 15:03:34,784 DEBUG utils] End download file PDF//139.pdf.
[2018-03-02 15:03:34,786 DEBUG dbutils] Update pdf_transaction for paper id=139.
[2018-03-02 15:03:34,786 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 139'
[2018-03-02 15:03:34,786 DEBUG dbutils] Query result: null
[2018-03-02 15:03:34,787 DEBUG scholar] Handle paper #150 (total 1170)
[2018-03-02 15:03:34,787 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:03:34,792 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:34,793 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:03:34,793 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for scholar.google.com
[2018-03-02 15:03:34,819 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:03:34,821 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:38,982 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:jThftMJJ-gcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jYfMw8WojSYZmBHdxi1DkYlZUgM5&scisf=3&ct=citation&cd=149&hl=en HTTP/1.1" 200 217
[2018-03-02 15:03:38,983 DEBUG scholar] EndNote file:
%0 Book Section
%T Chatbots as interface to ontologies
%A Augello, Agnese
%A Pilato, Giovanni
%A Vassallo, Giorgio
%A Gaglio, Salvatore
%B Advances onto the Internet of Things
%P 285-299
%D 2014
%I Springer

[2018-03-02 15:03:38,983 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:38,983 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:38,983 DEBUG __main__] Process content of EndNote file #150
{"title": "Chatbots as interface to ontologies", "url": "https://link.springer.com/chapter/10.1007/978-3-319-03992-3_20", "author": [{"shortname": "A Augello", "gid": "vPJnw0AAAAAJ"}, {"shortname": "G Pilato", "gid": "fAPQPiUAAAAJ"}, {"shortname": "G Vassallo", "gid": "7gEeTNYAAAAJ"}, {"shortname": "S Gaglio", "gid": "UcUoEdAAAAAJ"}], "year": 2014}
{"citedby": 7, "type": "Book Section", "title": "Chatbots as interface to ontologies", "author": ["Augello, Agnese", "Pilato, Giovanni", "Vassallo, Giorgio", "Gaglio, Salvatore"], "secondarytitle": "Advances onto the Internet of Things", "pages": "285-299", "year": "2014", "publisher": "Springer", "start_page": 285, "end_page": 299, "volume": 15, "EndNote": "%0 Book Section\n%T Chatbots as interface to ontologies\n%A Augello, Agnese\n%A Pilato, Giovanni\n%A Vassallo, Giorgio\n%A Gaglio, Salvatore\n%B Advances onto the Internet of Things\n%P 285-299\n%D 2014\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:jThftMJJ-gcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWpk_jYfMw8WojSYZmBHdxi1DkYlZUgM5&scisf=3&ct=citation&cd=149&hl=en"}
[2018-03-02 15:03:38,984 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots as interface to ontologies", "auth_count": 4, "g_type": "Book Section", "pages": 15, "year": 2014, "rg_id": null, "start_page": 285, "end_page": 299}.
[2018-03-02 15:03:38,984 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbots as interface to ontologies', 'auth_count': 4, 'g_type': 'Book Section', 'pages': 15, 'year': 2014, 'rg_id': None, 'start_page': 285, 'end_page': 299}
[2018-03-02 15:03:38,984 DEBUG dbutils] Query result: []
[2018-03-02 15:03:38,984 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:38,984 DEBUG dbutils] Add new paper (title='Chatbots as interface to ontologies')
[2018-03-02 15:03:38,984 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbots as interface to ontologies', 'year': 2014, 'publisher': 'Springer', 'start_page': 285, 'end_page': 299, 'pages': 15, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Chatbots as interface to ontologies\n%A Augello, Agnese\n%A Pilato, Giovanni\n%A Vassallo, Giorgio\n%A Gaglio, Salvatore\n%B Advances onto the Internet of Things\n%P 285-299\n%D 2014\n%I Springer\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:38,984 DEBUG dbutils] Query result: 140
[2018-03-02 15:03:38,986 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-03992-3_20.
[2018-03-02 15:03:38,986 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-03992-3_20.
[2018-03-02 15:03:39,001 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:03:39,302 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-03992-3_20 HTTP/1.1" 302 None
[2018-03-02 15:03:39,325 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 15:03:39,713 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=60A9B0631C3A0854099F71EE028996FF HTTP/1.1" 200 10276
[2018-03-02 15:03:39,803 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:03:39,803 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:03:39,992 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-03992-3_20 HTTP/1.1" 302 None
[2018-03-02 15:03:40,253 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=60A9B0631C3A0854099F71EE028996FF HTTP/1.1" 200 10276
[2018-03-02 15:03:40,526 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:03:40,526 DEBUG dbutils] Commiting transaction 150.
[2018-03-02 15:03:40,676 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:03:40,676 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:03:40,676 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:03:40,692 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:03:45,022 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=150&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:03:46,706 DEBUG scholar] Find papers on page #16 (max_google_papers = 300)
[2018-03-02 15:03:46,706 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:03:46,706 DEBUG scholar] Handle paper #151 (total 1170)
[2018-03-02 15:03:46,707 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:03:46,710 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:46,710 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:03:46,711 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for scholar.google.com
[2018-03-02 15:03:46,726 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:03:46,729 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:50,032 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:UkvNQfl4xoUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPQ37jO2SXXgm-_zsL-uhOdrzrGPG&scisf=3&ct=citation&cd=150&hl=en HTTP/1.1" 200 105
[2018-03-02 15:03:50,033 DEBUG scholar] EndNote file:
%0 Thesis
%T Using the Web to Model Modern and Quranic Arabic
%A Atwell, Eric
%I University of LEEDS

[2018-03-02 15:03:50,033 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:50,033 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:50,033 DEBUG __main__] Skip paper #151, empty year or authors fields.
[2018-03-02 15:03:50,034 DEBUG scholar] Handle paper #152 (total 1170)
[2018-03-02 15:03:50,034 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:03:50,037 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:50,037 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:03:50,431 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:v70r4rTBaQkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTsY3DCaSmCP21Ql2KBMqzerXhA7&scisf=3&ct=citation&cd=151&hl=en HTTP/1.1" 200 287
[2018-03-02 15:03:50,432 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Chatbots of the gods: imaginary abstracts for techno-spirituality research
%A Blythe, Mark
%A Buie, Elizabeth
%B Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational
%P 227-236
%@ 1450325424
%D 2014
%I ACM

[2018-03-02 15:03:50,432 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:50,432 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:50,432 DEBUG __main__] Process content of EndNote file #152
{"title": "Chatbots of the gods: imaginary abstracts for techno-spirituality research", "url": "https://dl.acm.org/citation.cfm?id=2641212", "author": [{"shortname": "M Blythe", "gid": "Zu2ayvcAAAAJ"}, {"shortname": "E Buie", "gid": "Q9jeAEQAAAAJ"}], "year": 2014}
{"citedby": 9, "type": "Conference Proceedings", "title": "Chatbots of the gods: imaginary abstracts for techno-spirituality research", "author": ["Blythe, Mark", "Buie, Elizabeth"], "secondarytitle": "Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational", "pages": "227-236", "isbn/issn": "1450325424", "year": "2014", "publisher": "ACM", "start_page": 227, "end_page": 236, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Chatbots of the gods: imaginary abstracts for techno-spirituality research\n%A Blythe, Mark\n%A Buie, Elizabeth\n%B Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational\n%P 227-236\n%@ 1450325424\n%D 2014\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:v70r4rTBaQkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTsY3DCaSmCP21Ql2KBMqzerXhA7&scisf=3&ct=citation&cd=151&hl=en"}
[2018-03-02 15:03:50,432 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots of the gods: imaginary abstracts for techno-spirituality research", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2014, "rg_id": null, "start_page": 227, "end_page": 236}.
[2018-03-02 15:03:50,432 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbots of the gods: imaginary abstracts for techno-spirituality research', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2014, 'rg_id': None, 'start_page': 227, 'end_page': 236}
[2018-03-02 15:03:50,432 DEBUG dbutils] Query result: []
[2018-03-02 15:03:50,433 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:50,433 DEBUG dbutils] Add new paper (title='Chatbots of the gods: imaginary abstracts for techno-spirituality research')
[2018-03-02 15:03:50,433 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbots of the gods: imaginary abstracts for techno-spirituality research', 'year': 2014, 'publisher': 'ACM', 'start_page': 227, 'end_page': 236, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Chatbots of the gods: imaginary abstracts for techno-spirituality research\n%A Blythe, Mark\n%A Buie, Elizabeth\n%B Proceedings of the 8th Nordic Conference on Human-Computer Interaction: Fun, Fast, Foundational\n%P 227-236\n%@ 1450325424\n%D 2014\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:50,434 DEBUG dbutils] Query result: 141
[2018-03-02 15:03:50,435 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Elizabeth_Buie/publication/286495716_Chatbots_of_the_gods_Imaginary_abstracts_for_techno-spirituality_research/links/56e6e86308ae85e780cfa25c/Chatbots-of-the-gods-Imaginary-abstracts-for-techno-spirituality-research.pdf.
[2018-03-02 15:03:50,436 WARNING utils] Download file (url='https://www.researchgate.net/profile/Elizabeth_Buie/publication/286495716_Chatbots_of_the_gods_Imaginary_abstracts_for_techno-spirituality_research/links/56e6e86308ae85e780cfa25c/Chatbots-of-the-gods-Imaginary-abstracts-for-techno-spirituality-research.pdf') and save (filename='PDF//141.pdf')
[2018-03-02 15:03:50,437 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:03:50,437 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:03:50,437 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for www.researchgate.net
[2018-03-02 15:03:50,456 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:03:52,234 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Elizabeth_Buie/publication/286495716_Chatbots_of_the_gods_Imaginary_abstracts_for_techno-spirituality_research/links/56e6e86308ae85e780cfa25c/Chatbots-of-the-gods-Imaginary-abstracts-for-techno-spirituality-research.pdf HTTP/1.1" 200 336076
[2018-03-02 15:03:52,235 DEBUG utils] Content-length=336076
[2018-03-02 15:03:52,235 DEBUG utils] Create file PDF//141.pdf, start download.
[2018-03-02 15:03:53,482 DEBUG utils] End download file PDF//141.pdf.
[2018-03-02 15:03:53,483 DEBUG dbutils] Update pdf_transaction for paper id=141.
[2018-03-02 15:03:53,483 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 141'
[2018-03-02 15:03:53,483 DEBUG dbutils] Query result: null
[2018-03-02 15:03:53,483 DEBUG scholar] Handle paper #153 (total 1170)
[2018-03-02 15:03:53,484 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:03:53,488 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:53,489 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:03:53,489 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for scholar.google.com
[2018-03-02 15:03:53,506 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:03:53,507 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:03:56,414 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:rpF0w_SDW38J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPfyOPvcOg_OUNyCTjme0FCZ_JSJV&scisf=3&ct=citation&cd=152&hl=en HTTP/1.1" 200 206
[2018-03-02 15:03:56,415 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Did it make you cry? Creating dramatic agency in immersive environments
%A Murray, Janet
%B International Conference on Virtual Storytelling
%P 83-94
%D 2005
%I Springer

[2018-03-02 15:03:56,415 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:56,415 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:56,415 DEBUG __main__] Process content of EndNote file #153
{"title": "Did it make you cry? Creating dramatic agency in immersive environments", "url": "https://link.springer.com/chapter/10.1007/11590361_10", "author": [{"shortname": "J Murray", "gid": "WjLym20AAAAJ"}], "year": 2005}
{"citedby": 19, "type": "Conference Proceedings", "title": "Did it make you cry? Creating dramatic agency in immersive environments", "author": ["Murray, Janet"], "secondarytitle": "International Conference on Virtual Storytelling", "pages": "83-94", "year": "2005", "publisher": "Springer", "start_page": 83, "end_page": 94, "volume": 12, "EndNote": "%0 Conference Proceedings\n%T Did it make you cry? Creating dramatic agency in immersive environments\n%A Murray, Janet\n%B International Conference on Virtual Storytelling\n%P 83-94\n%D 2005\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:rpF0w_SDW38J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPfyOPvcOg_OUNyCTjme0FCZ_JSJV&scisf=3&ct=citation&cd=152&hl=en"}
[2018-03-02 15:03:56,416 DEBUG dbutils] Get paper id {"DOI": null, "title": "Did it make you cry? Creating dramatic agency in immersive environments", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 12, "year": 2005, "rg_id": null, "start_page": 83, "end_page": 94}.
[2018-03-02 15:03:56,416 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Did it make you cry? Creating dramatic agency in immersive environments', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2005, 'rg_id': None, 'start_page': 83, 'end_page': 94}
[2018-03-02 15:03:56,416 DEBUG dbutils] Query result: []
[2018-03-02 15:03:56,416 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:56,416 DEBUG dbutils] Add new paper (title='Did it make you cry? Creating dramatic agency in immersive environments')
[2018-03-02 15:03:56,416 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Did it make you cry? Creating dramatic agency in immersive environments', 'year': 2005, 'publisher': 'Springer', 'start_page': 83, 'end_page': 94, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Did it make you cry? Creating dramatic agency in immersive environments\n%A Murray, Janet\n%B International Conference on Virtual Storytelling\n%P 83-94\n%D 2005\n%I Springer\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:56,416 DEBUG dbutils] Query result: 142
[2018-03-02 15:03:56,418 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/11590361_10.
[2018-03-02 15:03:56,418 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/11590361_10.
[2018-03-02 15:03:56,601 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/11590361_10 HTTP/1.1" 302 None
[2018-03-02 15:03:56,623 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 15:03:56,972 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=C37DAF4B4A04501C5E5A0C26B9E9EF9E HTTP/1.1" 200 10883
[2018-03-02 15:03:57,064 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:03:57,065 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:03:57,065 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for sci-hub.tw
[2018-03-02 15:03:57,252 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/11590361_10 HTTP/1.1" 302 None
[2018-03-02 15:03:57,522 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=C37DAF4B4A04501C5E5A0C26B9E9EF9E HTTP/1.1" 200 10883
[2018-03-02 15:03:57,760 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:03:57,761 DEBUG scholar] Handle paper #154 (total 1170)
[2018-03-02 15:03:57,761 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:03:57,765 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:03:57,765 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:03:58,272 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GsyDcZlazSIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPbS3DkvHAOCYZsBqpHOj7fPsZGdB&scisf=3&ct=citation&cd=153&hl=en HTTP/1.1" 200 264
[2018-03-02 15:03:58,273 DEBUG scholar] EndNote file:
%0 Book Section
%T Animated pedagogical agents: The effect of visual information on a historical figure application
%A Heller, R
%A Procter, M
%B Dynamic advancements in teaching and learning based technologies: New concepts
%P 66-78
%D 2011
%I IGI Global

[2018-03-02 15:03:58,273 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:03:58,273 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:03:58,273 DEBUG __main__] Process content of EndNote file #154
{"title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "url": "https://www.igi-global.com/chapter/animated-pedagogical-agents/49297", "author": [{"shortname": "R Heller", "gid": ""}, {"shortname": "M Procter", "gid": "6DeEyb0AAAAJ"}], "year": 2011}
{"citedby": 3, "type": "Book Section", "title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "author": ["Heller, R", "Procter, M"], "secondarytitle": "Dynamic advancements in teaching and learning based technologies: New concepts", "pages": "66-78", "year": "2011", "publisher": "IGI Global", "start_page": 66, "end_page": 78, "volume": 13, "EndNote": "%0 Book Section\n%T Animated pedagogical agents: The effect of visual information on a historical figure application\n%A Heller, R\n%A Procter, M\n%B Dynamic advancements in teaching and learning based technologies: New concepts\n%P 66-78\n%D 2011\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GsyDcZlazSIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPbS3DkvHAOCYZsBqpHOj7fPsZGdB&scisf=3&ct=citation&cd=153&hl=en"}
[2018-03-02 15:03:58,273 DEBUG dbutils] Get paper id {"DOI": null, "title": "Animated pedagogical agents: The effect of visual information on a historical figure application", "auth_count": 2, "g_type": "Book Section", "pages": 13, "year": 2011, "rg_id": null, "start_page": 66, "end_page": 78}.
[2018-03-02 15:03:58,274 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Animated pedagogical agents: The effect of visual information on a historical figure application', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 13, 'year': 2011, 'rg_id': None, 'start_page': 66, 'end_page': 78}
[2018-03-02 15:03:58,274 DEBUG dbutils] Query result: []
[2018-03-02 15:03:58,274 DEBUG dbutils] Paper id = None.
[2018-03-02 15:03:58,274 DEBUG dbutils] Add new paper (title='Animated pedagogical agents: The effect of visual information on a historical figure application')
[2018-03-02 15:03:58,274 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Animated pedagogical agents: The effect of visual information on a historical figure application', 'year': 2011, 'publisher': 'IGI Global', 'start_page': 66, 'end_page': 78, 'pages': 13, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Animated pedagogical agents: The effect of visual information on a historical figure application\n%A Heller, R\n%A Procter, M\n%B Dynamic advancements in teaching and learning based technologies: New concepts\n%P 66-78\n%D 2011\n%I IGI Global\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:03:58,274 DEBUG dbutils] Query result: 143
[2018-03-02 15:03:58,276 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.igi-global.com/chapter/animated-pedagogical-agents/49297.
[2018-03-02 15:03:58,276 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.igi-global.com/chapter/animated-pedagogical-agents/49297.
[2018-03-02 15:04:00,662 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.igi-global.com/chapter/animated-pedagogical-agents/49297 HTTP/1.1" 200 None
[2018-03-02 15:04:00,663 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:04:00,663 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:04:00,852 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.igi-global.com/chapter/animated-pedagogical-agents/49297 HTTP/1.1" 200 None
[2018-03-02 15:04:00,860 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:04:00,861 DEBUG scholar] Handle paper #155 (total 1170)
[2018-03-02 15:04:00,861 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:04:00,865 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:00,865 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:04:00,866 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for scholar.google.com
[2018-03-02 15:04:00,882 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:04:00,883 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:04:03,011 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:lQ_GOTDDhfcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPe2YuNFQlU1Mg7ozstvhvT7M-uuJ&scisf=3&ct=citation&cd=154&hl=en HTTP/1.1" 200 340
[2018-03-02 15:04:03,012 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish
%A Montero, Calkin S
%A Araki, Kenji
%B International Conference on Knowledge-Based and Intelligent Information and Engineering Systems
%P 361-368
%D 2007
%I Springer

[2018-03-02 15:04:03,012 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:03,012 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:03,012 DEBUG __main__] Process content of EndNote file #155
{"title": "Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish", "url": "https://link.springer.com/chapter/10.1007/978-3-540-74827-4_46", "author": [{"shortname": "CS Montero", "gid": "T9ev3vIAAAAJ"}, {"shortname": "K Araki", "gid": ""}], "year": 2007}
{"citedby": 2, "type": "Conference Proceedings", "title": "Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish", "author": ["Montero, Calkin S", "Araki, Kenji"], "secondarytitle": "International Conference on Knowledge-Based and Intelligent Information and Engineering Systems", "pages": "361-368", "year": "2007", "publisher": "Springer", "start_page": 361, "end_page": 368, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish\n%A Montero, Calkin S\n%A Araki, Kenji\n%B International Conference on Knowledge-Based and Intelligent Information and Engineering Systems\n%P 361-368\n%D 2007\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:lQ_GOTDDhfcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPe2YuNFQlU1Mg7ozstvhvT7M-uuJ&scisf=3&ct=citation&cd=154&hl=en"}
[2018-03-02 15:04:03,012 DEBUG dbutils] Get paper id {"DOI": null, "title": "Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 8, "year": 2007, "rg_id": null, "start_page": 361, "end_page": 368}.
[2018-03-02 15:04:03,012 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2007, 'rg_id': None, 'start_page': 361, 'end_page': 368}
[2018-03-02 15:04:03,013 DEBUG dbutils] Query result: []
[2018-03-02 15:04:03,013 DEBUG dbutils] Paper id = None.
[2018-03-02 15:04:03,013 DEBUG dbutils] Add new paper (title='Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish')
[2018-03-02 15:04:03,013 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish', 'year': 2007, 'publisher': 'Springer', 'start_page': 361, 'end_page': 368, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Evaluation of Trivial Dialogue Phrase Databases Through Practical Application to User-Computer Conversation-Case Study: English-Spanish\n%A Montero, Calkin S\n%A Araki, Kenji\n%B International Conference on Knowledge-Based and Intelligent Information and Engineering Systems\n%P 361-368\n%D 2007\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:04:03,013 DEBUG dbutils] Query result: 144
[2018-03-02 15:04:03,014 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://arakilab.media.eng.hokudai.ac.jp/~araki/2007/2007-B-9.pdf.
[2018-03-02 15:04:03,015 WARNING utils] Download file (url='http://arakilab.media.eng.hokudai.ac.jp/~araki/2007/2007-B-9.pdf') and save (filename='PDF//144.pdf')
[2018-03-02 15:04:03,015 DEBUG utils] Get current proxy for arakilab.media.eng.hokudai.ac.jp.
[2018-03-02 15:04:03,016 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:04:03,032 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): arakilab.media.eng.hokudai.ac.jp
[2018-03-02 15:04:04,201 DEBUG requests.packages.urllib3.connectionpool] "GET /~araki/2007/2007-B-9.pdf HTTP/1.1" 200 476130
[2018-03-02 15:04:04,201 DEBUG utils] Content-length=476130
[2018-03-02 15:04:04,202 DEBUG utils] Create file PDF//144.pdf, start download.
[2018-03-02 15:04:11,770 DEBUG utils] End download file PDF//144.pdf.
[2018-03-02 15:04:11,771 DEBUG dbutils] Update pdf_transaction for paper id=144.
[2018-03-02 15:04:11,771 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 144'
[2018-03-02 15:04:11,771 DEBUG dbutils] Query result: null
[2018-03-02 15:04:11,772 DEBUG scholar] Handle paper #156 (total 1170)
[2018-03-02 15:04:11,772 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:04:11,779 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:11,779 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:04:12,251 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:JnmhdNfnOLsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPQ1Y7zVI_c9Y_i0xpJS6A8tGtVuE&scisf=3&ct=citation&cd=155&hl=en HTTP/1.1" 200 241
[2018-03-02 15:04:12,253 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Arabic question-answering via instance based learning from an FAQ corpus
%A Shawar, B Abu
%A Atwell, Eric
%B Proceedings of the CL 2009 International Conference on Corpus Linguistics. UCREL
%V 386
%D 2009

[2018-03-02 15:04:12,253 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:12,253 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:12,254 DEBUG __main__] Process content of EndNote file #156
{"title": "Arabic question-answering via instance based learning from an FAQ corpus", "url": "http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf", "author": [{"shortname": "BA Shawar", "gid": ""}, {"shortname": "E Atwell", "gid": "Iu5WFskAAAAJ"}], "year": 2009}
{"citedby": 3, "type": "Conference Proceedings", "title": "Arabic question-answering via instance based learning from an FAQ corpus", "author": ["Shawar, B Abu", "Atwell, Eric"], "secondarytitle": "Proceedings of the CL 2009 International Conference on Corpus Linguistics. UCREL", "volume": "386", "year": "2009", "EndNote": "%0 Conference Proceedings\n%T Arabic question-answering via instance based learning from an FAQ corpus\n%A Shawar, B Abu\n%A Atwell, Eric\n%B Proceedings of the CL 2009 International Conference on Corpus Linguistics. UCREL\n%V 386\n%D 2009\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:JnmhdNfnOLsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPQ1Y7zVI_c9Y_i0xpJS6A8tGtVuE&scisf=3&ct=citation&cd=155&hl=en"}
[2018-03-02 15:04:12,254 DEBUG dbutils] Get paper id {"DOI": null, "title": "Arabic question-answering via instance based learning from an FAQ corpus", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 386, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:04:12,254 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Arabic question-answering via instance based learning from an FAQ corpus', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 386, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:04:12,254 DEBUG dbutils] Query result: [[139]]
[2018-03-02 15:04:12,254 DEBUG dbutils] Paper id = 139.
[2018-03-02 15:04:12,255 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf.
[2018-03-02 15:04:12,256 WARNING utils] Download file (url='http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf') and save (filename='PDF//139.pdf')
[2018-03-02 15:04:12,256 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 15:04:12,257 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:04:12,257 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for otherhost
[2018-03-02 15:04:12,276 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 15:04:12,772 DEBUG requests.packages.urllib3.connectionpool] "GET /download/35768291/ArabicQuestionAnswering.pdf HTTP/1.1" 404 None
[2018-03-02 15:04:12,776 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf.
[2018-03-02 15:04:12,776 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf.
[2018-03-02 15:04:13,005 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf HTTP/1.1" 302 None
[2018-03-02 15:04:13,352 DEBUG requests.packages.urllib3.connectionpool] "GET /download/35768291/ArabicQuestionAnswering.pdf HTTP/1.1" 404 None
[2018-03-02 15:04:13,353 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:04:13,353 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:04:13,354 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for sci-hub.tw
[2018-03-02 15:04:13,500 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf HTTP/1.1" 302 None
[2018-03-02 15:04:13,831 DEBUG requests.packages.urllib3.connectionpool] "GET /download/35768291/ArabicQuestionAnswering.pdf HTTP/1.1" 404 None
[2018-03-02 15:04:13,835 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:04:13,835 DEBUG __main__] Failed get_pdf from sci-hub for paper #144. URL=144
[2018-03-02 15:04:13,835 DEBUG scholar] Handle paper #157 (total 1170)
[2018-03-02 15:04:13,835 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:04:13,840 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:13,840 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:04:13,840 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for scholar.google.com
[2018-03-02 15:04:13,855 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:04:13,856 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:04:16,602 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:UY1wtkkIZnoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPftzdw8xF7zMK5gRa7LEX2C9J_iV&scisf=3&ct=citation&cd=156&hl=en HTTP/1.1" 200 314
[2018-03-02 15:04:16,603 DEBUG scholar] EndNote file:
%0 Journal Article
%T Conversational in-vehicle dialog systems: The past, present, and future
%A Weng, Fuliang
%A Angkititrakul, Pongtep
%A Shriberg, Elizabeth E
%A Heck, Larry
%A Peters, Stanley
%A Hansen, John HL
%J IEEE Signal Processing Magazine
%V 33
%N 6
%P 49-60
%@ 1053-5888
%D 2016
%I IEEE

[2018-03-02 15:04:16,603 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:16,603 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:16,603 DEBUG __main__] Process content of EndNote file #157
{"title": "Conversational in-vehicle dialog systems: The past, present, and future", "url": "http://ieeexplore.ieee.org/abstract/document/7736173/", "author": [{"shortname": "F Weng", "gid": "KOtHhfgAAAAJ"}, {"shortname": "P Angkititrakul", "gid": "G8oOG3QAAAAJ"}, {"shortname": "EE Shriberg", "gid": "nRZJYPIAAAAJ"}], "year": 2016}
{"citedby": 9, "type": "Journal Article", "title": "Conversational in-vehicle dialog systems: The past, present, and future", "author": ["Weng, Fuliang", "Angkititrakul, Pongtep", "Shriberg, Elizabeth E", "Heck, Larry", "Peters, Stanley", "Hansen, John HL"], "journal": "IEEE Signal Processing Magazine", "volume": 12, "numberorissue": "6", "pages": "49-60", "isbn/issn": "1053-5888", "year": "2016", "publisher": "IEEE", "start_page": 49, "end_page": 60, "EndNote": "%0 Journal Article\n%T Conversational in-vehicle dialog systems: The past, present, and future\n%A Weng, Fuliang\n%A Angkititrakul, Pongtep\n%A Shriberg, Elizabeth E\n%A Heck, Larry\n%A Peters, Stanley\n%A Hansen, John HL\n%J IEEE Signal Processing Magazine\n%V 33\n%N 6\n%P 49-60\n%@ 1053-5888\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:UY1wtkkIZnoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPftzdw8xF7zMK5gRa7LEX2C9J_iV&scisf=3&ct=citation&cd=156&hl=en"}
[2018-03-02 15:04:16,603 DEBUG dbutils] Get paper id {"DOI": null, "title": "Conversational in-vehicle dialog systems: The past, present, and future", "auth_count": 6, "g_type": "Journal Article", "pages": 12, "year": 2016, "rg_id": null, "start_page": 49, "end_page": 60}.
[2018-03-02 15:04:16,604 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Conversational in-vehicle dialog systems: The past, present, and future', 'auth_count': 6, 'g_type': 'Journal Article', 'pages': 12, 'year': 2016, 'rg_id': None, 'start_page': 49, 'end_page': 60}
[2018-03-02 15:04:16,604 DEBUG dbutils] Query result: []
[2018-03-02 15:04:16,604 DEBUG dbutils] Paper id = None.
[2018-03-02 15:04:16,604 DEBUG dbutils] Add new paper (title='Conversational in-vehicle dialog systems: The past, present, and future')
[2018-03-02 15:04:16,604 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Conversational in-vehicle dialog systems: The past, present, and future', 'year': 2016, 'publisher': 'IEEE', 'start_page': 49, 'end_page': 60, 'pages': 12, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Conversational in-vehicle dialog systems: The past, present, and future\n%A Weng, Fuliang\n%A Angkititrakul, Pongtep\n%A Shriberg, Elizabeth E\n%A Heck, Larry\n%A Peters, Stanley\n%A Hansen, John HL\n%J IEEE Signal Processing Magazine\n%V 33\n%N 6\n%P 49-60\n%@ 1053-5888\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 15:04:16,604 DEBUG dbutils] Query result: 145
[2018-03-02 15:04:16,606 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/bea1/fd8a09546a4aada1fee3d0200ad651edaee4.pdf.
[2018-03-02 15:04:16,607 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/bea1/fd8a09546a4aada1fee3d0200ad651edaee4.pdf') and save (filename='PDF//145.pdf')
[2018-03-02 15:04:16,608 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:04:16,608 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:04:16,624 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:04:18,754 DEBUG requests.packages.urllib3.connectionpool] "GET /bea1/fd8a09546a4aada1fee3d0200ad651edaee4.pdf HTTP/1.1" 200 2015430
[2018-03-02 15:04:18,754 DEBUG utils] Content-length=2015430
[2018-03-02 15:04:18,755 DEBUG utils] Create file PDF//145.pdf, start download.
[2018-03-02 15:04:26,258 DEBUG utils] End download file PDF//145.pdf.
[2018-03-02 15:04:26,260 DEBUG dbutils] Update pdf_transaction for paper id=145.
[2018-03-02 15:04:26,260 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 145'
[2018-03-02 15:04:26,260 DEBUG dbutils] Query result: null
[2018-03-02 15:04:26,261 DEBUG scholar] Handle paper #158 (total 1170)
[2018-03-02 15:04:26,261 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:04:26,265 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:26,266 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:04:26,730 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:05CQbVWVDnYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTEsIx02Is2u-X3dt0WWPSXR06Fb&scisf=3&ct=citation&cd=157&hl=en HTTP/1.1" 200 206
[2018-03-02 15:04:26,731 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Chatbots are natural web interface to information portals
%A Shawar, Bayan Abu
%B Proc. of INFOS 2008 The Sixth International Conference on Informatics and Systems
%D 2008

[2018-03-02 15:04:26,731 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:26,731 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:26,731 DEBUG __main__] Process content of EndNote file #158
{"title": "Chatbots are natural web interface to information portals", "url": "https://pdfs.semanticscholar.org/0ac1/5e5745841bb0c559021f3b57b7b37325bf6e.pdf", "author": [{"shortname": "BA Shawar", "gid": ""}], "year": 2008}
{"citedby": 2, "type": "Conference Proceedings", "title": "Chatbots are natural web interface to information portals", "author": ["Shawar, Bayan Abu"], "secondarytitle": "Proc. of INFOS 2008 The Sixth International Conference on Informatics and Systems", "year": "2008", "EndNote": "%0 Conference Proceedings\n%T Chatbots are natural web interface to information portals\n%A Shawar, Bayan Abu\n%B Proc. of INFOS 2008 The Sixth International Conference on Informatics and Systems\n%D 2008\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:05CQbVWVDnYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTEsIx02Is2u-X3dt0WWPSXR06Fb&scisf=3&ct=citation&cd=157&hl=en"}
[2018-03-02 15:04:26,731 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots are natural web interface to information portals", "auth_count": 1, "g_type": "Conference Proceedings", "pages": null, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:04:26,732 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbots are natural web interface to information portals', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:04:26,732 DEBUG dbutils] Query result: []
[2018-03-02 15:04:26,732 DEBUG dbutils] Paper id = None.
[2018-03-02 15:04:26,732 DEBUG dbutils] Add new paper (title='Chatbots are natural web interface to information portals')
[2018-03-02 15:04:26,732 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbots are natural web interface to information portals', 'year': 2008, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Chatbots are natural web interface to information portals\n%A Shawar, Bayan Abu\n%B Proc. of INFOS 2008 The Sixth International Conference on Informatics and Systems\n%D 2008\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:04:26,732 DEBUG dbutils] Query result: 146
[2018-03-02 15:04:26,734 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/0ac1/5e5745841bb0c559021f3b57b7b37325bf6e.pdf.
[2018-03-02 15:04:26,736 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/0ac1/5e5745841bb0c559021f3b57b7b37325bf6e.pdf') and save (filename='PDF//146.pdf')
[2018-03-02 15:04:26,736 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:04:26,736 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:04:26,736 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for otherhost
[2018-03-02 15:04:26,751 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:04:28,301 DEBUG requests.packages.urllib3.connectionpool] "GET /0ac1/5e5745841bb0c559021f3b57b7b37325bf6e.pdf HTTP/1.1" 200 83195
[2018-03-02 15:04:28,301 DEBUG utils] Content-length=83195
[2018-03-02 15:04:28,301 DEBUG utils] Create file PDF//146.pdf, start download.
[2018-03-02 15:04:28,424 DEBUG utils] End download file PDF//146.pdf.
[2018-03-02 15:04:28,425 DEBUG dbutils] Update pdf_transaction for paper id=146.
[2018-03-02 15:04:28,425 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 146'
[2018-03-02 15:04:28,425 DEBUG dbutils] Query result: null
[2018-03-02 15:04:28,426 DEBUG scholar] Handle paper #159 (total 1170)
[2018-03-02 15:04:28,426 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:04:28,431 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:28,432 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:04:28,432 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for scholar.google.com
[2018-03-02 15:04:28,447 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:04:28,448 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:04:29,181 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:sMQVGkfjyPsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTtoIcjRIoysxqzEoOmuRnpBUM24&scisf=3&ct=citation&cd=158&hl=en HTTP/1.1" 200 174
[2018-03-02 15:04:29,182 DEBUG scholar] EndNote file:
%0 Book
%T Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?
%A Savin-Baden, Maggi
%@ 1317514424
%D 2015
%I Routledge

[2018-03-02 15:04:29,182 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:29,182 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:29,182 DEBUG __main__] Process content of EndNote file #159
{"title": "Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?", "url": "https://books.google.com/books?hl=en&lr=&id=YAfwBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=lvXPastljU&sig=b1tC9qTVbCoX6cg98ga5Nx2d0_0", "author": [{"shortname": "M Savin", "gid": ""}], "year": 2015}
{"citedby": 15, "type": "Book", "title": "Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?", "author": ["Savin-Baden, Maggi"], "isbn/issn": "1317514424", "year": "2015", "publisher": "Routledge", "EndNote": "%0 Book\n%T Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?\n%A Savin-Baden, Maggi\n%@ 1317514424\n%D 2015\n%I Routledge\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:sMQVGkfjyPsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPTtoIcjRIoysxqzEoOmuRnpBUM24&scisf=3&ct=citation&cd=158&hl=en"}
[2018-03-02 15:04:29,182 DEBUG dbutils] Get paper id {"DOI": null, "title": "Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:04:29,182 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:04:29,183 DEBUG dbutils] Query result: []
[2018-03-02 15:04:29,183 DEBUG dbutils] Paper id = None.
[2018-03-02 15:04:29,183 DEBUG dbutils] Add new paper (title='Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?')
[2018-03-02 15:04:29,183 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?', 'year': 2015, 'publisher': 'Routledge', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Rethinking learning in an age of digital fluency: Is being digitally tethered a new learning nexus?\n%A Savin-Baden, Maggi\n%@ 1317514424\n%D 2015\n%I Routledge\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:04:29,183 DEBUG dbutils] Query result: 147
[2018-03-02 15:04:29,185 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=YAfwBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=lvXPastljU&sig=b1tC9qTVbCoX6cg98ga5Nx2d0_0.
[2018-03-02 15:04:29,185 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=YAfwBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=lvXPastljU&sig=b1tC9qTVbCoX6cg98ga5Nx2d0_0.
[2018-03-02 15:04:29,361 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=YAfwBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=lvXPastljU&sig=b1tC9qTVbCoX6cg98ga5Nx2d0_0 HTTP/1.1" 302 None
[2018-03-02 15:04:29,550 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:04:29,569 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:04:29,570 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:04:29,741 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=YAfwBgAAQBAJ&oi=fnd&pg=PP1&dq=Use+deep+learning+to+create+a+chatbot&ots=lvXPastljU&sig=b1tC9qTVbCoX6cg98ga5Nx2d0_0 HTTP/1.1" 302 None
[2018-03-02 15:04:29,936 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:04:29,967 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:04:29,968 DEBUG scholar] Handle paper #160 (total 1170)
[2018-03-02 15:04:29,968 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:04:29,971 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:04:29,971 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:04:30,221 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:_-3HC1JY9OcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPYdwiAr2EXH_BbTXtpP51wRXdzTq&scisf=3&ct=citation&cd=159&hl=en HTTP/1.1" 200 283
[2018-03-02 15:04:30,222 DEBUG scholar] EndNote file:
%0 Journal Article
%T Computational humor
%A Binsted, Kim
%A Nijholt, Anton
%A Stock, Oliviero
%A Strapparava, Carlo
%A Ritchie, G
%A Manurung, R
%A Pain, H
%A Waller, Annalu
%A O'Mara, D
%J IEEE Intelligent Systems
%V 21
%N 2
%P 59-69
%@ 1541-1672
%D 2006
%I IEEE

[2018-03-02 15:04:30,222 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:04:30,222 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:04:30,222 DEBUG __main__] Process content of EndNote file #160
{"title": "Computational humor", "url": "http://ieeexplore.ieee.org/abstract/document/1613822/", "author": [{"shortname": "K Binsted", "gid": "bd9-UG8AAAAJ"}, {"shortname": "A Nijholt", "gid": "tzYolooAAAAJ"}, {"shortname": "O Stock", "gid": "JZzEA9AAAAAJ"}], "year": 2006}
{"citedby": 57, "type": "Journal Article", "title": "Computational humor", "author": ["Binsted, Kim", "Nijholt, Anton", "Stock, Oliviero", "Strapparava, Carlo", "Ritchie, G", "Manurung, R", "Pain, H", "Waller, Annalu", "O'Mara, D"], "journal": "IEEE Intelligent Systems", "volume": 11, "numberorissue": "2", "pages": "59-69", "isbn/issn": "1541-1672", "year": "2006", "publisher": "IEEE", "start_page": 59, "end_page": 69, "EndNote": "%0 Journal Article\n%T Computational humor\n%A Binsted, Kim\n%A Nijholt, Anton\n%A Stock, Oliviero\n%A Strapparava, Carlo\n%A Ritchie, G\n%A Manurung, R\n%A Pain, H\n%A Waller, Annalu\n%A O'Mara, D\n%J IEEE Intelligent Systems\n%V 21\n%N 2\n%P 59-69\n%@ 1541-1672\n%D 2006\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:_-3HC1JY9OcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAPYdwiAr2EXH_BbTXtpP51wRXdzTq&scisf=3&ct=citation&cd=159&hl=en"}
[2018-03-02 15:04:30,222 DEBUG dbutils] Get paper id {"DOI": null, "title": "Computational humor", "auth_count": 9, "g_type": "Journal Article", "pages": 11, "year": 2006, "rg_id": null, "start_page": 59, "end_page": 69}.
[2018-03-02 15:04:30,222 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Computational humor', 'auth_count': 9, 'g_type': 'Journal Article', 'pages': 11, 'year': 2006, 'rg_id': None, 'start_page': 59, 'end_page': 69}
[2018-03-02 15:04:30,222 DEBUG dbutils] Query result: []
[2018-03-02 15:04:30,222 DEBUG dbutils] Paper id = None.
[2018-03-02 15:04:30,223 DEBUG dbutils] Add new paper (title='Computational humor')
[2018-03-02 15:04:30,223 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Computational humor', 'year': 2006, 'publisher': 'IEEE', 'start_page': 59, 'end_page': 69, 'pages': 11, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Journal Article\n%T Computational humor\n%A Binsted, Kim\n%A Nijholt, Anton\n%A Stock, Oliviero\n%A Strapparava, Carlo\n%A Ritchie, G\n%A Manurung, R\n%A Pain, H\n%A Waller, Annalu\n%A O'Mara, D\n%J IEEE Intelligent Systems\n%V 21\n%N 2\n%P 59-69\n%@ 1541-1672\n%D 2006\n%I IEEE\n", 'RIS': None, 'authors': 9, 'ignore': False, 'transaction': 1}
[2018-03-02 15:04:30,223 DEBUG dbutils] Query result: 148
[2018-03-02 15:04:30,224 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Ruli_Manurung/publication/3454330_Computational_Humor/links/09e415112f7cc1281d000000.pdf.
[2018-03-02 15:04:30,225 WARNING utils] Download file (url='https://www.researchgate.net/profile/Ruli_Manurung/publication/3454330_Computational_Humor/links/09e415112f7cc1281d000000.pdf') and save (filename='PDF//148.pdf')
[2018-03-02 15:04:30,225 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:04:30,225 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:04:30,597 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Ruli_Manurung/publication/3454330_Computational_Humor/links/09e415112f7cc1281d000000.pdf HTTP/1.1" 200 589563
[2018-03-02 15:04:30,598 DEBUG utils] Content-length=589563
[2018-03-02 15:04:30,598 DEBUG utils] Create file PDF//148.pdf, start download.
[2018-03-02 15:04:32,031 DEBUG utils] End download file PDF//148.pdf.
[2018-03-02 15:04:32,032 DEBUG dbutils] Update pdf_transaction for paper id=148.
[2018-03-02 15:04:32,032 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 148'
[2018-03-02 15:04:32,032 DEBUG dbutils] Query result: null
[2018-03-02 15:04:32,051 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:04:32,052 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:04:32,052 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:04:32,052 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for scholar.google.com
[2018-03-02 15:04:32,067 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:04:37,222 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.google.com', port=443): Max retries exceeded with url: /scholar?start=160&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.google.com', port=443): Max retries exceeded with url: /scholar?start=160&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:04:37,223 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for scholar.google.com
[2018-03-02 15:04:37,223 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:04:37,223 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:04:37,238 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:04:43,161 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=160&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:04:43,308 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:04:43,308 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:05:10,976 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:05:10,976 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:05:11,145 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:05:11,145 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:05:11,145 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for scholar.google.com
[2018-03-02 15:05:11,159 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.google.com
[2018-03-02 15:05:11,160 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.google.com
[2018-03-02 15:05:13,554 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=160&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:05:14,007 DEBUG scholar] Find papers on page #17 (max_google_papers = 300)
[2018-03-02 15:05:14,007 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:05:14,007 DEBUG scholar] Handle paper #161 (total 1170)
[2018-03-02 15:05:14,007 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:05:14,011 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:14,011 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:05:14,027 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:05:14,029 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:05:16,740 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Z0osUJhkbSkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlhmxxdljj-UQDSgDW1X2jqIJIlgm&scisf=3&ct=citation&cd=160&hl=en HTTP/1.1" 200 264
[2018-03-02 15:05:16,741 DEBUG scholar] EndNote file:
%0 Journal Article
%T Automating content generation for large-scale virtual learning environments using semantic Web services
%A Dunwell, Ian
%A Petridis, Panagiotis
%A Protopsaltis, Aristos
%A de Freitas, Sara
%A Panzoli, David
%A Samuels, Peter
%D 2010

[2018-03-02 15:05:16,741 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:05:16,741 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:05:16,741 DEBUG __main__] Process content of EndNote file #161
{"title": "Automating content generation for large-scale virtual learning environments using semantic Web services", "url": "http://researchrepository.murdoch.edu.au/id/eprint/26556/", "author": [{"shortname": "I Dunwell", "gid": ""}, {"shortname": "P Petridis", "gid": "3_sYmkkAAAAJ"}, {"shortname": "A Protopsaltis", "gid": "eWcOA1AAAAAJ"}, {"shortname": "S de Freitas", "gid": "d1iK6I0AAAAJ"}], "year": 2010}
{"citedby": 4, "type": "Journal Article", "title": "Automating content generation for large-scale virtual learning environments using semantic Web services", "author": ["Dunwell, Ian", "Petridis, Panagiotis", "Protopsaltis, Aristos", "de Freitas, Sara", "Panzoli, David", "Samuels, Peter"], "year": "2010", "EndNote": "%0 Journal Article\n%T Automating content generation for large-scale virtual learning environments using semantic Web services\n%A Dunwell, Ian\n%A Petridis, Panagiotis\n%A Protopsaltis, Aristos\n%A de Freitas, Sara\n%A Panzoli, David\n%A Samuels, Peter\n%D 2010\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Z0osUJhkbSkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlhmxxdljj-UQDSgDW1X2jqIJIlgm&scisf=3&ct=citation&cd=160&hl=en"}
[2018-03-02 15:05:16,741 DEBUG dbutils] Get paper id {"DOI": null, "title": "Automating content generation for large-scale virtual learning environments using semantic Web services", "auth_count": 6, "g_type": "Journal Article", "pages": null, "year": 2010, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:05:16,742 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Automating content generation for large-scale virtual learning environments using semantic Web services', 'auth_count': 6, 'g_type': 'Journal Article', 'pages': None, 'year': 2010, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:05:16,742 DEBUG dbutils] Query result: []
[2018-03-02 15:05:16,742 DEBUG dbutils] Paper id = None.
[2018-03-02 15:05:16,742 DEBUG dbutils] Add new paper (title='Automating content generation for large-scale virtual learning environments using semantic Web services')
[2018-03-02 15:05:16,742 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Automating content generation for large-scale virtual learning environments using semantic Web services', 'year': 2010, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Automating content generation for large-scale virtual learning environments using semantic Web services\n%A Dunwell, Ian\n%A Petridis, Panagiotis\n%A Protopsaltis, Aristos\n%A de Freitas, Sara\n%A Panzoli, David\n%A Samuels, Peter\n%D 2010\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 15:05:16,742 DEBUG dbutils] Query result: 149
[2018-03-02 15:05:16,743 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://researchrepository.murdoch.edu.au/id/eprint/26556/1/automating_content_generation.pdf.
[2018-03-02 15:05:16,744 WARNING utils] Download file (url='http://researchrepository.murdoch.edu.au/id/eprint/26556/1/automating_content_generation.pdf') and save (filename='PDF//149.pdf')
[2018-03-02 15:05:16,744 DEBUG utils] Get current proxy for researchrepository.murdoch.edu.au.
[2018-03-02 15:05:16,744 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:05:16,762 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): researchrepository.murdoch.edu.au
[2018-03-02 15:05:17,806 DEBUG requests.packages.urllib3.connectionpool] "GET /id/eprint/26556/1/automating_content_generation.pdf HTTP/1.1" 200 384493
[2018-03-02 15:05:17,806 DEBUG utils] Content-length=384493
[2018-03-02 15:05:17,807 DEBUG utils] Create file PDF//149.pdf, start download.
[2018-03-02 15:05:18,612 DEBUG utils] End download file PDF//149.pdf.
[2018-03-02 15:05:18,614 DEBUG dbutils] Update pdf_transaction for paper id=149.
[2018-03-02 15:05:18,614 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 149'
[2018-03-02 15:05:18,614 DEBUG dbutils] Query result: null
[2018-03-02 15:05:18,615 DEBUG scholar] Handle paper #162 (total 1170)
[2018-03-02 15:05:18,615 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:05:18,617 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:18,618 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:05:18,618 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for scholar.google.com
[2018-03-02 15:05:18,637 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:05:18,638 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:05:19,916 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kDL0vn9oAfsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlm_5rbdqv43vA5AaX7eGCmefD04j&scisf=3&ct=citation&cd=161&hl=en HTTP/1.1" 200 82
[2018-03-02 15:05:19,917 DEBUG scholar] EndNote file:
%0 Generic
%T Chatbot trained on movie dialogue
%A Roghult, Alexander
%D 2014

[2018-03-02 15:05:19,917 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:05:19,917 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:05:19,917 DEBUG __main__] Process content of EndNote file #162
{"title": "Chatbot trained on movie dialogue", "url": "http://www.diva-portal.org/smash/record.jsf?pid=diva2:770821", "author": [{"shortname": "A Roghult", "gid": ""}], "year": 2014}
{"type": "Generic", "title": "Chatbot trained on movie dialogue", "author": ["Roghult, Alexander"], "year": "2014", "EndNote": "%0 Generic\n%T Chatbot trained on movie dialogue\n%A Roghult, Alexander\n%D 2014\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kDL0vn9oAfsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlm_5rbdqv43vA5AaX7eGCmefD04j&scisf=3&ct=citation&cd=161&hl=en"}
[2018-03-02 15:05:19,917 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbot trained on movie dialogue", "auth_count": 1, "g_type": "Generic", "pages": null, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:05:19,917 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbot trained on movie dialogue', 'auth_count': 1, 'g_type': 'Generic', 'pages': None, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:05:19,917 DEBUG dbutils] Query result: []
[2018-03-02 15:05:19,917 DEBUG dbutils] Paper id = None.
[2018-03-02 15:05:19,917 DEBUG dbutils] Add new paper (title='Chatbot trained on movie dialogue')
[2018-03-02 15:05:19,918 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbot trained on movie dialogue', 'year': 2014, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Chatbot trained on movie dialogue\n%A Roghult, Alexander\n%D 2014\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:05:19,918 DEBUG dbutils] Query result: 150
[2018-03-02 15:05:19,919 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.diva-portal.org/smash/get/diva2:770821/FULLTEXT01.pdf.
[2018-03-02 15:05:19,920 WARNING utils] Download file (url='http://www.diva-portal.org/smash/get/diva2:770821/FULLTEXT01.pdf') and save (filename='PDF//150.pdf')
[2018-03-02 15:05:19,920 DEBUG utils] Get current proxy for www.diva-portal.org.
[2018-03-02 15:05:19,920 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:05:19,920 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for otherhost
[2018-03-02 15:05:19,936 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.diva-portal.org
[2018-03-02 15:05:20,197 DEBUG requests.packages.urllib3.connectionpool] "GET /smash/get/diva2:770821/FULLTEXT01.pdf HTTP/1.1" 200 335484
[2018-03-02 15:05:20,197 DEBUG utils] Content-length=335484
[2018-03-02 15:05:20,198 DEBUG utils] Create file PDF//150.pdf, start download.
[2018-03-02 15:05:20,854 DEBUG utils] End download file PDF//150.pdf.
[2018-03-02 15:05:20,855 DEBUG dbutils] Update pdf_transaction for paper id=150.
[2018-03-02 15:05:20,855 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 150'
[2018-03-02 15:05:20,855 DEBUG dbutils] Query result: null
[2018-03-02 15:05:20,856 DEBUG scholar] Handle paper #163 (total 1170)
[2018-03-02 15:05:20,856 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:05:20,859 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:20,859 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:05:21,120 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:bZfPi0tq0VAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlp2ZONYNZuMTrhaTkle0E9Nvlm7h&scisf=3&ct=citation&cd=162&hl=en HTTP/1.1" 200 239
[2018-03-02 15:05:21,121 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T ActBot: Sharing high-level robot AI scripts
%A Creusot, Clement
%B Robot and Human Interactive Communication (RO-MAN), 2016 25th IEEE International Symposium on
%P 172-178
%@ 1509039295
%D 2016
%I IEEE

[2018-03-02 15:05:21,121 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:05:21,121 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:05:21,121 DEBUG __main__] Process content of EndNote file #163
{"title": "ActBot: Sharing high-level robot AI scripts", "url": "http://ieeexplore.ieee.org/abstract/document/7745107/", "author": [{"shortname": "C Creusot", "gid": "vpqi4DIAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "ActBot: Sharing high-level robot AI scripts", "author": ["Creusot, Clement"], "secondarytitle": "Robot and Human Interactive Communication (RO-MAN), 2016 25th IEEE International Symposium on", "pages": "172-178", "isbn/issn": "1509039295", "year": "2016", "publisher": "IEEE", "start_page": 172, "end_page": 178, "volume": 7, "EndNote": "%0 Conference Proceedings\n%T ActBot: Sharing high-level robot AI scripts\n%A Creusot, Clement\n%B Robot and Human Interactive Communication (RO-MAN), 2016 25th IEEE International Symposium on\n%P 172-178\n%@ 1509039295\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:bZfPi0tq0VAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlp2ZONYNZuMTrhaTkle0E9Nvlm7h&scisf=3&ct=citation&cd=162&hl=en"}
[2018-03-02 15:05:21,122 DEBUG dbutils] Get paper id {"DOI": null, "title": "ActBot: Sharing high-level robot AI scripts", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 7, "year": 2016, "rg_id": null, "start_page": 172, "end_page": 178}.
[2018-03-02 15:05:21,122 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'ActBot: Sharing high-level robot AI scripts', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 7, 'year': 2016, 'rg_id': None, 'start_page': 172, 'end_page': 178}
[2018-03-02 15:05:21,122 DEBUG dbutils] Query result: []
[2018-03-02 15:05:21,122 DEBUG dbutils] Paper id = None.
[2018-03-02 15:05:21,122 DEBUG dbutils] Add new paper (title='ActBot: Sharing high-level robot AI scripts')
[2018-03-02 15:05:21,122 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'ActBot: Sharing high-level robot AI scripts', 'year': 2016, 'publisher': 'IEEE', 'start_page': 172, 'end_page': 178, 'pages': 7, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T ActBot: Sharing high-level robot AI scripts\n%A Creusot, Clement\n%B Robot and Human Interactive Communication (RO-MAN), 2016 25th IEEE International Symposium on\n%P 172-178\n%@ 1509039295\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:05:21,122 DEBUG dbutils] Query result: 151
[2018-03-02 15:05:21,124 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7745107/.
[2018-03-02 15:05:21,124 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7745107/.
[2018-03-02 15:05:21,310 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7745107/ HTTP/1.1" 200 None
[2018-03-02 15:05:21,311 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:05:21,311 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:05:21,311 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for sci-hub.tw
[2018-03-02 15:05:21,500 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7745107/ HTTP/1.1" 200 None
[2018-03-02 15:05:21,506 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true.
[2018-03-02 15:05:21,507 WARNING utils] Download file (url='http://twin.sci-hub.tw/360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true') and save (filename='PDF//151.pdf')
[2018-03-02 15:05:21,522 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 15:05:21,690 DEBUG requests.packages.urllib3.connectionpool] "GET /360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:05:21,691 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:05:21,691 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:05:21,706 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 15:05:21,890 DEBUG requests.packages.urllib3.connectionpool] "GET /360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:05:21,893 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:05:21,893 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:05:35,297 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:05:35,297 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:05:35,580 DEBUG requests.packages.urllib3.connectionpool] "GET /360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:05:35,581 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:05:35,581 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:05:35,581 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for sci-hub.tw
[2018-03-02 15:05:35,596 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): twin.sci-hub.tw
[2018-03-02 15:05:35,770 DEBUG requests.packages.urllib3.connectionpool] "GET /360c60820195f29ac47dbeffcc4c9cb8/creusot2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:05:35,775 DEBUG scholar] Handle paper #164 (total 1170)
[2018-03-02 15:05:35,775 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:05:35,778 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:35,778 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:05:35,779 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for scholar.google.com
[2018-03-02 15:05:35,796 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:05:35,797 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:05:39,920 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:R4LEQoUefL0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlujC9i7lRJirU2YdLJGc3O12wnIT&scisf=3&ct=citation&cd=163&hl=en HTTP/1.1" 200 191
[2018-03-02 15:05:39,921 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Safety in AI-HRI: Challenges Complementing User Experience Quality
%A Freedman, Richard G
%A Zilberstein, Shlomo
%B 2016 AAAI Fall Symposium Series
%D 2016

[2018-03-02 15:05:39,921 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:05:39,921 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:05:39,921 DEBUG __main__] Process content of EndNote file #164
{"title": "Safety in AI-HRI: Challenges Complementing User Experience Quality", "url": "http://www.aaai.org/ocs/index.php/FSS/FSS16/paper/download/14128/13663", "author": [{"shortname": "RG Freedman", "gid": "xzxQFKQAAAAJ"}, {"shortname": "S Zilberstein", "gid": "q_n7d6EAAAAJ"}], "year": 2016}
{"type": "Conference Proceedings", "title": "Safety in AI-HRI: Challenges Complementing User Experience Quality", "author": ["Freedman, Richard G", "Zilberstein, Shlomo"], "secondarytitle": "2016 AAAI Fall Symposium Series", "year": "2016", "EndNote": "%0 Conference Proceedings\n%T Safety in AI-HRI: Challenges Complementing User Experience Quality\n%A Freedman, Richard G\n%A Zilberstein, Shlomo\n%B 2016 AAAI Fall Symposium Series\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:R4LEQoUefL0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlujC9i7lRJirU2YdLJGc3O12wnIT&scisf=3&ct=citation&cd=163&hl=en"}
[2018-03-02 15:05:39,921 DEBUG dbutils] Get paper id {"DOI": null, "title": "Safety in AI-HRI: Challenges Complementing User Experience Quality", "auth_count": 2, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:05:39,921 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Safety in AI-HRI: Challenges Complementing User Experience Quality', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:05:39,921 DEBUG dbutils] Query result: []
[2018-03-02 15:05:39,922 DEBUG dbutils] Paper id = None.
[2018-03-02 15:05:39,922 DEBUG dbutils] Add new paper (title='Safety in AI-HRI: Challenges Complementing User Experience Quality')
[2018-03-02 15:05:39,922 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Safety in AI-HRI: Challenges Complementing User Experience Quality', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Safety in AI-HRI: Challenges Complementing User Experience Quality\n%A Freedman, Richard G\n%A Zilberstein, Shlomo\n%B 2016 AAAI Fall Symposium Series\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:05:39,922 DEBUG dbutils] Query result: 152
[2018-03-02 15:05:39,923 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aaai.org/ocs/index.php/FSS/FSS16/paper/download/14128/13663.
[2018-03-02 15:05:39,925 WARNING utils] Download file (url='http://www.aaai.org/ocs/index.php/FSS/FSS16/paper/download/14128/13663') and save (filename='PDF//152.pdf')
[2018-03-02 15:05:39,925 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 15:05:39,925 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:05:39,940 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aaai.org
[2018-03-02 15:05:41,050 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/FSS/FSS16/paper/download/14128/13663 HTTP/1.1" 200 None
[2018-03-02 15:05:41,060 DEBUG utils] Try get PDF from https://www.aaai.org/ocs/index.php/FSS/FSS16/paper/download/14128/13663.
[2018-03-02 15:05:41,060 WARNING utils] Download file (url='https://www.aaai.org/ocs/index.php/FSS/FSS16/paper/download/14128/13663') and save (filename='PDF//152.pdf')
[2018-03-02 15:05:41,060 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 15:05:41,060 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:05:41,060 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for otherhost
[2018-03-02 15:05:41,075 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.aaai.org
[2018-03-02 15:05:46,077 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770577B4E0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.aaai.org', port=443): Max retries exceeded with url: /ocs/index.php/FSS/FSS16/paper/download/14128/13663 (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770577B4E0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='www.aaai.org', port=443): Max retries exceeded with url: /ocs/index.php/FSS/FSS16/paper/download/14128/13663 (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x000000770577B4E0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 15:05:46,077 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for otherhost
[2018-03-02 15:05:46,077 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 15:05:46,077 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:05:46,093 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.aaai.org
[2018-03-02 15:05:48,102 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/FSS/FSS16/paper/download/14128/13663 HTTP/1.1" 200 479345
[2018-03-02 15:05:48,103 DEBUG utils] Content-length=479345
[2018-03-02 15:05:48,103 DEBUG utils] Create file PDF//152.pdf, start download.
[2018-03-02 15:05:52,250 DEBUG utils] End download file PDF//152.pdf.
[2018-03-02 15:05:52,253 DEBUG dbutils] Update pdf_transaction for paper id=152.
[2018-03-02 15:05:52,253 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 152'
[2018-03-02 15:05:52,253 DEBUG dbutils] Query result: null
[2018-03-02 15:05:52,253 DEBUG scholar] Handle paper #165 (total 1170)
[2018-03-02 15:05:52,253 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:05:52,259 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:52,259 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:05:52,730 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:8zmRWw3r2UEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlpXEOMjBpCh0ZYWeImeZkIkxYduj&scisf=3&ct=citation&cd=164&hl=en HTTP/1.1" 200 120
[2018-03-02 15:05:52,731 DEBUG scholar] EndNote file:
%0 Journal Article
%T Sequence-to-Sequence Learning for End-to-End Dialogue Systems
%A Van Landeghem, Jordy
%D 2016

[2018-03-02 15:05:52,731 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:05:52,731 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:05:52,732 DEBUG __main__] Process content of EndNote file #165
{"title": "Sequence-to-Sequence Learning for End-to-End Dialogue Systems", "url": "https://www.researchgate.net/profile/Jordy_Van_Landeghem/publication/313375963_Presentation_on_end-to-end_results_of_the_project/data/589884beaca2721f0daf3173/February06.pdf", "author": [{"shortname": "J Van Landeghem", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "Sequence-to-Sequence Learning for End-to-End Dialogue Systems", "author": ["Van Landeghem, Jordy"], "year": "2016", "EndNote": "%0 Journal Article\n%T Sequence-to-Sequence Learning for End-to-End Dialogue Systems\n%A Van Landeghem, Jordy\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:8zmRWw3r2UEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlpXEOMjBpCh0ZYWeImeZkIkxYduj&scisf=3&ct=citation&cd=164&hl=en"}
[2018-03-02 15:05:52,732 DEBUG dbutils] Get paper id {"DOI": null, "title": "Sequence-to-Sequence Learning for End-to-End Dialogue Systems", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:05:52,732 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Sequence-to-Sequence Learning for End-to-End Dialogue Systems', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:05:52,732 DEBUG dbutils] Query result: []
[2018-03-02 15:05:52,732 DEBUG dbutils] Paper id = None.
[2018-03-02 15:05:52,732 DEBUG dbutils] Add new paper (title='Sequence-to-Sequence Learning for End-to-End Dialogue Systems')
[2018-03-02 15:05:52,732 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Sequence-to-Sequence Learning for End-to-End Dialogue Systems', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Sequence-to-Sequence Learning for End-to-End Dialogue Systems\n%A Van Landeghem, Jordy\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:05:52,732 DEBUG dbutils] Query result: 153
[2018-03-02 15:05:52,734 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Jordy_Van_Landeghem/publication/313375963_Presentation_on_end-to-end_results_of_the_project/data/589884beaca2721f0daf3173/February06.pdf.
[2018-03-02 15:05:52,735 WARNING utils] Download file (url='https://www.researchgate.net/profile/Jordy_Van_Landeghem/publication/313375963_Presentation_on_end-to-end_results_of_the_project/data/589884beaca2721f0daf3173/February06.pdf') and save (filename='PDF//153.pdf')
[2018-03-02 15:05:52,735 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:05:52,735 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:05:52,735 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for www.researchgate.net
[2018-03-02 15:05:52,750 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:05:54,329 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Jordy_Van_Landeghem/publication/313375963_Presentation_on_end-to-end_results_of_the_project/data/589884beaca2721f0daf3173/February06.pdf HTTP/1.1" 429 None
[2018-03-02 15:05:54,733 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for www.researchgate.net
[2018-03-02 15:05:54,734 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:05:54,734 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:05:54,751 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:05:56,240 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Jordy_Van_Landeghem/publication/313375963_Presentation_on_end-to-end_results_of_the_project/data/589884beaca2721f0daf3173/February06.pdf HTTP/1.1" 200 1480079
[2018-03-02 15:05:56,240 DEBUG utils] Content-length=1480079
[2018-03-02 15:05:56,241 DEBUG utils] Create file PDF//153.pdf, start download.
[2018-03-02 15:05:59,757 DEBUG utils] End download file PDF//153.pdf.
[2018-03-02 15:05:59,758 DEBUG dbutils] Update pdf_transaction for paper id=153.
[2018-03-02 15:05:59,758 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 153'
[2018-03-02 15:05:59,758 DEBUG dbutils] Query result: null
[2018-03-02 15:05:59,759 DEBUG scholar] Handle paper #166 (total 1170)
[2018-03-02 15:05:59,759 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:05:59,762 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:05:59,763 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:05:59,763 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for scholar.google.com
[2018-03-02 15:05:59,785 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:05:59,786 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:01,779 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:PmafmghCxlEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlgb7PcaE0NxY3RzauHPTtqPviqmH&scisf=3&ct=citation&cd=165&hl=en HTTP/1.1" 200 196
[2018-03-02 15:06:01,780 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T A virtual laboratory model for encouraging undergraduate research
%A Way, Thomas P
%B ACM SIGCSE Bulletin
%V 38
%N 1
%P 203-207
%@ 1595932593
%D 2006
%I ACM

[2018-03-02 15:06:01,780 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:01,780 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:01,781 DEBUG __main__] Process content of EndNote file #166
{"title": "A virtual laboratory model for encouraging undergraduate research", "url": "https://dl.acm.org/citation.cfm?id=1121406", "author": [{"shortname": "TP Way", "gid": ""}], "year": 2006}
{"citedby": 21, "type": "Conference Proceedings", "title": "A virtual laboratory model for encouraging undergraduate research", "author": ["Way, Thomas P"], "secondarytitle": "ACM SIGCSE Bulletin", "volume": 5, "numberorissue": "1", "pages": "203-207", "isbn/issn": "1595932593", "year": "2006", "publisher": "ACM", "start_page": 203, "end_page": 207, "EndNote": "%0 Conference Proceedings\n%T A virtual laboratory model for encouraging undergraduate research\n%A Way, Thomas P\n%B ACM SIGCSE Bulletin\n%V 38\n%N 1\n%P 203-207\n%@ 1595932593\n%D 2006\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:PmafmghCxlEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlgb7PcaE0NxY3RzauHPTtqPviqmH&scisf=3&ct=citation&cd=165&hl=en"}
[2018-03-02 15:06:01,781 DEBUG dbutils] Get paper id {"DOI": null, "title": "A virtual laboratory model for encouraging undergraduate research", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 5, "year": 2006, "rg_id": null, "start_page": 203, "end_page": 207}.
[2018-03-02 15:06:01,781 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A virtual laboratory model for encouraging undergraduate research', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2006, 'rg_id': None, 'start_page': 203, 'end_page': 207}
[2018-03-02 15:06:01,781 DEBUG dbutils] Query result: []
[2018-03-02 15:06:01,781 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:01,781 DEBUG dbutils] Add new paper (title='A virtual laboratory model for encouraging undergraduate research')
[2018-03-02 15:06:01,781 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A virtual laboratory model for encouraging undergraduate research', 'year': 2006, 'publisher': 'ACM', 'start_page': 203, 'end_page': 207, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T A virtual laboratory model for encouraging undergraduate research\n%A Way, Thomas P\n%B ACM SIGCSE Bulletin\n%V 38\n%N 1\n%P 203-207\n%@ 1595932593\n%D 2006\n%I ACM\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:01,781 DEBUG dbutils] Query result: 154
[2018-03-02 15:06:01,783 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Thomas_Way/publication/221538308_A_Virtual_Laboratory_Model_for_Encouraging_Undergraduate_Research/links/566ccc6d08ae1a797e3db173/A-Virtual-Laboratory-Model-for-Encouraging-Undergraduate-Research.pdf.
[2018-03-02 15:06:01,785 WARNING utils] Download file (url='https://www.researchgate.net/profile/Thomas_Way/publication/221538308_A_Virtual_Laboratory_Model_for_Encouraging_Undergraduate_Research/links/566ccc6d08ae1a797e3db173/A-Virtual-Laboratory-Model-for-Encouraging-Undergraduate-Research.pdf') and save (filename='PDF//154.pdf')
[2018-03-02 15:06:01,786 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:06:01,786 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:06:01,786 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for www.researchgate.net
[2018-03-02 15:06:01,802 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:06:03,052 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Thomas_Way/publication/221538308_A_Virtual_Laboratory_Model_for_Encouraging_Undergraduate_Research/links/566ccc6d08ae1a797e3db173/A-Virtual-Laboratory-Model-for-Encouraging-Undergraduate-Research.pdf HTTP/1.1" 200 279159
[2018-03-02 15:06:03,053 DEBUG utils] Content-length=279159
[2018-03-02 15:06:03,054 DEBUG utils] Create file PDF//154.pdf, start download.
[2018-03-02 15:06:03,731 DEBUG utils] End download file PDF//154.pdf.
[2018-03-02 15:06:03,732 DEBUG dbutils] Update pdf_transaction for paper id=154.
[2018-03-02 15:06:03,732 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 154'
[2018-03-02 15:06:03,732 DEBUG dbutils] Query result: null
[2018-03-02 15:06:03,732 DEBUG scholar] Handle paper #167 (total 1170)
[2018-03-02 15:06:03,732 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:06:03,736 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:03,736 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:06:04,080 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:w72dl2qa8ZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAloXs-QO69QFg941JyJ02xpNHpt80&scisf=3&ct=citation&cd=166&hl=en HTTP/1.1" 200 239
[2018-03-02 15:06:04,081 DEBUG scholar] EndNote file:
%0 Journal Article
%T Language learning in mindbodyworld: A sociocognitive approach to second language acquisition
%A Atkinson, Dwight
%J Language Teaching
%V 47
%N 4
%P 467-483
%@ 0261-4448
%D 2014
%I Cambridge University Press

[2018-03-02 15:06:04,081 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:04,081 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:04,082 DEBUG __main__] Process content of EndNote file #167
{"title": "Language learning in mindbodyworld: A sociocognitive approach to second language acquisition", "url": "https://www.cambridge.org/core/journals/language-teaching/article/language-learning-in-mindbodyworld-a-sociocognitive-approach-to-second-language-acquisition/F8F022E944921041EE09639D69302694", "author": [{"shortname": "D Atkinson", "gid": "f8QZ68QAAAAJ"}], "year": 2014}
{"citedby": 28, "type": "Journal Article", "title": "Language learning in mindbodyworld: A sociocognitive approach to second language acquisition", "author": ["Atkinson, Dwight"], "journal": "Language Teaching", "volume": 17, "numberorissue": "4", "pages": "467-483", "isbn/issn": "0261-4448", "year": "2014", "publisher": "Cambridge University Press", "start_page": 467, "end_page": 483, "EndNote": "%0 Journal Article\n%T Language learning in mindbodyworld: A sociocognitive approach to second language acquisition\n%A Atkinson, Dwight\n%J Language Teaching\n%V 47\n%N 4\n%P 467-483\n%@ 0261-4448\n%D 2014\n%I Cambridge University Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:w72dl2qa8ZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAloXs-QO69QFg941JyJ02xpNHpt80&scisf=3&ct=citation&cd=166&hl=en"}
[2018-03-02 15:06:04,082 DEBUG dbutils] Get paper id {"DOI": null, "title": "Language learning in mindbodyworld: A sociocognitive approach to second language acquisition", "auth_count": 1, "g_type": "Journal Article", "pages": 17, "year": 2014, "rg_id": null, "start_page": 467, "end_page": 483}.
[2018-03-02 15:06:04,082 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Language learning in mindbodyworld: A sociocognitive approach to second language acquisition', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 17, 'year': 2014, 'rg_id': None, 'start_page': 467, 'end_page': 483}
[2018-03-02 15:06:04,082 DEBUG dbutils] Query result: []
[2018-03-02 15:06:04,082 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:04,082 DEBUG dbutils] Add new paper (title='Language learning in mindbodyworld: A sociocognitive approach to second language acquisition')
[2018-03-02 15:06:04,083 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Language learning in mindbodyworld: A sociocognitive approach to second language acquisition', 'year': 2014, 'publisher': 'Cambridge University Press', 'start_page': 467, 'end_page': 483, 'pages': 17, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Language learning in mindbodyworld: A sociocognitive approach to second language acquisition\n%A Atkinson, Dwight\n%J Language Teaching\n%V 47\n%N 4\n%P 467-483\n%@ 0261-4448\n%D 2014\n%I Cambridge University Press\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:04,083 DEBUG dbutils] Query result: 155
[2018-03-02 15:06:04,085 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.cambridge.org/core/journals/language-teaching/article/language-learning-in-mindbodyworld-a-sociocognitive-approach-to-second-language-acquisition/F8F022E944921041EE09639D69302694.
[2018-03-02 15:06:04,086 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.cambridge.org/core/journals/language-teaching/article/language-learning-in-mindbodyworld-a-sociocognitive-approach-to-second-language-acquisition/F8F022E944921041EE09639D69302694.
[2018-03-02 15:06:04,275 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/language-teaching/article/language-learning-in-mindbodyworld-a-sociocognitive-approach-to-second-language-acquisition/F8F022E944921041EE09639D69302694 HTTP/1.1" 200 None
[2018-03-02 15:06:04,276 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:06:04,276 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:06:04,429 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/language-teaching/article/language-learning-in-mindbodyworld-a-sociocognitive-approach-to-second-language-acquisition/F8F022E944921041EE09639D69302694 HTTP/1.1" 200 None
[2018-03-02 15:06:04,435 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true.
[2018-03-02 15:06:04,435 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true') and save (filename='PDF//155.pdf')
[2018-03-02 15:06:04,454 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cyber.sci-hub.tw
[2018-03-02 15:06:04,694 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:06:04,695 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:06:04,695 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:06:04,695 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for sci-hub.tw
[2018-03-02 15:06:04,712 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): cyber.sci-hub.tw
[2018-03-02 15:06:04,921 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:06:04,932 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:06:04,932 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:06:17,440 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:06:17,441 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:06:17,721 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true HTTP/1.1" 200 342960
[2018-03-02 15:06:17,721 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:06:17,722 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:06:17,736 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): cyber.sci-hub.tw
[2018-03-02 15:06:18,102 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMzAwMDE1Mw==/atkinson2013.pdf?download=true HTTP/1.1" 200 342960
[2018-03-02 15:06:18,103 DEBUG utils] Content-length=342960
[2018-03-02 15:06:18,103 DEBUG utils] Create file PDF//155.pdf, start download.
[2018-03-02 15:06:18,909 DEBUG utils] End download file PDF//155.pdf.
[2018-03-02 15:06:18,910 DEBUG dbutils] Update pdf_transaction for paper id=155.
[2018-03-02 15:06:18,910 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 155'
[2018-03-02 15:06:18,910 DEBUG dbutils] Query result: null
[2018-03-02 15:06:18,911 DEBUG scholar] Handle paper #168 (total 1170)
[2018-03-02 15:06:18,912 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:06:18,915 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:18,915 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:06:18,916 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for scholar.google.com
[2018-03-02 15:06:18,940 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:06:18,942 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:20,830 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:p-KDnEaP2twJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAltxT7mk69kak95PVP6xnhfaRRoSs&scisf=3&ct=citation&cd=167&hl=en HTTP/1.1" 200 239
[2018-03-02 15:06:20,831 DEBUG scholar] EndNote file:
%0 Journal Article
%T On the evaluation of dialogue systems with next utterance classification
%A Lowe, Ryan
%A Serban, Iulian V
%A Noseworthy, Mike
%A Charlin, Laurent
%A Pineau, Joelle
%J arXiv preprint arXiv:1605.05414
%D 2016

[2018-03-02 15:06:20,831 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:20,831 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:20,832 DEBUG __main__] Process content of EndNote file #168
{"title": "On the evaluation of dialogue systems with next utterance classification", "url": "https://arxiv.org/abs/1605.05414", "author": [{"shortname": "R Lowe", "gid": "iRgYMuEAAAAJ"}, {"shortname": "IV Serban", "gid": "0g31OfAAAAAJ"}, {"shortname": "M Noseworthy", "gid": "Ybj21gEAAAAJ"}, {"shortname": "L Charlin", "gid": "Cul0g2YAAAAJ"}], "year": 2016}
{"citedby": 12, "type": "Journal Article", "title": "On the evaluation of dialogue systems with next utterance classification", "author": ["Lowe, Ryan", "Serban, Iulian V", "Noseworthy, Mike", "Charlin, Laurent", "Pineau, Joelle"], "journal": "arXiv preprint arXiv:1605.05414", "year": "2016", "EndNote": "%0 Journal Article\n%T On the evaluation of dialogue systems with next utterance classification\n%A Lowe, Ryan\n%A Serban, Iulian V\n%A Noseworthy, Mike\n%A Charlin, Laurent\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1605.05414\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:p-KDnEaP2twJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAltxT7mk69kak95PVP6xnhfaRRoSs&scisf=3&ct=citation&cd=167&hl=en"}
[2018-03-02 15:06:20,832 DEBUG dbutils] Get paper id {"DOI": null, "title": "On the evaluation of dialogue systems with next utterance classification", "auth_count": 5, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:06:20,832 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'On the evaluation of dialogue systems with next utterance classification', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:06:20,832 DEBUG dbutils] Query result: []
[2018-03-02 15:06:20,832 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:20,832 DEBUG dbutils] Add new paper (title='On the evaluation of dialogue systems with next utterance classification')
[2018-03-02 15:06:20,832 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'On the evaluation of dialogue systems with next utterance classification', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T On the evaluation of dialogue systems with next utterance classification\n%A Lowe, Ryan\n%A Serban, Iulian V\n%A Noseworthy, Mike\n%A Charlin, Laurent\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1605.05414\n%D 2016\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:20,832 DEBUG dbutils] Query result: 156
[2018-03-02 15:06:20,833 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1605.05414.
[2018-03-02 15:06:20,835 WARNING utils] Download file (url='https://arxiv.org/pdf/1605.05414') and save (filename='PDF//156.pdf')
[2018-03-02 15:06:20,835 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:06:20,835 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:06:20,835 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for otherhost
[2018-03-02 15:06:20,850 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 15:06:22,739 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.05414 HTTP/1.1" 302 280
[2018-03-02 15:06:23,479 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.05414.pdf HTTP/1.1" 200 194583
[2018-03-02 15:06:23,480 DEBUG utils] Content-length=194583
[2018-03-02 15:06:23,481 DEBUG utils] Create file PDF//156.pdf, start download.
[2018-03-02 15:06:24,289 DEBUG utils] End download file PDF//156.pdf.
[2018-03-02 15:06:24,290 DEBUG dbutils] Update pdf_transaction for paper id=156.
[2018-03-02 15:06:24,290 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 156'
[2018-03-02 15:06:24,290 DEBUG dbutils] Query result: null
[2018-03-02 15:06:24,291 DEBUG scholar] Handle paper #169 (total 1170)
[2018-03-02 15:06:24,291 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:06:24,296 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:24,296 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:06:24,619 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:xZCrzzFTbGUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAllaw7FcQdWMbGDjtT09qNCKOJoma&scisf=3&ct=citation&cd=168&hl=en HTTP/1.1" 200 164
[2018-03-02 15:06:24,620 DEBUG scholar] EndNote file:
%0 Journal Article
%T User centric model of E-learning to build up virtual learning environment
%A Pattnayak, Jui
%A Pattnaik, Sabyasachi
%A Dash, Priyaranjan

[2018-03-02 15:06:24,620 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:24,621 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:24,621 DEBUG __main__] Skip paper #169, empty year or authors fields.
[2018-03-02 15:06:24,621 DEBUG scholar] Handle paper #170 (total 1170)
[2018-03-02 15:06:24,621 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:06:24,624 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:24,624 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:06:24,624 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for scholar.google.com
[2018-03-02 15:06:24,639 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:06:24,640 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:27,749 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AWtreunZcFsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplAlrM7Ozslby1ynNIOvsHtuzjiDR7E&scisf=3&ct=citation&cd=169&hl=en HTTP/1.1" 200 128
[2018-03-02 15:06:27,750 DEBUG scholar] EndNote file:
%0 Journal Article
%T MSc INFORMATION TECHNOLOGY (Business) Course Dissertations (Abstracts)
%A ALALSHEKMUBARAK, Abdulrahman

[2018-03-02 15:06:27,750 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:27,750 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:27,750 DEBUG __main__] Skip paper #170, empty year or authors fields.
[2018-03-02 15:06:27,770 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:06:27,770 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:06:27,770 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:06:27,784 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.google.com
[2018-03-02 15:06:27,785 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.google.com
[2018-03-02 15:06:31,154 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=170&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:06:31,865 DEBUG scholar] Find papers on page #18 (max_google_papers = 300)
[2018-03-02 15:06:31,865 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:06:31,866 DEBUG scholar] Handle paper #171 (total 1170)
[2018-03-02 15:06:31,866 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:06:31,870 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:31,870 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:06:31,870 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for scholar.google.com
[2018-03-02 15:06:31,884 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:06:31,886 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:34,218 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Pd39pXR7-MsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA43zojra1vm_Tf5seKmEUQ24l-TZM&scisf=3&ct=citation&cd=170&hl=en HTTP/1.1" 200 80
[2018-03-02 15:06:34,219 DEBUG scholar] EndNote file:
%0 Journal Article
%T Seeking the human in human-like computing
%A Dix, Alan

[2018-03-02 15:06:34,219 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:34,219 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:34,219 DEBUG __main__] Skip paper #171, empty year or authors fields.
[2018-03-02 15:06:34,219 DEBUG scholar] Handle paper #172 (total 1170)
[2018-03-02 15:06:34,220 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:06:34,223 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:34,223 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:06:34,720 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:8AjSB65KzUkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA42c8BLDOP4vNeJLBHOZEs--Bd29I&scisf=3&ct=citation&cd=171&hl=en HTTP/1.1" 200 320
[2018-03-02 15:06:34,721 DEBUG scholar] EndNote file:
%0 Book Section
%T Learning activity system design for autistic children using virtual pink dolphins
%A Chia, Noel Kok Hwee
%A Cai, Yiyu
%A Kee, Norman Kiak Nam
%A Thalmann, Nadia
%A Yang, Bianyue
%A Zheng, Jianmin
%A Thalmann, Daniel
%B 3D immersive and interactive learning
%P 105-121
%D 2013
%I Springer

[2018-03-02 15:06:34,721 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:34,721 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:34,721 DEBUG __main__] Process content of EndNote file #172
{"title": "Learning activity system design for autistic children using virtual pink dolphins", "url": "https://link.springer.com/chapter/10.1007/978-981-4021-90-6_8", "author": [{"shortname": "NKH Chia", "gid": ""}, {"shortname": "Y Cai", "gid": "7i4EbtwAAAAJ"}, {"shortname": "NKN Kee", "gid": ""}, {"shortname": "N Thalmann", "gid": "zSucrdMAAAAJ"}], "year": 2013}
{"citedby": 2, "type": "Book Section", "title": "Learning activity system design for autistic children using virtual pink dolphins", "author": ["Chia, Noel Kok Hwee", "Cai, Yiyu", "Kee, Norman Kiak Nam", "Thalmann, Nadia", "Yang, Bianyue", "Zheng, Jianmin", "Thalmann, Daniel"], "secondarytitle": "3D immersive and interactive learning", "pages": "105-121", "year": "2013", "publisher": "Springer", "start_page": 105, "end_page": 121, "volume": 17, "EndNote": "%0 Book Section\n%T Learning activity system design for autistic children using virtual pink dolphins\n%A Chia, Noel Kok Hwee\n%A Cai, Yiyu\n%A Kee, Norman Kiak Nam\n%A Thalmann, Nadia\n%A Yang, Bianyue\n%A Zheng, Jianmin\n%A Thalmann, Daniel\n%B 3D immersive and interactive learning\n%P 105-121\n%D 2013\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:8AjSB65KzUkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA42c8BLDOP4vNeJLBHOZEs--Bd29I&scisf=3&ct=citation&cd=171&hl=en"}
[2018-03-02 15:06:34,721 DEBUG dbutils] Get paper id {"DOI": null, "title": "Learning activity system design for autistic children using virtual pink dolphins", "auth_count": 7, "g_type": "Book Section", "pages": 17, "year": 2013, "rg_id": null, "start_page": 105, "end_page": 121}.
[2018-03-02 15:06:34,722 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Learning activity system design for autistic children using virtual pink dolphins', 'auth_count': 7, 'g_type': 'Book Section', 'pages': 17, 'year': 2013, 'rg_id': None, 'start_page': 105, 'end_page': 121}
[2018-03-02 15:06:34,722 DEBUG dbutils] Query result: []
[2018-03-02 15:06:34,722 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:34,722 DEBUG dbutils] Add new paper (title='Learning activity system design for autistic children using virtual pink dolphins')
[2018-03-02 15:06:34,722 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Learning activity system design for autistic children using virtual pink dolphins', 'year': 2013, 'publisher': 'Springer', 'start_page': 105, 'end_page': 121, 'pages': 17, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Learning activity system design for autistic children using virtual pink dolphins\n%A Chia, Noel Kok Hwee\n%A Cai, Yiyu\n%A Kee, Norman Kiak Nam\n%A Thalmann, Nadia\n%A Yang, Bianyue\n%A Zheng, Jianmin\n%A Thalmann, Daniel\n%B 3D immersive and interactive learning\n%P 105-121\n%D 2013\n%I Springer\n', 'RIS': None, 'authors': 7, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:34,722 DEBUG dbutils] Query result: 157
[2018-03-02 15:06:34,724 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-981-4021-90-6_8.
[2018-03-02 15:06:34,724 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-981-4021-90-6_8.
[2018-03-02 15:06:34,908 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-981-4021-90-6_8 HTTP/1.1" 302 None
[2018-03-02 15:06:34,931 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 15:06:38,400 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=567CE06FA24F94EE266A43A423B27428 HTTP/1.1" 200 9693
[2018-03-02 15:06:38,489 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:06:38,489 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:06:38,489 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for sci-hub.tw
[2018-03-02 15:06:38,668 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-981-4021-90-6_8 HTTP/1.1" 302 None
[2018-03-02 15:06:38,929 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=567CE06FA24F94EE266A43A423B27428 HTTP/1.1" 200 9693
[2018-03-02 15:06:39,171 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:06:39,172 DEBUG scholar] Handle paper #173 (total 1170)
[2018-03-02 15:06:39,172 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:06:39,177 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:39,177 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:06:39,177 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for scholar.google.com
[2018-03-02 15:06:39,191 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:06:39,192 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:40,548 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:J33KYDvFxRsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4yFXgM29A43nzC3iHNqqovoDl4wp&scisf=3&ct=citation&cd=172&hl=en HTTP/1.1" 200 244
[2018-03-02 15:06:40,548 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Using XNA-GSE game segments to engage students in advanced computer science education
%A Youngblood, G Michael
%B Proc. of the 2007 Conference on Game Development in Computer Science Eduation
%P 70-74
%D 2007

[2018-03-02 15:06:40,548 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:40,548 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:40,548 DEBUG __main__] Process content of EndNote file #173
{"title": "Using XNA-GSE game segments to engage students in advanced computer science education", "url": "https://www.researchgate.net/profile/Marla_Schweppe/publication/242417129_Combining_games_with_theatre_to_create_an_interdisciplinary_learning_experience_for_Computer_Science_students/links/53f477ba0cf2fceacc6e8000.pdf#page=71", "author": [{"shortname": "GM Youngblood", "gid": "7wuJg5EAAAAJ"}], "year": 2007}
{"citedby": 11, "type": "Conference Proceedings", "title": "Using XNA-GSE game segments to engage students in advanced computer science education", "author": ["Youngblood, G Michael"], "secondarytitle": "Proc. of the 2007 Conference on Game Development in Computer Science Eduation", "pages": "70-74", "year": "2007", "start_page": 70, "end_page": 74, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T Using XNA-GSE game segments to engage students in advanced computer science education\n%A Youngblood, G Michael\n%B Proc. of the 2007 Conference on Game Development in Computer Science Eduation\n%P 70-74\n%D 2007\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:J33KYDvFxRsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4yFXgM29A43nzC3iHNqqovoDl4wp&scisf=3&ct=citation&cd=172&hl=en"}
[2018-03-02 15:06:40,549 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using XNA-GSE game segments to engage students in advanced computer science education", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 5, "year": 2007, "rg_id": null, "start_page": 70, "end_page": 74}.
[2018-03-02 15:06:40,549 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using XNA-GSE game segments to engage students in advanced computer science education', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2007, 'rg_id': None, 'start_page': 70, 'end_page': 74}
[2018-03-02 15:06:40,549 DEBUG dbutils] Query result: []
[2018-03-02 15:06:40,549 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:40,549 DEBUG dbutils] Add new paper (title='Using XNA-GSE game segments to engage students in advanced computer science education')
[2018-03-02 15:06:40,549 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using XNA-GSE game segments to engage students in advanced computer science education', 'year': 2007, 'publisher': None, 'start_page': 70, 'end_page': 74, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Using XNA-GSE game segments to engage students in advanced computer science education\n%A Youngblood, G Michael\n%B Proc. of the 2007 Conference on Game Development in Computer Science Eduation\n%P 70-74\n%D 2007\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:40,549 DEBUG dbutils] Query result: 158
[2018-03-02 15:06:40,551 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Marla_Schweppe/publication/242417129_Combining_games_with_theatre_to_create_an_interdisciplinary_learning_experience_for_Computer_Science_students/links/53f477ba0cf2fceacc6e8000.pdf#page=71.
[2018-03-02 15:06:40,553 WARNING utils] Download file (url='https://www.researchgate.net/profile/Marla_Schweppe/publication/242417129_Combining_games_with_theatre_to_create_an_interdisciplinary_learning_experience_for_Computer_Science_students/links/53f477ba0cf2fceacc6e8000.pdf#page=71') and save (filename='PDF//158.pdf')
[2018-03-02 15:06:40,553 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:06:40,554 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:06:41,963 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Marla_Schweppe/publication/242417129_Combining_games_with_theatre_to_create_an_interdisciplinary_learning_experience_for_Computer_Science_students/links/53f477ba0cf2fceacc6e8000.pdf HTTP/1.1" 200 5822736
[2018-03-02 15:06:41,964 DEBUG utils] Content-length=5822736
[2018-03-02 15:06:41,965 DEBUG utils] Create file PDF//158.pdf, start download.
[2018-03-02 15:06:46,983 DEBUG utils] End download file PDF//158.pdf.
[2018-03-02 15:06:46,985 DEBUG dbutils] Update pdf_transaction for paper id=158.
[2018-03-02 15:06:46,985 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 158'
[2018-03-02 15:06:46,985 DEBUG dbutils] Query result: null
[2018-03-02 15:06:46,985 DEBUG scholar] Handle paper #174 (total 1170)
[2018-03-02 15:06:46,985 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:06:46,989 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:46,989 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:06:47,258 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:X7Oi8fm9MSoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA47n9a9zWhW2kWwq1QP2YDiAzS_Aa&scisf=3&ct=citation&cd=173&hl=en HTTP/1.1" 200 208
[2018-03-02 15:06:47,259 DEBUG scholar] EndNote file:
%0 Journal Article
%T The restaurant game: Learning social behavior and language from thousands of players online
%A Orkin, Jeff
%A Roy, Deb
%J Journal of Game Development
%V 3
%N 1
%P 39-60
%D 2007

[2018-03-02 15:06:47,259 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:47,260 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:47,260 DEBUG __main__] Process content of EndNote file #174
{"title": "The restaurant game: Learning social behavior and language from thousands of players online", "url": "https://www.researchgate.net/profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf", "author": [{"shortname": "J Orkin", "gid": "6jeMM0sAAAAJ"}, {"shortname": "D Roy", "gid": "btoec6QAAAAJ"}], "year": 2007}
{"citedby": 131, "type": "Journal Article", "title": "The restaurant game: Learning social behavior and language from thousands of players online", "author": ["Orkin, Jeff", "Roy, Deb"], "journal": "Journal of Game Development", "volume": 22, "numberorissue": "1", "pages": "39-60", "year": "2007", "start_page": 39, "end_page": 60, "EndNote": "%0 Journal Article\n%T The restaurant game: Learning social behavior and language from thousands of players online\n%A Orkin, Jeff\n%A Roy, Deb\n%J Journal of Game Development\n%V 3\n%N 1\n%P 39-60\n%D 2007\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:X7Oi8fm9MSoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA47n9a9zWhW2kWwq1QP2YDiAzS_Aa&scisf=3&ct=citation&cd=173&hl=en"}
[2018-03-02 15:06:47,260 DEBUG dbutils] Get paper id {"DOI": null, "title": "The restaurant game: Learning social behavior and language from thousands of players online", "auth_count": 2, "g_type": "Journal Article", "pages": 22, "year": 2007, "rg_id": null, "start_page": 39, "end_page": 60}.
[2018-03-02 15:06:47,260 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The restaurant game: Learning social behavior and language from thousands of players online', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 22, 'year': 2007, 'rg_id': None, 'start_page': 39, 'end_page': 60}
[2018-03-02 15:06:47,260 DEBUG dbutils] Query result: []
[2018-03-02 15:06:47,260 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:47,260 DEBUG dbutils] Add new paper (title='The restaurant game: Learning social behavior and language from thousands of players online')
[2018-03-02 15:06:47,260 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The restaurant game: Learning social behavior and language from thousands of players online', 'year': 2007, 'publisher': None, 'start_page': 39, 'end_page': 60, 'pages': 22, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The restaurant game: Learning social behavior and language from thousands of players online\n%A Orkin, Jeff\n%A Roy, Deb\n%J Journal of Game Development\n%V 3\n%N 1\n%P 39-60\n%D 2007\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:47,260 DEBUG dbutils] Query result: 159
[2018-03-02 15:06:47,262 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf.
[2018-03-02 15:06:47,263 WARNING utils] Download file (url='https://www.researchgate.net/profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf') and save (filename='PDF//159.pdf')
[2018-03-02 15:06:47,263 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:06:47,263 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:06:47,263 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for www.researchgate.net
[2018-03-02 15:06:47,278 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:06:48,204 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 503 Service Unavailable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable',)))

[2018-03-02 15:06:48,204 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for www.researchgate.net
[2018-03-02 15:06:48,204 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:06:48,204 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:06:48,219 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:06:49,089 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:06:49,089 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for www.researchgate.net
[2018-03-02 15:06:49,090 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:06:49,090 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:06:49,105 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:06:50,521 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Jeff_Orkin/publication/228359525_The_Restaurant_Game_Learning_social_behavior_and_language_from_thousands_of_players_online/links/00b4952bdba93c281d000000.pdf HTTP/1.1" 200 4062162
[2018-03-02 15:06:50,522 DEBUG utils] Content-length=4062162
[2018-03-02 15:06:50,522 DEBUG utils] Create file PDF//159.pdf, start download.
[2018-03-02 15:06:53,887 DEBUG utils] End download file PDF//159.pdf.
[2018-03-02 15:06:53,888 DEBUG dbutils] Update pdf_transaction for paper id=159.
[2018-03-02 15:06:53,888 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 159'
[2018-03-02 15:06:53,888 DEBUG dbutils] Query result: null
[2018-03-02 15:06:53,888 DEBUG scholar] Handle paper #175 (total 1170)
[2018-03-02 15:06:53,889 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:06:53,896 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:06:53,896 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:06:53,896 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for scholar.google.com
[2018-03-02 15:06:53,912 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:06:53,913 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:06:55,479 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:-_n2E2DJBToJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4-vz2XNcRRsAptnLatDmL8bCM1dq&scisf=3&ct=citation&cd=174&hl=en HTTP/1.1" 200 121
[2018-03-02 15:06:55,480 DEBUG scholar] EndNote file:
%0 Journal Article
%T Text stylometry for chat bot identification and intelligence estimation.
%A Ali, Nawaf
%D 2014

[2018-03-02 15:06:55,480 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:06:55,481 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:06:55,481 DEBUG __main__] Process content of EndNote file #175
{"title": "Text stylometry for chat bot identification and intelligence estimation.", "url": "http://ir.library.louisville.edu/etd/31/", "author": [{"shortname": "N Ali", "gid": "Px8XoecAAAAJ"}], "year": 2014}
{"citedby": 3, "type": "Journal Article", "title": "Text stylometry for chat bot identification and intelligence estimation.", "author": ["Ali, Nawaf"], "year": "2014", "EndNote": "%0 Journal Article\n%T Text stylometry for chat bot identification and intelligence estimation.\n%A Ali, Nawaf\n%D 2014\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:-_n2E2DJBToJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4-vz2XNcRRsAptnLatDmL8bCM1dq&scisf=3&ct=citation&cd=174&hl=en"}
[2018-03-02 15:06:55,481 DEBUG dbutils] Get paper id {"DOI": null, "title": "Text stylometry for chat bot identification and intelligence estimation.", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:06:55,481 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Text stylometry for chat bot identification and intelligence estimation.', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:06:55,481 DEBUG dbutils] Query result: []
[2018-03-02 15:06:55,481 DEBUG dbutils] Paper id = None.
[2018-03-02 15:06:55,481 DEBUG dbutils] Add new paper (title='Text stylometry for chat bot identification and intelligence estimation.')
[2018-03-02 15:06:55,481 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Text stylometry for chat bot identification and intelligence estimation.', 'year': 2014, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Text stylometry for chat bot identification and intelligence estimation.\n%A Ali, Nawaf\n%D 2014\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:06:55,482 DEBUG dbutils] Query result: 160
[2018-03-02 15:06:55,483 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://ir.library.louisville.edu/cgi/viewcontent.cgi?article=1030&context=etd.
[2018-03-02 15:06:55,484 WARNING utils] Download file (url='http://ir.library.louisville.edu/cgi/viewcontent.cgi?article=1030&context=etd') and save (filename='PDF//160.pdf')
[2018-03-02 15:06:55,484 DEBUG utils] Get current proxy for ir.library.louisville.edu.
[2018-03-02 15:06:55,484 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:06:55,499 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): ir.library.louisville.edu
[2018-03-02 15:06:56,281 DEBUG requests.packages.urllib3.connectionpool] "GET /cgi/viewcontent.cgi?article=1030&context=etd HTTP/1.1" 302 None
[2018-03-02 15:06:56,302 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): ir.library.louisville.edu
[2018-03-02 15:06:58,871 DEBUG requests.packages.urllib3.connectionpool] "GET /cgi/viewcontent.cgi?referer=&httpsredir=1&article=1030&context=etd HTTP/1.1" 200 3649949
[2018-03-02 15:06:58,871 DEBUG utils] Content-length=3649949
[2018-03-02 15:06:58,872 DEBUG utils] Create file PDF//160.pdf, start download.
[2018-03-02 15:07:44,717 DEBUG utils] End download file PDF//160.pdf.
[2018-03-02 15:07:44,719 DEBUG dbutils] Update pdf_transaction for paper id=160.
[2018-03-02 15:07:44,719 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 160'
[2018-03-02 15:07:44,719 DEBUG dbutils] Query result: null
[2018-03-02 15:07:44,720 DEBUG scholar] Handle paper #176 (total 1170)
[2018-03-02 15:07:44,720 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:07:44,726 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:07:44,726 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:07:45,147 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:auaCjxh3_RAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA43mb2WZZYyOdLbOM7yAkQJaKtZ53&scisf=3&ct=citation&cd=175&hl=en HTTP/1.1" 200 270
[2018-03-02 15:07:45,148 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Emotionally responsive robotic avatars as characters in virtual worlds
%A Slater, Stuart
%A Burden, David
%B Games and Virtual Worlds for Serious Applications, 2009. VS-GAMES'09. Conference in
%P 12-19
%@ 0769535887
%D 2009
%I IEEE

[2018-03-02 15:07:45,148 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:07:45,148 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:07:45,148 DEBUG __main__] Process content of EndNote file #176
{"title": "Emotionally responsive robotic avatars as characters in virtual worlds", "url": "http://ieeexplore.ieee.org/abstract/document/5116548/", "author": [{"shortname": "S Slater", "gid": ""}, {"shortname": "D Burden", "gid": ""}], "year": 2009}
{"citedby": 7, "type": "Conference Proceedings", "title": "Emotionally responsive robotic avatars as characters in virtual worlds", "author": ["Slater, Stuart", "Burden, David"], "secondarytitle": "Games and Virtual Worlds for Serious Applications, 2009. VS-GAMES'09. Conference in", "pages": "12-19", "isbn/issn": "0769535887", "year": "2009", "publisher": "IEEE", "start_page": 12, "end_page": 19, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Emotionally responsive robotic avatars as characters in virtual worlds\n%A Slater, Stuart\n%A Burden, David\n%B Games and Virtual Worlds for Serious Applications, 2009. VS-GAMES'09. Conference in\n%P 12-19\n%@ 0769535887\n%D 2009\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:auaCjxh3_RAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA43mb2WZZYyOdLbOM7yAkQJaKtZ53&scisf=3&ct=citation&cd=175&hl=en"}
[2018-03-02 15:07:45,148 DEBUG dbutils] Get paper id {"DOI": null, "title": "Emotionally responsive robotic avatars as characters in virtual worlds", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 8, "year": 2009, "rg_id": null, "start_page": 12, "end_page": 19}.
[2018-03-02 15:07:45,148 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Emotionally responsive robotic avatars as characters in virtual worlds', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2009, 'rg_id': None, 'start_page': 12, 'end_page': 19}
[2018-03-02 15:07:45,149 DEBUG dbutils] Query result: []
[2018-03-02 15:07:45,149 DEBUG dbutils] Paper id = None.
[2018-03-02 15:07:45,149 DEBUG dbutils] Add new paper (title='Emotionally responsive robotic avatars as characters in virtual worlds')
[2018-03-02 15:07:45,149 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Emotionally responsive robotic avatars as characters in virtual worlds', 'year': 2009, 'publisher': 'IEEE', 'start_page': 12, 'end_page': 19, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Conference Proceedings\n%T Emotionally responsive robotic avatars as characters in virtual worlds\n%A Slater, Stuart\n%A Burden, David\n%B Games and Virtual Worlds for Serious Applications, 2009. VS-GAMES'09. Conference in\n%P 12-19\n%@ 0769535887\n%D 2009\n%I IEEE\n", 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:07:45,149 DEBUG dbutils] Query result: 161
[2018-03-02 15:07:45,150 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf.
[2018-03-02 15:07:45,151 WARNING utils] Download file (url='https://www.researchgate.net/profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf') and save (filename='PDF//161.pdf')
[2018-03-02 15:07:45,151 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:07:45,151 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:07:45,151 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for www.researchgate.net
[2018-03-02 15:07:45,167 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:07:47,278 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf HTTP/1.1" 429 None
[2018-03-02 15:07:47,450 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for www.researchgate.net
[2018-03-02 15:07:47,451 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:07:47,451 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:07:47,467 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:07:48,494 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 503 Service Unavailable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable',)))

[2018-03-02 15:07:48,494 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for www.researchgate.net
[2018-03-02 15:07:48,494 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:07:48,495 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:07:48,509 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:07:49,730 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf HTTP/1.1" 429 None
[2018-03-02 15:07:49,912 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for www.researchgate.net
[2018-03-02 15:07:49,912 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:07:49,912 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:07:49,927 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:07:51,946 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf HTTP/1.1" 429 None
[2018-03-02 15:07:52,232 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for www.researchgate.net
[2018-03-02 15:07:52,232 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:07:52,232 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:07:52,246 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:07:55,108 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/David_Burden/publication/224534934_Emotionally_Responsive_Robotic_Avatars_as_Characters_in_Virtual_Worlds/links/00b495180476067c10000000.pdf HTTP/1.1" 200 421771
[2018-03-02 15:07:55,109 DEBUG utils] Content-length=421771
[2018-03-02 15:07:55,109 DEBUG utils] Create file PDF//161.pdf, start download.
[2018-03-02 15:07:57,472 DEBUG utils] End download file PDF//161.pdf.
[2018-03-02 15:07:57,473 DEBUG dbutils] Update pdf_transaction for paper id=161.
[2018-03-02 15:07:57,474 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 161'
[2018-03-02 15:07:57,474 DEBUG dbutils] Query result: null
[2018-03-02 15:07:57,474 DEBUG scholar] Handle paper #177 (total 1170)
[2018-03-02 15:07:57,475 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:07:57,479 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:07:57,480 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:07:57,480 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for scholar.google.com
[2018-03-02 15:07:57,495 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:07:59,588 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:eGRVrRE7KeAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA410ARWwtMNKSCGlt4Np51gFgda-n&scisf=3&ct=citation&cd=176&hl=en HTTP/1.1" 200 305
[2018-03-02 15:07:59,588 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development
%A Sivakumar, Gandhi
%A Johnson, Drew
%A Hodge, Rashida
%B Big Data (Big Data), 2016 IEEE International Conference on
%P 2610-2615
%@ 1467390054
%D 2016
%I IEEE

[2018-03-02 15:07:59,589 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:07:59,589 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:07:59,589 DEBUG __main__] Process content of EndNote file #177
{"title": "Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development", "url": "http://ieeexplore.ieee.org/abstract/document/7840903/", "author": [{"shortname": "G Sivakumar", "gid": ""}, {"shortname": "D Johnson", "gid": ""}], "year": 2016}
{"type": "Conference Proceedings", "title": "Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development", "author": ["Sivakumar, Gandhi", "Johnson, Drew", "Hodge, Rashida"], "secondarytitle": "Big Data (Big Data), 2016 IEEE International Conference on", "pages": "2610-2615", "isbn/issn": "1467390054", "year": "2016", "publisher": "IEEE", "start_page": 2610, "end_page": 2615, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development\n%A Sivakumar, Gandhi\n%A Johnson, Drew\n%A Hodge, Rashida\n%B Big Data (Big Data), 2016 IEEE International Conference on\n%P 2610-2615\n%@ 1467390054\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:eGRVrRE7KeAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA410ARWwtMNKSCGlt4Np51gFgda-n&scisf=3&ct=citation&cd=176&hl=en"}
[2018-03-02 15:07:59,589 DEBUG dbutils] Get paper id {"DOI": null, "title": "Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 6, "year": 2016, "rg_id": null, "start_page": 2610, "end_page": 2615}.
[2018-03-02 15:07:59,589 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2016, 'rg_id': None, 'start_page': 2610, 'end_page': 2615}
[2018-03-02 15:07:59,589 DEBUG dbutils] Query result: []
[2018-03-02 15:07:59,589 DEBUG dbutils] Paper id = None.
[2018-03-02 15:07:59,589 DEBUG dbutils] Add new paper (title='Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development')
[2018-03-02 15:07:59,589 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development', 'year': 2016, 'publisher': 'IEEE', 'start_page': 2610, 'end_page': 2615, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Unravelling the Myth of big data and artificial intelligence in sustainable natural resource development\n%A Sivakumar, Gandhi\n%A Johnson, Drew\n%A Hodge, Rashida\n%B Big Data (Big Data), 2016 IEEE International Conference on\n%P 2610-2615\n%@ 1467390054\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:07:59,590 DEBUG dbutils] Query result: 162
[2018-03-02 15:07:59,591 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7840903/.
[2018-03-02 15:07:59,591 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7840903/.
[2018-03-02 15:07:59,608 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:07:59,867 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7840903/ HTTP/1.1" 200 None
[2018-03-02 15:07:59,868 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:07:59,868 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:08:00,058 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7840903/ HTTP/1.1" 200 None
[2018-03-02 15:08:00,064 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true.
[2018-03-02 15:08:00,065 WARNING utils] Download file (url='http://twin.sci-hub.tw/d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true') and save (filename='PDF//162.pdf')
[2018-03-02 15:08:00,080 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: twin.sci-hub.tw
[2018-03-02 15:08:00,267 DEBUG requests.packages.urllib3.connectionpool] "GET /d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:08:00,268 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:08:00,268 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:08:00,268 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for sci-hub.tw
[2018-03-02 15:08:00,283 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): twin.sci-hub.tw
[2018-03-02 15:08:00,464 DEBUG requests.packages.urllib3.connectionpool] "GET /d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:08:00,467 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:08:00,467 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:08:09,190 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:08:09,191 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:08:09,457 DEBUG requests.packages.urllib3.connectionpool] "GET /d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:08:09,458 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:08:09,458 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:08:09,472 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): twin.sci-hub.tw
[2018-03-02 15:08:09,646 DEBUG requests.packages.urllib3.connectionpool] "GET /d24389528dfcb979b8c1b5328e1134e1/sivakumar2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:08:09,653 DEBUG scholar] Handle paper #178 (total 1170)
[2018-03-02 15:08:09,653 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:08:09,656 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:08:09,657 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:08:10,041 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:TtGZXql9XvgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA41uMvyrYSYnI6o3n0nf9CAk7dhIC&scisf=3&ct=citation&cd=177&hl=en HTTP/1.1" 200 350
[2018-03-02 15:08:10,042 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T MANA for the Ageing
%A Powers, David MW
%A Luerssen, Martin H
%A Lewis, Trent W
%A Leibbrandt, Richard E
%A Milne, Marissa
%A Pashalis, John
%A Treharne, Kenneth
%B Proceedings of the 2010 Workshop on Companionable Dialogue Systems
%P 7-12
%@ 1932432817
%D 2010
%I Association for Computational Linguistics

[2018-03-02 15:08:10,042 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:08:10,042 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:08:10,042 DEBUG __main__] Process content of EndNote file #178
{"title": "MANA for the Ageing", "url": "https://dl.acm.org/citation.cfm?id=1870561", "author": [{"shortname": "DMW Powers", "gid": "qTvbbD4AAAAJ"}, {"shortname": "MH Luerssen", "gid": "JFvU8UMAAAAJ"}, {"shortname": "TW Lewis", "gid": "A4TxjLoAAAAJ"}], "year": 2010}
{"citedby": 6, "type": "Conference Proceedings", "title": "MANA for the Ageing", "author": ["Powers, David MW", "Luerssen, Martin H", "Lewis, Trent W", "Leibbrandt, Richard E", "Milne, Marissa", "Pashalis, John", "Treharne, Kenneth"], "secondarytitle": "Proceedings of the 2010 Workshop on Companionable Dialogue Systems", "pages": "7-12", "isbn/issn": "1932432817", "year": "2010", "publisher": "Association for Computational Linguistics", "start_page": 7, "end_page": 12, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T MANA for the Ageing\n%A Powers, David MW\n%A Luerssen, Martin H\n%A Lewis, Trent W\n%A Leibbrandt, Richard E\n%A Milne, Marissa\n%A Pashalis, John\n%A Treharne, Kenneth\n%B Proceedings of the 2010 Workshop on Companionable Dialogue Systems\n%P 7-12\n%@ 1932432817\n%D 2010\n%I Association for Computational Linguistics\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:TtGZXql9XvgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA41uMvyrYSYnI6o3n0nf9CAk7dhIC&scisf=3&ct=citation&cd=177&hl=en"}
[2018-03-02 15:08:10,043 DEBUG dbutils] Get paper id {"DOI": null, "title": "MANA for the Ageing", "auth_count": 7, "g_type": "Conference Proceedings", "pages": 6, "year": 2010, "rg_id": null, "start_page": 7, "end_page": 12}.
[2018-03-02 15:08:10,043 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'MANA for the Ageing', 'auth_count': 7, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2010, 'rg_id': None, 'start_page': 7, 'end_page': 12}
[2018-03-02 15:08:10,043 DEBUG dbutils] Query result: []
[2018-03-02 15:08:10,043 DEBUG dbutils] Paper id = None.
[2018-03-02 15:08:10,043 DEBUG dbutils] Add new paper (title='MANA for the Ageing')
[2018-03-02 15:08:10,043 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'MANA for the Ageing', 'year': 2010, 'publisher': 'Association for Computational Linguistics', 'start_page': 7, 'end_page': 12, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T MANA for the Ageing\n%A Powers, David MW\n%A Luerssen, Martin H\n%A Lewis, Trent W\n%A Leibbrandt, Richard E\n%A Milne, Marissa\n%A Pashalis, John\n%A Treharne, Kenneth\n%B Proceedings of the 2010 Workshop on Companionable Dialogue Systems\n%P 7-12\n%@ 1932432817\n%D 2010\n%I Association for Computational Linguistics\n', 'RIS': None, 'authors': 7, 'ignore': False, 'transaction': 1}
[2018-03-02 15:08:10,043 DEBUG dbutils] Query result: 163
[2018-03-02 15:08:10,045 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/W10-2702.
[2018-03-02 15:08:10,046 WARNING utils] Download file (url='http://www.aclweb.org/anthology/W10-2702') and save (filename='PDF//163.pdf')
[2018-03-02 15:08:10,046 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:08:10,046 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:08:10,047 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for otherhost
[2018-03-02 15:08:10,065 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 15:08:10,729 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W10-2702 HTTP/1.1" 200 None
[2018-03-02 15:08:10,729 DEBUG utils] Downloading the entire file.
[2018-03-02 15:08:10,730 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:08:10,730 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:08:10,744 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 15:08:11,390 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/W10-2702 HTTP/1.1" 200 None
[2018-03-02 15:08:17,625 DEBUG utils] Save file PDF//163.pdf.
[2018-03-02 15:08:17,627 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1870561.
[2018-03-02 15:08:17,628 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1870561.
[2018-03-02 15:08:18,880 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1870561 HTTP/1.1" 200 None
[2018-03-02 15:08:18,881 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:08:18,881 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:08:18,881 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for sci-hub.tw
[2018-03-02 15:08:19,069 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1870561 HTTP/1.1" 200 None
[2018-03-02 15:08:19,078 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:08:19,080 DEBUG scholar] Handle paper #179 (total 1170)
[2018-03-02 15:08:19,080 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:08:19,083 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:08:19,083 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:08:19,083 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for scholar.google.com
[2018-03-02 15:08:19,122 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:08:19,124 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:08:20,501 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:7u4B21vNR1wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4zzS-Kz-hEqv9EcO9sO-1yWEdmiW&scisf=3&ct=citation&cd=178&hl=en HTTP/1.1" 200 171
[2018-03-02 15:08:20,502 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.
%A Hohn, Sviatlana
%B AAAI
%P 4166-4167
%D 2015

[2018-03-02 15:08:20,502 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:08:20,502 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:08:20,502 DEBUG __main__] Process content of EndNote file #179
{"title": "Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.", "url": "http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9606/9715", "author": [{"shortname": "S H\u00f6hn", "gid": ""}], "year": 2015}
{"type": "Conference Proceedings", "title": "Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.", "author": ["H\u00f6hn, Sviatlana"], "secondarytitle": "AAAI", "pages": "4166-4167", "year": "2015", "start_page": 4166, "end_page": 4167, "volume": 2, "EndNote": "%0 Conference Proceedings\n%T Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.\n%A H\u00f6hn, Sviatlana\n%B AAAI\n%P 4166-4167\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:7u4B21vNR1wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA4zzS-Kz-hEqv9EcO9sO-1yWEdmiW&scisf=3&ct=citation&cd=178&hl=en"}
[2018-03-02 15:08:20,502 DEBUG dbutils] Get paper id {"DOI": null, "title": "Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 2, "year": 2015, "rg_id": null, "start_page": 4166, "end_page": 4167}.
[2018-03-02 15:08:20,502 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 2, 'year': 2015, 'rg_id': None, 'start_page': 4166, 'end_page': 4167}
[2018-03-02 15:08:20,503 DEBUG dbutils] Query result: []
[2018-03-02 15:08:20,503 DEBUG dbutils] Paper id = None.
[2018-03-02 15:08:20,503 DEBUG dbutils] Add new paper (title='Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.')
[2018-03-02 15:08:20,503 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.', 'year': 2015, 'publisher': None, 'start_page': 4166, 'end_page': 4167, 'pages': 2, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Dealing with Trouble: A Data-Driven Model of a Repair Type for a Conversational Agent.\n%A Hohn, Sviatlana\n%B AAAI\n%P 4166-4167\n%D 2015\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:08:20,503 DEBUG dbutils] Query result: 164
[2018-03-02 15:08:20,504 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9606/9715.
[2018-03-02 15:08:20,505 WARNING utils] Download file (url='http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9606/9715') and save (filename='PDF//164.pdf')
[2018-03-02 15:08:20,505 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 15:08:20,505 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:08:20,506 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for otherhost
[2018-03-02 15:08:20,521 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.aaai.org
[2018-03-02 15:08:21,301 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/AAAI/AAAI15/paper/download/9606/9715 HTTP/1.1" 200 None
[2018-03-02 15:08:21,311 DEBUG utils] Try get PDF from https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9606/9715.
[2018-03-02 15:08:21,311 WARNING utils] Download file (url='https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9606/9715') and save (filename='PDF//164.pdf')
[2018-03-02 15:08:21,311 DEBUG utils] Get current proxy for www.aaai.org.
[2018-03-02 15:08:21,311 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:08:21,325 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.aaai.org
[2018-03-02 15:08:23,376 DEBUG requests.packages.urllib3.connectionpool] "GET /ocs/index.php/AAAI/AAAI15/paper/download/9606/9715 HTTP/1.1" 200 437531
[2018-03-02 15:08:23,377 DEBUG utils] Content-length=437531
[2018-03-02 15:08:23,377 DEBUG utils] Create file PDF//164.pdf, start download.
[2018-03-02 15:08:25,067 DEBUG utils] End download file PDF//164.pdf.
[2018-03-02 15:08:25,069 DEBUG dbutils] Update pdf_transaction for paper id=164.
[2018-03-02 15:08:25,069 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 164'
[2018-03-02 15:08:25,069 DEBUG dbutils] Query result: null
[2018-03-02 15:08:25,070 DEBUG scholar] Handle paper #180 (total 1170)
[2018-03-02 15:08:25,070 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:08:25,074 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:08:25,074 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:08:25,352 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:jzHV9h387uMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA43j14vXTRtMWjzPgwomINzQe0lkI&scisf=3&ct=citation&cd=179&hl=en HTTP/1.1" 200 175
[2018-03-02 15:08:25,353 DEBUG scholar] EndNote file:
%0 Journal Article
%T Would You Like to Have a Question?
%A Dorsen, Annie
%A Soloski, Alexis
%J Theater
%V 42
%N 2
%P 79-89
%@ 0161-0775
%D 2012
%I Duke Univ Press

[2018-03-02 15:08:25,353 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:08:25,353 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:08:25,354 DEBUG __main__] Process content of EndNote file #180
{"title": "Would You Like to Have a Question?", "url": "http://theater.dukejournals.org/content/42/2/79.full.pdf", "author": [{"shortname": "A Dorsen", "gid": ""}, {"shortname": "A Soloski", "gid": ""}], "year": 2012}
{"type": "Journal Article", "title": "Would You Like to Have a Question?", "author": ["Dorsen, Annie", "Soloski, Alexis"], "journal": "Theater", "volume": 11, "numberorissue": "2", "pages": "79-89", "isbn/issn": "0161-0775", "year": "2012", "publisher": "Duke Univ Press", "start_page": 79, "end_page": 89, "EndNote": "%0 Journal Article\n%T Would You Like to Have a Question?\n%A Dorsen, Annie\n%A Soloski, Alexis\n%J Theater\n%V 42\n%N 2\n%P 79-89\n%@ 0161-0775\n%D 2012\n%I Duke Univ Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:jzHV9h387uMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplA43j14vXTRtMWjzPgwomINzQe0lkI&scisf=3&ct=citation&cd=179&hl=en"}
[2018-03-02 15:08:25,354 DEBUG dbutils] Get paper id {"DOI": null, "title": "Would You Like to Have a Question?", "auth_count": 2, "g_type": "Journal Article", "pages": 11, "year": 2012, "rg_id": null, "start_page": 79, "end_page": 89}.
[2018-03-02 15:08:25,354 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Would You Like to Have a Question?', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 11, 'year': 2012, 'rg_id': None, 'start_page': 79, 'end_page': 89}
[2018-03-02 15:08:25,354 DEBUG dbutils] Query result: []
[2018-03-02 15:08:25,354 DEBUG dbutils] Paper id = None.
[2018-03-02 15:08:25,354 DEBUG dbutils] Add new paper (title='Would You Like to Have a Question?')
[2018-03-02 15:08:25,354 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Would You Like to Have a Question?', 'year': 2012, 'publisher': 'Duke Univ Press', 'start_page': 79, 'end_page': 89, 'pages': 11, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Would You Like to Have a Question?\n%A Dorsen, Annie\n%A Soloski, Alexis\n%J Theater\n%V 42\n%N 2\n%P 79-89\n%@ 0161-0775\n%D 2012\n%I Duke Univ Press\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:08:25,354 DEBUG dbutils] Query result: 165
[2018-03-02 15:08:25,356 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://theater.dukejournals.org/content/42/2/79.full.pdf.
[2018-03-02 15:08:25,357 WARNING utils] Download file (url='http://theater.dukejournals.org/content/42/2/79.full.pdf') and save (filename='PDF//165.pdf')
[2018-03-02 15:08:25,357 DEBUG utils] Get current proxy for theater.dukejournals.org.
[2018-03-02 15:08:25,357 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:08:25,357 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for otherhost
[2018-03-02 15:08:25,372 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): theater.dukejournals.org
[2018-03-02 15:08:25,996 DEBUG requests.packages.urllib3.connectionpool] "GET /content/42/2/79.full.pdf HTTP/1.1" 301 285
[2018-03-02 15:08:26,019 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): read.dukeupress.edu
[2018-03-02 15:08:28,259 DEBUG requests.packages.urllib3.connectionpool] "GET /HTTPHandlers/UrlRedirectHandler.ashx?request=article&subdomain=theater&volume=42&issue=2&page=79&pageType=full.pdf HTTP/1.1" 301 208
[2018-03-02 15:08:28,769 DEBUG requests.packages.urllib3.connectionpool] "GET /theater/article/42/2/79/24368/Would-You-Like-to-Have-a-Question HTTP/1.1" 302 214
[2018-03-02 15:08:30,553 DEBUG requests.packages.urllib3.connectionpool] "GET /theater/article-abstract/42/2/79/24368/Would-You-Like-to-Have-a-Question?redirectedFrom=fulltext HTTP/1.1" 200 22560
[2018-03-02 15:08:31,188 DEBUG utils] Content-length=22560
[2018-03-02 15:08:31,189 DEBUG utils] Create file PDF//165.pdf, start download.
[2018-03-02 15:08:31,192 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 22560

[2018-03-02 15:08:31,192 DEBUG __main__] Failed get_pdf from Google Scholar for paper #165. URL=165
[2018-03-02 15:08:31,194 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://theater.dukejournals.org/content/42/2/79.full.pdf.
[2018-03-02 15:08:31,195 DEBUG scihub] Get page from sci-hub for paper with DOI=http://theater.dukejournals.org/content/42/2/79.full.pdf.
[2018-03-02 15:08:36,215 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:08:36,215 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for sci-hub.tw
[2018-03-02 15:08:36,229 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): sci-hub.tw
[2018-03-02 15:08:41,318 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:08:41,318 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for sci-hub.tw
[2018-03-02 15:08:41,335 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): sci-hub.tw
[2018-03-02 15:08:46,429 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:08:46,429 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for sci-hub.tw
[2018-03-02 15:08:46,443 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): sci-hub.tw
[2018-03-02 15:08:51,538 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:08:51,538 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for sci-hub.tw
[2018-03-02 15:08:51,552 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (8): sci-hub.tw
[2018-03-02 15:08:56,688 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:08:56,688 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for sci-hub.tw
[2018-03-02 15:08:56,702 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (9): sci-hub.tw
[2018-03-02 15:09:01,818 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:01,818 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for sci-hub.tw
[2018-03-02 15:09:01,833 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (10): sci-hub.tw
[2018-03-02 15:09:06,957 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:06,957 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for sci-hub.tw
[2018-03-02 15:09:06,972 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (11): sci-hub.tw
[2018-03-02 15:09:12,066 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:12,066 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for sci-hub.tw
[2018-03-02 15:09:12,080 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (12): sci-hub.tw
[2018-03-02 15:09:17,178 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:17,178 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for sci-hub.tw
[2018-03-02 15:09:17,191 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (13): sci-hub.tw
[2018-03-02 15:09:22,287 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:22,287 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for sci-hub.tw
[2018-03-02 15:09:22,302 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (14): sci-hub.tw
[2018-03-02 15:09:27,397 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:27,397 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for sci-hub.tw
[2018-03-02 15:09:27,411 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (15): sci-hub.tw
[2018-03-02 15:09:32,518 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:32,518 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for sci-hub.tw
[2018-03-02 15:09:32,534 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (16): sci-hub.tw
[2018-03-02 15:09:37,627 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:37,627 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for sci-hub.tw
[2018-03-02 15:09:37,641 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (17): sci-hub.tw
[2018-03-02 15:09:42,737 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:42,737 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for sci-hub.tw
[2018-03-02 15:09:42,752 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (18): sci-hub.tw
[2018-03-02 15:09:47,856 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:47,856 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for sci-hub.tw
[2018-03-02 15:09:47,871 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (19): sci-hub.tw
[2018-03-02 15:09:52,987 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:52,987 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for sci-hub.tw
[2018-03-02 15:09:53,001 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (20): sci-hub.tw
[2018-03-02 15:09:58,096 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:09:58,096 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for sci-hub.tw
[2018-03-02 15:09:58,111 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (21): sci-hub.tw
[2018-03-02 15:10:03,198 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:10:03,199 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for sci-hub.tw
[2018-03-02 15:10:03,213 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (22): sci-hub.tw
[2018-03-02 15:10:08,326 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:10:08,327 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for sci-hub.tw
[2018-03-02 15:10:08,344 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (23): sci-hub.tw
[2018-03-02 15:10:13,436 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 340, in get_request
    resp = SESSION.get(url, stream=stream, timeout=5, verify=False)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='sci-hub.tw', port=80): Read timed out. (read timeout=5)

[2018-03-02 15:10:13,436 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for sci-hub.tw
[2018-03-02 15:10:13,437 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:10:13,437 DEBUG __main__] Failed get_pdf from sci-hub for paper #165. URL=165
[2018-03-02 15:10:13,462 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:10:13,462 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:10:13,462 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:10:13,462 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for scholar.google.com
[2018-03-02 15:10:13,477 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:10:14,895 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=180&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:10:15,130 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:10:15,130 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:10:33,841 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:10:33,841 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:10:33,983 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:10:33,984 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:10:34,267 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=180&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:10:34,760 DEBUG scholar] Find papers on page #19 (max_google_papers = 300)
[2018-03-02 15:10:34,760 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:10:34,763 DEBUG scholar] Handle paper #181 (total 1170)
[2018-03-02 15:10:34,763 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:10:34,766 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:10:34,766 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:10:34,766 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for scholar.google.com
[2018-03-02 15:10:34,786 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:10:34,787 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:10:36,024 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Y6WexHIEou8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1gk3amd_afAijKyiyVScUfPfcjnR&scisf=3&ct=citation&cd=180&hl=en HTTP/1.1" 200 185
[2018-03-02 15:10:36,025 DEBUG scholar] EndNote file:
%0 Journal Article
%T Multiparticipant chat analysis: A survey
%A Uthus, David C
%A Aha, David W
%J Artificial Intelligence
%V 199
%P 106-121
%@ 0004-3702
%D 2013
%I Elsevier

[2018-03-02 15:10:36,025 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:10:36,025 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:10:36,025 DEBUG __main__] Process content of EndNote file #181
{"title": "Multiparticipant chat analysis: A survey", "url": "https://www.sciencedirect.com/science/article/pii/S0004370213000234", "author": [{"shortname": "DC Uthus", "gid": "9k31iVQAAAAJ"}, {"shortname": "DW Aha", "gid": "V6bim9AAAAAJ"}], "year": 2013}
{"citedby": 28, "type": "Journal Article", "title": "Multiparticipant chat analysis: A survey", "author": ["Uthus, David C", "Aha, David W"], "journal": "Artificial Intelligence", "volume": 16, "pages": "106-121", "isbn/issn": "0004-3702", "year": "2013", "publisher": "Elsevier", "start_page": 106, "end_page": 121, "EndNote": "%0 Journal Article\n%T Multiparticipant chat analysis: A survey\n%A Uthus, David C\n%A Aha, David W\n%J Artificial Intelligence\n%V 199\n%P 106-121\n%@ 0004-3702\n%D 2013\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Y6WexHIEou8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1gk3amd_afAijKyiyVScUfPfcjnR&scisf=3&ct=citation&cd=180&hl=en"}
[2018-03-02 15:10:36,026 DEBUG dbutils] Get paper id {"DOI": null, "title": "Multiparticipant chat analysis: A survey", "auth_count": 2, "g_type": "Journal Article", "pages": 16, "year": 2013, "rg_id": null, "start_page": 106, "end_page": 121}.
[2018-03-02 15:10:36,026 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Multiparticipant chat analysis: A survey', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 16, 'year': 2013, 'rg_id': None, 'start_page': 106, 'end_page': 121}
[2018-03-02 15:10:36,026 DEBUG dbutils] Query result: []
[2018-03-02 15:10:36,026 DEBUG dbutils] Paper id = None.
[2018-03-02 15:10:36,026 DEBUG dbutils] Add new paper (title='Multiparticipant chat analysis: A survey')
[2018-03-02 15:10:36,026 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Multiparticipant chat analysis: A survey', 'year': 2013, 'publisher': 'Elsevier', 'start_page': 106, 'end_page': 121, 'pages': 16, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Multiparticipant chat analysis: A survey\n%A Uthus, David C\n%A Aha, David W\n%J Artificial Intelligence\n%V 199\n%P 106-121\n%@ 0004-3702\n%D 2013\n%I Elsevier\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:10:36,026 DEBUG dbutils] Query result: 166
[2018-03-02 15:10:36,028 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.sciencedirect.com/science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1.
[2018-03-02 15:10:36,028 WARNING utils] Download file (url='https://www.sciencedirect.com/science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1') and save (filename='PDF//166.pdf')
[2018-03-02 15:10:36,029 DEBUG utils] Get current proxy for www.sciencedirect.com.
[2018-03-02 15:10:36,029 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:10:36,047 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.sciencedirect.com
[2018-03-02 15:10:37,236 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.sciencedirect.com', port=443): Max retries exceeded with url: /science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.sciencedirect.com', port=443): Max retries exceeded with url: /science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 15:10:37,236 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for otherhost
[2018-03-02 15:10:37,237 DEBUG utils] Get current proxy for www.sciencedirect.com.
[2018-03-02 15:10:37,237 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:10:37,275 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.sciencedirect.com
[2018-03-02 15:10:41,385 DEBUG requests.packages.urllib3.connectionpool] "GET /science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1 HTTP/1.1" 200 1737
[2018-03-02 15:10:41,427 DEBUG utils] Content-length=1737
[2018-03-02 15:10:41,428 DEBUG utils] Create file PDF//166.pdf, start download.
[2018-03-02 15:10:41,429 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 1737

[2018-03-02 15:10:41,429 DEBUG __main__] Failed get_pdf from Google Scholar for paper #166. URL=166
[2018-03-02 15:10:41,431 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S0004370213000234.
[2018-03-02 15:10:41,432 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S0004370213000234.
[2018-03-02 15:10:41,452 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (24): sci-hub.tw
[2018-03-02 15:10:41,706 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0004370213000234 HTTP/1.1" 200 None
[2018-03-02 15:10:41,707 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:10:41,707 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:10:41,895 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0004370213000234 HTTP/1.1" 200 None
[2018-03-02 15:10:41,901 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true.
[2018-03-02 15:10:41,901 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true') and save (filename='PDF//166.pdf')
[2018-03-02 15:10:41,916 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 15:10:42,187 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:10:42,188 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:10:42,188 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:10:42,189 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for sci-hub.tw
[2018-03-02 15:10:42,209 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): cyber.sci-hub.tw
[2018-03-02 15:10:42,445 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:10:42,449 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:10:42,450 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:11:02,108 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:11:02,109 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:11:02,460 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true HTTP/1.1" 200 443575
[2018-03-02 15:11:02,461 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:11:02,461 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:11:02,476 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): cyber.sci-hub.tw
[2018-03-02 15:11:02,776 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmFydGludC4yMDEzLjAyLjAwNA==/uthus2013.pdf?download=true HTTP/1.1" 200 443575
[2018-03-02 15:11:02,777 DEBUG utils] Content-length=443575
[2018-03-02 15:11:02,778 DEBUG utils] Create file PDF//166.pdf, start download.
[2018-03-02 15:11:03,634 DEBUG utils] End download file PDF//166.pdf.
[2018-03-02 15:11:03,635 DEBUG dbutils] Update pdf_transaction for paper id=166.
[2018-03-02 15:11:03,635 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 166'
[2018-03-02 15:11:03,635 DEBUG dbutils] Query result: null
[2018-03-02 15:11:03,636 DEBUG scholar] Handle paper #182 (total 1170)
[2018-03-02 15:11:03,636 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:11:03,639 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:11:03,639 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:11:03,865 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nIhVkb3_zcIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1qIExcZ7jhvtZeLmwH8ybxoz3XIn&scisf=3&ct=citation&cd=181&hl=en HTTP/1.1" 200 114
[2018-03-02 15:11:03,865 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Fairytale Child Chatbot.
%A Rosa, Rudolf
%B ITAT
%P 79-84
%D 2014
%I Citeseer

[2018-03-02 15:11:03,866 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:11:03,866 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:11:03,866 DEBUG __main__] Process content of EndNote file #182
{"title": "Fairytale Child Chatbot.", "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf", "author": [{"shortname": "R Rosa", "gid": "LZlPeSwAAAAJ"}], "year": 2014}
{"type": "Conference Proceedings", "title": "Fairytale Child Chatbot.", "author": ["Rosa, Rudolf"], "secondarytitle": "ITAT", "pages": "79-84", "year": "2014", "publisher": "Citeseer", "start_page": 79, "end_page": 84, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Fairytale Child Chatbot.\n%A Rosa, Rudolf\n%B ITAT\n%P 79-84\n%D 2014\n%I Citeseer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:nIhVkb3_zcIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1qIExcZ7jhvtZeLmwH8ybxoz3XIn&scisf=3&ct=citation&cd=181&hl=en"}
[2018-03-02 15:11:03,866 DEBUG dbutils] Get paper id {"DOI": null, "title": "Fairytale Child Chatbot.", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 6, "year": 2014, "rg_id": null, "start_page": 79, "end_page": 84}.
[2018-03-02 15:11:03,866 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Fairytale Child Chatbot.', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2014, 'rg_id': None, 'start_page': 79, 'end_page': 84}
[2018-03-02 15:11:03,867 DEBUG dbutils] Query result: []
[2018-03-02 15:11:03,867 DEBUG dbutils] Paper id = None.
[2018-03-02 15:11:03,867 DEBUG dbutils] Add new paper (title='Fairytale Child Chatbot.')
[2018-03-02 15:11:03,867 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Fairytale Child Chatbot.', 'year': 2014, 'publisher': 'Citeseer', 'start_page': 79, 'end_page': 84, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Fairytale Child Chatbot.\n%A Rosa, Rudolf\n%B ITAT\n%P 79-84\n%D 2014\n%I Citeseer\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:11:03,867 DEBUG dbutils] Query result: 167
[2018-03-02 15:11:03,869 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf.
[2018-03-02 15:11:03,870 WARNING utils] Download file (url='http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf') and save (filename='PDF//167.pdf')
[2018-03-02 15:11:03,870 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 15:11:03,870 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:11:03,870 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for otherhost
[2018-03-02 15:11:03,887 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): citeseerx.ist.psu.edu
[2018-03-02 15:11:04,384 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 200 None
[2018-03-02 15:11:04,384 DEBUG utils] Downloading the entire file.
[2018-03-02 15:11:04,385 DEBUG utils] Get current proxy for citeseerx.ist.psu.edu.
[2018-03-02 15:11:04,385 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:11:04,399 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): citeseerx.ist.psu.edu
[2018-03-02 15:11:04,828 DEBUG requests.packages.urllib3.connectionpool] "GET /viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 302 0
[2018-03-02 15:11:05,085 DEBUG requests.packages.urllib3.connectionpool] "GET /messages/downloadsexceeded.html HTTP/1.1" 200 206
[2018-03-02 15:11:05,088 DEBUG utils] Save file PDF//167.pdf.
[2018-03-02 15:11:05,090 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf.
[2018-03-02 15:11:05,090 DEBUG scihub] Get page from sci-hub for paper with DOI=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf.
[2018-03-02 15:11:08,334 DEBUG requests.packages.urllib3.connectionpool] "GET //http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:11,714 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:15,195 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:18,514 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 404 None
[2018-03-02 15:11:18,515 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:11:18,515 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:11:18,515 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for sci-hub.tw
[2018-03-02 15:11:21,334 DEBUG requests.packages.urllib3.connectionpool] "GET //http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:23,424 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:25,394 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 307 None
[2018-03-02 15:11:27,653 DEBUG requests.packages.urllib3.connectionpool] "GET /http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf HTTP/1.1" 404 None
[2018-03-02 15:11:27,657 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:11:27,657 DEBUG __main__] Failed get_pdf from sci-hub for paper #167. URL=167
[2018-03-02 15:11:27,658 DEBUG scholar] Handle paper #183 (total 1170)
[2018-03-02 15:11:27,658 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:11:27,660 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:11:27,660 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:11:27,660 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for scholar.google.com
[2018-03-02 15:11:27,676 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:11:27,677 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:11:30,464 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Snn8xenQ59kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1rwVR69hZC4NwH_UanEkwvluntri&scisf=3&ct=citation&cd=182&hl=en HTTP/1.1" 200 434
[2018-03-02 15:11:30,465 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes
%A Urbaniak, Kathryn
%A Venkatesh, Vivek
%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education
%P 432-438
%@ 1880094983
%D 2012
%I Association for the Advancement of Computing in Education (AACE)

[2018-03-02 15:11:30,465 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:11:30,465 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:11:30,465 DEBUG __main__] Process content of EndNote file #183
{"title": "Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes", "url": "https://www.learntechlib.org/p/41629/", "author": [{"shortname": "K Urbaniak", "gid": ""}, {"shortname": "V Venkatesh", "gid": ""}], "year": 2012}
{"citedby": 1, "type": "Conference Proceedings", "title": "Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes", "author": ["Urbaniak, Kathryn", "Venkatesh, Vivek"], "secondarytitle": "E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education", "pages": "432-438", "isbn/issn": "1880094983", "year": "2012", "publisher": "Association for the Advancement of Computing in Education (AACE)", "start_page": 432, "end_page": 438, "volume": 7, "EndNote": "%0 Conference Proceedings\n%T Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes\n%A Urbaniak, Kathryn\n%A Venkatesh, Vivek\n%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education\n%P 432-438\n%@ 1880094983\n%D 2012\n%I Association for the Advancement of Computing in Education (AACE)\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Snn8xenQ59kJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1rwVR69hZC4NwH_UanEkwvluntri&scisf=3&ct=citation&cd=182&hl=en"}
[2018-03-02 15:11:30,465 DEBUG dbutils] Get paper id {"DOI": null, "title": "Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 7, "year": 2012, "rg_id": null, "start_page": 432, "end_page": 438}.
[2018-03-02 15:11:30,466 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 7, 'year': 2012, 'rg_id': None, 'start_page': 432, 'end_page': 438}
[2018-03-02 15:11:30,466 DEBUG dbutils] Query result: []
[2018-03-02 15:11:30,466 DEBUG dbutils] Paper id = None.
[2018-03-02 15:11:30,466 DEBUG dbutils] Add new paper (title='Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes')
[2018-03-02 15:11:30,466 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes', 'year': 2012, 'publisher': 'Association for the Advancement of Computing in Education (AACE)', 'start_page': 432, 'end_page': 438, 'pages': 7, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Building an Ontology for Student Models of English As Second Language Essays: A Synthesis of Literature and Results of Development of Topic Map Indexes\n%A Urbaniak, Kathryn\n%A Venkatesh, Vivek\n%B E-Learn: World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education\n%P 432-438\n%@ 1880094983\n%D 2012\n%I Association for the Advancement of Computing in Education (AACE)\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:11:30,466 DEBUG dbutils] Query result: 168
[2018-03-02 15:11:30,467 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/41629/proceeding_41629.pdf.
[2018-03-02 15:11:30,467 WARNING utils] Download file (url='https://www.learntechlib.org/p/41629/proceeding_41629.pdf') and save (filename='PDF//168.pdf')
[2018-03-02 15:11:30,467 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 15:11:30,468 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:11:30,468 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for otherhost
[2018-03-02 15:11:30,483 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.learntechlib.org
[2018-03-02 15:11:30,485 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.learntechlib.org
[2018-03-02 15:11:32,678 DEBUG requests.packages.urllib3.connectionpool] "GET /p/41629/proceeding_41629.pdf HTTP/1.1" 302 137
[2018-03-02 15:11:32,953 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/41629 HTTP/1.1" 301 0
[2018-03-02 15:11:34,896 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/41629/ HTTP/1.1" 200 17685
[2018-03-02 15:11:34,940 DEBUG utils] Content-length=17685
[2018-03-02 15:11:34,941 DEBUG utils] Create file PDF//168.pdf, start download.
[2018-03-02 15:11:34,942 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 17685

[2018-03-02 15:11:34,942 DEBUG __main__] Failed get_pdf from Google Scholar for paper #168. URL=168
[2018-03-02 15:11:34,944 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/41629/.
[2018-03-02 15:11:34,944 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/41629/.
[2018-03-02 15:11:35,163 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/41629/ HTTP/1.1" 302 None
[2018-03-02 15:11:35,190 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.learntechlib.org
[2018-03-02 15:11:36,504 DEBUG requests.packages.urllib3.connectionpool] "GET /p/41629/ HTTP/1.1" 200 None
[2018-03-02 15:11:36,538 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:11:36,539 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:11:36,724 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/41629/ HTTP/1.1" 302 None
[2018-03-02 15:11:36,747 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 15:11:40,266 DEBUG requests.packages.urllib3.connectionpool] "GET /p/41629/ HTTP/1.1" 200 17890
[2018-03-02 15:11:40,357 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:11:40,358 DEBUG scholar] Handle paper #184 (total 1170)
[2018-03-02 15:11:40,358 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:11:40,360 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:11:40,360 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:11:40,844 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:njdJV5QVJOoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1hrHLi_gBzaYmlV4XZ6cZv2L2fko&scisf=3&ct=citation&cd=183&hl=en HTTP/1.1" 200 333
[2018-03-02 15:11:40,845 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Multidisciplinary instruction with the natural language toolkit
%A Bird, Steven
%A Klein, Ewan
%A Loper, Edward
%A Baldridge, Jason
%B Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics
%P 62-70
%@ 1932432140
%D 2008
%I Association for Computational Linguistics

[2018-03-02 15:11:40,845 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:11:40,845 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:11:40,845 DEBUG __main__] Process content of EndNote file #184
{"title": "Multidisciplinary instruction with the natural language toolkit", "url": "https://dl.acm.org/citation.cfm?id=1627317", "author": [{"shortname": "S Bird", "gid": "xoyloJAAAAAJ"}, {"shortname": "E Klein", "gid": "Sh28erYAAAAJ"}, {"shortname": "E Loper", "gid": ""}, {"shortname": "J Baldridge", "gid": ""}], "year": 2008}
{"citedby": 49, "type": "Conference Proceedings", "title": "Multidisciplinary instruction with the natural language toolkit", "author": ["Bird, Steven", "Klein, Ewan", "Loper, Edward", "Baldridge, Jason"], "secondarytitle": "Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics", "pages": "62-70", "isbn/issn": "1932432140", "year": "2008", "publisher": "Association for Computational Linguistics", "start_page": 62, "end_page": 70, "volume": 9, "EndNote": "%0 Conference Proceedings\n%T Multidisciplinary instruction with the natural language toolkit\n%A Bird, Steven\n%A Klein, Ewan\n%A Loper, Edward\n%A Baldridge, Jason\n%B Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics\n%P 62-70\n%@ 1932432140\n%D 2008\n%I Association for Computational Linguistics\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:njdJV5QVJOoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1hrHLi_gBzaYmlV4XZ6cZv2L2fko&scisf=3&ct=citation&cd=183&hl=en"}
[2018-03-02 15:11:40,845 DEBUG dbutils] Get paper id {"DOI": null, "title": "Multidisciplinary instruction with the natural language toolkit", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 9, "year": 2008, "rg_id": null, "start_page": 62, "end_page": 70}.
[2018-03-02 15:11:40,845 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Multidisciplinary instruction with the natural language toolkit', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 9, 'year': 2008, 'rg_id': None, 'start_page': 62, 'end_page': 70}
[2018-03-02 15:11:40,845 DEBUG dbutils] Query result: []
[2018-03-02 15:11:40,846 DEBUG dbutils] Paper id = None.
[2018-03-02 15:11:40,846 DEBUG dbutils] Add new paper (title='Multidisciplinary instruction with the natural language toolkit')
[2018-03-02 15:11:40,846 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Multidisciplinary instruction with the natural language toolkit', 'year': 2008, 'publisher': 'Association for Computational Linguistics', 'start_page': 62, 'end_page': 70, 'pages': 9, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Multidisciplinary instruction with the natural language toolkit\n%A Bird, Steven\n%A Klein, Ewan\n%A Loper, Edward\n%A Baldridge, Jason\n%B Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics\n%P 62-70\n%@ 1932432140\n%D 2008\n%I Association for Computational Linguistics\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:11:40,846 DEBUG dbutils] Query result: 169
[2018-03-02 15:11:40,847 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://minerva-access.unimelb.edu.au/bitstream/handle/11343/34948/67733_00004215_01_nltk.pdf?sequence=1.
[2018-03-02 15:11:40,847 WARNING utils] Download file (url='https://minerva-access.unimelb.edu.au/bitstream/handle/11343/34948/67733_00004215_01_nltk.pdf?sequence=1') and save (filename='PDF//169.pdf')
[2018-03-02 15:11:40,847 DEBUG utils] Get current proxy for minerva-access.unimelb.edu.au.
[2018-03-02 15:11:40,847 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:11:40,861 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): minerva-access.unimelb.edu.au
[2018-03-02 15:11:46,068 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/handle/11343/34948/67733_00004215_01_nltk.pdf?sequence=1 HTTP/1.1" 200 127816
[2018-03-02 15:11:46,069 DEBUG utils] Content-length=127816
[2018-03-02 15:11:46,070 DEBUG utils] Create file PDF//169.pdf, start download.
[2018-03-02 15:12:01,065 DEBUG utils] End download file PDF//169.pdf.
[2018-03-02 15:12:01,066 DEBUG dbutils] Update pdf_transaction for paper id=169.
[2018-03-02 15:12:01,067 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 169'
[2018-03-02 15:12:01,067 DEBUG dbutils] Query result: null
[2018-03-02 15:12:01,067 DEBUG scholar] Handle paper #185 (total 1170)
[2018-03-02 15:12:01,068 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:12:01,070 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:12:01,070 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:12:01,070 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for scholar.google.com
[2018-03-02 15:12:01,088 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:12:01,089 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:12:03,032 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:WPgAWIm9NicJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1gn6HjvTJReBjDcQ-B668qlDqYn6&scisf=3&ct=citation&cd=184&hl=en HTTP/1.1" 200 138
[2018-03-02 15:12:03,033 DEBUG scholar] EndNote file:
%0 Journal Article
%T 'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence
%A Atkinson, Robert
%D 2016

[2018-03-02 15:12:03,033 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:12:03,033 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:12:03,033 DEBUG __main__] Process content of EndNote file #185
{"title": "'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence", "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3066182", "author": [{"shortname": "R Atkinson", "gid": ""}], "year": 2016}
{"citedby": 4, "type": "Journal Article", "title": "'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence", "author": ["Atkinson, Robert"], "year": "2016", "EndNote": "%0 Journal Article\n%T 'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence\n%A Atkinson, Robert\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:WPgAWIm9NicJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1gn6HjvTJReBjDcQ-B668qlDqYn6&scisf=3&ct=citation&cd=184&hl=en"}
[2018-03-02 15:12:03,034 DEBUG dbutils] Get paper id {"DOI": null, "title": "'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:12:03,034 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': "'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence", 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:12:03,034 DEBUG dbutils] Query result: []
[2018-03-02 15:12:03,034 DEBUG dbutils] Paper id = None.
[2018-03-02 15:12:03,034 DEBUG dbutils] Add new paper (title=''It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence')
[2018-03-02 15:12:03,034 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': "'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence", 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': "%0 Journal Article\n%T 'It's Going to Kill Us!'And Other Myths About the Future of Artificial Intelligence\n%A Atkinson, Robert\n%D 2016\n", 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:12:03,034 DEBUG dbutils] Query result: 170
[2018-03-02 15:12:03,035 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://files.eric.ed.gov/fulltext/EJ1121424.pdf.
[2018-03-02 15:12:03,036 WARNING utils] Download file (url='https://files.eric.ed.gov/fulltext/EJ1121424.pdf') and save (filename='PDF//170.pdf')
[2018-03-02 15:12:03,036 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 15:12:03,036 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:12:03,036 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for otherhost
[2018-03-02 15:12:03,050 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 15:12:04,163 DEBUG requests.packages.urllib3.connectionpool] "GET /fulltext/EJ1121424.pdf HTTP/1.1" 200 129920
[2018-03-02 15:12:04,164 DEBUG utils] Content-length=129920
[2018-03-02 15:12:04,164 DEBUG utils] Create file PDF//170.pdf, start download.
[2018-03-02 15:12:04,612 DEBUG utils] End download file PDF//170.pdf.
[2018-03-02 15:12:04,614 DEBUG dbutils] Update pdf_transaction for paper id=170.
[2018-03-02 15:12:04,614 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 170'
[2018-03-02 15:12:04,614 DEBUG dbutils] Query result: null
[2018-03-02 15:12:04,615 DEBUG scholar] Handle paper #186 (total 1170)
[2018-03-02 15:12:04,615 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:12:04,619 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:12:04,619 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:12:04,993 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:A4jRV2ZkAeMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1inf0QGiSC00_kOYkFn_A1aOWNCC&scisf=3&ct=citation&cd=185&hl=en HTTP/1.1" 200 185
[2018-03-02 15:12:04,994 DEBUG scholar] EndNote file:
%0 Journal Article
%T Speech and language in humanoid robots
%A Cangelosi, Angelo
%A Ogata, Tetsuya
%J Humanoid Robotics: A Reference
%P 1-32
%@ 9400771940
%D 2016
%I Springer

[2018-03-02 15:12:04,994 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:12:04,994 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:12:04,994 DEBUG __main__] Process content of EndNote file #186
{"title": "Speech and language in humanoid robots", "url": "https://link.springer.com/content/pdf/10.1007/978-94-007-7194-9_135-1.pdf", "author": [{"shortname": "A Cangelosi", "gid": "NyoHewcAAAAJ"}, {"shortname": "T Ogata", "gid": "_SB7ZjQAAAAJ"}], "year": 2016}
{"citedby": 2, "type": "Journal Article", "title": "Speech and language in humanoid robots", "author": ["Cangelosi, Angelo", "Ogata, Tetsuya"], "journal": "Humanoid Robotics: A Reference", "pages": "1-32", "isbn/issn": "9400771940", "year": "2016", "publisher": "Springer", "start_page": 1, "end_page": 32, "volume": 32, "EndNote": "%0 Journal Article\n%T Speech and language in humanoid robots\n%A Cangelosi, Angelo\n%A Ogata, Tetsuya\n%J Humanoid Robotics: A Reference\n%P 1-32\n%@ 9400771940\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:A4jRV2ZkAeMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1inf0QGiSC00_kOYkFn_A1aOWNCC&scisf=3&ct=citation&cd=185&hl=en"}
[2018-03-02 15:12:04,994 DEBUG dbutils] Get paper id {"DOI": null, "title": "Speech and language in humanoid robots", "auth_count": 2, "g_type": "Journal Article", "pages": 32, "year": 2016, "rg_id": null, "start_page": 1, "end_page": 32}.
[2018-03-02 15:12:04,994 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Speech and language in humanoid robots', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 32, 'year': 2016, 'rg_id': None, 'start_page': 1, 'end_page': 32}
[2018-03-02 15:12:04,995 DEBUG dbutils] Query result: []
[2018-03-02 15:12:04,995 DEBUG dbutils] Paper id = None.
[2018-03-02 15:12:04,995 DEBUG dbutils] Add new paper (title='Speech and language in humanoid robots')
[2018-03-02 15:12:04,995 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Speech and language in humanoid robots', 'year': 2016, 'publisher': 'Springer', 'start_page': 1, 'end_page': 32, 'pages': 32, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Speech and language in humanoid robots\n%A Cangelosi, Angelo\n%A Ogata, Tetsuya\n%J Humanoid Robotics: A Reference\n%P 1-32\n%@ 9400771940\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:12:04,995 DEBUG dbutils] Query result: 171
[2018-03-02 15:12:04,996 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/content/pdf/10.1007/978-94-007-7194-9_135-1.pdf.
[2018-03-02 15:12:04,996 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/content/pdf/10.1007/978-94-007-7194-9_135-1.pdf.
[2018-03-02 15:12:05,183 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-94-007-7194-9_135-1.pdf HTTP/1.1" 200 None
[2018-03-02 15:12:05,185 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:05,185 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:12:05,185 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for sci-hub.tw
[2018-03-02 15:12:05,373 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-94-007-7194-9_135-1.pdf HTTP/1.1" 200 None
[2018-03-02 15:12:05,381 DEBUG scihub] URL for PDF: https://sci-hub.tw/saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf.
[2018-03-02 15:12:05,381 WARNING utils] Download file (url='https://sci-hub.tw/saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf') and save (filename='PDF//171.pdf')
[2018-03-02 15:12:05,396 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (41): sci-hub.tw
[2018-03-02 15:12:06,092 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:06,092 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:06,092 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:12:06,127 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:08,355 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:08,356 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for sci-hub.tw
[2018-03-02 15:12:08,372 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (42): sci-hub.tw
[2018-03-02 15:12:08,969 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:08,970 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:08,970 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:12:08,985 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:11,466 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:11,466 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for sci-hub.tw
[2018-03-02 15:12:11,482 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (43): sci-hub.tw
[2018-03-02 15:12:12,112 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:12,113 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:12,113 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:12:12,127 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:12,907 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:12:12,907 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for sci-hub.tw
[2018-03-02 15:12:12,922 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (44): sci-hub.tw
[2018-03-02 15:12:13,496 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:13,496 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:13,496 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:12:13,511 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:15,664 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:15,664 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for sci-hub.tw
[2018-03-02 15:12:15,680 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (45): sci-hub.tw
[2018-03-02 15:12:16,295 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:16,295 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:16,296 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:12:16,310 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:18,126 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:18,126 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for sci-hub.tw
[2018-03-02 15:12:18,141 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (46): sci-hub.tw
[2018-03-02 15:12:18,785 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:18,786 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:18,786 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:12:18,800 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:19,674 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:19,674 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for sci-hub.tw
[2018-03-02 15:12:19,689 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (47): sci-hub.tw
[2018-03-02 15:12:20,382 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:20,382 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:20,383 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:12:20,400 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): sci-hub.tw
[2018-03-02 15:12:21,574 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:21,574 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for sci-hub.tw
[2018-03-02 15:12:21,591 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (48): sci-hub.tw
[2018-03-02 15:12:22,258 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:22,258 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:22,259 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:12:22,274 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 15:12:23,284 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:23,284 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for sci-hub.tw
[2018-03-02 15:12:23,299 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (49): sci-hub.tw
[2018-03-02 15:12:23,965 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:23,966 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:23,966 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:12:23,982 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 15:12:24,885 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:24,886 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for sci-hub.tw
[2018-03-02 15:12:24,902 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (50): sci-hub.tw
[2018-03-02 15:12:25,605 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:25,606 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:25,606 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:12:25,621 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): sci-hub.tw
[2018-03-02 15:12:27,863 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:27,863 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for sci-hub.tw
[2018-03-02 15:12:27,879 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (51): sci-hub.tw
[2018-03-02 15:12:28,495 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:28,496 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:28,496 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:12:28,512 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:30,864 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:30,864 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for sci-hub.tw
[2018-03-02 15:12:30,879 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (52): sci-hub.tw
[2018-03-02 15:12:31,457 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:31,458 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:31,458 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:12:31,472 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:32,403 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:12:32,404 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for sci-hub.tw
[2018-03-02 15:12:32,420 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (53): sci-hub.tw
[2018-03-02 15:12:33,054 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:33,055 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:33,055 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:12:33,070 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:37,583 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:37,583 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for sci-hub.tw
[2018-03-02 15:12:37,598 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (54): sci-hub.tw
[2018-03-02 15:12:38,286 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:38,287 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:38,287 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:12:38,301 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:39,833 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:39,834 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for sci-hub.tw
[2018-03-02 15:12:39,848 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (55): sci-hub.tw
[2018-03-02 15:12:40,514 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:40,515 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:40,515 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:12:40,532 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:41,694 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:41,694 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for sci-hub.tw
[2018-03-02 15:12:41,710 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (56): sci-hub.tw
[2018-03-02 15:12:42,334 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:42,336 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:42,336 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:12:42,351 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:43,299 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:12:43,299 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for sci-hub.tw
[2018-03-02 15:12:43,313 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (57): sci-hub.tw
[2018-03-02 15:12:43,948 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:43,949 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:43,949 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:12:43,965 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:46,415 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:46,415 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for sci-hub.tw
[2018-03-02 15:12:46,432 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (58): sci-hub.tw
[2018-03-02 15:12:47,034 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:47,035 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:47,035 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:12:47,051 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:51,943 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='sci-hub.tw', port=443): Max retries exceeded with url: /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 15:12:51,943 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for sci-hub.tw
[2018-03-02 15:12:51,958 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (59): sci-hub.tw
[2018-03-02 15:12:52,604 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:52,605 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:52,605 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:12:52,620 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:57,513 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:57,513 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for sci-hub.tw
[2018-03-02 15:12:57,529 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (60): sci-hub.tw
[2018-03-02 15:12:58,154 DEBUG requests.packages.urllib3.connectionpool] "GET /saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf HTTP/1.1" 200 362626
[2018-03-02 15:12:58,155 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:12:58,155 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:12:58,170 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): sci-hub.tw
[2018-03-02 15:12:59,616 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
ssl.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 621, in urlopen
    raise SSLError(e)
requests.packages.urllib3.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 497, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)

[2018-03-02 15:12:59,616 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for sci-hub.tw
[2018-03-02 15:12:59,619 DEBUG scholar] Handle paper #187 (total 1170)
[2018-03-02 15:12:59,620 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:12:59,622 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:12:59,622 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:12:59,622 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for scholar.google.com
[2018-03-02 15:12:59,640 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:12:59,641 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:13:01,602 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:C2R7bYpC5OwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1j-l5sRv06_NED-mToZrg3zJ06Ye&scisf=3&ct=citation&cd=186&hl=en HTTP/1.1" 200 252
[2018-03-02 15:13:01,603 DEBUG scholar] EndNote file:
%0 Journal Article
%T A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication
%A DHARMAWANSA, ASANKA DHARSHANA
%D 2015
%I ????????

[2018-03-02 15:13:01,603 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:13:01,603 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:13:01,603 DEBUG __main__] Process content of EndNote file #187
{"title": "A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal\u00a0\u2026", "url": "http://ir.nagaokaut.ac.jp/dspace/bitstream/10649/778/1/k747.pdf", "author": [{"shortname": "AD DHARMAWANSA", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication", "author": ["DHARMAWANSA, ASANKA DHARSHANA"], "year": "2015", "publisher": "\u9577\u5ca1\u6280\u8853\u79d1\u5b66\u5927\u5b66", "EndNote": "%0 Journal Article\n%T A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication\n%A DHARMAWANSA, ASANKA DHARSHANA\n%D 2015\n%I \u9577\u5ca1\u6280\u8853\u79d1\u5b66\u5927\u5b66\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:C2R7bYpC5OwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1j-l5sRv06_NED-mToZrg3zJ06Ye&scisf=3&ct=citation&cd=186&hl=en"}
[2018-03-02 15:13:01,603 DEBUG dbutils] Get paper id {"DOI": null, "title": "A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:13:01,603 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:13:01,604 DEBUG dbutils] Query result: []
[2018-03-02 15:13:01,604 DEBUG dbutils] Paper id = None.
[2018-03-02 15:13:01,604 DEBUG dbutils] Add new paper (title='A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication')
[2018-03-02 15:13:01,604 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication', 'year': 2015, 'publisher': '????????', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A Mechanism to Create a Delighted Student with Enhancing the Effectiveness of the Virtual Learning and Investigate the Behavior of Non-verbal Communication\n%A DHARMAWANSA, ASANKA DHARSHANA\n%D 2015\n%I ????????\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:13:01,604 DEBUG dbutils] Query result: 172
[2018-03-02 15:13:01,605 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://ir.nagaokaut.ac.jp/dspace/bitstream/10649/778/1/k747.pdf.
[2018-03-02 15:13:01,605 WARNING utils] Download file (url='http://ir.nagaokaut.ac.jp/dspace/bitstream/10649/778/1/k747.pdf') and save (filename='PDF//172.pdf')
[2018-03-02 15:13:01,605 DEBUG utils] Get current proxy for ir.nagaokaut.ac.jp.
[2018-03-02 15:13:01,605 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:13:01,621 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): ir.nagaokaut.ac.jp
[2018-03-02 15:13:04,822 DEBUG requests.packages.urllib3.connectionpool] "GET /dspace/bitstream/10649/778/1/k747.pdf HTTP/1.1" 200 11413896
[2018-03-02 15:13:04,823 DEBUG utils] Content-length=11413896
[2018-03-02 15:13:04,823 DEBUG utils] Create file PDF//172.pdf, start download.
[2018-03-02 15:13:20,776 DEBUG utils] End download file PDF//172.pdf.
[2018-03-02 15:13:20,777 DEBUG dbutils] Update pdf_transaction for paper id=172.
[2018-03-02 15:13:20,777 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 172'
[2018-03-02 15:13:20,777 DEBUG dbutils] Query result: null
[2018-03-02 15:13:20,777 DEBUG scholar] Handle paper #188 (total 1170)
[2018-03-02 15:13:20,778 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:13:20,780 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:13:20,780 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:13:21,124 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GbhjvcdhY90J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1lTA4QWcwuHIjxrdFDVvVDd6_Kmy&scisf=3&ct=citation&cd=187&hl=en HTTP/1.1" 200 296
[2018-03-02 15:13:21,125 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Share-and-chat: Achieving human-level video commenting by search and multi-view embedding
%A Li, Yehao
%A Yao, Ting
%A Mei, Tao
%A Chao, Hongyang
%A Rui, Yong
%B Proceedings of the 2016 ACM on Multimedia Conference
%P 928-937
%@ 1450336035
%D 2016
%I ACM

[2018-03-02 15:13:21,125 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:13:21,125 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:13:21,125 DEBUG __main__] Process content of EndNote file #188
{"title": "Share-and-chat: Achieving human-level video commenting by search and multi-view embedding", "url": "https://dl.acm.org/citation.cfm?id=2964320", "author": [{"shortname": "Y Li", "gid": ""}, {"shortname": "T Yao", "gid": "7Yc6yssAAAAJ"}, {"shortname": "T Mei", "gid": "7Yq4wf4AAAAJ"}, {"shortname": "H Chao", "gid": "qnbpG6gAAAAJ"}, {"shortname": "Y Rui", "gid": "rCGsLtcAAAAJ"}], "year": 2016}
{"citedby": 5, "type": "Conference Proceedings", "title": "Share-and-chat: Achieving human-level video commenting by search and multi-view embedding", "author": ["Li, Yehao", "Yao, Ting", "Mei, Tao", "Chao, Hongyang", "Rui, Yong"], "secondarytitle": "Proceedings of the 2016 ACM on Multimedia Conference", "pages": "928-937", "isbn/issn": "1450336035", "year": "2016", "publisher": "ACM", "start_page": 928, "end_page": 937, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Share-and-chat: Achieving human-level video commenting by search and multi-view embedding\n%A Li, Yehao\n%A Yao, Ting\n%A Mei, Tao\n%A Chao, Hongyang\n%A Rui, Yong\n%B Proceedings of the 2016 ACM on Multimedia Conference\n%P 928-937\n%@ 1450336035\n%D 2016\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GbhjvcdhY90J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1lTA4QWcwuHIjxrdFDVvVDd6_Kmy&scisf=3&ct=citation&cd=187&hl=en"}
[2018-03-02 15:13:21,125 DEBUG dbutils] Get paper id {"DOI": null, "title": "Share-and-chat: Achieving human-level video commenting by search and multi-view embedding", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 928, "end_page": 937}.
[2018-03-02 15:13:21,126 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Share-and-chat: Achieving human-level video commenting by search and multi-view embedding', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 928, 'end_page': 937}
[2018-03-02 15:13:21,126 DEBUG dbutils] Query result: []
[2018-03-02 15:13:21,126 DEBUG dbutils] Paper id = None.
[2018-03-02 15:13:21,126 DEBUG dbutils] Add new paper (title='Share-and-chat: Achieving human-level video commenting by search and multi-view embedding')
[2018-03-02 15:13:21,126 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Share-and-chat: Achieving human-level video commenting by search and multi-view embedding', 'year': 2016, 'publisher': 'ACM', 'start_page': 928, 'end_page': 937, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Share-and-chat: Achieving human-level video commenting by search and multi-view embedding\n%A Li, Yehao\n%A Yao, Ting\n%A Mei, Tao\n%A Chao, Hongyang\n%A Rui, Yong\n%B Proceedings of the 2016 ACM on Multimedia Conference\n%P 928-937\n%@ 1450336035\n%D 2016\n%I ACM\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:13:21,126 DEBUG dbutils] Query result: 173
[2018-03-02 15:13:21,127 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2964320.
[2018-03-02 15:13:21,127 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2964320.
[2018-03-02 15:13:21,141 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:13:22,332 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2964320 HTTP/1.1" 200 None
[2018-03-02 15:13:22,333 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:13:22,333 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:13:22,512 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2964320 HTTP/1.1" 200 None
[2018-03-02 15:13:22,518 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true.
[2018-03-02 15:13:22,518 WARNING utils] Download file (url='http://twin.sci-hub.tw/2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true') and save (filename='PDF//173.pdf')
[2018-03-02 15:13:22,549 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: twin.sci-hub.tw
[2018-03-02 15:13:22,683 DEBUG requests.packages.urllib3.connectionpool] "GET /2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:13:22,684 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:13:22,684 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:13:22,684 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for sci-hub.tw
[2018-03-02 15:13:22,698 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): twin.sci-hub.tw
[2018-03-02 15:13:22,832 DEBUG requests.packages.urllib3.connectionpool] "GET /2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:13:22,835 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:13:22,835 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:20:31,558 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:20:31,559 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:20:31,717 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: twin.sci-hub.tw
[2018-03-02 15:20:31,883 DEBUG requests.packages.urllib3.connectionpool] "GET /2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:20:31,885 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:20:31,885 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:20:31,901 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): twin.sci-hub.tw
[2018-03-02 15:20:32,074 DEBUG requests.packages.urllib3.connectionpool] "GET /2c3639e6d11f6976a9580848b5b50d35/li2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:20:32,079 DEBUG scholar] Handle paper #189 (total 1170)
[2018-03-02 15:20:32,079 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:20:32,083 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:32,083 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:20:32,083 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for scholar.google.com
[2018-03-02 15:20:32,105 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:32,108 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:34,664 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:34,666 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for scholar.google.com
[2018-03-02 15:20:34,667 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:34,667 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:20:34,681 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:34,682 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:36,504 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:36,507 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for scholar.google.com
[2018-03-02 15:20:36,507 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:36,508 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 15:20:36,522 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:36,524 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:46,444 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:46,465 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for scholar.google.com
[2018-03-02 15:20:46,465 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:46,466 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:20:46,480 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:46,482 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:48,904 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:48,906 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for scholar.google.com
[2018-03-02 15:20:48,907 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:48,907 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:20:48,921 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:48,922 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:50,844 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:50,847 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for scholar.google.com
[2018-03-02 15:20:50,847 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:50,847 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:20:50,863 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:50,864 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:54,854 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:54,856 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for scholar.google.com
[2018-03-02 15:20:54,856 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:54,856 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:20:54,871 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:54,872 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:20:58,304 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:20:58,306 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for scholar.google.com
[2018-03-02 15:20:58,306 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:20:58,306 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:20:58,321 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:20:58,322 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:01,783 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:01,785 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for scholar.google.com
[2018-03-02 15:21:01,786 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:01,786 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:21:01,800 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:01,801 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:06,373 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:06,376 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for scholar.google.com
[2018-03-02 15:21:06,377 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:06,377 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:21:06,392 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:06,393 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:09,374 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:09,376 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for scholar.google.com
[2018-03-02 15:21:09,376 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:09,376 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:21:09,392 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:09,393 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:13,173 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:13,175 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for scholar.google.com
[2018-03-02 15:21:13,176 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:13,176 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:21:13,191 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:13,192 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:15,573 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:15,576 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for scholar.google.com
[2018-03-02 15:21:15,576 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:15,576 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:21:15,592 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:15,593 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:18,423 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:18,425 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for scholar.google.com
[2018-03-02 15:21:18,426 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:18,426 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 15:21:18,440 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:18,442 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:23,443 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703EF49B0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703EF49B0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703EF49B0>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 15:21:23,443 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for scholar.google.com
[2018-03-02 15:21:23,444 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:23,444 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:21:23,459 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:23,461 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:26,054 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:26,056 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for scholar.google.com
[2018-03-02 15:21:26,056 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:26,056 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:21:26,071 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:26,072 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:29,005 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:29,007 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for scholar.google.com
[2018-03-02 15:21:29,008 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:29,008 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:21:29,023 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:29,024 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:31,763 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:31,765 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for scholar.google.com
[2018-03-02 15:21:31,765 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:31,765 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:21:31,780 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:31,781 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:35,993 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:35,995 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for scholar.google.com
[2018-03-02 15:21:35,996 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:35,996 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:21:41,013 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 393, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 389, in _make_request
    httplib_response = conn.getresponse()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1002, in recv_into
    return self.read(nbytes, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 865, in read
    return self._sslobj.read(len, buffer)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 625, in read
    v = self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 261, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\packages\six.py", line 686, in reraise
    raise value
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 595, in urlopen
    chunked=chunked)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 395, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 315, in _raise_timeout
    raise ReadTimeoutError(self, url, "Read timed out. (read timeout=%s)" % timeout_value)
requests.packages.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Read timed out. (read timeout=5)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 499, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Read timed out. (read timeout=5)

[2018-03-02 15:21:41,013 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for scholar.google.com
[2018-03-02 15:21:41,013 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:41,014 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:21:41,037 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:41,038 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:43,612 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:43,614 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for scholar.google.com
[2018-03-02 15:21:43,616 DEBUG scholar] Upload empty EndNote file.
[2018-03-02 15:21:43,616 DEBUG __main__] Skip paper #189, empty year or authors fields.
[2018-03-02 15:21:43,617 DEBUG scholar] Handle paper #190 (total 1170)
[2018-03-02 15:21:43,617 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:21:43,622 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:43,623 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:21:43,639 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:43,641 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:46,123 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:46,125 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for scholar.google.com
[2018-03-02 15:21:46,126 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:46,126 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:21:46,144 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:46,146 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:48,063 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:48,065 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for scholar.google.com
[2018-03-02 15:21:48,066 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:48,066 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:21:48,081 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:53,213 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:21:53,213 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for scholar.google.com
[2018-03-02 15:21:53,214 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:53,214 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:21:53,229 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:53,230 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:21:55,524 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:55,526 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for scholar.google.com
[2018-03-02 15:21:55,526 DEBUG utils] Status code 403 has 21 appearance. Cookies will reload.
[2018-03-02 15:21:55,526 DEBUG utils] Start delete cookies for google.com and google scholar
[2018-03-02 15:21:55,526 DEBUG utils] Delete cookies for googleusercontent.com
[2018-03-02 15:21:55,526 DEBUG utils] Delete cookies for google.com
[2018-03-02 15:21:55,527 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:55,527 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:21:55,542 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:55,544 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:21:57,953 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:21:57,955 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for scholar.google.com
[2018-03-02 15:21:57,955 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:21:57,955 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:21:57,970 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:21:57,971 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:00,323 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:00,325 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for scholar.google.com
[2018-03-02 15:22:00,326 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:00,326 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:22:00,341 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:00,342 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:02,863 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:02,864 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for scholar.google.com
[2018-03-02 15:22:02,865 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:02,865 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:22:02,880 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:02,882 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:05,590 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:05,592 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for scholar.google.com
[2018-03-02 15:22:05,592 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:05,592 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:22:05,607 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:12,830 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:732: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

[2018-03-02 15:22:12,830 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for scholar.google.com
[2018-03-02 15:22:12,832 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:12,832 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:22:12,847 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:12,848 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:16,843 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:16,845 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for scholar.google.com
[2018-03-02 15:22:16,845 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:16,845 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:22:16,865 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:16,866 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:19,392 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:19,395 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for scholar.google.com
[2018-03-02 15:22:19,395 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:19,395 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:22:19,410 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:24,581 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:22:24,582 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for scholar.google.com
[2018-03-02 15:22:24,582 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:24,582 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:22:24,596 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:24,598 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:26,843 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:26,845 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for scholar.google.com
[2018-03-02 15:22:26,845 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:26,845 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:22:26,860 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:26,861 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:30,111 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:30,113 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for scholar.google.com
[2018-03-02 15:22:30,113 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:30,114 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:22:30,129 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:30,130 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:32,502 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:32,504 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for scholar.google.com
[2018-03-02 15:22:32,505 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:32,505 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:22:32,520 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:32,522 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:36,523 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:36,525 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for scholar.google.com
[2018-03-02 15:22:36,526 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:36,526 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:22:36,541 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:36,542 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:40,114 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:40,117 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for scholar.google.com
[2018-03-02 15:22:40,117 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:40,118 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:22:40,132 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:40,133 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:44,191 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:44,193 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for scholar.google.com
[2018-03-02 15:22:44,194 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:44,194 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:22:44,230 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:22:44,231 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:48,216 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en HTTP/1.1" 403 None
[2018-03-02 15:22:48,219 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for scholar.google.com
[2018-03-02 15:22:48,219 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:48,219 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:22:48,233 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:22:53,452 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:22:53,453 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for scholar.google.com
[2018-03-02 15:22:53,454 DEBUG scholar] Upload empty EndNote file.
[2018-03-02 15:22:53,455 DEBUG __main__] Skip paper #190, empty year or authors fields.
[2018-03-02 15:22:53,475 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:22:53,475 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:22:53,476 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:22:53,490 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:22:53,760 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.google.com', port=443): Max retries exceeded with url: /scholar?start=190&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.google.com', port=443): Max retries exceeded with url: /scholar?start=190&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:22:53,760 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for scholar.google.com
[2018-03-02 15:22:53,761 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:22:53,761 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:22:53,776 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:22:56,865 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=190&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:22:57,699 DEBUG scholar] Find papers on page #20 (max_google_papers = 300)
[2018-03-02 15:22:57,700 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:22:57,700 DEBUG scholar] Handle paper #191 (total 1170)
[2018-03-02 15:22:57,700 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:22:57,703 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:22:57,703 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:22:57,703 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for scholar.google.com
[2018-03-02 15:22:57,721 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:22:59,055 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:6-OhVpaG-6YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvZp4UjPKOegInEd2kVlwYUBM8aPc&scisf=3&ct=citation&cd=190&hl=en HTTP/1.1" 200 308
[2018-03-02 15:22:59,056 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T An Artificial Intelligence approach to Arabic and Islamic content on the internet
%A Atwell, Eric
%A Brierley, Claire
%A Dukes, Kais
%A Sawalha, Majdi
%A Sharaf, Abdul-Baquee
%B Proceedings of NITS 3rd National Information Technology Symposium
%P 1-8
%D 2011
%I Leeds

[2018-03-02 15:22:59,056 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:22:59,057 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:22:59,057 DEBUG __main__] Process content of EndNote file #191
{"title": "An Artificial Intelligence approach to Arabic and Islamic content on the internet", "url": "https://www.researchgate.net/profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf", "author": [{"shortname": "E Atwell", "gid": "Iu5WFskAAAAJ"}, {"shortname": "C Brierley", "gid": ""}, {"shortname": "K Dukes", "gid": "wmRDl-4AAAAJ"}, {"shortname": "M Sawalha", "gid": "6LD7HyIAAAAJ"}], "year": 2011}
{"citedby": 40, "type": "Conference Proceedings", "title": "An Artificial Intelligence approach to Arabic and Islamic content on the internet", "author": ["Atwell, Eric", "Brierley, Claire", "Dukes, Kais", "Sawalha, Majdi", "Sharaf, Abdul-Baquee"], "secondarytitle": "Proceedings of NITS 3rd National Information Technology Symposium", "pages": "1-8", "year": "2011", "publisher": "Leeds", "start_page": 1, "end_page": 8, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T An Artificial Intelligence approach to Arabic and Islamic content on the internet\n%A Atwell, Eric\n%A Brierley, Claire\n%A Dukes, Kais\n%A Sawalha, Majdi\n%A Sharaf, Abdul-Baquee\n%B Proceedings of NITS 3rd National Information Technology Symposium\n%P 1-8\n%D 2011\n%I Leeds\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:6-OhVpaG-6YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvZp4UjPKOegInEd2kVlwYUBM8aPc&scisf=3&ct=citation&cd=190&hl=en"}
[2018-03-02 15:22:59,057 DEBUG dbutils] Get paper id {"DOI": null, "title": "An Artificial Intelligence approach to Arabic and Islamic content on the internet", "auth_count": 5, "g_type": "Conference Proceedings", "pages": 8, "year": 2011, "rg_id": null, "start_page": 1, "end_page": 8}.
[2018-03-02 15:22:59,057 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An Artificial Intelligence approach to Arabic and Islamic content on the internet', 'auth_count': 5, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2011, 'rg_id': None, 'start_page': 1, 'end_page': 8}
[2018-03-02 15:22:59,057 DEBUG dbutils] Query result: []
[2018-03-02 15:22:59,057 DEBUG dbutils] Paper id = None.
[2018-03-02 15:22:59,057 DEBUG dbutils] Add new paper (title='An Artificial Intelligence approach to Arabic and Islamic content on the internet')
[2018-03-02 15:22:59,057 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An Artificial Intelligence approach to Arabic and Islamic content on the internet', 'year': 2011, 'publisher': 'Leeds', 'start_page': 1, 'end_page': 8, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T An Artificial Intelligence approach to Arabic and Islamic content on the internet\n%A Atwell, Eric\n%A Brierley, Claire\n%A Dukes, Kais\n%A Sawalha, Majdi\n%A Sharaf, Abdul-Baquee\n%B Proceedings of NITS 3rd National Information Technology Symposium\n%P 1-8\n%D 2011\n%I Leeds\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:22:59,058 DEBUG dbutils] Query result: 174
[2018-03-02 15:22:59,059 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf.
[2018-03-02 15:22:59,062 WARNING utils] Download file (url='https://www.researchgate.net/profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf') and save (filename='PDF//174.pdf')
[2018-03-02 15:22:59,062 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:22:59,062 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:22:59,062 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for www.researchgate.net
[2018-03-02 15:22:59,077 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:23:00,232 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf HTTP/1.1" 429 None
[2018-03-02 15:23:00,411 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for www.researchgate.net
[2018-03-02 15:23:00,412 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:23:00,412 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:23:00,427 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:23:01,394 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 307 Temporary Redirect

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 307 Temporary Redirect',)))

[2018-03-02 15:23:01,394 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for www.researchgate.net
[2018-03-02 15:23:01,395 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:23:01,395 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:23:01,409 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:23:02,753 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Eric_Atwell/publication/262198563_An_Artificial_Intelligence_Approach_to_Arabic_and_Islamic_Content_on_the_Internet/links/544d469f0cf2d6347f45c51c/An-Artificial-Intelligence-Approach-to-Arabic-and-Islamic-Content-on-the-Internet.pdf HTTP/1.1" 200 258696
[2018-03-02 15:23:02,754 DEBUG utils] Content-length=258696
[2018-03-02 15:23:02,754 DEBUG utils] Create file PDF//174.pdf, start download.
[2018-03-02 15:23:03,531 DEBUG utils] End download file PDF//174.pdf.
[2018-03-02 15:23:03,532 DEBUG dbutils] Update pdf_transaction for paper id=174.
[2018-03-02 15:23:03,532 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 174'
[2018-03-02 15:23:03,532 DEBUG dbutils] Query result: null
[2018-03-02 15:23:03,532 DEBUG scholar] Handle paper #192 (total 1170)
[2018-03-02 15:23:03,532 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:23:03,539 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:03,539 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:23:03,801 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:3WalR_o9EooJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvYujV8c86LDJbS7v-EDSFrSka3za&scisf=3&ct=citation&cd=191&hl=en HTTP/1.1" 200 131
[2018-03-02 15:23:03,802 DEBUG scholar] EndNote file:
%0 Generic
%T Open sourcing a deep learning solution for detecting NSFW images
%A Mahadeokar, Jay
%A Pesavento, Gerry
%D 2016

[2018-03-02 15:23:03,802 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:03,802 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:03,802 DEBUG __main__] Process content of EndNote file #192
{"title": "Open sourcing a deep learning solution for detecting NSFW images", "url": "http://blog.csdn.net/laowu8615/article/details/70049747", "author": [{"shortname": "J Mahadeokar", "gid": ""}, {"shortname": "G Pesavento", "gid": ""}], "year": 2016}
{"citedby": 2, "type": "Generic", "title": "Open sourcing a deep learning solution for detecting NSFW images", "author": ["Mahadeokar, Jay", "Pesavento, Gerry"], "year": "2016", "EndNote": "%0 Generic\n%T Open sourcing a deep learning solution for detecting NSFW images\n%A Mahadeokar, Jay\n%A Pesavento, Gerry\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:3WalR_o9EooJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvYujV8c86LDJbS7v-EDSFrSka3za&scisf=3&ct=citation&cd=191&hl=en"}
[2018-03-02 15:23:03,802 DEBUG dbutils] Get paper id {"DOI": null, "title": "Open sourcing a deep learning solution for detecting NSFW images", "auth_count": 2, "g_type": "Generic", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:23:03,803 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Open sourcing a deep learning solution for detecting NSFW images', 'auth_count': 2, 'g_type': 'Generic', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:23:03,803 DEBUG dbutils] Query result: []
[2018-03-02 15:23:03,803 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:03,803 DEBUG dbutils] Add new paper (title='Open sourcing a deep learning solution for detecting NSFW images')
[2018-03-02 15:23:03,803 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Open sourcing a deep learning solution for detecting NSFW images', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Open sourcing a deep learning solution for detecting NSFW images\n%A Mahadeokar, Jay\n%A Pesavento, Gerry\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:03,803 DEBUG dbutils] Query result: 175
[2018-03-02 15:23:03,804 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://blog.csdn.net/laowu8615/article/details/70049747.
[2018-03-02 15:23:03,805 DEBUG scihub] Get page from sci-hub for paper with DOI=http://blog.csdn.net/laowu8615/article/details/70049747.
[2018-03-02 15:23:03,820 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:23:04,153 DEBUG requests.packages.urllib3.connectionpool] "GET //http://blog.csdn.net/laowu8615/article/details/70049747 HTTP/1.1" 302 None
[2018-03-02 15:23:04,177 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): blog.csdn.net
[2018-03-02 15:23:05,020 DEBUG requests.packages.urllib3.connectionpool] "GET /laowu8615/article/details/70049747 HTTP/1.1" 200 None
[2018-03-02 15:23:05,264 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:23:05,264 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:23:05,264 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for sci-hub.tw
[2018-03-02 15:23:05,443 DEBUG requests.packages.urllib3.connectionpool] "GET //http://blog.csdn.net/laowu8615/article/details/70049747 HTTP/1.1" 302 None
[2018-03-02 15:23:05,791 DEBUG requests.packages.urllib3.connectionpool] "GET /laowu8615/article/details/70049747 HTTP/1.1" 200 None
[2018-03-02 15:23:06,121 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:23:06,122 DEBUG scholar] Handle paper #193 (total 1170)
[2018-03-02 15:23:06,122 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:23:06,125 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:06,125 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:23:06,126 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for scholar.google.com
[2018-03-02 15:23:06,140 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:23:06,141 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:23:07,563 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:tn714wTQQeAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvfrcmE1CmsIQxt4Mra6vlNeFvfow&scisf=3&ct=citation&cd=192&hl=en HTTP/1.1" 200 72
[2018-03-02 15:23:07,563 DEBUG scholar] EndNote file:
%0 Journal Article
%T Game-Based Teaching
%A Bauman, Eric B
%D 2013

[2018-03-02 15:23:07,564 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:07,564 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:07,564 DEBUG __main__] Process content of EndNote file #193
{"title": "Game-Based Teaching", "url": "http://www.hagerstowncc.edu/sites/default/files/documents/13-bauman-gamebased-teaching-ce.pdf", "author": [{"shortname": "EB Bauman", "gid": "gWG89QUAAAAJ"}], "year": 2013}
{"type": "Journal Article", "title": "Game-Based Teaching", "author": ["Bauman, Eric B"], "year": "2013", "EndNote": "%0 Journal Article\n%T Game-Based Teaching\n%A Bauman, Eric B\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:tn714wTQQeAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvfrcmE1CmsIQxt4Mra6vlNeFvfow&scisf=3&ct=citation&cd=192&hl=en"}
[2018-03-02 15:23:07,564 DEBUG dbutils] Get paper id {"DOI": null, "title": "Game-Based Teaching", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:23:07,564 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Game-Based Teaching', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:23:07,564 DEBUG dbutils] Query result: []
[2018-03-02 15:23:07,564 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:07,564 DEBUG dbutils] Add new paper (title='Game-Based Teaching')
[2018-03-02 15:23:07,564 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Game-Based Teaching', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Game-Based Teaching\n%A Bauman, Eric B\n%D 2013\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:07,565 DEBUG dbutils] Query result: 176
[2018-03-02 15:23:07,566 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.hagerstowncc.edu/sites/default/files/documents/13-bauman-gamebased-teaching-ce.pdf.
[2018-03-02 15:23:07,567 WARNING utils] Download file (url='http://www.hagerstowncc.edu/sites/default/files/documents/13-bauman-gamebased-teaching-ce.pdf') and save (filename='PDF//176.pdf')
[2018-03-02 15:23:07,567 DEBUG utils] Get current proxy for www.hagerstowncc.edu.
[2018-03-02 15:23:07,567 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:23:07,567 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for otherhost
[2018-03-02 15:23:07,586 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.hagerstowncc.edu
[2018-03-02 15:23:08,214 DEBUG requests.packages.urllib3.connectionpool] "GET /sites/default/files/documents/13-bauman-gamebased-teaching-ce.pdf HTTP/1.1" 200 3555858
[2018-03-02 15:23:08,215 DEBUG utils] Content-length=3555858
[2018-03-02 15:23:08,215 DEBUG utils] Create file PDF//176.pdf, start download.
[2018-03-02 15:23:13,646 DEBUG utils] End download file PDF//176.pdf.
[2018-03-02 15:23:13,647 DEBUG dbutils] Update pdf_transaction for paper id=176.
[2018-03-02 15:23:13,647 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 176'
[2018-03-02 15:23:13,648 DEBUG dbutils] Query result: null
[2018-03-02 15:23:13,648 DEBUG scholar] Handle paper #194 (total 1170)
[2018-03-02 15:23:13,649 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:23:13,652 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:13,652 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:23:13,928 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:n46vNJ2ssg0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvQsZy-ALs7ANPTUiGWr6jZlOirsQ&scisf=3&ct=citation&cd=193&hl=en HTTP/1.1" 200 207
[2018-03-02 15:23:13,929 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Devious chatbots-interactive malware with a plot
%A Jonathan, Pan Juin Yang
%A Fung, Chun Che
%A Wong, Kok Wai
%B FIRA RoboWorld Congress
%P 110-118
%D 2009
%I Springer

[2018-03-02 15:23:13,929 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:13,929 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:13,929 DEBUG __main__] Process content of EndNote file #194
{"title": "Devious chatbots-interactive malware with a plot", "url": "https://link.springer.com/chapter/10.1007/978-3-642-03986-7_13", "author": [{"shortname": "PJY Jonathan", "gid": ""}, {"shortname": "CC Fung", "gid": "Jvc4wz8AAAAJ"}, {"shortname": "KW Wong", "gid": "ftBKWiUAAAAJ"}], "year": 2009}
{"citedby": 6, "type": "Conference Proceedings", "title": "Devious chatbots-interactive malware with a plot", "author": ["Jonathan, Pan Juin Yang", "Fung, Chun Che", "Wong, Kok Wai"], "secondarytitle": "FIRA RoboWorld Congress", "pages": "110-118", "year": "2009", "publisher": "Springer", "start_page": 110, "end_page": 118, "volume": 9, "EndNote": "%0 Conference Proceedings\n%T Devious chatbots-interactive malware with a plot\n%A Jonathan, Pan Juin Yang\n%A Fung, Chun Che\n%A Wong, Kok Wai\n%B FIRA RoboWorld Congress\n%P 110-118\n%D 2009\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:n46vNJ2ssg0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvQsZy-ALs7ANPTUiGWr6jZlOirsQ&scisf=3&ct=citation&cd=193&hl=en"}
[2018-03-02 15:23:13,929 DEBUG dbutils] Get paper id {"DOI": null, "title": "Devious chatbots-interactive malware with a plot", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 9, "year": 2009, "rg_id": null, "start_page": 110, "end_page": 118}.
[2018-03-02 15:23:13,929 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Devious chatbots-interactive malware with a plot', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 9, 'year': 2009, 'rg_id': None, 'start_page': 110, 'end_page': 118}
[2018-03-02 15:23:13,929 DEBUG dbutils] Query result: []
[2018-03-02 15:23:13,929 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:13,929 DEBUG dbutils] Add new paper (title='Devious chatbots-interactive malware with a plot')
[2018-03-02 15:23:13,930 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Devious chatbots-interactive malware with a plot', 'year': 2009, 'publisher': 'Springer', 'start_page': 110, 'end_page': 118, 'pages': 9, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Devious chatbots-interactive malware with a plot\n%A Jonathan, Pan Juin Yang\n%A Fung, Chun Che\n%A Wong, Kok Wai\n%B FIRA RoboWorld Congress\n%P 110-118\n%D 2009\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:13,930 DEBUG dbutils] Query result: 177
[2018-03-02 15:23:13,931 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://researchrepository.murdoch.edu.au/id/eprint/3394/1/devious_chatbots.pdf.
[2018-03-02 15:23:13,932 WARNING utils] Download file (url='http://researchrepository.murdoch.edu.au/id/eprint/3394/1/devious_chatbots.pdf') and save (filename='PDF//177.pdf')
[2018-03-02 15:23:13,932 DEBUG utils] Get current proxy for researchrepository.murdoch.edu.au.
[2018-03-02 15:23:13,932 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:23:13,949 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): researchrepository.murdoch.edu.au
[2018-03-02 15:23:14,461 DEBUG requests.packages.urllib3.connectionpool] "GET /id/eprint/3394/1/devious_chatbots.pdf HTTP/1.1" 200 215074
[2018-03-02 15:23:14,461 DEBUG utils] Content-length=215074
[2018-03-02 15:23:14,462 DEBUG utils] Create file PDF//177.pdf, start download.
[2018-03-02 15:23:14,965 DEBUG utils] End download file PDF//177.pdf.
[2018-03-02 15:23:14,967 DEBUG dbutils] Update pdf_transaction for paper id=177.
[2018-03-02 15:23:14,967 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 177'
[2018-03-02 15:23:14,967 DEBUG dbutils] Query result: null
[2018-03-02 15:23:14,967 DEBUG scholar] Handle paper #195 (total 1170)
[2018-03-02 15:23:14,967 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:23:14,971 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:14,971 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:23:14,971 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for scholar.google.com
[2018-03-02 15:23:14,986 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:23:14,987 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:23:19,343 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5JXjQQGR_pgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvdGY7XIwXKqHlh2zqkm4xiCUV1yV&scisf=3&ct=citation&cd=194&hl=en HTTP/1.1" 200 204
[2018-03-02 15:23:19,344 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Call Me... Maybe: A Framework for Integrating the Internet into ELT.
%A Chinnery, George M
%B English Teaching Forum
%V 52
%N 1
%P 2-13
%@ 1559-663X
%D 2014
%I ERIC

[2018-03-02 15:23:19,344 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:19,344 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:19,344 DEBUG __main__] Process content of EndNote file #195
{"title": "Call Me... Maybe: A Framework for Integrating the Internet into ELT.", "url": "https://eric.ed.gov/?id=EJ1029158", "author": [{"shortname": "GM Chinnery", "gid": ""}], "year": 2014}
{"citedby": 13, "type": "Conference Proceedings", "title": "Call Me... Maybe: A Framework for Integrating the Internet into ELT.", "author": ["Chinnery, George M"], "secondarytitle": "English Teaching Forum", "volume": 12, "numberorissue": "1", "pages": "2-13", "isbn/issn": "1559-663X", "year": "2014", "publisher": "ERIC", "start_page": 2, "end_page": 13, "EndNote": "%0 Conference Proceedings\n%T Call Me... Maybe: A Framework for Integrating the Internet into ELT.\n%A Chinnery, George M\n%B English Teaching Forum\n%V 52\n%N 1\n%P 2-13\n%@ 1559-663X\n%D 2014\n%I ERIC\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5JXjQQGR_pgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvdGY7XIwXKqHlh2zqkm4xiCUV1yV&scisf=3&ct=citation&cd=194&hl=en"}
[2018-03-02 15:23:19,344 DEBUG dbutils] Get paper id {"DOI": null, "title": "Call Me... Maybe: A Framework for Integrating the Internet into ELT.", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 12, "year": 2014, "rg_id": null, "start_page": 2, "end_page": 13}.
[2018-03-02 15:23:19,344 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Call Me... Maybe: A Framework for Integrating the Internet into ELT.', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 12, 'year': 2014, 'rg_id': None, 'start_page': 2, 'end_page': 13}
[2018-03-02 15:23:19,344 DEBUG dbutils] Query result: []
[2018-03-02 15:23:19,344 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:19,344 DEBUG dbutils] Add new paper (title='Call Me... Maybe: A Framework for Integrating the Internet into ELT.')
[2018-03-02 15:23:19,345 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Call Me... Maybe: A Framework for Integrating the Internet into ELT.', 'year': 2014, 'publisher': 'ERIC', 'start_page': 2, 'end_page': 13, 'pages': 12, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Call Me... Maybe: A Framework for Integrating the Internet into ELT.\n%A Chinnery, George M\n%B English Teaching Forum\n%V 52\n%N 1\n%P 2-13\n%@ 1559-663X\n%D 2014\n%I ERIC\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:19,345 DEBUG dbutils] Query result: 178
[2018-03-02 15:23:19,346 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://files.eric.ed.gov/fulltext/EJ1029158.pdf.
[2018-03-02 15:23:19,347 WARNING utils] Download file (url='https://files.eric.ed.gov/fulltext/EJ1029158.pdf') and save (filename='PDF//178.pdf')
[2018-03-02 15:23:19,348 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 15:23:19,348 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:23:19,348 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for otherhost
[2018-03-02 15:23:19,366 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 15:23:25,241 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='files.eric.ed.gov', port=443): Max retries exceeded with url: /fulltext/EJ1029158.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='files.eric.ed.gov', port=443): Max retries exceeded with url: /fulltext/EJ1029158.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:23:25,241 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for otherhost
[2018-03-02 15:23:25,242 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 15:23:25,242 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:23:25,256 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 15:23:30,390 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='files.eric.ed.gov', port=443): Max retries exceeded with url: /fulltext/EJ1029158.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='files.eric.ed.gov', port=443): Max retries exceeded with url: /fulltext/EJ1029158.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:23:30,390 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for otherhost
[2018-03-02 15:23:30,391 DEBUG utils] Get current proxy for files.eric.ed.gov.
[2018-03-02 15:23:30,391 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:23:30,405 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): files.eric.ed.gov
[2018-03-02 15:23:33,845 DEBUG requests.packages.urllib3.connectionpool] "GET /fulltext/EJ1029158.pdf HTTP/1.1" 200 146848
[2018-03-02 15:23:33,846 DEBUG utils] Content-length=146848
[2018-03-02 15:23:33,847 DEBUG utils] Create file PDF//178.pdf, start download.
[2018-03-02 15:23:35,024 DEBUG utils] End download file PDF//178.pdf.
[2018-03-02 15:23:35,026 DEBUG dbutils] Update pdf_transaction for paper id=178.
[2018-03-02 15:23:35,026 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 178'
[2018-03-02 15:23:35,026 DEBUG dbutils] Query result: null
[2018-03-02 15:23:35,027 DEBUG scholar] Handle paper #196 (total 1170)
[2018-03-02 15:23:35,027 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:23:35,032 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:35,032 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:23:35,699 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5vlpr0QQwnIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvcQbSeUmW_93Dl2JooP1hcoscDke&scisf=3&ct=citation&cd=195&hl=en HTTP/1.1" 200 304
[2018-03-02 15:23:35,700 DEBUG scholar] EndNote file:
%0 Book
%T Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 2023, 2016, Proceedings
%A Traum, David
%A Swartout, William
%A Khooshabeh, Peter
%A Kopp, Stefan
%A Scherer, Stefan
%A Leuski, Anton
%V 10011
%@ 3319476653
%D 2016
%I Springer

[2018-03-02 15:23:35,700 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:35,700 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:35,700 DEBUG __main__] Process content of EndNote file #196
{"title": "Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 20\u201323, 2016, Proceedings", "url": "https://books.google.com/books?hl=en&lr=&id=t4pJDQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=dOx48METq1&sig=5d4aKaTsft4upTK0OE_8m8xJuDU", "author": [{"shortname": "D Traum", "gid": "evVAmhQAAAAJ"}, {"shortname": "W Swartout", "gid": "IqLMqrYAAAAJ"}, {"shortname": "P Khooshabeh", "gid": "r1D2bkwAAAAJ"}, {"shortname": "S Kopp", "gid": "2AEULN0AAAAJ"}], "year": 2016}
{"type": "Book", "title": "Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 20\u201323, 2016, Proceedings", "author": ["Traum, David", "Swartout, William", "Khooshabeh, Peter", "Kopp, Stefan", "Scherer, Stefan", "Leuski, Anton"], "volume": "10011", "isbn/issn": "3319476653", "year": "2016", "publisher": "Springer", "EndNote": "%0 Book\n%T Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 20\u201323, 2016, Proceedings\n%A Traum, David\n%A Swartout, William\n%A Khooshabeh, Peter\n%A Kopp, Stefan\n%A Scherer, Stefan\n%A Leuski, Anton\n%V 10011\n%@ 3319476653\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5vlpr0QQwnIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvcQbSeUmW_93Dl2JooP1hcoscDke&scisf=3&ct=citation&cd=195&hl=en"}
[2018-03-02 15:23:35,700 DEBUG dbutils] Get paper id {"DOI": null, "title": "Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 20\u201323, 2016, Proceedings", "auth_count": 6, "g_type": "Book", "pages": 10011, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:23:35,700 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 2023, 2016, Proceedings', 'auth_count': 6, 'g_type': 'Book', 'pages': 10011, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:23:35,700 DEBUG dbutils] Query result: []
[2018-03-02 15:23:35,701 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:35,701 DEBUG dbutils] Add new paper (title='Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 2023, 2016, Proceedings')
[2018-03-02 15:23:35,701 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 2023, 2016, Proceedings', 'year': 2016, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': 10011, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Intelligent Virtual Agents: 16th International Conference, IVA 2016, Los Angeles, CA, USA, September 2023, 2016, Proceedings\n%A Traum, David\n%A Swartout, William\n%A Khooshabeh, Peter\n%A Kopp, Stefan\n%A Scherer, Stefan\n%A Leuski, Anton\n%V 10011\n%@ 3319476653\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 6, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:35,701 DEBUG dbutils] Query result: 179
[2018-03-02 15:23:35,702 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=t4pJDQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=dOx48METq1&sig=5d4aKaTsft4upTK0OE_8m8xJuDU.
[2018-03-02 15:23:35,703 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=t4pJDQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=dOx48METq1&sig=5d4aKaTsft4upTK0OE_8m8xJuDU.
[2018-03-02 15:23:35,919 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=t4pJDQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=dOx48METq1&sig=5d4aKaTsft4upTK0OE_8m8xJuDU HTTP/1.1" 302 None
[2018-03-02 15:23:36,112 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:23:36,117 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:23:36,118 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:23:36,291 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=t4pJDQAAQBAJ&oi=fnd&pg=PR5&dq=Use+deep+learning+to+create+a+chatbot&ots=dOx48METq1&sig=5d4aKaTsft4upTK0OE_8m8xJuDU HTTP/1.1" 302 None
[2018-03-02 15:23:36,520 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:23:36,549 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:23:36,550 DEBUG scholar] Handle paper #197 (total 1170)
[2018-03-02 15:23:36,550 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:23:36,554 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:36,554 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:23:36,554 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for scholar.google.com
[2018-03-02 15:23:36,569 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:23:36,570 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:23:40,250 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:cDnJa3P8soUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvbfZqd2TVGWiWwiLPxNgGbs9bXJv&scisf=3&ct=citation&cd=196&hl=en HTTP/1.1" 200 190
[2018-03-02 15:23:40,250 DEBUG scholar] EndNote file:
%0 Journal Article
%T The Impact of Artificial Intelligence on Global Trends
%A Pavaloiu, Alice
%J Journal of Multidisciplinary Developments
%V 1
%N 1
%P 21-37
%@ 2564-6095
%D 2016

[2018-03-02 15:23:40,250 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:40,251 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:40,251 DEBUG __main__] Process content of EndNote file #197
{"title": "The Impact of Artificial Intelligence on Global Trends", "url": "http://jomude.com/index.php/jomude/article/view/16", "author": [{"shortname": "A Pavaloiu", "gid": "81zJjekAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "The Impact of Artificial Intelligence on Global Trends", "author": ["Pavaloiu, Alice"], "journal": "Journal of Multidisciplinary Developments", "volume": 17, "numberorissue": "1", "pages": "21-37", "isbn/issn": "2564-6095", "year": "2016", "start_page": 21, "end_page": 37, "EndNote": "%0 Journal Article\n%T The Impact of Artificial Intelligence on Global Trends\n%A Pavaloiu, Alice\n%J Journal of Multidisciplinary Developments\n%V 1\n%N 1\n%P 21-37\n%@ 2564-6095\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:cDnJa3P8soUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvbfZqd2TVGWiWwiLPxNgGbs9bXJv&scisf=3&ct=citation&cd=196&hl=en"}
[2018-03-02 15:23:40,251 DEBUG dbutils] Get paper id {"DOI": null, "title": "The Impact of Artificial Intelligence on Global Trends", "auth_count": 1, "g_type": "Journal Article", "pages": 17, "year": 2016, "rg_id": null, "start_page": 21, "end_page": 37}.
[2018-03-02 15:23:40,251 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The Impact of Artificial Intelligence on Global Trends', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 17, 'year': 2016, 'rg_id': None, 'start_page': 21, 'end_page': 37}
[2018-03-02 15:23:40,251 DEBUG dbutils] Query result: []
[2018-03-02 15:23:40,251 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:40,251 DEBUG dbutils] Add new paper (title='The Impact of Artificial Intelligence on Global Trends')
[2018-03-02 15:23:40,251 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The Impact of Artificial Intelligence on Global Trends', 'year': 2016, 'publisher': None, 'start_page': 21, 'end_page': 37, 'pages': 17, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The Impact of Artificial Intelligence on Global Trends\n%A Pavaloiu, Alice\n%J Journal of Multidisciplinary Developments\n%V 1\n%N 1\n%P 21-37\n%@ 2564-6095\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:40,251 DEBUG dbutils] Query result: 180
[2018-03-02 15:23:40,254 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://jomude.com/index.php/jomude/article/download/16/108.
[2018-03-02 15:23:40,255 WARNING utils] Download file (url='http://jomude.com/index.php/jomude/article/download/16/108') and save (filename='PDF//180.pdf')
[2018-03-02 15:23:40,255 DEBUG utils] Get current proxy for jomude.com.
[2018-03-02 15:23:40,255 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:23:40,255 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for otherhost
[2018-03-02 15:23:40,272 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): jomude.com
[2018-03-02 15:23:41,325 DEBUG requests.packages.urllib3.connectionpool] "GET /index.php/jomude/article/download/16/108 HTTP/1.1" 200 853204
[2018-03-02 15:23:41,326 DEBUG utils] Content-length=853204
[2018-03-02 15:23:41,327 DEBUG utils] Create file PDF//180.pdf, start download.
[2018-03-02 15:23:44,275 DEBUG utils] End download file PDF//180.pdf.
[2018-03-02 15:23:44,277 DEBUG dbutils] Update pdf_transaction for paper id=180.
[2018-03-02 15:23:44,277 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 180'
[2018-03-02 15:23:44,277 DEBUG dbutils] Query result: null
[2018-03-02 15:23:44,277 DEBUG scholar] Handle paper #198 (total 1170)
[2018-03-02 15:23:44,277 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:23:44,281 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:44,282 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:23:44,666 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GJBAwC1CEVgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvV729atz1IEDOyNFL3rKS8NqeFmC&scisf=3&ct=citation&cd=197&hl=en HTTP/1.1" 200 173
[2018-03-02 15:23:44,667 DEBUG scholar] EndNote file:
%0 Book
%T Interactive dramaturgies: new approaches in multimedia content and design
%A Hagebolling, Heide
%@ 3540442065
%D 2004
%I Springer Science & Business Media

[2018-03-02 15:23:44,667 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:44,667 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:44,667 DEBUG __main__] Process content of EndNote file #198
{"title": "Interactive dramaturgies: new approaches in multimedia content and design", "url": "https://books.google.com/books?hl=en&lr=&id=8RaLnK7ejjsC&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=6v4poyh3JV&sig=QkX5rQk_iCIZq0yUzpD9Ym0P-M8", "author": [{"shortname": "H Hageb\u00f6lling", "gid": ""}], "year": 2004}
{"citedby": 35, "type": "Book", "title": "Interactive dramaturgies: new approaches in multimedia content and design", "author": ["Hageb\u00f6lling, Heide"], "isbn/issn": "3540442065", "year": "2004", "publisher": "Springer Science & Business Media", "EndNote": "%0 Book\n%T Interactive dramaturgies: new approaches in multimedia content and design\n%A Hageb\u00f6lling, Heide\n%@ 3540442065\n%D 2004\n%I Springer Science & Business Media\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GJBAwC1CEVgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvV729atz1IEDOyNFL3rKS8NqeFmC&scisf=3&ct=citation&cd=197&hl=en"}
[2018-03-02 15:23:44,667 DEBUG dbutils] Get paper id {"DOI": null, "title": "Interactive dramaturgies: new approaches in multimedia content and design", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2004, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:23:44,667 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Interactive dramaturgies: new approaches in multimedia content and design', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2004, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:23:44,668 DEBUG dbutils] Query result: []
[2018-03-02 15:23:44,668 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:44,668 DEBUG dbutils] Add new paper (title='Interactive dramaturgies: new approaches in multimedia content and design')
[2018-03-02 15:23:44,668 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Interactive dramaturgies: new approaches in multimedia content and design', 'year': 2004, 'publisher': 'Springer Science & Business Media', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Interactive dramaturgies: new approaches in multimedia content and design\n%A Hagebolling, Heide\n%@ 3540442065\n%D 2004\n%I Springer Science & Business Media\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:44,668 DEBUG dbutils] Query result: 181
[2018-03-02 15:23:44,670 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=8RaLnK7ejjsC&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=6v4poyh3JV&sig=QkX5rQk_iCIZq0yUzpD9Ym0P-M8.
[2018-03-02 15:23:44,670 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=8RaLnK7ejjsC&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=6v4poyh3JV&sig=QkX5rQk_iCIZq0yUzpD9Ym0P-M8.
[2018-03-02 15:23:44,842 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=8RaLnK7ejjsC&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=6v4poyh3JV&sig=QkX5rQk_iCIZq0yUzpD9Ym0P-M8 HTTP/1.1" 302 None
[2018-03-02 15:23:45,042 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:23:45,063 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:23:45,063 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:23:45,064 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for sci-hub.tw
[2018-03-02 15:23:45,240 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=8RaLnK7ejjsC&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=6v4poyh3JV&sig=QkX5rQk_iCIZq0yUzpD9Ym0P-M8 HTTP/1.1" 302 None
[2018-03-02 15:23:45,432 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:23:45,459 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:23:45,461 DEBUG scholar] Handle paper #199 (total 1170)
[2018-03-02 15:23:45,461 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:23:45,466 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:23:45,466 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:23:45,466 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for scholar.google.com
[2018-03-02 15:23:45,482 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:23:45,483 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:23:48,592 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:sm2fm9Klx74J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvbPdN2NdvaqrBcyTJFE_T4YS5eca&scisf=3&ct=citation&cd=198&hl=en HTTP/1.1" 200 164
[2018-03-02 15:23:48,593 DEBUG scholar] EndNote file:
%0 Journal Article
%T Ultimate IQ: one test to rule them all
%A Biever, Celeste
%J New Scientist
%V 211
%N 2829
%P 42-45
%@ 0262-4079
%D 2011
%I Elsevier

[2018-03-02 15:23:48,593 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:23:48,593 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:23:48,593 DEBUG __main__] Process content of EndNote file #199
{"title": "Ultimate IQ: one test to rule them all", "url": "https://www.sciencedirect.com/science/article/pii/S0262407911622276", "author": [{"shortname": "C Biever", "gid": ""}], "year": 2011}
{"citedby": 7, "type": "Journal Article", "title": "Ultimate IQ: one test to rule them all", "author": ["Biever, Celeste"], "journal": "New Scientist", "volume": 4, "numberorissue": "2829", "pages": "42-45", "isbn/issn": "0262-4079", "year": "2011", "publisher": "Elsevier", "start_page": 42, "end_page": 45, "EndNote": "%0 Journal Article\n%T Ultimate IQ: one test to rule them all\n%A Biever, Celeste\n%J New Scientist\n%V 211\n%N 2829\n%P 42-45\n%@ 0262-4079\n%D 2011\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:sm2fm9Klx74J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvbPdN2NdvaqrBcyTJFE_T4YS5eca&scisf=3&ct=citation&cd=198&hl=en"}
[2018-03-02 15:23:48,593 DEBUG dbutils] Get paper id {"DOI": null, "title": "Ultimate IQ: one test to rule them all", "auth_count": 1, "g_type": "Journal Article", "pages": 4, "year": 2011, "rg_id": null, "start_page": 42, "end_page": 45}.
[2018-03-02 15:23:48,594 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Ultimate IQ: one test to rule them all', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 4, 'year': 2011, 'rg_id': None, 'start_page': 42, 'end_page': 45}
[2018-03-02 15:23:48,594 DEBUG dbutils] Query result: []
[2018-03-02 15:23:48,594 DEBUG dbutils] Paper id = None.
[2018-03-02 15:23:48,594 DEBUG dbutils] Add new paper (title='Ultimate IQ: one test to rule them all')
[2018-03-02 15:23:48,594 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Ultimate IQ: one test to rule them all', 'year': 2011, 'publisher': 'Elsevier', 'start_page': 42, 'end_page': 45, 'pages': 4, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Ultimate IQ: one test to rule them all\n%A Biever, Celeste\n%J New Scientist\n%V 211\n%N 2829\n%P 42-45\n%@ 0262-4079\n%D 2011\n%I Elsevier\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:23:48,594 DEBUG dbutils] Query result: 182
[2018-03-02 15:23:48,596 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S0262407911622276.
[2018-03-02 15:23:48,596 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S0262407911622276.
[2018-03-02 15:23:48,825 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0262407911622276 HTTP/1.1" 200 None
[2018-03-02 15:23:48,826 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:23:48,826 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:23:49,010 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S0262407911622276 HTTP/1.1" 200 None
[2018-03-02 15:23:49,016 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true.
[2018-03-02 15:23:49,017 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true') and save (filename='PDF//182.pdf')
[2018-03-02 15:23:49,031 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 15:23:49,260 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:23:49,261 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:23:49,261 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:23:49,261 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for sci-hub.tw
[2018-03-02 15:23:49,276 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): cyber.sci-hub.tw
[2018-03-02 15:23:49,540 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:23:49,543 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:23:49,543 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:24:02,263 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:24:02,264 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:24:02,612 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true HTTP/1.1" 200 1044534
[2018-03-02 15:24:02,613 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:24:02,613 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:24:02,629 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): cyber.sci-hub.tw
[2018-03-02 15:24:02,881 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9zMDI2Mi00MDc5KDExKTYyMjI3LTY=/biever2011.pdf?download=true HTTP/1.1" 200 1044534
[2018-03-02 15:24:02,882 DEBUG utils] Content-length=1044534
[2018-03-02 15:24:02,883 DEBUG utils] Create file PDF//182.pdf, start download.
[2018-03-02 15:24:04,304 DEBUG utils] End download file PDF//182.pdf.
[2018-03-02 15:24:04,305 DEBUG dbutils] Update pdf_transaction for paper id=182.
[2018-03-02 15:24:04,305 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 182'
[2018-03-02 15:24:04,305 DEBUG dbutils] Query result: null
[2018-03-02 15:24:04,305 DEBUG scholar] Handle paper #200 (total 1170)
[2018-03-02 15:24:04,306 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:24:04,309 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:04,309 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:24:04,800 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KsRhZcwVtAgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvXlb9dfi6CMAj95frpw5wqSH4M10&scisf=3&ct=citation&cd=199&hl=en HTTP/1.1" 200 366
[2018-03-02 15:24:04,801 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Augmented LSTM Framework to Construct Medical Self-diagnosis Android
%A Liu, Chaochun
%A Sun, Huan
%A Du, Nan
%A Tan, Shulong
%A Fei, Hongliang
%A Fan, Wei
%A Yang, Tao
%A Wu, Hao
%A Li, Yaliang
%A Zhang, Chenwei
%B Data Mining (ICDM), 2016 IEEE 16th International Conference on
%P 251-260
%@ 1509054731
%D 2016
%I IEEE

[2018-03-02 15:24:04,801 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:04,801 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:04,801 DEBUG __main__] Process content of EndNote file #200
{"title": "Augmented LSTM Framework to Construct Medical Self-diagnosis Android", "url": "http://ieeexplore.ieee.org/abstract/document/7837849/", "author": [{"shortname": "C Liu", "gid": "kPdsCPMAAAAJ"}, {"shortname": "H Sun", "gid": "wIFkulcAAAAJ"}, {"shortname": "N Du", "gid": "v474hP4AAAAJ"}, {"shortname": "S Tan", "gid": "glaTwrUAAAAJ"}, {"shortname": "H Fei", "gid": ""}, {"shortname": "W Fan", "gid": ""}], "year": 2016}
{"citedby": 3, "type": "Conference Proceedings", "title": "Augmented LSTM Framework to Construct Medical Self-diagnosis Android", "author": ["Liu, Chaochun", "Sun, Huan", "Du, Nan", "Tan, Shulong", "Fei, Hongliang", "Fan, Wei", "Yang, Tao", "Wu, Hao", "Li, Yaliang", "Zhang, Chenwei"], "secondarytitle": "Data Mining (ICDM), 2016 IEEE 16th International Conference on", "pages": "251-260", "isbn/issn": "1509054731", "year": "2016", "publisher": "IEEE", "start_page": 251, "end_page": 260, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Augmented LSTM Framework to Construct Medical Self-diagnosis Android\n%A Liu, Chaochun\n%A Sun, Huan\n%A Du, Nan\n%A Tan, Shulong\n%A Fei, Hongliang\n%A Fan, Wei\n%A Yang, Tao\n%A Wu, Hao\n%A Li, Yaliang\n%A Zhang, Chenwei\n%B Data Mining (ICDM), 2016 IEEE 16th International Conference on\n%P 251-260\n%@ 1509054731\n%D 2016\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KsRhZcwVtAgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplEvXlb9dfi6CMAj95frpw5wqSH4M10&scisf=3&ct=citation&cd=199&hl=en"}
[2018-03-02 15:24:04,801 DEBUG dbutils] Get paper id {"DOI": null, "title": "Augmented LSTM Framework to Construct Medical Self-diagnosis Android", "auth_count": 10, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 251, "end_page": 260}.
[2018-03-02 15:24:04,801 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Augmented LSTM Framework to Construct Medical Self-diagnosis Android', 'auth_count': 10, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 251, 'end_page': 260}
[2018-03-02 15:24:04,802 DEBUG dbutils] Query result: []
[2018-03-02 15:24:04,802 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:04,802 DEBUG dbutils] Add new paper (title='Augmented LSTM Framework to Construct Medical Self-diagnosis Android')
[2018-03-02 15:24:04,802 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Augmented LSTM Framework to Construct Medical Self-diagnosis Android', 'year': 2016, 'publisher': 'IEEE', 'start_page': 251, 'end_page': 260, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Augmented LSTM Framework to Construct Medical Self-diagnosis Android\n%A Liu, Chaochun\n%A Sun, Huan\n%A Du, Nan\n%A Tan, Shulong\n%A Fei, Hongliang\n%A Fan, Wei\n%A Yang, Tao\n%A Wu, Hao\n%A Li, Yaliang\n%A Zhang, Chenwei\n%B Data Mining (ICDM), 2016 IEEE 16th International Conference on\n%P 251-260\n%@ 1509054731\n%D 2016\n%I IEEE\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:04,802 DEBUG dbutils] Query result: 183
[2018-03-02 15:24:04,804 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/68bc/c7b233ca3ef6b1f6d751c3325e301ebaf2ee.pdf.
[2018-03-02 15:24:04,806 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/68bc/c7b233ca3ef6b1f6d751c3325e301ebaf2ee.pdf') and save (filename='PDF//183.pdf')
[2018-03-02 15:24:04,806 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:24:04,806 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:24:04,821 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:24:06,617 DEBUG requests.packages.urllib3.connectionpool] "GET /68bc/c7b233ca3ef6b1f6d751c3325e301ebaf2ee.pdf HTTP/1.1" 200 802192
[2018-03-02 15:24:06,617 DEBUG utils] Content-length=802192
[2018-03-02 15:24:06,618 DEBUG utils] Create file PDF//183.pdf, start download.
[2018-03-02 15:24:08,790 DEBUG utils] End download file PDF//183.pdf.
[2018-03-02 15:24:08,791 DEBUG dbutils] Update pdf_transaction for paper id=183.
[2018-03-02 15:24:08,791 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 183'
[2018-03-02 15:24:08,791 DEBUG dbutils] Query result: null
[2018-03-02 15:24:08,816 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:24:08,816 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:24:08,816 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:24:08,817 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for scholar.google.com
[2018-03-02 15:24:08,832 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:24:11,190 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=200&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:24:11,962 DEBUG scholar] Find papers on page #21 (max_google_papers = 300)
[2018-03-02 15:24:11,962 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:24:11,963 DEBUG scholar] Handle paper #201 (total 1170)
[2018-03-02 15:24:11,963 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:24:11,967 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:11,968 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:24:11,984 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:24:11,986 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:24:14,670 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:NTtJermVHlwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB6gAZlMZka4SR0IgBZRy4aYP9HM1&scisf=3&ct=citation&cd=200&hl=en HTTP/1.1" 200 307
[2018-03-02 15:24:14,670 DEBUG scholar] EndNote file:
%0 Journal Article
%T Shared spaces in a safeurban jungle: Juggling pedagogical goals and student needs and expectations
%A Steventon, Graham
%A Grove, Paul
%A Childs, Mark
%J Proceedings of the Australasian Society for Computers in Learning in Tertiary Education (ascilite), Melbourne
%D 2008

[2018-03-02 15:24:14,671 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:14,671 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:14,671 DEBUG __main__] Process content of EndNote file #201
{"title": "Shared spaces in a 'safe'urban jungle: Juggling pedagogical goals and student needs and expectations", "url": "http://www.ascilite.org/conferences/melbourne08/procs/steventon.pdf", "author": [{"shortname": "G Steventon", "gid": ""}, {"shortname": "P Grove", "gid": ""}, {"shortname": "M Childs", "gid": "2-ZhpXsAAAAJ"}], "year": 2008}
{"citedby": 4, "type": "Journal Article", "title": "Shared spaces in a \u2018safe\u2019urban jungle: Juggling pedagogical goals and student needs and expectations", "author": ["Steventon, Graham", "Grove, Paul", "Childs, Mark"], "journal": "Proceedings of the Australasian Society for Computers in Learning in Tertiary Education (ascilite), Melbourne", "year": "2008", "EndNote": "%0 Journal Article\n%T Shared spaces in a \u2018safe\u2019urban jungle: Juggling pedagogical goals and student needs and expectations\n%A Steventon, Graham\n%A Grove, Paul\n%A Childs, Mark\n%J Proceedings of the Australasian Society for Computers in Learning in Tertiary Education (ascilite), Melbourne\n%D 2008\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:NTtJermVHlwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB6gAZlMZka4SR0IgBZRy4aYP9HM1&scisf=3&ct=citation&cd=200&hl=en"}
[2018-03-02 15:24:14,671 DEBUG dbutils] Get paper id {"DOI": null, "title": "Shared spaces in a \u2018safe\u2019urban jungle: Juggling pedagogical goals and student needs and expectations", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:24:14,671 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Shared spaces in a safeurban jungle: Juggling pedagogical goals and student needs and expectations', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:24:14,671 DEBUG dbutils] Query result: []
[2018-03-02 15:24:14,671 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:14,671 DEBUG dbutils] Add new paper (title='Shared spaces in a safeurban jungle: Juggling pedagogical goals and student needs and expectations')
[2018-03-02 15:24:14,671 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Shared spaces in a safeurban jungle: Juggling pedagogical goals and student needs and expectations', 'year': 2008, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Shared spaces in a safeurban jungle: Juggling pedagogical goals and student needs and expectations\n%A Steventon, Graham\n%A Grove, Paul\n%A Childs, Mark\n%J Proceedings of the Australasian Society for Computers in Learning in Tertiary Education (ascilite), Melbourne\n%D 2008\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:14,672 DEBUG dbutils] Query result: 184
[2018-03-02 15:24:14,673 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.ascilite.org/conferences/melbourne08/procs/steventon.pdf.
[2018-03-02 15:24:14,674 WARNING utils] Download file (url='http://www.ascilite.org/conferences/melbourne08/procs/steventon.pdf') and save (filename='PDF//184.pdf')
[2018-03-02 15:24:14,674 DEBUG utils] Get current proxy for www.ascilite.org.
[2018-03-02 15:24:14,674 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:24:14,674 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for otherhost
[2018-03-02 15:24:14,691 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.ascilite.org
[2018-03-02 15:24:16,399 DEBUG requests.packages.urllib3.connectionpool] "GET /conferences/melbourne08/procs/steventon.pdf HTTP/1.1" 200 472213
[2018-03-02 15:24:16,399 DEBUG utils] Content-length=472213
[2018-03-02 15:24:16,401 DEBUG utils] Create file PDF//184.pdf, start download.
[2018-03-02 15:24:19,603 DEBUG utils] End download file PDF//184.pdf.
[2018-03-02 15:24:19,604 DEBUG dbutils] Update pdf_transaction for paper id=184.
[2018-03-02 15:24:19,604 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 184'
[2018-03-02 15:24:19,604 DEBUG dbutils] Query result: null
[2018-03-02 15:24:19,605 DEBUG scholar] Handle paper #202 (total 1170)
[2018-03-02 15:24:19,605 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:24:19,611 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:19,611 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:24:19,611 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for scholar.google.com
[2018-03-02 15:24:19,631 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:24:19,632 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:24:22,444 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KQv0uFkmAF8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFBzdQnVTg1wQF4O7YUWmoh7IAdWRc&scisf=3&ct=citation&cd=201&hl=en HTTP/1.1" 200 170
[2018-03-02 15:24:22,445 DEBUG scholar] EndNote file:
%0 Thesis
%T Data-driven Repair Models for Text Chat with Language Learners
%A Hohn, Sviatlana
%D 2016
%I University of Luxembourg,? Luxembourg,?? Luxembourg

[2018-03-02 15:24:22,445 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:22,445 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:22,446 DEBUG __main__] Process content of EndNote file #202
{"title": "Data-driven Repair Models for Text Chat with Language Learners", "url": "http://orbilu.uni.lu/handle/10993/27057", "author": [{"shortname": "S H\u00f6hn", "gid": ""}], "year": 2016}
{"type": "Thesis", "title": "Data-driven Repair Models for Text Chat with Language Learners", "author": ["H\u00f6hn, Sviatlana"], "year": "2016", "publisher": "University of Luxembourg,\u200b Luxembourg,\u200b\u200b Luxembourg", "EndNote": "%0 Thesis\n%T Data-driven Repair Models for Text Chat with Language Learners\n%A H\u00f6hn, Sviatlana\n%D 2016\n%I University of Luxembourg,\u200b Luxembourg,\u200b\u200b Luxembourg\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KQv0uFkmAF8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFBzdQnVTg1wQF4O7YUWmoh7IAdWRc&scisf=3&ct=citation&cd=201&hl=en"}
[2018-03-02 15:24:22,446 DEBUG dbutils] Get paper id {"DOI": null, "title": "Data-driven Repair Models for Text Chat with Language Learners", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:24:22,446 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Data-driven Repair Models for Text Chat with Language Learners', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:24:22,446 DEBUG dbutils] Query result: []
[2018-03-02 15:24:22,446 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:22,446 DEBUG dbutils] Add new paper (title='Data-driven Repair Models for Text Chat with Language Learners')
[2018-03-02 15:24:22,446 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Data-driven Repair Models for Text Chat with Language Learners', 'year': 2016, 'publisher': 'University of Luxembourg,\u200b Luxembourg,\u200b\u200b Luxembourg', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T Data-driven Repair Models for Text Chat with Language Learners\n%A Hohn, Sviatlana\n%D 2016\n%I University of Luxembourg,\u200b Luxembourg,\u200b\u200b Luxembourg\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:22,446 DEBUG dbutils] Query result: 185
[2018-03-02 15:24:22,448 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://orbilu.uni.lu/bitstream/10993/27057/1/hoehn-introduction.pdf.
[2018-03-02 15:24:22,449 WARNING utils] Download file (url='http://orbilu.uni.lu/bitstream/10993/27057/1/hoehn-introduction.pdf') and save (filename='PDF//185.pdf')
[2018-03-02 15:24:22,450 DEBUG utils] Get current proxy for orbilu.uni.lu.
[2018-03-02 15:24:22,450 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:24:22,465 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): orbilu.uni.lu
[2018-03-02 15:24:22,850 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10993/27057/1/hoehn-introduction.pdf HTTP/1.1" 404 None
[2018-03-02 15:24:22,871 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://orbilu.uni.lu/handle/10993/27057.
[2018-03-02 15:24:22,871 DEBUG scihub] Get page from sci-hub for paper with DOI=http://orbilu.uni.lu/handle/10993/27057.
[2018-03-02 15:24:23,069 DEBUG requests.packages.urllib3.connectionpool] "GET //http://orbilu.uni.lu/handle/10993/27057 HTTP/1.1" 302 None
[2018-03-02 15:24:23,190 DEBUG requests.packages.urllib3.connectionpool] "GET /handle/10993/27057 HTTP/1.1" 200 None
[2018-03-02 15:24:23,200 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:24:23,200 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:24:23,200 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for sci-hub.tw
[2018-03-02 15:24:23,390 DEBUG requests.packages.urllib3.connectionpool] "GET //http://orbilu.uni.lu/handle/10993/27057 HTTP/1.1" 302 None
[2018-03-02 15:24:23,552 DEBUG requests.packages.urllib3.connectionpool] "GET /handle/10993/27057 HTTP/1.1" 200 None
[2018-03-02 15:24:23,595 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:24:23,596 DEBUG scholar] Handle paper #203 (total 1170)
[2018-03-02 15:24:23,597 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:24:23,600 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:23,600 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:24:24,114 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:H5Cp70-I10MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_7InjQ_A72sCXfNiI2uPWo95lIJ&scisf=3&ct=citation&cd=202&hl=en HTTP/1.1" 200 192
[2018-03-02 15:24:24,115 DEBUG scholar] EndNote file:
%0 Thesis
%T Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents
%A Sephton, Nicholas
%D 2016
%I University of York

[2018-03-02 15:24:24,115 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:24,115 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:24,115 DEBUG __main__] Process content of EndNote file #203
{"title": "Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents", "url": "http://etheses.whiterose.ac.uk/id/eprint/17331", "author": [{"shortname": "N Sephton", "gid": "YDbAicMAAAAJ"}], "year": 2016}
{"type": "Thesis", "title": "Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents", "author": ["Sephton, Nicholas"], "year": "2016", "publisher": "University of York", "EndNote": "%0 Thesis\n%T Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents\n%A Sephton, Nicholas\n%D 2016\n%I University of York\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:H5Cp70-I10MJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_7InjQ_A72sCXfNiI2uPWo95lIJ&scisf=3&ct=citation&cd=202&hl=en"}
[2018-03-02 15:24:24,115 DEBUG dbutils] Get paper id {"DOI": null, "title": "Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:24:24,115 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:24:24,115 DEBUG dbutils] Query result: []
[2018-03-02 15:24:24,116 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:24,116 DEBUG dbutils] Add new paper (title='Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents')
[2018-03-02 15:24:24,116 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents', 'year': 2016, 'publisher': 'University of York', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T Applying Artificial Intelligence and Machine Learning Techniques to Create Varying Play Style in Artificial Game Opponents\n%A Sephton, Nicholas\n%D 2016\n%I University of York\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:24,116 DEBUG dbutils] Query result: 186
[2018-03-02 15:24:24,117 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://etheses.whiterose.ac.uk/17331/1/Submission%202017-05-18.pdf.
[2018-03-02 15:24:24,118 WARNING utils] Download file (url='http://etheses.whiterose.ac.uk/17331/1/Submission%202017-05-18.pdf') and save (filename='PDF//186.pdf')
[2018-03-02 15:24:24,119 DEBUG utils] Get current proxy for etheses.whiterose.ac.uk.
[2018-03-02 15:24:24,119 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:24:24,119 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for otherhost
[2018-03-02 15:24:24,136 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): etheses.whiterose.ac.uk
[2018-03-02 15:24:25,069 DEBUG requests.packages.urllib3.connectionpool] "GET /17331/1/Submission%202017-05-18.pdf HTTP/1.1" 200 19642190
[2018-03-02 15:24:25,070 DEBUG utils] Content-length=19642190
[2018-03-02 15:24:25,070 DEBUG utils] Create file PDF//186.pdf, start download.
[2018-03-02 15:24:47,162 DEBUG utils] End download file PDF//186.pdf.
[2018-03-02 15:24:47,164 DEBUG dbutils] Update pdf_transaction for paper id=186.
[2018-03-02 15:24:47,164 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 186'
[2018-03-02 15:24:47,165 DEBUG dbutils] Query result: null
[2018-03-02 15:24:47,165 DEBUG scholar] Handle paper #204 (total 1170)
[2018-03-02 15:24:47,165 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:24:47,170 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:47,171 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:24:47,171 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for scholar.google.com
[2018-03-02 15:24:47,189 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:24:47,190 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:24:47,963 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:XoCFeAPudFUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB12JjdZLuGHAxeFwEyr7KiY1zYBY&scisf=3&ct=citation&cd=203&hl=en HTTP/1.1" 200 166
[2018-03-02 15:24:47,964 DEBUG scholar] EndNote file:
%0 Journal Article
%T 2016 IEEE 8 th International Conference on Intelligent Systems
%A Yager, Ronald
%A Sgurev, Vassil
%A Hadjiski, Mincho
%A Jotsov, Vladimir

[2018-03-02 15:24:47,964 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:47,964 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:47,964 DEBUG __main__] Skip paper #204, empty year or authors fields.
[2018-03-02 15:24:47,965 DEBUG scholar] Handle paper #205 (total 1170)
[2018-03-02 15:24:47,965 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:24:47,967 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:47,967 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:24:48,449 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:awxdTPqR5MwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFBzEGT1x9djngrb53cdY7b90O-QPJ&scisf=3&ct=citation&cd=204&hl=en HTTP/1.1" 200 182
[2018-03-02 15:24:48,450 DEBUG scholar] EndNote file:
%0 Journal Article
%T Knowledge Enhanced Hybrid Neural Network for Text Matching
%A Wu, Yu
%A Wu, Wei
%A Li, Zhoujun
%A Zhou, Ming
%J arXiv preprint arXiv:1611.04684
%D 2016

[2018-03-02 15:24:48,450 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:48,450 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:48,450 DEBUG __main__] Process content of EndNote file #205
{"title": "Knowledge Enhanced Hybrid Neural Network for Text Matching", "url": "https://arxiv.org/abs/1611.04684", "author": [{"shortname": "Y Wu", "gid": "aQizmzsAAAAJ"}, {"shortname": "W Wu", "gid": "YtqXSzMAAAAJ"}, {"shortname": "Z Li", "gid": ""}, {"shortname": "M Zhou", "gid": ""}], "year": 1611}
{"citedby": 3, "type": "Journal Article", "title": "Knowledge Enhanced Hybrid Neural Network for Text Matching", "author": ["Wu, Yu", "Wu, Wei", "Li, Zhoujun", "Zhou, Ming"], "journal": "arXiv preprint arXiv:1611.04684", "year": "2016", "EndNote": "%0 Journal Article\n%T Knowledge Enhanced Hybrid Neural Network for Text Matching\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J arXiv preprint arXiv:1611.04684\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:awxdTPqR5MwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFBzEGT1x9djngrb53cdY7b90O-QPJ&scisf=3&ct=citation&cd=204&hl=en"}
[2018-03-02 15:24:48,450 DEBUG dbutils] Get paper id {"DOI": null, "title": "Knowledge Enhanced Hybrid Neural Network for Text Matching", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:24:48,451 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Knowledge Enhanced Hybrid Neural Network for Text Matching', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:24:48,451 DEBUG dbutils] Query result: []
[2018-03-02 15:24:48,451 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:48,451 DEBUG dbutils] Add new paper (title='Knowledge Enhanced Hybrid Neural Network for Text Matching')
[2018-03-02 15:24:48,451 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Knowledge Enhanced Hybrid Neural Network for Text Matching', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Knowledge Enhanced Hybrid Neural Network for Text Matching\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J arXiv preprint arXiv:1611.04684\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:48,451 DEBUG dbutils] Query result: 187
[2018-03-02 15:24:48,452 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1611.04684.
[2018-03-02 15:24:48,453 WARNING utils] Download file (url='https://arxiv.org/pdf/1611.04684') and save (filename='PDF//187.pdf')
[2018-03-02 15:24:48,454 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:24:48,454 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:24:48,473 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: arxiv.org
[2018-03-02 15:24:48,475 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): arxiv.org
[2018-03-02 15:24:49,719 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1611.04684 HTTP/1.1" 302 280
[2018-03-02 15:24:50,431 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1611.04684.pdf HTTP/1.1" 200 601625
[2018-03-02 15:24:50,431 DEBUG utils] Content-length=601625
[2018-03-02 15:24:50,432 DEBUG utils] Create file PDF//187.pdf, start download.
[2018-03-02 15:24:52,557 DEBUG utils] End download file PDF//187.pdf.
[2018-03-02 15:24:52,559 DEBUG dbutils] Update pdf_transaction for paper id=187.
[2018-03-02 15:24:52,559 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 187'
[2018-03-02 15:24:52,559 DEBUG dbutils] Query result: null
[2018-03-02 15:24:52,560 DEBUG scholar] Handle paper #206 (total 1170)
[2018-03-02 15:24:52,560 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:24:52,564 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:24:52,564 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:24:52,565 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for scholar.google.com
[2018-03-02 15:24:52,583 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:24:52,584 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:24:55,239 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:B3XPqE-uzMsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_FGC4roJ3hFe7M5fmmx8vlOhiDN&scisf=3&ct=citation&cd=205&hl=en HTTP/1.1" 200 241
[2018-03-02 15:24:55,240 DEBUG scholar] EndNote file:
%0 Journal Article
%T A survey of available corpora for building data-driven dialogue systems
%A Serban, Iulian Vlad
%A Lowe, Ryan
%A Henderson, Peter
%A Charlin, Laurent
%A Pineau, Joelle
%J arXiv preprint arXiv:1512.05742
%D 2015

[2018-03-02 15:24:55,240 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:24:55,240 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:24:55,240 DEBUG __main__] Process content of EndNote file #206
{"title": "A survey of available corpora for building data-driven dialogue systems", "url": "https://arxiv.org/abs/1512.05742", "author": [{"shortname": "IV Serban", "gid": "0g31OfAAAAAJ"}, {"shortname": "R Lowe", "gid": "iRgYMuEAAAAJ"}, {"shortname": "P Henderson", "gid": "BDxQ5soAAAAJ"}, {"shortname": "L Charlin", "gid": "Cul0g2YAAAAJ"}], "year": 2015}
{"citedby": 36, "type": "Journal Article", "title": "A survey of available corpora for building data-driven dialogue systems", "author": ["Serban, Iulian Vlad", "Lowe, Ryan", "Henderson, Peter", "Charlin, Laurent", "Pineau, Joelle"], "journal": "arXiv preprint arXiv:1512.05742", "year": "2015", "EndNote": "%0 Journal Article\n%T A survey of available corpora for building data-driven dialogue systems\n%A Serban, Iulian Vlad\n%A Lowe, Ryan\n%A Henderson, Peter\n%A Charlin, Laurent\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1512.05742\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:B3XPqE-uzMsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_FGC4roJ3hFe7M5fmmx8vlOhiDN&scisf=3&ct=citation&cd=205&hl=en"}
[2018-03-02 15:24:55,240 DEBUG dbutils] Get paper id {"DOI": null, "title": "A survey of available corpora for building data-driven dialogue systems", "auth_count": 5, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:24:55,240 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A survey of available corpora for building data-driven dialogue systems', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:24:55,241 DEBUG dbutils] Query result: []
[2018-03-02 15:24:55,241 DEBUG dbutils] Paper id = None.
[2018-03-02 15:24:55,241 DEBUG dbutils] Add new paper (title='A survey of available corpora for building data-driven dialogue systems')
[2018-03-02 15:24:55,241 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A survey of available corpora for building data-driven dialogue systems', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A survey of available corpora for building data-driven dialogue systems\n%A Serban, Iulian Vlad\n%A Lowe, Ryan\n%A Henderson, Peter\n%A Charlin, Laurent\n%A Pineau, Joelle\n%J arXiv preprint arXiv:1512.05742\n%D 2015\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:24:55,241 DEBUG dbutils] Query result: 188
[2018-03-02 15:24:55,243 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1512.05742.
[2018-03-02 15:24:55,245 WARNING utils] Download file (url='https://arxiv.org/pdf/1512.05742') and save (filename='PDF//188.pdf')
[2018-03-02 15:24:55,245 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:24:55,245 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:24:55,245 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for otherhost
[2018-03-02 15:24:55,265 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 15:24:58,438 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1512.05742 HTTP/1.1" 302 280
[2018-03-02 15:24:59,410 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1512.05742.pdf HTTP/1.1" 200 1079429
[2018-03-02 15:24:59,411 DEBUG utils] Content-length=1079429
[2018-03-02 15:24:59,412 DEBUG utils] Create file PDF//188.pdf, start download.
[2018-03-02 15:25:02,723 DEBUG utils] End download file PDF//188.pdf.
[2018-03-02 15:25:02,725 DEBUG dbutils] Update pdf_transaction for paper id=188.
[2018-03-02 15:25:02,725 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 188'
[2018-03-02 15:25:02,725 DEBUG dbutils] Query result: null
[2018-03-02 15:25:02,726 DEBUG scholar] Handle paper #207 (total 1170)
[2018-03-02 15:25:02,726 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:25:02,730 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:02,730 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:25:03,949 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GXDnOJTP8CcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB7WVWq8c8h07blxCjqpMp6re0Grp&scisf=3&ct=citation&cd=206&hl=en HTTP/1.1" 200 247
[2018-03-02 15:25:03,950 DEBUG scholar] EndNote file:
%0 Journal Article
%T Innovation report 3
%A Sharples, Mike
%A Adams, Anne
%A Ferguson, Rebecca
%A Gaved, Mark
%A McAndrew, Patrick
%A Rienties, Bart
%A Weller, Martin
%A Whitelock, Denise
%J Education
%V 34
%N 2
%P 251-273
%D 2012

[2018-03-02 15:25:03,950 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:03,951 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:03,951 DEBUG __main__] Process content of EndNote file #207
{"title": "Innovation report 3", "url": "https://cdn.studyinternational.com/news/wp-content/uploads/2016/12/proxima.iet.open.ac.uk_public_innovating_pedagogy_2016.pdf", "author": [{"shortname": "M Sharples", "gid": "0KzFF40AAAAJ"}, {"shortname": "A Adams", "gid": "UQ7Z3OkAAAAJ"}, {"shortname": "R Ferguson", "gid": "lfxvlmwAAAAJ"}, {"shortname": "M Gaved", "gid": "yAasr00AAAAJ"}], "year": 2012}
{"citedby": 1, "type": "Journal Article", "title": "Innovation report 3", "author": ["Sharples, Mike", "Adams, Anne", "Ferguson, Rebecca", "Gaved, Mark", "McAndrew, Patrick", "Rienties, Bart", "Weller, Martin", "Whitelock, Denise"], "journal": "Education", "volume": 23, "numberorissue": "2", "pages": "251-273", "year": "2012", "start_page": 251, "end_page": 273, "EndNote": "%0 Journal Article\n%T Innovation report 3\n%A Sharples, Mike\n%A Adams, Anne\n%A Ferguson, Rebecca\n%A Gaved, Mark\n%A McAndrew, Patrick\n%A Rienties, Bart\n%A Weller, Martin\n%A Whitelock, Denise\n%J Education\n%V 34\n%N 2\n%P 251-273\n%D 2012\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GXDnOJTP8CcJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB7WVWq8c8h07blxCjqpMp6re0Grp&scisf=3&ct=citation&cd=206&hl=en"}
[2018-03-02 15:25:03,951 DEBUG dbutils] Get paper id {"DOI": null, "title": "Innovation report 3", "auth_count": 8, "g_type": "Journal Article", "pages": 23, "year": 2012, "rg_id": null, "start_page": 251, "end_page": 273}.
[2018-03-02 15:25:03,951 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Innovation report 3', 'auth_count': 8, 'g_type': 'Journal Article', 'pages': 23, 'year': 2012, 'rg_id': None, 'start_page': 251, 'end_page': 273}
[2018-03-02 15:25:03,951 DEBUG dbutils] Query result: []
[2018-03-02 15:25:03,951 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:03,951 DEBUG dbutils] Add new paper (title='Innovation report 3')
[2018-03-02 15:25:03,951 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Innovation report 3', 'year': 2012, 'publisher': None, 'start_page': 251, 'end_page': 273, 'pages': 23, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Innovation report 3\n%A Sharples, Mike\n%A Adams, Anne\n%A Ferguson, Rebecca\n%A Gaved, Mark\n%A McAndrew, Patrick\n%A Rienties, Bart\n%A Weller, Martin\n%A Whitelock, Denise\n%J Education\n%V 34\n%N 2\n%P 251-273\n%D 2012\n', 'RIS': None, 'authors': 8, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:03,951 DEBUG dbutils] Query result: 189
[2018-03-02 15:25:03,953 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://cdn.studyinternational.com/news/wp-content/uploads/2016/12/proxima.iet.open.ac.uk_public_innovating_pedagogy_2016.pdf.
[2018-03-02 15:25:03,955 WARNING utils] Download file (url='https://cdn.studyinternational.com/news/wp-content/uploads/2016/12/proxima.iet.open.ac.uk_public_innovating_pedagogy_2016.pdf') and save (filename='PDF//189.pdf')
[2018-03-02 15:25:03,956 DEBUG utils] Get current proxy for cdn.studyinternational.com.
[2018-03-02 15:25:03,956 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:25:03,971 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): cdn.studyinternational.com
[2018-03-02 15:25:07,391 DEBUG requests.packages.urllib3.connectionpool] "GET /news/wp-content/uploads/2016/12/proxima.iet.open.ac.uk_public_innovating_pedagogy_2016.pdf HTTP/1.1" 200 1922063
[2018-03-02 15:25:07,391 DEBUG utils] Content-length=1922063
[2018-03-02 15:25:07,391 DEBUG utils] Create file PDF//189.pdf, start download.
[2018-03-02 15:25:11,087 DEBUG utils] End download file PDF//189.pdf.
[2018-03-02 15:25:11,088 DEBUG dbutils] Update pdf_transaction for paper id=189.
[2018-03-02 15:25:11,089 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 189'
[2018-03-02 15:25:11,089 DEBUG dbutils] Query result: null
[2018-03-02 15:25:11,089 DEBUG scholar] Handle paper #208 (total 1170)
[2018-03-02 15:25:11,089 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:25:11,092 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:11,093 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:25:11,093 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for scholar.google.com
[2018-03-02 15:25:11,111 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:25:11,113 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:25:13,109 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4qeO1P6RWfgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_8Cl7sZJCWCjx-3uo_QVr3CTrlT&scisf=3&ct=citation&cd=207&hl=en HTTP/1.1" 200 280
[2018-03-02 15:25:13,109 DEBUG scholar] EndNote file:
%0 Journal Article
%T Creativity evaluation in a cognitive architecture
%A Augello, Agnese
%A Infantino, Ignazio
%A Pilato, Giovanni
%A Rizzo, Riccardo
%A Vella, Filippo
%J Biologically Inspired Cognitive Architectures
%V 11
%P 29-37
%@ 2212-683X
%D 2015
%I Elsevier

[2018-03-02 15:25:13,110 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:13,110 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:13,110 DEBUG __main__] Process content of EndNote file #208
{"title": "Creativity evaluation in a cognitive architecture", "url": "https://www.sciencedirect.com/science/article/pii/S2212683X14000760", "author": [{"shortname": "A Augello", "gid": "vPJnw0AAAAAJ"}, {"shortname": "I Infantino", "gid": "LwTTH9YAAAAJ"}, {"shortname": "G Pilato", "gid": "fAPQPiUAAAAJ"}, {"shortname": "R Rizzo", "gid": "Srf4GfwAAAAJ"}], "year": 2015}
{"citedby": 12, "type": "Journal Article", "title": "Creativity evaluation in a cognitive architecture", "author": ["Augello, Agnese", "Infantino, Ignazio", "Pilato, Giovanni", "Rizzo, Riccardo", "Vella, Filippo"], "journal": "Biologically Inspired Cognitive Architectures", "volume": 9, "pages": "29-37", "isbn/issn": "2212-683X", "year": "2015", "publisher": "Elsevier", "start_page": 29, "end_page": 37, "EndNote": "%0 Journal Article\n%T Creativity evaluation in a cognitive architecture\n%A Augello, Agnese\n%A Infantino, Ignazio\n%A Pilato, Giovanni\n%A Rizzo, Riccardo\n%A Vella, Filippo\n%J Biologically Inspired Cognitive Architectures\n%V 11\n%P 29-37\n%@ 2212-683X\n%D 2015\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4qeO1P6RWfgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB_8Cl7sZJCWCjx-3uo_QVr3CTrlT&scisf=3&ct=citation&cd=207&hl=en"}
[2018-03-02 15:25:13,110 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creativity evaluation in a cognitive architecture", "auth_count": 5, "g_type": "Journal Article", "pages": 9, "year": 2015, "rg_id": null, "start_page": 29, "end_page": 37}.
[2018-03-02 15:25:13,110 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creativity evaluation in a cognitive architecture', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': 9, 'year': 2015, 'rg_id': None, 'start_page': 29, 'end_page': 37}
[2018-03-02 15:25:13,110 DEBUG dbutils] Query result: []
[2018-03-02 15:25:13,110 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:13,110 DEBUG dbutils] Add new paper (title='Creativity evaluation in a cognitive architecture')
[2018-03-02 15:25:13,111 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creativity evaluation in a cognitive architecture', 'year': 2015, 'publisher': 'Elsevier', 'start_page': 29, 'end_page': 37, 'pages': 9, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Creativity evaluation in a cognitive architecture\n%A Augello, Agnese\n%A Infantino, Ignazio\n%A Pilato, Giovanni\n%A Rizzo, Riccardo\n%A Vella, Filippo\n%J Biologically Inspired Cognitive Architectures\n%V 11\n%P 29-37\n%@ 2212-683X\n%D 2015\n%I Elsevier\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:13,111 DEBUG dbutils] Query result: 190
[2018-03-02 15:25:13,112 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/6b07/ea8a3c82c8b3587622662850f91deb40bd03.pdf.
[2018-03-02 15:25:13,115 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/6b07/ea8a3c82c8b3587622662850f91deb40bd03.pdf') and save (filename='PDF//190.pdf')
[2018-03-02 15:25:13,115 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:25:13,115 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:25:13,115 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for otherhost
[2018-03-02 15:25:13,130 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:25:14,164 DEBUG requests.packages.urllib3.connectionpool] "GET /6b07/ea8a3c82c8b3587622662850f91deb40bd03.pdf HTTP/1.1" 200 286067
[2018-03-02 15:25:14,165 DEBUG utils] Content-length=286067
[2018-03-02 15:25:14,165 DEBUG utils] Create file PDF//190.pdf, start download.
[2018-03-02 15:25:14,999 DEBUG utils] End download file PDF//190.pdf.
[2018-03-02 15:25:15,000 DEBUG dbutils] Update pdf_transaction for paper id=190.
[2018-03-02 15:25:15,000 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 190'
[2018-03-02 15:25:15,000 DEBUG dbutils] Query result: null
[2018-03-02 15:25:15,001 DEBUG scholar] Handle paper #209 (total 1170)
[2018-03-02 15:25:15,001 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:25:15,004 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:15,005 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:25:15,418 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:IYa_-WS097AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB86NdTe6-adxSyPHilTRs2AZU12s&scisf=3&ct=citation&cd=208&hl=en HTTP/1.1" 200 312
[2018-03-02 15:25:15,419 DEBUG scholar] EndNote file:
%0 Journal Article
%T Science through Second Life: A Case Study of MUVEs in an
%A Wellman, Elizabeth
%A Arreguin, Cathy
%J Virtual Learning Environments: Concepts, Methodologies, Tools and Applications: Concepts, Methodologies, Tools and Applications
%V 1
%P 451
%@ 1466600128
%D 2012
%I IGI Global

[2018-03-02 15:25:15,419 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:15,419 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:15,419 DEBUG __main__] Process content of EndNote file #209
{"title": "Science through Second Life: A Case Study of MUVE's in an", "url": "https://books.google.com/books?hl=en&lr=&id=T5-eBQAAQBAJ&oi=fnd&pg=PA451&dq=Use+deep+learning+to+create+a+chatbot&ots=BMsiNEgfZh&sig=WhpYUHcv-P8UDQEgrMlPPy1lOaA", "author": [{"shortname": "E Wellman", "gid": ""}, {"shortname": "C Arreguin", "gid": ""}], "year": 2012}
{"citedby": 1, "type": "Journal Article", "title": "Science through Second Life: A Case Study of MUVE\u2019s in an", "author": ["Wellman, Elizabeth", "Arreguin, Cathy"], "journal": "Virtual Learning Environments: Concepts, Methodologies, Tools and Applications: Concepts, Methodologies, Tools and Applications", "volume": "1", "pages": "451", "isbn/issn": "1466600128", "year": "2012", "publisher": "IGI Global", "EndNote": "%0 Journal Article\n%T Science through Second Life: A Case Study of MUVE\u2019s in an\n%A Wellman, Elizabeth\n%A Arreguin, Cathy\n%J Virtual Learning Environments: Concepts, Methodologies, Tools and Applications: Concepts, Methodologies, Tools and Applications\n%V 1\n%P 451\n%@ 1466600128\n%D 2012\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:IYa_-WS097AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB86NdTe6-adxSyPHilTRs2AZU12s&scisf=3&ct=citation&cd=208&hl=en"}
[2018-03-02 15:25:15,419 DEBUG dbutils] Get paper id {"DOI": null, "title": "Science through Second Life: A Case Study of MUVE\u2019s in an", "auth_count": 2, "g_type": "Journal Article", "pages": 1, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:25:15,420 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Science through Second Life: A Case Study of MUVEs in an', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 1, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:25:15,420 DEBUG dbutils] Query result: []
[2018-03-02 15:25:15,420 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:15,420 DEBUG dbutils] Add new paper (title='Science through Second Life: A Case Study of MUVEs in an')
[2018-03-02 15:25:15,420 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Science through Second Life: A Case Study of MUVEs in an', 'year': 2012, 'publisher': 'IGI Global', 'start_page': None, 'end_page': None, 'pages': 1, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Science through Second Life: A Case Study of MUVEs in an\n%A Wellman, Elizabeth\n%A Arreguin, Cathy\n%J Virtual Learning Environments: Concepts, Methodologies, Tools and Applications: Concepts, Methodologies, Tools and Applications\n%V 1\n%P 451\n%@ 1466600128\n%D 2012\n%I IGI Global\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:15,420 DEBUG dbutils] Query result: 191
[2018-03-02 15:25:15,422 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=T5-eBQAAQBAJ&oi=fnd&pg=PA451&dq=Use+deep+learning+to+create+a+chatbot&ots=BMsiNEgfZh&sig=WhpYUHcv-P8UDQEgrMlPPy1lOaA.
[2018-03-02 15:25:15,422 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=T5-eBQAAQBAJ&oi=fnd&pg=PA451&dq=Use+deep+learning+to+create+a+chatbot&ots=BMsiNEgfZh&sig=WhpYUHcv-P8UDQEgrMlPPy1lOaA.
[2018-03-02 15:25:15,597 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=T5-eBQAAQBAJ&oi=fnd&pg=PA451&dq=Use+deep+learning+to+create+a+chatbot&ots=BMsiNEgfZh&sig=WhpYUHcv-P8UDQEgrMlPPy1lOaA HTTP/1.1" 302 None
[2018-03-02 15:25:15,790 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:25:15,794 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:25:15,795 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:25:15,968 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=T5-eBQAAQBAJ&oi=fnd&pg=PA451&dq=Use+deep+learning+to+create+a+chatbot&ots=BMsiNEgfZh&sig=WhpYUHcv-P8UDQEgrMlPPy1lOaA HTTP/1.1" 302 None
[2018-03-02 15:25:16,169 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:25:16,206 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:25:16,208 DEBUG scholar] Handle paper #210 (total 1170)
[2018-03-02 15:25:16,208 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:25:16,213 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:16,213 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:25:16,213 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for scholar.google.com
[2018-03-02 15:25:16,251 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:25:16,252 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:25:19,088 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:mkUGlGzzr10J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB5QVRfXPBDY-TwWANAtslKAE8AwR&scisf=3&ct=citation&cd=209&hl=en HTTP/1.1" 200 228
[2018-03-02 15:25:19,089 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Creating spoken dialogue characters from corpora without annotations
%A Gandhe, Sudeep
%A Traum, David
%B Eighth Annual Conference of the International Speech Communication Association
%D 2007

[2018-03-02 15:25:19,089 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:19,089 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:19,089 DEBUG __main__] Process content of EndNote file #210
{"title": "Creating spoken dialogue characters from corpora without annotations", "url": "http://www.isca-speech.org/archive/interspeech_2007/i07_2201.html", "author": [{"shortname": "S Gandhe", "gid": "lL37lMwAAAAJ"}, {"shortname": "D Traum", "gid": "evVAmhQAAAAJ"}], "year": 2007}
{"citedby": 24, "type": "Conference Proceedings", "title": "Creating spoken dialogue characters from corpora without annotations", "author": ["Gandhe, Sudeep", "Traum, David"], "secondarytitle": "Eighth Annual Conference of the International Speech Communication Association", "year": "2007", "EndNote": "%0 Conference Proceedings\n%T Creating spoken dialogue characters from corpora without annotations\n%A Gandhe, Sudeep\n%A Traum, David\n%B Eighth Annual Conference of the International Speech Communication Association\n%D 2007\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:mkUGlGzzr10J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFB5QVRfXPBDY-TwWANAtslKAE8AwR&scisf=3&ct=citation&cd=209&hl=en"}
[2018-03-02 15:25:19,090 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creating spoken dialogue characters from corpora without annotations", "auth_count": 2, "g_type": "Conference Proceedings", "pages": null, "year": 2007, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:25:19,090 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creating spoken dialogue characters from corpora without annotations', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2007, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:25:19,090 DEBUG dbutils] Query result: []
[2018-03-02 15:25:19,090 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:19,090 DEBUG dbutils] Add new paper (title='Creating spoken dialogue characters from corpora without annotations')
[2018-03-02 15:25:19,090 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creating spoken dialogue characters from corpora without annotations', 'year': 2007, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Creating spoken dialogue characters from corpora without annotations\n%A Gandhe, Sudeep\n%A Traum, David\n%B Eighth Annual Conference of the International Speech Communication Association\n%D 2007\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:19,090 DEBUG dbutils] Query result: 192
[2018-03-02 15:25:19,092 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/5624539/10.1.1.81.4758.pdf.
[2018-03-02 15:25:19,093 WARNING utils] Download file (url='http://www.academia.edu/download/5624539/10.1.1.81.4758.pdf') and save (filename='PDF//192.pdf')
[2018-03-02 15:25:19,093 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 15:25:19,093 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:25:19,111 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 15:25:19,536 DEBUG requests.packages.urllib3.connectionpool] "GET /download/5624539/10.1.1.81.4758.pdf HTTP/1.1" 404 None
[2018-03-02 15:25:19,540 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.isca-speech.org/archive/interspeech_2007/i07_2201.html.
[2018-03-02 15:25:19,541 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.isca-speech.org/archive/interspeech_2007/i07_2201.html.
[2018-03-02 15:25:19,729 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.isca-speech.org/archive/interspeech_2007/i07_2201.html HTTP/1.1" 302 None
[2018-03-02 15:25:19,751 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.isca-speech.org
[2018-03-02 15:25:20,786 DEBUG requests.packages.urllib3.connectionpool] "GET /archive/interspeech_2007/i07_2201.html HTTP/1.1" 200 2275
[2018-03-02 15:25:20,794 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:25:20,794 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:25:20,795 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for sci-hub.tw
[2018-03-02 15:25:20,982 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.isca-speech.org/archive/interspeech_2007/i07_2201.html HTTP/1.1" 302 None
[2018-03-02 15:25:21,006 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.isca-speech.org
[2018-03-02 15:25:21,609 DEBUG requests.packages.urllib3.connectionpool] "GET /archive/interspeech_2007/i07_2201.html HTTP/1.1" 200 2275
[2018-03-02 15:25:21,615 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:25:21,615 DEBUG dbutils] Commiting transaction 210.
[2018-03-02 15:25:21,785 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:25:21,785 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:25:21,785 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:25:21,799 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.google.com
[2018-03-02 15:25:21,801 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.google.com
[2018-03-02 15:25:24,740 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=210&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:25:25,486 DEBUG scholar] Find papers on page #22 (max_google_papers = 300)
[2018-03-02 15:25:25,487 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:25:25,487 DEBUG scholar] Handle paper #211 (total 1170)
[2018-03-02 15:25:25,487 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:25:25,491 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:25,491 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:25:25,491 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for scholar.google.com
[2018-03-02 15:25:25,507 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:25:25,508 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:25:26,830 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:pxxrk5YdegwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUWxRQCETHTlc0-f9wgWa2cX1ybfA&scisf=3&ct=citation&cd=210&hl=en HTTP/1.1" 200 275
[2018-03-02 15:25:26,831 DEBUG scholar] EndNote file:
%0 Journal Article
%T Grammatical error simulation for computer-assisted language learning
%A Lee, Sungjin
%A Lee, Jonghoon
%A Noh, Hyungjong
%A Lee, Kyusong
%A Lee, Gary Geunbae
%J Knowledge-Based Systems
%V 24
%N 6
%P 868-876
%@ 0950-7051
%D 2011
%I Elsevier

[2018-03-02 15:25:26,831 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:26,831 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:26,832 DEBUG __main__] Process content of EndNote file #211
{"title": "Grammatical error simulation for computer-assisted language learning", "url": "https://www.sciencedirect.com/science/article/pii/S095070511100058X", "author": [{"shortname": "S Lee", "gid": "QRUsx4QAAAAJ"}, {"shortname": "J Lee", "gid": ""}, {"shortname": "H Noh", "gid": ""}, {"shortname": "K Lee", "gid": "20KuF74AAAAJ"}, {"shortname": "GG Lee", "gid": "t30saScAAAAJ"}], "year": 2011}
{"citedby": 10, "type": "Journal Article", "title": "Grammatical error simulation for computer-assisted language learning", "author": ["Lee, Sungjin", "Lee, Jonghoon", "Noh, Hyungjong", "Lee, Kyusong", "Lee, Gary Geunbae"], "journal": "Knowledge-Based Systems", "volume": 9, "numberorissue": "6", "pages": "868-876", "isbn/issn": "0950-7051", "year": "2011", "publisher": "Elsevier", "start_page": 868, "end_page": 876, "EndNote": "%0 Journal Article\n%T Grammatical error simulation for computer-assisted language learning\n%A Lee, Sungjin\n%A Lee, Jonghoon\n%A Noh, Hyungjong\n%A Lee, Kyusong\n%A Lee, Gary Geunbae\n%J Knowledge-Based Systems\n%V 24\n%N 6\n%P 868-876\n%@ 0950-7051\n%D 2011\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:pxxrk5YdegwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUWxRQCETHTlc0-f9wgWa2cX1ybfA&scisf=3&ct=citation&cd=210&hl=en"}
[2018-03-02 15:25:26,832 DEBUG dbutils] Get paper id {"DOI": null, "title": "Grammatical error simulation for computer-assisted language learning", "auth_count": 5, "g_type": "Journal Article", "pages": 9, "year": 2011, "rg_id": null, "start_page": 868, "end_page": 876}.
[2018-03-02 15:25:26,832 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Grammatical error simulation for computer-assisted language learning', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': 9, 'year': 2011, 'rg_id': None, 'start_page': 868, 'end_page': 876}
[2018-03-02 15:25:26,832 DEBUG dbutils] Query result: []
[2018-03-02 15:25:26,832 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:26,832 DEBUG dbutils] Add new paper (title='Grammatical error simulation for computer-assisted language learning')
[2018-03-02 15:25:26,833 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Grammatical error simulation for computer-assisted language learning', 'year': 2011, 'publisher': 'Elsevier', 'start_page': 868, 'end_page': 876, 'pages': 9, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Grammatical error simulation for computer-assisted language learning\n%A Lee, Sungjin\n%A Lee, Jonghoon\n%A Noh, Hyungjong\n%A Lee, Kyusong\n%A Lee, Gary Geunbae\n%J Knowledge-Based Systems\n%V 24\n%N 6\n%P 868-876\n%@ 0950-7051\n%D 2011\n%I Elsevier\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:26,833 DEBUG dbutils] Query result: 193
[2018-03-02 15:25:26,835 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S095070511100058X.
[2018-03-02 15:25:26,835 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S095070511100058X.
[2018-03-02 15:25:27,039 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S095070511100058X HTTP/1.1" 200 None
[2018-03-02 15:25:27,040 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:25:27,040 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:25:27,231 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S095070511100058X HTTP/1.1" 200 None
[2018-03-02 15:25:27,241 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true.
[2018-03-02 15:25:27,242 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true') and save (filename='PDF//193.pdf')
[2018-03-02 15:25:27,258 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 15:25:27,480 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:25:27,481 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:25:27,482 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:25:27,482 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for sci-hub.tw
[2018-03-02 15:25:27,495 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (8): cyber.sci-hub.tw
[2018-03-02 15:25:27,748 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:25:27,772 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:25:27,772 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:25:44,660 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:25:44,660 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:25:44,984 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:25:44,985 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:25:44,985 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:25:45,001 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (9): cyber.sci-hub.tw
[2018-03-02 15:25:45,242 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNi9qLmtub3N5cy4yMDExLjAzLjAwOA==/lee2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:25:45,246 DEBUG scholar] Handle paper #212 (total 1170)
[2018-03-02 15:25:45,246 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:25:45,252 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:45,252 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:25:45,508 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KGTT8sq7zEQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUVY4ioUIt4gL9KLEurHzptbHxIqT&scisf=3&ct=citation&cd=211&hl=en HTTP/1.1" 200 158
[2018-03-02 15:25:45,509 DEBUG scholar] EndNote file:
%0 Book Section
%T Social Challenges for the Social Machine
%A Hendler, James
%A Mulvehill, Alice M
%B Social Machines
%P 138-162
%D 2016
%I Springer

[2018-03-02 15:25:45,509 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:45,509 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:45,509 DEBUG __main__] Process content of EndNote file #212
{"title": "Social Challenges for the Social Machine", "url": "https://link.springer.com/chapter/10.1007/978-1-4842-1156-4_8", "author": [{"shortname": "J Hendler", "gid": "JNPbTdIAAAAJ"}, {"shortname": "AM Mulvehill", "gid": ""}], "year": 2016}
{"type": "Book Section", "title": "Social Challenges for the Social Machine", "author": ["Hendler, James", "Mulvehill, Alice M"], "secondarytitle": "Social Machines", "pages": "138-162", "year": "2016", "publisher": "Springer", "start_page": 138, "end_page": 162, "volume": 25, "EndNote": "%0 Book Section\n%T Social Challenges for the Social Machine\n%A Hendler, James\n%A Mulvehill, Alice M\n%B Social Machines\n%P 138-162\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KGTT8sq7zEQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUVY4ioUIt4gL9KLEurHzptbHxIqT&scisf=3&ct=citation&cd=211&hl=en"}
[2018-03-02 15:25:45,509 DEBUG dbutils] Get paper id {"DOI": null, "title": "Social Challenges for the Social Machine", "auth_count": 2, "g_type": "Book Section", "pages": 25, "year": 2016, "rg_id": null, "start_page": 138, "end_page": 162}.
[2018-03-02 15:25:45,509 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Social Challenges for the Social Machine', 'auth_count': 2, 'g_type': 'Book Section', 'pages': 25, 'year': 2016, 'rg_id': None, 'start_page': 138, 'end_page': 162}
[2018-03-02 15:25:45,509 DEBUG dbutils] Query result: []
[2018-03-02 15:25:45,509 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:45,510 DEBUG dbutils] Add new paper (title='Social Challenges for the Social Machine')
[2018-03-02 15:25:45,510 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Social Challenges for the Social Machine', 'year': 2016, 'publisher': 'Springer', 'start_page': 138, 'end_page': 162, 'pages': 25, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Social Challenges for the Social Machine\n%A Hendler, James\n%A Mulvehill, Alice M\n%B Social Machines\n%P 138-162\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:45,510 DEBUG dbutils] Query result: 194
[2018-03-02 15:25:45,511 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-1-4842-1156-4_8.
[2018-03-02 15:25:45,512 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-1-4842-1156-4_8.
[2018-03-02 15:25:45,699 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-1-4842-1156-4_8 HTTP/1.1" 302 None
[2018-03-02 15:25:45,721 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): libgen.io
[2018-03-02 15:25:46,100 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=E09536D0C5F95B92649810B92D345C50 HTTP/1.1" 200 9859
[2018-03-02 15:25:46,192 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:25:46,192 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:25:46,192 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for sci-hub.tw
[2018-03-02 15:25:46,386 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-1-4842-1156-4_8 HTTP/1.1" 302 None
[2018-03-02 15:25:46,626 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=E09536D0C5F95B92649810B92D345C50 HTTP/1.1" 200 9859
[2018-03-02 15:25:46,835 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:25:46,837 DEBUG scholar] Handle paper #213 (total 1170)
[2018-03-02 15:25:46,837 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:25:46,840 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:46,841 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:25:46,841 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for scholar.google.com
[2018-03-02 15:25:46,857 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:25:46,859 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:25:49,737 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:a5wQwqLaATMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUUXsrG1fS8anx0raKVS-tbh8j4w-&scisf=3&ct=citation&cd=212&hl=en HTTP/1.1" 200 385
[2018-03-02 15:25:49,738 DEBUG scholar] EndNote file:
%0 Book Section
%T NeuroCarePersonalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments
%A Hardy, Sandro
%A Reuter, Christian
%A Gobel, Stefan
%A Steinmetz, Ralf
%A Baller, Gisa
%A Kalbe, Elke
%A El Moussaoui, Abdelkarim
%A Abels, Sven
%A Dienst, Susanne
%A Dornhofer, Mareike
%B Ambient Assisted Living
%P 53-63
%D 2015
%I Springer

[2018-03-02 15:25:49,738 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:49,738 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:49,739 DEBUG __main__] Process content of EndNote file #213
{"title": "NeuroCare\u2014Personalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments", "url": "https://link.springer.com/chapter/10.1007/978-3-319-11866-6_4", "author": [{"shortname": "S Hardy", "gid": ""}, {"shortname": "C Reuter", "gid": ""}, {"shortname": "S G\u00f6bel", "gid": "rhR2e_YAAAAJ"}, {"shortname": "R Steinmetz", "gid": "S8m0ZkkAAAAJ"}, {"shortname": "G Baller", "gid": ""}], "year": 2015}
{"type": "Book Section", "title": "NeuroCare\u2014Personalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments", "author": ["Hardy, Sandro", "Reuter, Christian", "G\u00f6bel, Stefan", "Steinmetz, Ralf", "Baller, Gisa", "Kalbe, Elke", "El Moussaoui, Abdelkarim", "Abels, Sven", "Dienst, Susanne", "Dornh\u00f6fer, Mareike"], "secondarytitle": "Ambient Assisted Living", "pages": "53-63", "year": "2015", "publisher": "Springer", "start_page": 53, "end_page": 63, "volume": 11, "EndNote": "%0 Book Section\n%T NeuroCare\u2014Personalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments\n%A Hardy, Sandro\n%A Reuter, Christian\n%A G\u00f6bel, Stefan\n%A Steinmetz, Ralf\n%A Baller, Gisa\n%A Kalbe, Elke\n%A El Moussaoui, Abdelkarim\n%A Abels, Sven\n%A Dienst, Susanne\n%A Dornh\u00f6fer, Mareike\n%B Ambient Assisted Living\n%P 53-63\n%D 2015\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:a5wQwqLaATMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUUXsrG1fS8anx0raKVS-tbh8j4w-&scisf=3&ct=citation&cd=212&hl=en"}
[2018-03-02 15:25:49,739 DEBUG dbutils] Get paper id {"DOI": null, "title": "NeuroCare\u2014Personalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments", "auth_count": 10, "g_type": "Book Section", "pages": 11, "year": 2015, "rg_id": null, "start_page": 53, "end_page": 63}.
[2018-03-02 15:25:49,739 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'NeuroCarePersonalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments', 'auth_count': 10, 'g_type': 'Book Section', 'pages': 11, 'year': 2015, 'rg_id': None, 'start_page': 53, 'end_page': 63}
[2018-03-02 15:25:49,739 DEBUG dbutils] Query result: []
[2018-03-02 15:25:49,739 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:49,739 DEBUG dbutils] Add new paper (title='NeuroCarePersonalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments')
[2018-03-02 15:25:49,739 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'NeuroCarePersonalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments', 'year': 2015, 'publisher': 'Springer', 'start_page': 53, 'end_page': 63, 'pages': 11, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T NeuroCarePersonalization and Adaptation of Digital Training Programs for Mild Cognitive Impairments\n%A Hardy, Sandro\n%A Reuter, Christian\n%A Gobel, Stefan\n%A Steinmetz, Ralf\n%A Baller, Gisa\n%A Kalbe, Elke\n%A El Moussaoui, Abdelkarim\n%A Abels, Sven\n%A Dienst, Susanne\n%A Dornhofer, Mareike\n%B Ambient Assisted Living\n%P 53-63\n%D 2015\n%I Springer\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:49,740 DEBUG dbutils] Query result: 195
[2018-03-02 15:25:49,741 DEBUG __main__] Getting PDF-file on Google Scholar by url : ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf.
[2018-03-02 15:25:49,742 WARNING utils] Download file (url='ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf') and save (filename='PDF//195.pdf')
[2018-03-02 15:25:49,743 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,743 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:25:49,743 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for otherhost
[2018-03-02 15:25:49,757 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,757 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for otherhost
[2018-03-02 15:25:49,757 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,757 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:25:49,771 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,771 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for otherhost
[2018-03-02 15:25:49,772 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,772 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:25:49,785 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,785 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for otherhost
[2018-03-02 15:25:49,786 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,786 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:25:49,800 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,800 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for otherhost
[2018-03-02 15:25:49,800 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,800 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:25:49,815 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,815 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for otherhost
[2018-03-02 15:25:49,815 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,815 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:25:49,829 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,829 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for otherhost
[2018-03-02 15:25:49,829 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,829 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:25:49,843 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,843 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for otherhost
[2018-03-02 15:25:49,843 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,843 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:25:49,857 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,857 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for otherhost
[2018-03-02 15:25:49,857 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,857 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:25:49,871 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,872 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for otherhost
[2018-03-02 15:25:49,872 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,872 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:25:49,890 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,890 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for otherhost
[2018-03-02 15:25:49,890 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,890 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:25:49,905 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,905 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for otherhost
[2018-03-02 15:25:49,905 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,905 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:25:49,922 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,922 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for otherhost
[2018-03-02 15:25:49,922 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,922 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:25:49,960 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,961 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for otherhost
[2018-03-02 15:25:49,961 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,961 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:25:49,975 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,975 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for otherhost
[2018-03-02 15:25:49,976 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,976 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:25:49,989 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:49,989 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for otherhost
[2018-03-02 15:25:49,990 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:49,990 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:25:50,003 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:50,003 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for otherhost
[2018-03-02 15:25:50,004 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:50,004 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:25:50,020 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:50,020 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for otherhost
[2018-03-02 15:25:50,020 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:50,020 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:25:50,034 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:50,034 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for otherhost
[2018-03-02 15:25:50,035 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:50,035 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:25:50,049 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:50,049 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for otherhost
[2018-03-02 15:25:50,049 DEBUG utils] Get current proxy for dmz02.kom.e-technik.tu-darmstadt.de.
[2018-03-02 15:25:50,049 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:25:50,062 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 590, in send
    adapter = self.get_adapter(url=request.url)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 672, in get_adapter
    raise InvalidSchema("No connection adapters were found for '%s'" % url)
requests.exceptions.InvalidSchema: No connection adapters were found for 'ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf'

[2018-03-02 15:25:50,062 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for otherhost
[2018-03-02 15:25:50,065 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-11866-6_4.
[2018-03-02 15:25:50,065 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-11866-6_4.
[2018-03-02 15:25:50,328 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-11866-6_4 HTTP/1.1" 302 None
[2018-03-02 15:25:50,642 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=F89B680E02F277DF93BCBB6FB5321568 HTTP/1.1" 200 9756
[2018-03-02 15:25:50,733 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:25:50,733 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:25:50,910 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-11866-6_4 HTTP/1.1" 302 None
[2018-03-02 15:25:51,197 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=F89B680E02F277DF93BCBB6FB5321568 HTTP/1.1" 200 9756
[2018-03-02 15:25:51,428 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:25:51,429 DEBUG scholar] Handle paper #214 (total 1170)
[2018-03-02 15:25:51,429 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:25:51,433 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:25:51,433 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:25:51,918 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5UR3c6MQwKUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUYFovIsMV6IahaMxHbd0D_qiRmSO&scisf=3&ct=citation&cd=213&hl=en HTTP/1.1" 200 188
[2018-03-02 15:25:51,918 DEBUG scholar] EndNote file:
%0 Journal Article
%T Response Selection with Topic Clues for Retrieval-based Chatbots
%A Wu, Yu
%A Wu, Wei
%A Li, Zhoujun
%A Zhou, Ming
%J arXiv preprint arXiv:1605.00090
%D 2016

[2018-03-02 15:25:51,918 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:25:51,918 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:25:51,919 DEBUG __main__] Process content of EndNote file #214
{"title": "Response Selection with Topic Clues for Retrieval-based Chatbots", "url": "https://arxiv.org/abs/1605.00090", "author": [{"shortname": "Y Wu", "gid": "aQizmzsAAAAJ"}, {"shortname": "W Wu", "gid": "YtqXSzMAAAAJ"}, {"shortname": "Z Li", "gid": ""}, {"shortname": "M Zhou", "gid": ""}], "year": 1605}
{"type": "Journal Article", "title": "Response Selection with Topic Clues for Retrieval-based Chatbots", "author": ["Wu, Yu", "Wu, Wei", "Li, Zhoujun", "Zhou, Ming"], "journal": "arXiv preprint arXiv:1605.00090", "year": "2016", "EndNote": "%0 Journal Article\n%T Response Selection with Topic Clues for Retrieval-based Chatbots\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J arXiv preprint arXiv:1605.00090\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5UR3c6MQwKUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUYFovIsMV6IahaMxHbd0D_qiRmSO&scisf=3&ct=citation&cd=213&hl=en"}
[2018-03-02 15:25:51,919 DEBUG dbutils] Get paper id {"DOI": null, "title": "Response Selection with Topic Clues for Retrieval-based Chatbots", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:25:51,919 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Response Selection with Topic Clues for Retrieval-based Chatbots', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:25:51,919 DEBUG dbutils] Query result: []
[2018-03-02 15:25:51,919 DEBUG dbutils] Paper id = None.
[2018-03-02 15:25:51,919 DEBUG dbutils] Add new paper (title='Response Selection with Topic Clues for Retrieval-based Chatbots')
[2018-03-02 15:25:51,919 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Response Selection with Topic Clues for Retrieval-based Chatbots', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Response Selection with Topic Clues for Retrieval-based Chatbots\n%A Wu, Yu\n%A Wu, Wei\n%A Li, Zhoujun\n%A Zhou, Ming\n%J arXiv preprint arXiv:1605.00090\n%D 2016\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:25:51,919 DEBUG dbutils] Query result: 196
[2018-03-02 15:25:51,921 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1605.00090.
[2018-03-02 15:25:51,922 WARNING utils] Download file (url='https://arxiv.org/pdf/1605.00090') and save (filename='PDF//196.pdf')
[2018-03-02 15:25:51,922 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:25:51,922 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:25:51,937 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 15:25:55,476 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.00090 HTTP/1.1" 302 280
[2018-03-02 15:25:56,458 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1605.00090.pdf HTTP/1.1" 200 743346
[2018-03-02 15:25:56,458 DEBUG utils] Content-length=743346
[2018-03-02 15:25:56,459 DEBUG utils] Create file PDF//196.pdf, start download.
[2018-03-02 15:26:07,184 DEBUG utils] End download file PDF//196.pdf.
[2018-03-02 15:26:07,186 DEBUG dbutils] Update pdf_transaction for paper id=196.
[2018-03-02 15:26:07,186 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 196'
[2018-03-02 15:26:07,186 DEBUG dbutils] Query result: null
[2018-03-02 15:26:07,187 DEBUG scholar] Handle paper #215 (total 1170)
[2018-03-02 15:26:07,187 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:26:07,191 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:26:07,191 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:26:07,191 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for scholar.google.com
[2018-03-02 15:26:07,211 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:26:07,213 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:26:09,258 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:7DawLSgNwuwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUWtavAHuaJN5SN1VD78fN5SL9KJW&scisf=3&ct=citation&cd=214&hl=en HTTP/1.1" 200 333
[2018-03-02 15:26:09,259 DEBUG scholar] EndNote file:
%0 Journal Article
%T An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction
%A Jia, Jiyou
%J Learning Culture and Language through ICTs: Methods for Enhanced Instruction: Methods for Enhanced Instruction
%P 194
%@ 1605661678
%D 2009
%I IGI Global

[2018-03-02 15:26:09,259 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:26:09,259 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:26:09,259 DEBUG __main__] Process content of EndNote file #215
{"title": "An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction", "url": "https://books.google.com/books?hl=en&lr=&id=ihwv7TNtUSgC&oi=fnd&pg=PA194&dq=Use+deep+learning+to+create+a+chatbot&ots=fb2WQbHs5v&sig=4Dl0rIn3aMYadinQff91TaGgBXo", "author": [{"shortname": "J Jia", "gid": ""}], "year": 2009}
{"citedby": 3, "type": "Journal Article", "title": "An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction", "author": ["Jia, Jiyou"], "journal": "Learning Culture and Language through ICTs: Methods for Enhanced Instruction: Methods for Enhanced Instruction", "pages": "194", "isbn/issn": "1605661678", "year": "2009", "publisher": "IGI Global", "EndNote": "%0 Journal Article\n%T An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction\n%A Jia, Jiyou\n%J Learning Culture and Language through ICTs: Methods for Enhanced Instruction: Methods for Enhanced Instruction\n%P 194\n%@ 1605661678\n%D 2009\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:7DawLSgNwuwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUWtavAHuaJN5SN1VD78fN5SL9KJW&scisf=3&ct=citation&cd=214&hl=en"}
[2018-03-02 15:26:09,259 DEBUG dbutils] Get paper id {"DOI": null, "title": "An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:26:09,259 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:26:09,260 DEBUG dbutils] Query result: []
[2018-03-02 15:26:09,260 DEBUG dbutils] Paper id = None.
[2018-03-02 15:26:09,260 DEBUG dbutils] Add new paper (title='An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction')
[2018-03-02 15:26:09,260 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction', 'year': 2009, 'publisher': 'IGI Global', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T An Intelligent Web-Based Human-Computer Interaction System with Natural Language CSIEC and its Integration into English Instruction\n%A Jia, Jiyou\n%J Learning Culture and Language through ICTs: Methods for Enhanced Instruction: Methods for Enhanced Instruction\n%P 194\n%@ 1605661678\n%D 2009\n%I IGI Global\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:26:09,260 DEBUG dbutils] Query result: 197
[2018-03-02 15:26:09,262 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf.
[2018-03-02 15:26:09,264 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf') and save (filename='PDF//197.pdf')
[2018-03-02 15:26:09,265 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:09,265 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:26:09,265 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for otherhost
[2018-03-02 15:26:09,283 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:10,917 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:10,918 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:10,918 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for otherhost
[2018-03-02 15:26:10,920 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:10,920 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:26:10,935 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:13,857 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:13,858 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:13,858 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for otherhost
[2018-03-02 15:26:13,860 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:13,860 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:26:13,874 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:15,317 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:15,318 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:15,318 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for otherhost
[2018-03-02 15:26:15,320 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:15,320 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:26:15,335 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:18,058 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:18,059 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:18,059 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for otherhost
[2018-03-02 15:26:18,061 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:18,061 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:26:18,078 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:20,697 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:20,697 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:20,697 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for otherhost
[2018-03-02 15:26:20,699 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:20,699 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:26:20,715 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:23,418 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:23,418 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:23,419 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for otherhost
[2018-03-02 15:26:23,420 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:23,420 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:26:23,435 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:24,967 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:24,968 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:24,968 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for otherhost
[2018-03-02 15:26:24,970 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:24,970 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:26:24,985 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:27,327 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:27,328 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:27,328 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for otherhost
[2018-03-02 15:26:27,330 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:27,330 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:26:27,343 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:28,667 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:28,668 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:28,668 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for otherhost
[2018-03-02 15:26:28,670 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:28,670 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:26:28,686 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:29,991 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:29,991 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:29,991 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for otherhost
[2018-03-02 15:26:29,993 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:29,994 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:26:30,008 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:32,007 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:32,008 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:32,009 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for otherhost
[2018-03-02 15:26:32,010 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:32,010 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:26:32,028 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:35,267 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:35,268 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:35,268 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for otherhost
[2018-03-02 15:26:35,270 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:35,270 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:26:35,285 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:36,597 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:36,598 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:36,598 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for otherhost
[2018-03-02 15:26:36,600 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:36,600 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:26:36,614 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:38,187 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:38,188 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:38,188 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for otherhost
[2018-03-02 15:26:38,189 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:38,190 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:26:38,203 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:40,470 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:40,471 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:40,471 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for otherhost
[2018-03-02 15:26:40,473 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:40,473 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:26:40,488 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:42,177 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:42,177 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:42,178 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for otherhost
[2018-03-02 15:26:42,179 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:42,179 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:26:42,195 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:43,327 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:43,328 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:43,328 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for otherhost
[2018-03-02 15:26:43,330 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:43,330 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:26:43,345 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:44,127 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:44,128 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:44,128 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for otherhost
[2018-03-02 15:26:44,130 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:44,130 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:26:44,144 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:46,009 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:46,010 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:46,010 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for otherhost
[2018-03-02 15:26:46,011 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:26:46,012 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:26:46,027 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:26:47,347 DEBUG requests.packages.urllib3.connectionpool] "GET /432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf HTTP/1.1" 404 None
[2018-03-02 15:26:47,348 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:26:47,348 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for otherhost
[2018-03-02 15:26:47,352 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=ihwv7TNtUSgC&oi=fnd&pg=PA194&dq=Use+deep+learning+to+create+a+chatbot&ots=fb2WQbHs5v&sig=4Dl0rIn3aMYadinQff91TaGgBXo.
[2018-03-02 15:26:47,352 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=ihwv7TNtUSgC&oi=fnd&pg=PA194&dq=Use+deep+learning+to+create+a+chatbot&ots=fb2WQbHs5v&sig=4Dl0rIn3aMYadinQff91TaGgBXo.
[2018-03-02 15:26:47,567 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=ihwv7TNtUSgC&oi=fnd&pg=PA194&dq=Use+deep+learning+to+create+a+chatbot&ots=fb2WQbHs5v&sig=4Dl0rIn3aMYadinQff91TaGgBXo HTTP/1.1" 302 None
[2018-03-02 15:26:47,797 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:26:47,811 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:26:47,812 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:26:47,812 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for sci-hub.tw
[2018-03-02 15:26:48,036 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=ihwv7TNtUSgC&oi=fnd&pg=PA194&dq=Use+deep+learning+to+create+a+chatbot&ots=fb2WQbHs5v&sig=4Dl0rIn3aMYadinQff91TaGgBXo HTTP/1.1" 302 None
[2018-03-02 15:26:48,247 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:26:48,276 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:26:48,279 DEBUG scholar] Handle paper #216 (total 1170)
[2018-03-02 15:26:48,279 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:26:48,282 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:26:48,282 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:26:48,677 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5iLpBBOMXa4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUcNFqDm_9o0tLlP9BfGFeJ43idHi&scisf=3&ct=citation&cd=215&hl=en HTTP/1.1" 200 134
[2018-03-02 15:26:48,678 DEBUG scholar] EndNote file:
%0 Book
%T Intelligent Tutoring Systems
%A Ashlay, Kevin
%A Chan, Tak-Wai
%A Ikeda, Mitsuru
%@ 3540351604
%D 2006
%I Springer

[2018-03-02 15:26:48,678 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:26:48,679 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:26:48,679 DEBUG __main__] Process content of EndNote file #216
{"title": "Intelligent Tutoring Systems", "url": "https://link.springer.com/content/pdf/10.1007/11774303.pdf", "author": [{"shortname": "K Ashlay", "gid": ""}, {"shortname": "TW Chan", "gid": ""}, {"shortname": "M Ikeda", "gid": "PCe4CO0AAAAJ"}], "year": 2006}
{"citedby": 1, "type": "Book", "title": "Intelligent Tutoring Systems", "author": ["Ashlay, Kevin", "Chan, Tak-Wai", "Ikeda, Mitsuru"], "isbn/issn": "3540351604", "year": "2006", "publisher": "Springer", "EndNote": "%0 Book\n%T Intelligent Tutoring Systems\n%A Ashlay, Kevin\n%A Chan, Tak-Wai\n%A Ikeda, Mitsuru\n%@ 3540351604\n%D 2006\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5iLpBBOMXa4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUcNFqDm_9o0tLlP9BfGFeJ43idHi&scisf=3&ct=citation&cd=215&hl=en"}
[2018-03-02 15:26:48,679 DEBUG dbutils] Get paper id {"DOI": null, "title": "Intelligent Tutoring Systems", "auth_count": 3, "g_type": "Book", "pages": null, "year": 2006, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:26:48,679 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Intelligent Tutoring Systems', 'auth_count': 3, 'g_type': 'Book', 'pages': None, 'year': 2006, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:26:48,679 DEBUG dbutils] Query result: []
[2018-03-02 15:26:48,679 DEBUG dbutils] Paper id = None.
[2018-03-02 15:26:48,679 DEBUG dbutils] Add new paper (title='Intelligent Tutoring Systems')
[2018-03-02 15:26:48,679 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Intelligent Tutoring Systems', 'year': 2006, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Intelligent Tutoring Systems\n%A Ashlay, Kevin\n%A Chan, Tak-Wai\n%A Ikeda, Mitsuru\n%@ 3540351604\n%D 2006\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:26:48,680 DEBUG dbutils] Query result: 198
[2018-03-02 15:26:48,681 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/content/pdf/10.1007/11774303.pdf.
[2018-03-02 15:26:48,681 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/content/pdf/10.1007/11774303.pdf.
[2018-03-02 15:26:48,937 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/11774303.pdf HTTP/1.1" 302 None
[2018-03-02 15:26:48,959 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 15:26:49,271 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=EEC3B1FFF23F2D1527EE359C97ADA16C HTTP/1.1" 200 13405
[2018-03-02 15:26:49,386 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:26:49,386 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:26:49,577 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/11774303.pdf HTTP/1.1" 302 None
[2018-03-02 15:26:49,797 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=EEC3B1FFF23F2D1527EE359C97ADA16C HTTP/1.1" 200 13405
[2018-03-02 15:26:50,046 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:26:50,047 DEBUG scholar] Handle paper #217 (total 1170)
[2018-03-02 15:26:50,048 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:26:50,050 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:26:50,050 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:26:50,050 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for scholar.google.com
[2018-03-02 15:26:50,064 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:26:50,065 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:26:51,857 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Wb3WQwZu_9AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFURU3sqTE4JaHsmYKOUzd6qtiVWOm&scisf=3&ct=citation&cd=216&hl=en HTTP/1.1" 200 319
[2018-03-02 15:26:51,858 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Using NLTK for educational and scientific purposes
%A Lobur, Mykhailo
%A Romanyuk, AnDriy
%A Romanyshyn, Mariana
%B CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of
%P 426-428
%@ 9662191178
%D 2011
%I IEEE

[2018-03-02 15:26:51,858 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:26:51,859 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:26:51,859 DEBUG __main__] Process content of EndNote file #217
{"title": "Using NLTK for educational and scientific purposes", "url": "http://ieeexplore.ieee.org/abstract/document/5744524/", "author": [{"shortname": "M Lobur", "gid": ""}, {"shortname": "AD Romanyuk", "gid": ""}], "year": 2011}
{"citedby": 8, "type": "Conference Proceedings", "title": "Using NLTK for educational and scientific purposes", "author": ["Lobur, Mykhailo", "Romanyuk, AnDriy", "Romanyshyn, Mariana"], "secondarytitle": "CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of", "pages": "426-428", "isbn/issn": "9662191178", "year": "2011", "publisher": "IEEE", "start_page": 426, "end_page": 428, "volume": 3, "EndNote": "%0 Conference Proceedings\n%T Using NLTK for educational and scientific purposes\n%A Lobur, Mykhailo\n%A Romanyuk, AnDriy\n%A Romanyshyn, Mariana\n%B CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of\n%P 426-428\n%@ 9662191178\n%D 2011\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Wb3WQwZu_9AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFURU3sqTE4JaHsmYKOUzd6qtiVWOm&scisf=3&ct=citation&cd=216&hl=en"}
[2018-03-02 15:26:51,859 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using NLTK for educational and scientific purposes", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 3, "year": 2011, "rg_id": null, "start_page": 426, "end_page": 428}.
[2018-03-02 15:26:51,859 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using NLTK for educational and scientific purposes', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 3, 'year': 2011, 'rg_id': None, 'start_page': 426, 'end_page': 428}
[2018-03-02 15:26:51,859 DEBUG dbutils] Query result: []
[2018-03-02 15:26:51,859 DEBUG dbutils] Paper id = None.
[2018-03-02 15:26:51,859 DEBUG dbutils] Add new paper (title='Using NLTK for educational and scientific purposes')
[2018-03-02 15:26:51,859 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using NLTK for educational and scientific purposes', 'year': 2011, 'publisher': 'IEEE', 'start_page': 426, 'end_page': 428, 'pages': 3, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Using NLTK for educational and scientific purposes\n%A Lobur, Mykhailo\n%A Romanyuk, AnDriy\n%A Romanyshyn, Mariana\n%B CAD Systems in Microelectronics (CADSM), 2011 11th International Conference The Experience of Designing and Application of\n%P 426-428\n%@ 9662191178\n%D 2011\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:26:51,860 DEBUG dbutils] Query result: 199
[2018-03-02 15:26:51,861 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/5744524/.
[2018-03-02 15:26:51,861 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/5744524/.
[2018-03-02 15:26:54,027 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/5744524/ HTTP/1.1" 200 None
[2018-03-02 15:26:54,028 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:26:54,028 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:26:54,028 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for sci-hub.tw
[2018-03-02 15:26:54,211 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/5744524/ HTTP/1.1" 200 None
[2018-03-02 15:26:54,217 DEBUG scihub] URL for PDF: http://direct.sci-hub.tw/ieeexplore.ieee.org/8681cdeec06a25a9f91c98e7c33a1f62.pdf?download=true.
[2018-03-02 15:26:54,218 WARNING utils] Download file (url='http://direct.sci-hub.tw/ieeexplore.ieee.org/8681cdeec06a25a9f91c98e7c33a1f62.pdf?download=true') and save (filename='PDF//199.pdf')
[2018-03-02 15:26:54,236 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): direct.sci-hub.tw
[2018-03-02 15:26:55,147 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/8681cdeec06a25a9f91c98e7c33a1f62.pdf?download=true HTTP/1.1" 200 345965
[2018-03-02 15:26:55,148 DEBUG utils] Get current proxy for direct.sci-hub.tw.
[2018-03-02 15:26:55,148 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:26:55,164 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): direct.sci-hub.tw
[2018-03-02 15:26:55,477 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/8681cdeec06a25a9f91c98e7c33a1f62.pdf?download=true HTTP/1.1" 200 345965
[2018-03-02 15:26:55,478 DEBUG utils] Content-length=345965
[2018-03-02 15:26:55,479 DEBUG utils] Create file PDF//199.pdf, start download.
[2018-03-02 15:26:56,076 DEBUG utils] End download file PDF//199.pdf.
[2018-03-02 15:26:56,077 DEBUG dbutils] Update pdf_transaction for paper id=199.
[2018-03-02 15:26:56,077 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 199'
[2018-03-02 15:26:56,077 DEBUG dbutils] Query result: null
[2018-03-02 15:26:56,077 DEBUG scholar] Handle paper #218 (total 1170)
[2018-03-02 15:26:56,078 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:26:56,081 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:26:56,082 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:26:56,408 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KPA2VEi__rMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUY80xV2HMiMh4bd09L-S3F47yGHH&scisf=3&ct=citation&cd=217&hl=en HTTP/1.1" 200 332
[2018-03-02 15:26:56,409 DEBUG scholar] EndNote file:
%0 Journal Article
%T A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models
%A Suleman, Raja M
%A Mizoguchi, Riichiro
%A Ikeda, Mitsuru
%J International Journal of Artificial Intelligence in Education
%V 26
%N 4
%P 1069-1115
%@ 1560-4292
%D 2016
%I Springer

[2018-03-02 15:26:56,409 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:26:56,409 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:26:56,410 DEBUG __main__] Process content of EndNote file #218
{"title": "A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models", "url": "https://link.springer.com/article/10.1007/s40593-016-0118-8", "author": [{"shortname": "RM Suleman", "gid": "bLQu4GMAAAAJ"}, {"shortname": "R Mizoguchi", "gid": "8vYF2UIAAAAJ"}, {"shortname": "M Ikeda", "gid": "PCe4CO0AAAAJ"}], "year": 2016}
{"type": "Journal Article", "title": "A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models", "author": ["Suleman, Raja M", "Mizoguchi, Riichiro", "Ikeda, Mitsuru"], "journal": "International Journal of Artificial Intelligence in Education", "volume": 47, "numberorissue": "4", "pages": "1069-1115", "isbn/issn": "1560-4292", "year": "2016", "publisher": "Springer", "start_page": 1069, "end_page": 1115, "EndNote": "%0 Journal Article\n%T A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models\n%A Suleman, Raja M\n%A Mizoguchi, Riichiro\n%A Ikeda, Mitsuru\n%J International Journal of Artificial Intelligence in Education\n%V 26\n%N 4\n%P 1069-1115\n%@ 1560-4292\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KPA2VEi__rMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUY80xV2HMiMh4bd09L-S3F47yGHH&scisf=3&ct=citation&cd=217&hl=en"}
[2018-03-02 15:26:56,410 DEBUG dbutils] Get paper id {"DOI": null, "title": "A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models", "auth_count": 3, "g_type": "Journal Article", "pages": 47, "year": 2016, "rg_id": null, "start_page": 1069, "end_page": 1115}.
[2018-03-02 15:26:56,410 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 47, 'year': 2016, 'rg_id': None, 'start_page': 1069, 'end_page': 1115}
[2018-03-02 15:26:56,410 DEBUG dbutils] Query result: []
[2018-03-02 15:26:56,410 DEBUG dbutils] Paper id = None.
[2018-03-02 15:26:56,410 DEBUG dbutils] Add new paper (title='A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models')
[2018-03-02 15:26:56,410 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models', 'year': 2016, 'publisher': 'Springer', 'start_page': 1069, 'end_page': 1115, 'pages': 47, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A New Perspective of Negotiation-Based Dialog to Enhance Metacognitive Skills in the Context of Open Learner Models\n%A Suleman, Raja M\n%A Mizoguchi, Riichiro\n%A Ikeda, Mitsuru\n%J International Journal of Artificial Intelligence in Education\n%V 26\n%N 4\n%P 1069-1115\n%@ 1560-4292\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:26:56,410 DEBUG dbutils] Query result: 200
[2018-03-02 15:26:56,413 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/article/10.1007/s40593-016-0118-8.
[2018-03-02 15:26:56,413 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/article/10.1007/s40593-016-0118-8.
[2018-03-02 15:26:56,597 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/article/10.1007/s40593-016-0118-8 HTTP/1.1" 200 None
[2018-03-02 15:26:56,598 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:26:56,598 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:26:56,598 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for sci-hub.tw
[2018-03-02 15:26:56,807 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/article/10.1007/s40593-016-0118-8 HTTP/1.1" 200 None
[2018-03-02 15:26:56,815 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true.
[2018-03-02 15:26:56,816 WARNING utils] Download file (url='http://twin.sci-hub.tw/d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true') and save (filename='PDF//200.pdf')
[2018-03-02 15:26:56,832 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 15:26:57,011 DEBUG requests.packages.urllib3.connectionpool] "GET /d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:26:57,012 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:26:57,012 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:26:57,029 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 15:26:57,207 DEBUG requests.packages.urllib3.connectionpool] "GET /d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:26:57,210 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:26:57,210 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:27:07,837 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:27:07,837 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:27:08,087 DEBUG requests.packages.urllib3.connectionpool] "GET /d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:08,087 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:27:08,088 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:27:08,088 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for sci-hub.tw
[2018-03-02 15:27:08,103 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): twin.sci-hub.tw
[2018-03-02 15:27:08,277 DEBUG requests.packages.urllib3.connectionpool] "GET /d432d28e6c10d301050eb7d622912ec3/suleman2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:08,281 DEBUG scholar] Handle paper #219 (total 1170)
[2018-03-02 15:27:08,281 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:27:08,285 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:08,285 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:27:08,285 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for scholar.google.com
[2018-03-02 15:27:08,303 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:27:08,304 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:27:11,537 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:c4OQZCiketwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUSmGVRWGOksvwx1MERtacIsM-PhD&scisf=3&ct=citation&cd=218&hl=en HTTP/1.1" 200 335
[2018-03-02 15:27:11,538 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Computer-Aided Ethnography in Engineering Design
%A Dixon, Adam
%A Liu, Ying
%A Setchi, Rossi
%B ASME 2016 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference
%P V007T06A007-V007T06A007
%D 2016
%I American Society of Mechanical Engineers

[2018-03-02 15:27:11,538 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:11,538 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:11,539 DEBUG __main__] Process content of EndNote file #219
{"title": "Computer-Aided Ethnography in Engineering Design", "url": "http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=2592105", "author": [{"shortname": "A Dixon", "gid": ""}, {"shortname": "Y Liu", "gid": "dFgj9cwAAAAJ"}, {"shortname": "R Setchi", "gid": ""}], "year": 2016}
{"type": "Conference Proceedings", "title": "Computer-Aided Ethnography in Engineering Design", "author": ["Dixon, Adam", "Liu, Ying", "Setchi, Rossi"], "secondarytitle": "ASME 2016 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference", "pages": "V007T06A007-V007T06A007", "year": "2016", "publisher": "American Society of Mechanical Engineers", "start_page": 7, "EndNote": "%0 Conference Proceedings\n%T Computer-Aided Ethnography in Engineering Design\n%A Dixon, Adam\n%A Liu, Ying\n%A Setchi, Rossi\n%B ASME 2016 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference\n%P V007T06A007-V007T06A007\n%D 2016\n%I American Society of Mechanical Engineers\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:c4OQZCiketwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUSmGVRWGOksvwx1MERtacIsM-PhD&scisf=3&ct=citation&cd=218&hl=en"}
[2018-03-02 15:27:11,539 DEBUG dbutils] Get paper id {"DOI": null, "title": "Computer-Aided Ethnography in Engineering Design", "auth_count": 3, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": 7, "end_page": null}.
[2018-03-02 15:27:11,539 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Computer-Aided Ethnography in Engineering Design', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': 7, 'end_page': None}
[2018-03-02 15:27:11,539 DEBUG dbutils] Query result: []
[2018-03-02 15:27:11,540 DEBUG dbutils] Paper id = None.
[2018-03-02 15:27:11,540 DEBUG dbutils] Add new paper (title='Computer-Aided Ethnography in Engineering Design')
[2018-03-02 15:27:11,540 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Computer-Aided Ethnography in Engineering Design', 'year': 2016, 'publisher': 'American Society of Mechanical Engineers', 'start_page': 7, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Computer-Aided Ethnography in Engineering Design\n%A Dixon, Adam\n%A Liu, Ying\n%A Setchi, Rossi\n%B ASME 2016 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference\n%P V007T06A007-V007T06A007\n%D 2016\n%I American Society of Mechanical Engineers\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:27:11,540 DEBUG dbutils] Query result: 201
[2018-03-02 15:27:11,542 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=2592105.
[2018-03-02 15:27:11,542 DEBUG scihub] Get page from sci-hub for paper with DOI=http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=2592105.
[2018-03-02 15:27:12,907 DEBUG requests.packages.urllib3.connectionpool] "GET //http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=2592105 HTTP/1.1" 200 None
[2018-03-02 15:27:12,908 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:27:12,908 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:27:13,097 DEBUG requests.packages.urllib3.connectionpool] "GET //http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=2592105 HTTP/1.1" 200 None
[2018-03-02 15:27:13,102 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true.
[2018-03-02 15:27:13,103 WARNING utils] Download file (url='http://twin.sci-hub.tw/ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true') and save (filename='PDF//201.pdf')
[2018-03-02 15:27:13,227 DEBUG requests.packages.urllib3.connectionpool] "GET /ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:13,227 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:27:13,227 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:27:13,227 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for sci-hub.tw
[2018-03-02 15:27:13,248 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): twin.sci-hub.tw
[2018-03-02 15:27:13,426 DEBUG requests.packages.urllib3.connectionpool] "GET /ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:13,429 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:27:13,429 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:27:19,883 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:27:19,884 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:27:20,157 DEBUG requests.packages.urllib3.connectionpool] "GET /ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:20,158 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:27:20,158 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:27:20,173 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): twin.sci-hub.tw
[2018-03-02 15:27:20,346 DEBUG requests.packages.urllib3.connectionpool] "GET /ce055095d5097a7c3195d3977947e440/dixon2016.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:20,351 DEBUG scholar] Handle paper #220 (total 1170)
[2018-03-02 15:27:20,351 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:27:20,355 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:20,355 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:27:20,896 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:evExNmnx-ZwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUQ5n_rf3Wh3ccMfGzA7gwIx8emdI&scisf=3&ct=citation&cd=219&hl=en HTTP/1.1" 200 284
[2018-03-02 15:27:20,897 DEBUG scholar] EndNote file:
%0 Journal Article
%T A systematic review of CALL in English as a second language: Focus on primary and secondary education
%A Macaro, Ernesto
%A Handley, Zoe
%A Walter, Catherine
%J Language Teaching
%V 45
%N 1
%P 1-43
%@ 1475-3049
%D 2012
%I Cambridge University Press

[2018-03-02 15:27:20,897 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:20,897 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:20,898 DEBUG __main__] Process content of EndNote file #220
{"title": "A systematic review of CALL in English as a second language: Focus on primary and secondary education", "url": "https://www.cambridge.org/core/journals/language-teaching/article/systematic-review-of-call-in-english-as-a-second-language-focus-on-primary-and-secondary-education/07ED8AFA7FDA97380F606AEC56674A47", "author": [{"shortname": "E Macaro", "gid": ""}, {"shortname": "Z Handley", "gid": "YW4l6bIAAAAJ"}, {"shortname": "C Walter", "gid": ""}], "year": 2012}
{"citedby": 70, "type": "Journal Article", "title": "A systematic review of CALL in English as a second language: Focus on primary and secondary education", "author": ["Macaro, Ernesto", "Handley, Z\u00f6e", "Walter, Catherine"], "journal": "Language Teaching", "volume": 43, "numberorissue": "1", "pages": "1-43", "isbn/issn": "1475-3049", "year": "2012", "publisher": "Cambridge University Press", "start_page": 1, "end_page": 43, "EndNote": "%0 Journal Article\n%T A systematic review of CALL in English as a second language: Focus on primary and secondary education\n%A Macaro, Ernesto\n%A Handley, Z\u00f6e\n%A Walter, Catherine\n%J Language Teaching\n%V 45\n%N 1\n%P 1-43\n%@ 1475-3049\n%D 2012\n%I Cambridge University Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:evExNmnx-ZwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplFUQ5n_rf3Wh3ccMfGzA7gwIx8emdI&scisf=3&ct=citation&cd=219&hl=en"}
[2018-03-02 15:27:20,898 DEBUG dbutils] Get paper id {"DOI": null, "title": "A systematic review of CALL in English as a second language: Focus on primary and secondary education", "auth_count": 3, "g_type": "Journal Article", "pages": 43, "year": 2012, "rg_id": null, "start_page": 1, "end_page": 43}.
[2018-03-02 15:27:20,898 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A systematic review of CALL in English as a second language: Focus on primary and secondary education', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 43, 'year': 2012, 'rg_id': None, 'start_page': 1, 'end_page': 43}
[2018-03-02 15:27:20,898 DEBUG dbutils] Query result: []
[2018-03-02 15:27:20,898 DEBUG dbutils] Paper id = None.
[2018-03-02 15:27:20,898 DEBUG dbutils] Add new paper (title='A systematic review of CALL in English as a second language: Focus on primary and secondary education')
[2018-03-02 15:27:20,898 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A systematic review of CALL in English as a second language: Focus on primary and secondary education', 'year': 2012, 'publisher': 'Cambridge University Press', 'start_page': 1, 'end_page': 43, 'pages': 43, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A systematic review of CALL in English as a second language: Focus on primary and secondary education\n%A Macaro, Ernesto\n%A Handley, Zoe\n%A Walter, Catherine\n%J Language Teaching\n%V 45\n%N 1\n%P 1-43\n%@ 1475-3049\n%D 2012\n%I Cambridge University Press\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:27:20,899 DEBUG dbutils] Query result: 202
[2018-03-02 15:27:20,900 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://search.proquest.com/openview/83c97a209c174153d8a7b05d1321d374/1.pdf?pq-origsite=gscholar&cbl=47776.
[2018-03-02 15:27:20,901 WARNING utils] Download file (url='http://search.proquest.com/openview/83c97a209c174153d8a7b05d1321d374/1.pdf?pq-origsite=gscholar&cbl=47776') and save (filename='PDF//202.pdf')
[2018-03-02 15:27:20,902 DEBUG utils] Get current proxy for search.proquest.com.
[2018-03-02 15:27:20,902 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:27:20,921 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): search.proquest.com
[2018-03-02 15:27:21,556 DEBUG requests.packages.urllib3.connectionpool] "GET /openview/83c97a209c174153d8a7b05d1321d374/1.pdf?pq-origsite=gscholar&cbl=47776 HTTP/1.1" 302 0
[2018-03-02 15:27:21,579 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): search.proquest.com
[2018-03-02 15:27:23,419 DEBUG requests.packages.urllib3.connectionpool] "GET /openview/83c97a209c174153d8a7b05d1321d374/1.pdf?pq-origsite=gscholar&cbl=47776 HTTP/1.1" 200 4912
[2018-03-02 15:27:23,430 DEBUG utils] Content-length=4912
[2018-03-02 15:27:23,430 DEBUG utils] Create file PDF//202.pdf, start download.
[2018-03-02 15:27:23,432 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 4912

[2018-03-02 15:27:23,432 DEBUG __main__] Failed get_pdf from Google Scholar for paper #202. URL=202
[2018-03-02 15:27:23,434 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.cambridge.org/core/journals/language-teaching/article/systematic-review-of-call-in-english-as-a-second-language-focus-on-primary-and-secondary-education/07ED8AFA7FDA97380F606AEC56674A47.
[2018-03-02 15:27:23,435 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.cambridge.org/core/journals/language-teaching/article/systematic-review-of-call-in-english-as-a-second-language-focus-on-primary-and-secondary-education/07ED8AFA7FDA97380F606AEC56674A47.
[2018-03-02 15:27:23,867 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/language-teaching/article/systematic-review-of-call-in-english-as-a-second-language-focus-on-primary-and-secondary-education/07ED8AFA7FDA97380F606AEC56674A47 HTTP/1.1" 200 None
[2018-03-02 15:27:23,868 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:27:23,868 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:27:23,868 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for sci-hub.tw
[2018-03-02 15:27:24,308 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/language-teaching/article/systematic-review-of-call-in-english-as-a-second-language-focus-on-primary-and-secondary-education/07ED8AFA7FDA97380F606AEC56674A47 HTTP/1.1" 200 None
[2018-03-02 15:27:24,315 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true.
[2018-03-02 15:27:24,316 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true') and save (filename='PDF//202.pdf')
[2018-03-02 15:27:24,356 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 15:27:24,636 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:24,637 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:27:24,638 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:27:24,653 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (10): cyber.sci-hub.tw
[2018-03-02 15:27:24,879 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:24,882 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:27:24,882 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:27:36,210 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:27:36,210 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:27:36,556 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true HTTP/1.1" 200 642221
[2018-03-02 15:27:36,557 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:27:36,557 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:27:36,557 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for sci-hub.tw
[2018-03-02 15:27:36,574 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (11): cyber.sci-hub.tw
[2018-03-02 15:27:36,983 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMDI2MTQ0NDgxMTAwMDM5NQ==/macaro2011.pdf?download=true HTTP/1.1" 200 642221
[2018-03-02 15:27:36,984 DEBUG utils] Content-length=642221
[2018-03-02 15:27:36,984 DEBUG utils] Create file PDF//202.pdf, start download.
[2018-03-02 15:27:37,688 DEBUG utils] End download file PDF//202.pdf.
[2018-03-02 15:27:37,690 DEBUG dbutils] Update pdf_transaction for paper id=202.
[2018-03-02 15:27:37,690 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 202'
[2018-03-02 15:27:37,690 DEBUG dbutils] Query result: null
[2018-03-02 15:27:37,690 DEBUG dbutils] Commiting transaction 220.
[2018-03-02 15:27:37,806 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:27:37,806 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:27:37,806 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:27:37,806 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for scholar.google.com
[2018-03-02 15:27:37,823 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:27:40,268 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=220&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:27:41,116 DEBUG scholar] Find papers on page #23 (max_google_papers = 300)
[2018-03-02 15:27:41,117 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:27:41,117 DEBUG scholar] Handle paper #221 (total 1170)
[2018-03-02 15:27:41,117 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:27:41,122 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:41,122 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:27:41,137 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:27:41,138 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:27:43,506 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:VWnOr_EU2ZsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2MtQ-YW7mwAUrUL9YsYitlddkbEH&scisf=3&ct=citation&cd=220&hl=en HTTP/1.1" 200 78
[2018-03-02 15:27:43,507 DEBUG scholar] EndNote file:
%0 Journal Article
%T FY2014 IAMU Capacity building project
%A John, Peter

[2018-03-02 15:27:43,507 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:43,507 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:43,507 DEBUG __main__] Skip paper #221, empty year or authors fields.
[2018-03-02 15:27:43,508 DEBUG scholar] Handle paper #222 (total 1170)
[2018-03-02 15:27:43,508 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:27:43,510 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:43,510 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:27:43,510 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for scholar.google.com
[2018-03-02 15:27:43,526 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:27:43,528 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:27:44,765 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:xU4Gq_ykOIYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2CXDGNKitnL3OlDUoqdOUYky5lrT&scisf=3&ct=citation&cd=221&hl=en HTTP/1.1" 200 241
[2018-03-02 15:27:44,766 DEBUG scholar] EndNote file:
%0 Book Section
%T AIML knowledge base construction from text corpora
%A De Gasperis, Giovanni
%A Chiari, Isabella
%A Florio, Niva
%B Artificial intelligence, evolutionary computing and metaheuristics
%P 287-318
%D 2013
%I Springer

[2018-03-02 15:27:44,766 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:44,767 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:44,767 DEBUG __main__] Process content of EndNote file #222
{"title": "AIML knowledge base construction from text corpora", "url": "https://link.springer.com/chapter/10.1007/978-3-642-29694-9_12", "author": [{"shortname": "G De Gasperis", "gid": "RhXvFdIAAAAJ"}, {"shortname": "I Chiari", "gid": ""}, {"shortname": "N Florio", "gid": ""}], "year": 2013}
{"citedby": 2, "type": "Book Section", "title": "AIML knowledge base construction from text corpora", "author": ["De Gasperis, Giovanni", "Chiari, Isabella", "Florio, Niva"], "secondarytitle": "Artificial intelligence, evolutionary computing and metaheuristics", "pages": "287-318", "year": "2013", "publisher": "Springer", "start_page": 287, "end_page": 318, "volume": 32, "EndNote": "%0 Book Section\n%T AIML knowledge base construction from text corpora\n%A De Gasperis, Giovanni\n%A Chiari, Isabella\n%A Florio, Niva\n%B Artificial intelligence, evolutionary computing and metaheuristics\n%P 287-318\n%D 2013\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:xU4Gq_ykOIYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2CXDGNKitnL3OlDUoqdOUYky5lrT&scisf=3&ct=citation&cd=221&hl=en"}
[2018-03-02 15:27:44,767 DEBUG dbutils] Get paper id {"DOI": null, "title": "AIML knowledge base construction from text corpora", "auth_count": 3, "g_type": "Book Section", "pages": 32, "year": 2013, "rg_id": null, "start_page": 287, "end_page": 318}.
[2018-03-02 15:27:44,767 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'AIML knowledge base construction from text corpora', 'auth_count': 3, 'g_type': 'Book Section', 'pages': 32, 'year': 2013, 'rg_id': None, 'start_page': 287, 'end_page': 318}
[2018-03-02 15:27:44,767 DEBUG dbutils] Query result: []
[2018-03-02 15:27:44,767 DEBUG dbutils] Paper id = None.
[2018-03-02 15:27:44,767 DEBUG dbutils] Add new paper (title='AIML knowledge base construction from text corpora')
[2018-03-02 15:27:44,768 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'AIML knowledge base construction from text corpora', 'year': 2013, 'publisher': 'Springer', 'start_page': 287, 'end_page': 318, 'pages': 32, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T AIML knowledge base construction from text corpora\n%A De Gasperis, Giovanni\n%A Chiari, Isabella\n%A Florio, Niva\n%B Artificial intelligence, evolutionary computing and metaheuristics\n%P 287-318\n%D 2013\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:27:44,768 DEBUG dbutils] Query result: 203
[2018-03-02 15:27:44,770 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/a07f/2f2293427d64a47f0cf1b8cba8cbc95bfdaa.pdf.
[2018-03-02 15:27:44,770 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/a07f/2f2293427d64a47f0cf1b8cba8cbc95bfdaa.pdf') and save (filename='PDF//203.pdf')
[2018-03-02 15:27:44,770 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:27:44,771 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:27:44,771 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for otherhost
[2018-03-02 15:27:44,788 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:27:44,789 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:27:46,393 DEBUG requests.packages.urllib3.connectionpool] "GET /a07f/2f2293427d64a47f0cf1b8cba8cbc95bfdaa.pdf HTTP/1.1" 200 534505
[2018-03-02 15:27:46,394 DEBUG utils] Content-length=534505
[2018-03-02 15:27:46,394 DEBUG utils] Create file PDF//203.pdf, start download.
[2018-03-02 15:27:48,909 DEBUG utils] End download file PDF//203.pdf.
[2018-03-02 15:27:48,911 DEBUG dbutils] Update pdf_transaction for paper id=203.
[2018-03-02 15:27:48,911 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 203'
[2018-03-02 15:27:48,911 DEBUG dbutils] Query result: null
[2018-03-02 15:27:48,911 DEBUG scholar] Handle paper #223 (total 1170)
[2018-03-02 15:27:48,912 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:27:48,918 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:48,918 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:27:49,272 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:GH-57oUo0QQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2L38-PnM4zErfxShNmXuJbhVj7KJ&scisf=3&ct=citation&cd=222&hl=en HTTP/1.1" 200 284
[2018-03-02 15:27:49,272 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Paradise lost? Primary empathy in online communities of interest and ways of use
%A Lambropoulos, Niki
%B 1st Conference on Online Communities and Social Computing, in the 11th International Conference on Human-Computer Interaction
%P 22-27
%D 2005

[2018-03-02 15:27:49,273 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:49,273 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:49,273 DEBUG __main__] Process content of EndNote file #223
{"title": "Paradise lost? Primary empathy in online communities of interest and ways of use", "url": "https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/266450915_Paradise_Lost_Primary_Empathy_in_Online_Communities_of_Interest_and_Ways_of_Use/links/54eca5f40cf27fbfd771350c.pdf", "author": [{"shortname": "N Lambropoulos", "gid": "_VULjWQAAAAJ"}], "year": 2005}
{"citedby": 3, "type": "Conference Proceedings", "title": "Paradise lost? Primary empathy in online communities of interest and ways of use", "author": ["Lambropoulos, Niki"], "secondarytitle": "1st Conference on Online Communities and Social Computing, in the 11th International Conference on Human-Computer Interaction", "pages": "22-27", "year": "2005", "start_page": 22, "end_page": 27, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Paradise lost? Primary empathy in online communities of interest and ways of use\n%A Lambropoulos, Niki\n%B 1st Conference on Online Communities and Social Computing, in the 11th International Conference on Human-Computer Interaction\n%P 22-27\n%D 2005\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:GH-57oUo0QQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2L38-PnM4zErfxShNmXuJbhVj7KJ&scisf=3&ct=citation&cd=222&hl=en"}
[2018-03-02 15:27:49,273 DEBUG dbutils] Get paper id {"DOI": null, "title": "Paradise lost? Primary empathy in online communities of interest and ways of use", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 6, "year": 2005, "rg_id": null, "start_page": 22, "end_page": 27}.
[2018-03-02 15:27:49,273 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Paradise lost? Primary empathy in online communities of interest and ways of use', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2005, 'rg_id': None, 'start_page': 22, 'end_page': 27}
[2018-03-02 15:27:49,273 DEBUG dbutils] Query result: []
[2018-03-02 15:27:49,274 DEBUG dbutils] Paper id = None.
[2018-03-02 15:27:49,274 DEBUG dbutils] Add new paper (title='Paradise lost? Primary empathy in online communities of interest and ways of use')
[2018-03-02 15:27:49,274 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Paradise lost? Primary empathy in online communities of interest and ways of use', 'year': 2005, 'publisher': None, 'start_page': 22, 'end_page': 27, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Paradise lost? Primary empathy in online communities of interest and ways of use\n%A Lambropoulos, Niki\n%B 1st Conference on Online Communities and Social Computing, in the 11th International Conference on Human-Computer Interaction\n%P 22-27\n%D 2005\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:27:49,274 DEBUG dbutils] Query result: 204
[2018-03-02 15:27:49,276 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/266450915_Paradise_Lost_Primary_Empathy_in_Online_Communities_of_Interest_and_Ways_of_Use/links/54eca5f40cf27fbfd771350c.pdf.
[2018-03-02 15:27:49,277 WARNING utils] Download file (url='https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/266450915_Paradise_Lost_Primary_Empathy_in_Online_Communities_of_Interest_and_Ways_of_Use/links/54eca5f40cf27fbfd771350c.pdf') and save (filename='PDF//204.pdf')
[2018-03-02 15:27:49,277 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:27:49,277 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:27:49,277 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for www.researchgate.net
[2018-03-02 15:27:49,293 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:27:51,109 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Niki_Lambropoulos2/publication/266450915_Paradise_Lost_Primary_Empathy_in_Online_Communities_of_Interest_and_Ways_of_Use/links/54eca5f40cf27fbfd771350c.pdf HTTP/1.1" 200 386590
[2018-03-02 15:27:51,110 DEBUG utils] Content-length=386590
[2018-03-02 15:27:51,110 DEBUG utils] Create file PDF//204.pdf, start download.
[2018-03-02 15:27:52,150 DEBUG utils] End download file PDF//204.pdf.
[2018-03-02 15:27:52,152 DEBUG dbutils] Update pdf_transaction for paper id=204.
[2018-03-02 15:27:52,153 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 204'
[2018-03-02 15:27:52,153 DEBUG dbutils] Query result: null
[2018-03-02 15:27:52,156 DEBUG scholar] Handle paper #224 (total 1170)
[2018-03-02 15:27:52,157 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:27:52,166 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:27:52,166 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:27:52,166 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for scholar.google.com
[2018-03-02 15:27:52,187 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:27:52,190 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:27:53,847 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:DsbQ0WJ_Jj4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2Pi1bzYLPBjKCtHFNK5FCpdb5E9h&scisf=3&ct=citation&cd=223&hl=en HTTP/1.1" 200 200
[2018-03-02 15:27:53,848 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Engaging with computer science through magic shows
%A Curzon, Paul
%A McOwan, Peter W
%B ACM SIGCSE Bulletin
%V 40
%N 3
%P 179-183
%@ 1605580783
%D 2008
%I ACM

[2018-03-02 15:27:53,848 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:27:53,848 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:27:53,849 DEBUG __main__] Process content of EndNote file #224
{"title": "Engaging with computer science through magic shows", "url": "https://dl.acm.org/citation.cfm?id=1384320", "author": [{"shortname": "P Curzon", "gid": "bsquen0AAAAJ"}, {"shortname": "PW McOwan", "gid": "vdnBx0AAAAAJ"}], "year": 2008}
{"citedby": 39, "type": "Conference Proceedings", "title": "Engaging with computer science through magic shows", "author": ["Curzon, Paul", "McOwan, Peter W"], "secondarytitle": "ACM SIGCSE Bulletin", "volume": 5, "numberorissue": "3", "pages": "179-183", "isbn/issn": "1605580783", "year": "2008", "publisher": "ACM", "start_page": 179, "end_page": 183, "EndNote": "%0 Conference Proceedings\n%T Engaging with computer science through magic shows\n%A Curzon, Paul\n%A McOwan, Peter W\n%B ACM SIGCSE Bulletin\n%V 40\n%N 3\n%P 179-183\n%@ 1605580783\n%D 2008\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:DsbQ0WJ_Jj4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2Pi1bzYLPBjKCtHFNK5FCpdb5E9h&scisf=3&ct=citation&cd=223&hl=en"}
[2018-03-02 15:27:53,849 DEBUG dbutils] Get paper id {"DOI": null, "title": "Engaging with computer science through magic shows", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 5, "year": 2008, "rg_id": null, "start_page": 179, "end_page": 183}.
[2018-03-02 15:27:53,849 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Engaging with computer science through magic shows', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2008, 'rg_id': None, 'start_page': 179, 'end_page': 183}
[2018-03-02 15:27:53,849 DEBUG dbutils] Query result: []
[2018-03-02 15:27:53,849 DEBUG dbutils] Paper id = None.
[2018-03-02 15:27:53,849 DEBUG dbutils] Add new paper (title='Engaging with computer science through magic shows')
[2018-03-02 15:27:53,849 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Engaging with computer science through magic shows', 'year': 2008, 'publisher': 'ACM', 'start_page': 179, 'end_page': 183, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Engaging with computer science through magic shows\n%A Curzon, Paul\n%A McOwan, Peter W\n%B ACM SIGCSE Bulletin\n%V 40\n%N 3\n%P 179-183\n%@ 1605580783\n%D 2008\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:27:53,849 DEBUG dbutils] Query result: 205
[2018-03-02 15:27:53,851 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1384320.
[2018-03-02 15:27:53,851 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1384320.
[2018-03-02 15:27:55,409 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1384320 HTTP/1.1" 200 None
[2018-03-02 15:27:55,411 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:27:55,411 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:27:55,968 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1384320 HTTP/1.1" 200 None
[2018-03-02 15:27:55,975 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true.
[2018-03-02 15:27:55,976 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true') and save (filename='PDF//205.pdf')
[2018-03-02 15:27:55,993 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dabamirror.sci-hub.tw
[2018-03-02 15:27:56,166 DEBUG requests.packages.urllib3.connectionpool] "GET /6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:56,166 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:27:56,167 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:27:56,167 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for sci-hub.tw
[2018-03-02 15:27:56,186 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dabamirror.sci-hub.tw
[2018-03-02 15:27:56,356 DEBUG requests.packages.urllib3.connectionpool] "GET /6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:27:56,359 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:27:56,359 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:28:01,715 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:28:01,715 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:28:02,057 DEBUG requests.packages.urllib3.connectionpool] "GET /6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:28:02,058 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:28:02,058 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:28:02,073 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): dabamirror.sci-hub.tw
[2018-03-02 15:28:02,245 DEBUG requests.packages.urllib3.connectionpool] "GET /6acca6ced1ede81effff9fa32282ee4a/curzon2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:28:02,250 DEBUG scholar] Handle paper #225 (total 1170)
[2018-03-02 15:28:02,251 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:28:02,254 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:02,255 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:28:02,686 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:i4zA_XHHlxQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2GPFUEj-zDuF1RSg8ntfSJSN_rDl&scisf=3&ct=citation&cd=224&hl=en HTTP/1.1" 200 282
[2018-03-02 15:28:02,687 DEBUG scholar] EndNote file:
%0 Book
%T Merge: The closing gap between technology and us
%A Stephenson, Chris
%A Choucair, Elda
%A Thalheimer, Holger
%A Devoy, Malcolm
%A Bowling, Mark
%A Holden, Mark
%A Jeffrey, Patrick
%A Rowley, Phil
%A Young, Rob
%A Roberts, Toby
%D 1973
%I Musa Creative Lab

[2018-03-02 15:28:02,687 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:02,687 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:02,687 DEBUG __main__] Process content of EndNote file #225
{"title": "Merge: The closing gap between technology and us", "url": "https://books.google.com/books?hl=en&lr=&id=RWdGDwAAQBAJ&oi=fnd&pg=PA8&dq=Use+deep+learning+to+create+a+chatbot&ots=OsCRbp-Vol&sig=EsBTASBqP0YSScH5YBcRwLGNhG4", "author": [{"shortname": "C Stephenson", "gid": ""}, {"shortname": "E Choucair", "gid": ""}, {"shortname": "H Thalheimer", "gid": ""}, {"shortname": "M Devoy", "gid": ""}], "year": 1973}
{"type": "Book", "title": "Merge: The closing gap between technology and us", "author": ["Stephenson, Chris", "Choucair, Elda", "Thalheimer, Holger", "Devoy, Malcolm", "Bowling, Mark", "Holden, Mark", "Jeffrey, Patrick", "Rowley, Phil", "Young, Rob", "Roberts, Toby"], "year": "1973", "publisher": "Musa Creative Lab", "EndNote": "%0 Book\n%T Merge: The closing gap between technology and us\n%A Stephenson, Chris\n%A Choucair, Elda\n%A Thalheimer, Holger\n%A Devoy, Malcolm\n%A Bowling, Mark\n%A Holden, Mark\n%A Jeffrey, Patrick\n%A Rowley, Phil\n%A Young, Rob\n%A Roberts, Toby\n%D 1973\n%I Musa Creative Lab\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:i4zA_XHHlxQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2GPFUEj-zDuF1RSg8ntfSJSN_rDl&scisf=3&ct=citation&cd=224&hl=en"}
[2018-03-02 15:28:02,687 DEBUG dbutils] Get paper id {"DOI": null, "title": "Merge: The closing gap between technology and us", "auth_count": 10, "g_type": "Book", "pages": null, "year": 1973, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:02,687 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Merge: The closing gap between technology and us', 'auth_count': 10, 'g_type': 'Book', 'pages': None, 'year': 1973, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:02,688 DEBUG dbutils] Query result: []
[2018-03-02 15:28:02,688 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:02,688 DEBUG dbutils] Add new paper (title='Merge: The closing gap between technology and us')
[2018-03-02 15:28:02,688 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Merge: The closing gap between technology and us', 'year': 1973, 'publisher': 'Musa Creative Lab', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Merge: The closing gap between technology and us\n%A Stephenson, Chris\n%A Choucair, Elda\n%A Thalheimer, Holger\n%A Devoy, Malcolm\n%A Bowling, Mark\n%A Holden, Mark\n%A Jeffrey, Patrick\n%A Rowley, Phil\n%A Young, Rob\n%A Roberts, Toby\n%D 1973\n%I Musa Creative Lab\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:02,688 DEBUG dbutils] Query result: 206
[2018-03-02 15:28:02,690 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=RWdGDwAAQBAJ&oi=fnd&pg=PA8&dq=Use+deep+learning+to+create+a+chatbot&ots=OsCRbp-Vol&sig=EsBTASBqP0YSScH5YBcRwLGNhG4.
[2018-03-02 15:28:02,690 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=RWdGDwAAQBAJ&oi=fnd&pg=PA8&dq=Use+deep+learning+to+create+a+chatbot&ots=OsCRbp-Vol&sig=EsBTASBqP0YSScH5YBcRwLGNhG4.
[2018-03-02 15:28:02,906 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=RWdGDwAAQBAJ&oi=fnd&pg=PA8&dq=Use+deep+learning+to+create+a+chatbot&ots=OsCRbp-Vol&sig=EsBTASBqP0YSScH5YBcRwLGNhG4 HTTP/1.1" 302 None
[2018-03-02 15:28:03,116 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:28:03,138 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:28:03,138 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:28:03,138 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for sci-hub.tw
[2018-03-02 15:28:03,366 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=RWdGDwAAQBAJ&oi=fnd&pg=PA8&dq=Use+deep+learning+to+create+a+chatbot&ots=OsCRbp-Vol&sig=EsBTASBqP0YSScH5YBcRwLGNhG4 HTTP/1.1" 302 None
[2018-03-02 15:28:03,616 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:28:03,649 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:28:03,650 DEBUG scholar] Handle paper #226 (total 1170)
[2018-03-02 15:28:03,650 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:28:03,656 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:03,656 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:28:03,656 DEBUG utils] Change proxy to {'https': '190.7.112.18:3130'} for scholar.google.com
[2018-03-02 15:28:03,672 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:28:03,674 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:28:08,845 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:aOpXG-GigaUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2Km_yE5Xg6UV2ntY5Xuz4YRiOfCj&scisf=3&ct=citation&cd=225&hl=en HTTP/1.1" 200 163
[2018-03-02 15:28:08,847 DEBUG scholar] EndNote file:
%0 Journal Article
%T Generative Knowledge Transfer for Neural Language Models
%A Shin, Sungho
%A Hwang, Kyuyeon
%A Sung, Wonyong
%J ArXiv e-prints
%D 2016

[2018-03-02 15:28:08,847 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:08,847 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:08,847 DEBUG __main__] Process content of EndNote file #226
{"title": "Generative Knowledge Transfer for Neural Language Models", "url": "https://www.researchgate.net/profile/Sungho_Shin3/publication/306187628_Generative_Knowledge_Transfer_for_Neural_Language_Models/links/58f5cb6fa6fdcc11e56a0335/Generative-Knowledge-Transfer-for-Neural-Language-Models.pdf", "author": [{"shortname": "S Shin", "gid": "_miYJfIAAAAJ"}, {"shortname": "K Hwang", "gid": "ebMDwfsAAAAJ"}, {"shortname": "W Sung", "gid": "1IfNFz4AAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Generative Knowledge Transfer for Neural Language Models", "author": ["Shin, Sungho", "Hwang, Kyuyeon", "Sung, Wonyong"], "journal": "ArXiv e-prints", "year": "2016", "EndNote": "%0 Journal Article\n%T Generative Knowledge Transfer for Neural Language Models\n%A Shin, Sungho\n%A Hwang, Kyuyeon\n%A Sung, Wonyong\n%J ArXiv e-prints\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:aOpXG-GigaUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2Km_yE5Xg6UV2ntY5Xuz4YRiOfCj&scisf=3&ct=citation&cd=225&hl=en"}
[2018-03-02 15:28:08,847 DEBUG dbutils] Get paper id {"DOI": null, "title": "Generative Knowledge Transfer for Neural Language Models", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:08,848 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Generative Knowledge Transfer for Neural Language Models', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:08,848 DEBUG dbutils] Query result: []
[2018-03-02 15:28:08,848 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:08,848 DEBUG dbutils] Add new paper (title='Generative Knowledge Transfer for Neural Language Models')
[2018-03-02 15:28:08,848 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Generative Knowledge Transfer for Neural Language Models', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Generative Knowledge Transfer for Neural Language Models\n%A Shin, Sungho\n%A Hwang, Kyuyeon\n%A Sung, Wonyong\n%J ArXiv e-prints\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:08,848 DEBUG dbutils] Query result: 207
[2018-03-02 15:28:08,849 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Sungho_Shin3/publication/306187628_Generative_Knowledge_Transfer_for_Neural_Language_Models/links/58f5cb6fa6fdcc11e56a0335/Generative-Knowledge-Transfer-for-Neural-Language-Models.pdf.
[2018-03-02 15:28:08,850 WARNING utils] Download file (url='https://www.researchgate.net/profile/Sungho_Shin3/publication/306187628_Generative_Knowledge_Transfer_for_Neural_Language_Models/links/58f5cb6fa6fdcc11e56a0335/Generative-Knowledge-Transfer-for-Neural-Language-Models.pdf') and save (filename='PDF//207.pdf')
[2018-03-02 15:28:08,850 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:28:08,850 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:28:09,309 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Sungho_Shin3/publication/306187628_Generative_Knowledge_Transfer_for_Neural_Language_Models/links/58f5cb6fa6fdcc11e56a0335/Generative-Knowledge-Transfer-for-Neural-Language-Models.pdf HTTP/1.1" 200 530649
[2018-03-02 15:28:09,310 DEBUG utils] Content-length=530649
[2018-03-02 15:28:09,310 DEBUG utils] Create file PDF//207.pdf, start download.
[2018-03-02 15:28:10,727 DEBUG utils] End download file PDF//207.pdf.
[2018-03-02 15:28:10,728 DEBUG dbutils] Update pdf_transaction for paper id=207.
[2018-03-02 15:28:10,728 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 207'
[2018-03-02 15:28:10,728 DEBUG dbutils] Query result: null
[2018-03-02 15:28:10,728 DEBUG scholar] Handle paper #227 (total 1170)
[2018-03-02 15:28:10,729 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:28:10,732 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:10,732 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:28:11,096 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:2bVwbPgGfiEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2GFLdzwlFK-JKTIbG7bqBltvXeKC&scisf=3&ct=citation&cd=226&hl=en HTTP/1.1" 200 75
[2018-03-02 15:28:11,097 DEBUG scholar] EndNote file:
%0 Generic
%T A Mind of Its Own
%A Lerner, Edward M
%D 2016
%I Analog

[2018-03-02 15:28:11,097 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:11,097 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:11,097 DEBUG __main__] Process content of EndNote file #227
{"title": "A Mind of Its Own", "url": "http://www.analogsf.com/assets/6/6/FactArticle_Mind_Part1_Lerner.pdf", "author": [{"shortname": "EM Lerner", "gid": ""}], "year": 2016}
{"citedby": 2, "type": "Generic", "title": "A Mind of Its Own", "author": ["Lerner, Edward M"], "year": "2016", "publisher": "Analog", "EndNote": "%0 Generic\n%T A Mind of Its Own\n%A Lerner, Edward M\n%D 2016\n%I Analog\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:2bVwbPgGfiEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2GFLdzwlFK-JKTIbG7bqBltvXeKC&scisf=3&ct=citation&cd=226&hl=en"}
[2018-03-02 15:28:11,097 DEBUG dbutils] Get paper id {"DOI": null, "title": "A Mind of Its Own", "auth_count": 1, "g_type": "Generic", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:11,097 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A Mind of Its Own', 'auth_count': 1, 'g_type': 'Generic', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:11,098 DEBUG dbutils] Query result: []
[2018-03-02 15:28:11,098 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:11,098 DEBUG dbutils] Add new paper (title='A Mind of Its Own')
[2018-03-02 15:28:11,098 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A Mind of Its Own', 'year': 2016, 'publisher': 'Analog', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T A Mind of Its Own\n%A Lerner, Edward M\n%D 2016\n%I Analog\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:11,098 DEBUG dbutils] Query result: 208
[2018-03-02 15:28:11,099 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.analogsf.com/assets/6/6/FactArticle_Mind_Part1_Lerner.pdf.
[2018-03-02 15:28:11,101 WARNING utils] Download file (url='http://www.analogsf.com/assets/6/6/FactArticle_Mind_Part1_Lerner.pdf') and save (filename='PDF//208.pdf')
[2018-03-02 15:28:11,102 DEBUG utils] Get current proxy for www.analogsf.com.
[2018-03-02 15:28:11,102 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:28:11,117 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.analogsf.com
[2018-03-02 15:28:11,786 DEBUG requests.packages.urllib3.connectionpool] "GET /assets/6/6/FactArticle_Mind_Part1_Lerner.pdf HTTP/1.1" 200 202676
[2018-03-02 15:28:11,787 DEBUG utils] Content-length=202676
[2018-03-02 15:28:11,787 DEBUG utils] Create file PDF//208.pdf, start download.
[2018-03-02 15:28:16,966 DEBUG utils] End download file PDF//208.pdf.
[2018-03-02 15:28:16,968 DEBUG dbutils] Update pdf_transaction for paper id=208.
[2018-03-02 15:28:16,968 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 208'
[2018-03-02 15:28:16,968 DEBUG dbutils] Query result: null
[2018-03-02 15:28:16,969 DEBUG scholar] Handle paper #228 (total 1170)
[2018-03-02 15:28:16,969 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:28:16,975 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:16,976 DEBUG utils] Proxy: {'https': '190.7.112.18:3130'}
[2018-03-02 15:28:16,976 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for scholar.google.com
[2018-03-02 15:28:16,993 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:28:16,995 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:28:18,466 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:fyB8erLT8ugJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2IKBhDT4qFVmV70dy9wbYn4DeLGs&scisf=3&ct=citation&cd=227&hl=en HTTP/1.1" 200 151
[2018-03-02 15:28:18,467 DEBUG scholar] EndNote file:
%0 Journal Article
%T Theoretical Robopsychology: Samu Has Learned Turing Machines
%A Batfai, Norbert
%J arXiv preprint arXiv:1606.02767
%D 2016

[2018-03-02 15:28:18,467 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:18,467 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:18,467 DEBUG __main__] Process content of EndNote file #228
{"title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "url": "https://arxiv.org/abs/1606.02767", "author": [{"shortname": "N B\u00e1tfai", "gid": "ouiM--QAAAAJ"}], "year": 1606}
{"type": "Journal Article", "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "author": ["B\u00e1tfai, Norbert"], "journal": "arXiv preprint arXiv:1606.02767", "year": "2016", "EndNote": "%0 Journal Article\n%T Theoretical Robopsychology: Samu Has Learned Turing Machines\n%A B\u00e1tfai, Norbert\n%J arXiv preprint arXiv:1606.02767\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:fyB8erLT8ugJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2IKBhDT4qFVmV70dy9wbYn4DeLGs&scisf=3&ct=citation&cd=227&hl=en"}
[2018-03-02 15:28:18,467 DEBUG dbutils] Get paper id {"DOI": null, "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:18,468 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Theoretical Robopsychology: Samu Has Learned Turing Machines', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:18,468 DEBUG dbutils] Query result: []
[2018-03-02 15:28:18,468 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:18,468 DEBUG dbutils] Add new paper (title='Theoretical Robopsychology: Samu Has Learned Turing Machines')
[2018-03-02 15:28:18,468 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Theoretical Robopsychology: Samu Has Learned Turing Machines', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Theoretical Robopsychology: Samu Has Learned Turing Machines\n%A Batfai, Norbert\n%J arXiv preprint arXiv:1606.02767\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:18,468 DEBUG dbutils] Query result: 209
[2018-03-02 15:28:18,470 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1606.02767.
[2018-03-02 15:28:18,470 WARNING utils] Download file (url='https://arxiv.org/pdf/1606.02767') and save (filename='PDF//209.pdf')
[2018-03-02 15:28:18,471 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:28:18,471 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:28:18,471 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for otherhost
[2018-03-02 15:28:18,487 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 15:28:23,207 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.02767 HTTP/1.1" 302 280
[2018-03-02 15:28:24,296 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1606.02767.pdf HTTP/1.1" 200 333924
[2018-03-02 15:28:24,296 DEBUG utils] Content-length=333924
[2018-03-02 15:28:24,297 DEBUG utils] Create file PDF//209.pdf, start download.
[2018-03-02 15:28:27,386 DEBUG utils] End download file PDF//209.pdf.
[2018-03-02 15:28:27,387 DEBUG dbutils] Update pdf_transaction for paper id=209.
[2018-03-02 15:28:27,388 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 209'
[2018-03-02 15:28:27,388 DEBUG dbutils] Query result: null
[2018-03-02 15:28:27,388 DEBUG scholar] Handle paper #229 (total 1170)
[2018-03-02 15:28:27,388 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:28:27,395 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:27,395 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:28:27,665 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Bjdn-Nte5DIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2HmbpJMvGUOsYHOYOP56oqotkyOr&scisf=3&ct=citation&cd=228&hl=en HTTP/1.1" 200 230
[2018-03-02 15:28:27,667 DEBUG scholar] EndNote file:
%0 Book
%T Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings
%A Ikeda, Mitsuru
%A Ashlay, Kevin
%A Chan, Tak-Wai
%V 4053
%@ 3540351604
%D 2006
%I Springer

[2018-03-02 15:28:27,667 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:27,667 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:27,667 DEBUG __main__] Process content of EndNote file #229
{"title": "Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings", "url": "https://books.google.com/books?hl=en&lr=&id=ntAGCAAAQBAJ&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=n1_SfHiLoR&sig=iUJfxMV-OUa4IV66m0NqzF7kqvI", "author": [{"shortname": "M Ikeda", "gid": "PCe4CO0AAAAJ"}, {"shortname": "K Ashlay", "gid": ""}, {"shortname": "TW Chan", "gid": ""}], "year": 2006}
{"type": "Book", "title": "Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings", "author": ["Ikeda, Mitsuru", "Ashlay, Kevin", "Chan, Tak-Wai"], "volume": "4053", "isbn/issn": "3540351604", "year": "2006", "publisher": "Springer", "EndNote": "%0 Book\n%T Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings\n%A Ikeda, Mitsuru\n%A Ashlay, Kevin\n%A Chan, Tak-Wai\n%V 4053\n%@ 3540351604\n%D 2006\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Bjdn-Nte5DIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2HmbpJMvGUOsYHOYOP56oqotkyOr&scisf=3&ct=citation&cd=228&hl=en"}
[2018-03-02 15:28:27,667 DEBUG dbutils] Get paper id {"DOI": null, "title": "Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings", "auth_count": 3, "g_type": "Book", "pages": 4053, "year": 2006, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:27,667 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings', 'auth_count': 3, 'g_type': 'Book', 'pages': 4053, 'year': 2006, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:27,668 DEBUG dbutils] Query result: []
[2018-03-02 15:28:27,668 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:27,668 DEBUG dbutils] Add new paper (title='Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings')
[2018-03-02 15:28:27,668 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings', 'year': 2006, 'publisher': 'Springer', 'start_page': None, 'end_page': None, 'pages': 4053, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Intelligent Tutoring Systems: 8th International Conference, ITS 2006, Jhongli, Taiwan, June 26-30, 2006 Proceedings\n%A Ikeda, Mitsuru\n%A Ashlay, Kevin\n%A Chan, Tak-Wai\n%V 4053\n%@ 3540351604\n%D 2006\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:27,668 DEBUG dbutils] Query result: 210
[2018-03-02 15:28:27,670 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=ntAGCAAAQBAJ&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=n1_SfHiLoR&sig=iUJfxMV-OUa4IV66m0NqzF7kqvI.
[2018-03-02 15:28:27,670 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=ntAGCAAAQBAJ&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=n1_SfHiLoR&sig=iUJfxMV-OUa4IV66m0NqzF7kqvI.
[2018-03-02 15:28:27,864 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=ntAGCAAAQBAJ&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=n1_SfHiLoR&sig=iUJfxMV-OUa4IV66m0NqzF7kqvI HTTP/1.1" 302 None
[2018-03-02 15:28:28,057 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:28:28,062 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:28:28,062 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:28:28,265 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=ntAGCAAAQBAJ&oi=fnd&pg=PA1&dq=Use+deep+learning+to+create+a+chatbot&ots=n1_SfHiLoR&sig=iUJfxMV-OUa4IV66m0NqzF7kqvI HTTP/1.1" 302 None
[2018-03-02 15:28:28,479 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:28:28,511 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:28:28,512 DEBUG scholar] Handle paper #230 (total 1170)
[2018-03-02 15:28:28,512 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:28:28,515 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:28,515 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:28:28,516 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for scholar.google.com
[2018-03-02 15:28:28,530 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:28:28,532 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.googleusercontent.com
[2018-03-02 15:28:29,835 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kJOD30MdCi0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2EF8wSGsZZqkAHFXmSxWTdKpEhiP&scisf=3&ct=citation&cd=229&hl=en HTTP/1.1" 200 177
[2018-03-02 15:28:29,836 DEBUG scholar] EndNote file:
%0 Book Section
%T Spoken Language Understanding
%A McTear, Michael
%A Callejas, Zoraida
%A Griol, David
%B The Conversational Interface
%P 161-185
%D 2016
%I Springer

[2018-03-02 15:28:29,836 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:29,836 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:29,836 DEBUG __main__] Process content of EndNote file #230
{"title": "Spoken Language Understanding", "url": "https://link.springer.com/10.1007/978-3-319-32967-3_8", "author": [{"shortname": "M McTear", "gid": "APTzAoIAAAAJ"}, {"shortname": "Z Callejas", "gid": "WE75b8AAAAAJ"}, {"shortname": "D Griol", "gid": ""}], "year": 2016}
{"type": "Book Section", "title": "Spoken Language Understanding", "author": ["McTear, Michael", "Callejas, Zoraida", "Griol, David"], "secondarytitle": "The Conversational Interface", "pages": "161-185", "year": "2016", "publisher": "Springer", "start_page": 161, "end_page": 185, "volume": 25, "EndNote": "%0 Book Section\n%T Spoken Language Understanding\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%B The Conversational Interface\n%P 161-185\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kJOD30MdCi0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplF2EF8wSGsZZqkAHFXmSxWTdKpEhiP&scisf=3&ct=citation&cd=229&hl=en"}
[2018-03-02 15:28:29,837 DEBUG dbutils] Get paper id {"DOI": null, "title": "Spoken Language Understanding", "auth_count": 3, "g_type": "Book Section", "pages": 25, "year": 2016, "rg_id": null, "start_page": 161, "end_page": 185}.
[2018-03-02 15:28:29,837 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Spoken Language Understanding', 'auth_count': 3, 'g_type': 'Book Section', 'pages': 25, 'year': 2016, 'rg_id': None, 'start_page': 161, 'end_page': 185}
[2018-03-02 15:28:29,837 DEBUG dbutils] Query result: []
[2018-03-02 15:28:29,837 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:29,837 DEBUG dbutils] Add new paper (title='Spoken Language Understanding')
[2018-03-02 15:28:29,837 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Spoken Language Understanding', 'year': 2016, 'publisher': 'Springer', 'start_page': 161, 'end_page': 185, 'pages': 25, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Spoken Language Understanding\n%A McTear, Michael\n%A Callejas, Zoraida\n%A Griol, David\n%B The Conversational Interface\n%P 161-185\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:29,837 DEBUG dbutils] Query result: 211
[2018-03-02 15:28:29,840 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.sri.com/sites/default/files/publications/spoken_lanugage_understanding.pdf.
[2018-03-02 15:28:29,841 WARNING utils] Download file (url='https://www.sri.com/sites/default/files/publications/spoken_lanugage_understanding.pdf') and save (filename='PDF//211.pdf')
[2018-03-02 15:28:29,841 DEBUG utils] Get current proxy for www.sri.com.
[2018-03-02 15:28:29,841 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:28:29,858 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.sri.com
[2018-03-02 15:28:33,640 DEBUG requests.packages.urllib3.connectionpool] "GET /sites/default/files/publications/spoken_lanugage_understanding.pdf HTTP/1.1" 200 477975
[2018-03-02 15:28:33,640 DEBUG utils] Content-length=477975
[2018-03-02 15:28:33,640 DEBUG utils] Create file PDF//211.pdf, start download.
[2018-03-02 15:28:36,538 DEBUG utils] End download file PDF//211.pdf.
[2018-03-02 15:28:36,539 DEBUG dbutils] Update pdf_transaction for paper id=211.
[2018-03-02 15:28:36,539 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 211'
[2018-03-02 15:28:36,539 DEBUG dbutils] Query result: null
[2018-03-02 15:28:36,561 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:28:36,561 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:28:36,561 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:28:36,597 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.google.com
[2018-03-02 15:28:36,598 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): scholar.google.com
[2018-03-02 15:28:37,929 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=230&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:28:38,372 DEBUG scholar] Find papers on page #24 (max_google_papers = 300)
[2018-03-02 15:28:38,372 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:28:38,373 DEBUG scholar] Handle paper #231 (total 1170)
[2018-03-02 15:28:38,373 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:28:38,375 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:38,375 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:28:38,375 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for scholar.google.com
[2018-03-02 15:28:38,391 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:28:38,392 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:28:39,676 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:iCxAL98Pzq4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEvv5tX34MckyRad_oZkYv6Qh00zm&scisf=3&ct=citation&cd=230&hl=en HTTP/1.1" 200 152
[2018-03-02 15:28:39,677 DEBUG scholar] EndNote file:
%0 Book Section
%T Creating a Game World
%A van der Spuy, Rex
%B Foundation Game Design with HTML5 and JavaScript
%P 179-241
%D 2012
%I Springer

[2018-03-02 15:28:39,677 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:39,677 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:39,677 DEBUG __main__] Process content of EndNote file #231
{"title": "Creating a Game World", "url": "https://link.springer.com/chapter/10.1007/978-1-4302-4717-3_4", "author": [{"shortname": "R van der Spuy", "gid": ""}], "year": 2012}
{"type": "Book Section", "title": "Creating a Game World", "author": ["van der Spuy, Rex"], "secondarytitle": "Foundation Game Design with HTML5 and JavaScript", "pages": "179-241", "year": "2012", "publisher": "Springer", "start_page": 179, "end_page": 241, "volume": 63, "EndNote": "%0 Book Section\n%T Creating a Game World\n%A van der Spuy, Rex\n%B Foundation Game Design with HTML5 and JavaScript\n%P 179-241\n%D 2012\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:iCxAL98Pzq4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEvv5tX34MckyRad_oZkYv6Qh00zm&scisf=3&ct=citation&cd=230&hl=en"}
[2018-03-02 15:28:39,677 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creating a Game World", "auth_count": 1, "g_type": "Book Section", "pages": 63, "year": 2012, "rg_id": null, "start_page": 179, "end_page": 241}.
[2018-03-02 15:28:39,677 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creating a Game World', 'auth_count': 1, 'g_type': 'Book Section', 'pages': 63, 'year': 2012, 'rg_id': None, 'start_page': 179, 'end_page': 241}
[2018-03-02 15:28:39,677 DEBUG dbutils] Query result: []
[2018-03-02 15:28:39,677 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:39,677 DEBUG dbutils] Add new paper (title='Creating a Game World')
[2018-03-02 15:28:39,678 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creating a Game World', 'year': 2012, 'publisher': 'Springer', 'start_page': 179, 'end_page': 241, 'pages': 63, 'g_type': 'Book Section', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book Section\n%T Creating a Game World\n%A van der Spuy, Rex\n%B Foundation Game Design with HTML5 and JavaScript\n%P 179-241\n%D 2012\n%I Springer\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:39,678 DEBUG dbutils] Query result: 212
[2018-03-02 15:28:39,679 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-1-4302-4717-3_4.
[2018-03-02 15:28:39,680 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-1-4302-4717-3_4.
[2018-03-02 15:28:40,027 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-1-4302-4717-3_4 HTTP/1.1" 200 None
[2018-03-02 15:28:40,028 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:28:40,028 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:28:40,029 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for sci-hub.tw
[2018-03-02 15:28:40,257 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-1-4302-4717-3_4 HTTP/1.1" 200 None
[2018-03-02 15:28:40,266 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:28:40,267 DEBUG scholar] Handle paper #232 (total 1170)
[2018-03-02 15:28:40,268 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:28:40,271 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:40,272 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:28:40,516 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:y97mJjewQ1AJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEkzoMUoquJI9n9a67jyQ3p_U3zBt&scisf=3&ct=citation&cd=231&hl=en HTTP/1.1" 200 140
[2018-03-02 15:28:40,517 DEBUG scholar] EndNote file:
%0 Journal Article
%T A General Introduction to Computer Assisted Language Learning Philip Hubbard, Stanford University
%A Hubbard, In P

[2018-03-02 15:28:40,517 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:40,517 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:40,517 DEBUG __main__] Skip paper #232, empty year or authors fields.
[2018-03-02 15:28:40,517 DEBUG scholar] Handle paper #233 (total 1170)
[2018-03-02 15:28:40,517 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:28:40,520 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:28:40,521 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:28:40,521 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for scholar.google.com
[2018-03-02 15:28:40,536 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:28:40,538 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:28:43,305 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4oha5awJj6wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEjWGeFTCCpCcFkSPMkd37TbEuH9A&scisf=3&ct=citation&cd=232&hl=en HTTP/1.1" 200 190
[2018-03-02 15:28:43,306 DEBUG scholar] EndNote file:
%0 Journal Article
%T Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures
%A Yampolskiy, Roman V
%A Spellchecker, MS
%J arXiv preprint arXiv:1610.07997
%D 2016

[2018-03-02 15:28:43,306 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:28:43,306 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:28:43,306 DEBUG __main__] Process content of EndNote file #233
{"title": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures", "url": "https://arxiv.org/abs/1610.07997", "author": [{"shortname": "RV Yampolskiy", "gid": "0_Rq68cAAAAJ"}, {"shortname": "MS Spellchecker", "gid": ""}], "year": 1610}
{"citedby": 7, "type": "Journal Article", "title": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures", "author": ["Yampolskiy, Roman V", "Spellchecker, MS"], "journal": "arXiv preprint arXiv:1610.07997", "year": "2016", "EndNote": "%0 Journal Article\n%T Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures\n%A Yampolskiy, Roman V\n%A Spellchecker, MS\n%J arXiv preprint arXiv:1610.07997\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4oha5awJj6wJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEjWGeFTCCpCcFkSPMkd37TbEuH9A&scisf=3&ct=citation&cd=232&hl=en"}
[2018-03-02 15:28:43,306 DEBUG dbutils] Get paper id {"DOI": null, "title": "Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:28:43,307 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:28:43,307 DEBUG dbutils] Query result: []
[2018-03-02 15:28:43,307 DEBUG dbutils] Paper id = None.
[2018-03-02 15:28:43,307 DEBUG dbutils] Add new paper (title='Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures')
[2018-03-02 15:28:43,307 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Artificial Intelligence Safety and Cybersecurity: a Timeline of AI Failures\n%A Yampolskiy, Roman V\n%A Spellchecker, MS\n%J arXiv preprint arXiv:1610.07997\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:28:43,307 DEBUG dbutils] Query result: 213
[2018-03-02 15:28:43,309 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://arxiv.org/pdf/1610.07997.
[2018-03-02 15:28:43,312 WARNING utils] Download file (url='https://arxiv.org/pdf/1610.07997') and save (filename='PDF//213.pdf')
[2018-03-02 15:28:43,312 DEBUG utils] Get current proxy for arxiv.org.
[2018-03-02 15:28:43,313 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:28:43,313 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for otherhost
[2018-03-02 15:28:43,329 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): arxiv.org
[2018-03-02 15:28:46,975 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1610.07997 HTTP/1.1" 302 280
[2018-03-02 15:28:47,994 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/1610.07997.pdf HTTP/1.1" 200 280423
[2018-03-02 15:28:47,994 DEBUG utils] Content-length=280423
[2018-03-02 15:28:47,995 DEBUG utils] Create file PDF//213.pdf, start download.
[2018-03-02 15:29:01,450 DEBUG utils] End download file PDF//213.pdf.
[2018-03-02 15:29:01,452 DEBUG dbutils] Update pdf_transaction for paper id=213.
[2018-03-02 15:29:01,452 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 213'
[2018-03-02 15:29:01,452 DEBUG dbutils] Query result: null
[2018-03-02 15:29:01,452 DEBUG scholar] Handle paper #234 (total 1170)
[2018-03-02 15:29:01,452 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:29:01,456 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:29:01,456 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:29:01,935 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:NuBj79jVBx4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEoPLkYYbaJCGkiPqLAvXGcAE2Ys9&scisf=3&ct=citation&cd=233&hl=en HTTP/1.1" 200 66
[2018-03-02 15:29:01,936 DEBUG scholar] EndNote file:
%0 Generic
%T Trend Compendium 2030
%A Berger, Roland
%D 2013

[2018-03-02 15:29:01,936 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:29:01,936 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:29:01,936 DEBUG __main__] Process content of EndNote file #234
{"title": "Trend Compendium 2030", "url": "https://www.rolandberger.com/publications/publication_pdf/roland_berger_trend_compendium_2030___trend_5_dynamic_technology_and_innovation.pdf", "author": [{"shortname": "R Berger", "gid": ""}], "year": 2013}
{"citedby": 9, "type": "Generic", "title": "Trend Compendium 2030", "author": ["Berger, Roland"], "year": "2013", "EndNote": "%0 Generic\n%T Trend Compendium 2030\n%A Berger, Roland\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:NuBj79jVBx4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEoPLkYYbaJCGkiPqLAvXGcAE2Ys9&scisf=3&ct=citation&cd=233&hl=en"}
[2018-03-02 15:29:01,936 DEBUG dbutils] Get paper id {"DOI": null, "title": "Trend Compendium 2030", "auth_count": 1, "g_type": "Generic", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:29:01,936 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Trend Compendium 2030', 'auth_count': 1, 'g_type': 'Generic', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:29:01,936 DEBUG dbutils] Query result: []
[2018-03-02 15:29:01,936 DEBUG dbutils] Paper id = None.
[2018-03-02 15:29:01,936 DEBUG dbutils] Add new paper (title='Trend Compendium 2030')
[2018-03-02 15:29:01,937 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Trend Compendium 2030', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Trend Compendium 2030\n%A Berger, Roland\n%D 2013\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:29:01,937 DEBUG dbutils] Query result: 214
[2018-03-02 15:29:01,938 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.rolandberger.com/publications/publication_pdf/roland_berger_trend_compendium_2030___trend_5_dynamic_technology_and_innovation.pdf.
[2018-03-02 15:29:01,939 WARNING utils] Download file (url='https://www.rolandberger.com/publications/publication_pdf/roland_berger_trend_compendium_2030___trend_5_dynamic_technology_and_innovation.pdf') and save (filename='PDF//214.pdf')
[2018-03-02 15:29:01,939 DEBUG utils] Get current proxy for www.rolandberger.com.
[2018-03-02 15:29:01,939 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:29:01,958 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.rolandberger.com
[2018-03-02 15:29:06,086 DEBUG requests.packages.urllib3.connectionpool] "GET /publications/publication_pdf/roland_berger_trend_compendium_2030___trend_5_dynamic_technology_and_innovation.pdf HTTP/1.1" 200 984639
[2018-03-02 15:29:06,087 DEBUG utils] Content-length=984639
[2018-03-02 15:29:06,088 DEBUG utils] Create file PDF//214.pdf, start download.
[2018-03-02 15:29:48,544 DEBUG utils] End download file PDF//214.pdf.
[2018-03-02 15:29:48,546 DEBUG dbutils] Update pdf_transaction for paper id=214.
[2018-03-02 15:29:48,546 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 214'
[2018-03-02 15:29:48,546 DEBUG dbutils] Query result: null
[2018-03-02 15:29:48,547 DEBUG scholar] Handle paper #235 (total 1170)
[2018-03-02 15:29:48,547 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:29:48,551 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:29:48,551 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:29:48,551 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for scholar.google.com
[2018-03-02 15:29:48,572 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:29:48,573 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:29:50,473 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:RGUaHMPcXIMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEj27GAyAQSKLTpJu-CbiCL2O8rKW&scisf=3&ct=citation&cd=234&hl=en HTTP/1.1" 200 166
[2018-03-02 15:29:50,474 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T TNT: Technological Thinking, with No Technology
%A Frank, Ian
%A Field, MH
%B Australian Computers in Education Conference
%D 2008

[2018-03-02 15:29:50,474 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:29:50,474 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:29:50,474 DEBUG __main__] Process content of EndNote file #235
{"title": "TNT: Technological Thinking, with No Technology", "url": "http://www.koto-tsukuri.org/tnt-paper5.pdf", "author": [{"shortname": "I Frank", "gid": ""}, {"shortname": "MH Field", "gid": ""}], "year": 2008}
{"citedby": 2, "type": "Conference Proceedings", "title": "TNT: Technological Thinking, with No Technology", "author": ["Frank, Ian", "Field, MH"], "secondarytitle": "Australian Computers in Education Conference", "year": "2008", "EndNote": "%0 Conference Proceedings\n%T TNT: Technological Thinking, with No Technology\n%A Frank, Ian\n%A Field, MH\n%B Australian Computers in Education Conference\n%D 2008\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:RGUaHMPcXIMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEj27GAyAQSKLTpJu-CbiCL2O8rKW&scisf=3&ct=citation&cd=234&hl=en"}
[2018-03-02 15:29:50,474 DEBUG dbutils] Get paper id {"DOI": null, "title": "TNT: Technological Thinking, with No Technology", "auth_count": 2, "g_type": "Conference Proceedings", "pages": null, "year": 2008, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:29:50,474 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'TNT: Technological Thinking, with No Technology', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2008, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:29:50,475 DEBUG dbutils] Query result: []
[2018-03-02 15:29:50,475 DEBUG dbutils] Paper id = None.
[2018-03-02 15:29:50,475 DEBUG dbutils] Add new paper (title='TNT: Technological Thinking, with No Technology')
[2018-03-02 15:29:50,475 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'TNT: Technological Thinking, with No Technology', 'year': 2008, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T TNT: Technological Thinking, with No Technology\n%A Frank, Ian\n%A Field, MH\n%B Australian Computers in Education Conference\n%D 2008\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:29:50,475 DEBUG dbutils] Query result: 215
[2018-03-02 15:29:50,477 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.koto-tsukuri.org/tnt-paper5.pdf.
[2018-03-02 15:29:50,477 WARNING utils] Download file (url='http://www.koto-tsukuri.org/tnt-paper5.pdf') and save (filename='PDF//215.pdf')
[2018-03-02 15:29:50,478 DEBUG utils] Get current proxy for www.koto-tsukuri.org.
[2018-03-02 15:29:50,478 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:29:50,478 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for otherhost
[2018-03-02 15:29:50,493 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.koto-tsukuri.org
[2018-03-02 15:29:51,396 DEBUG requests.packages.urllib3.connectionpool] "GET /tnt-paper5.pdf HTTP/1.1" 200 255452
[2018-03-02 15:29:51,396 DEBUG utils] Content-length=255452
[2018-03-02 15:29:51,397 DEBUG utils] Create file PDF//215.pdf, start download.
[2018-03-02 15:29:52,460 DEBUG utils] End download file PDF//215.pdf.
[2018-03-02 15:29:52,462 DEBUG dbutils] Update pdf_transaction for paper id=215.
[2018-03-02 15:29:52,462 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 215'
[2018-03-02 15:29:52,462 DEBUG dbutils] Query result: null
[2018-03-02 15:29:52,463 DEBUG scholar] Handle paper #236 (total 1170)
[2018-03-02 15:29:52,463 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:29:52,468 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:29:52,468 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:29:52,836 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:aVqy_sW42-UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEndd1u2NNMIIrTUU64jAczGo2DqM&scisf=3&ct=citation&cd=235&hl=en HTTP/1.1" 200 298
[2018-03-02 15:29:52,837 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Overview of NTCIR-13
%A Kato, Makoto P
%A Liu, Yiqun
%A Gurrin, Cathal
%A Joho, Hideo
%A Hopfgartner, Frank
%A Zhou, Liting
%A Dang-Nguyen, Duc-Tien
%A Gupta, Rashmi
%A Albatal, Rami
%A Yamamoto, Shuhei
%B Proceedings of the 12th NTCIR Conference
%D 2016

[2018-03-02 15:29:52,838 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:29:52,838 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:29:52,838 DEBUG __main__] Process content of EndNote file #236
{"title": "Overview of NTCIR-13", "url": "http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html", "author": [{"shortname": "MP Kato", "gid": ""}, {"shortname": "Y Liu", "gid": ""}, {"shortname": "C Gurrin", "gid": "NSm2hJMAAAAJ"}, {"shortname": "H Joho", "gid": "8W8gwisAAAAJ"}], "year": 2016}
{"citedby": 6, "type": "Conference Proceedings", "title": "Overview of NTCIR-13", "author": ["Kato, Makoto P", "Liu, Yiqun", "Gurrin, Cathal", "Joho, Hideo", "Hopfgartner, Frank", "Zhou, Liting", "Dang-Nguyen, Duc-Tien", "Gupta, Rashmi", "Albatal, Rami", "Yamamoto, Shuhei"], "secondarytitle": "Proceedings of the 12th NTCIR Conference", "year": "2016", "EndNote": "%0 Conference Proceedings\n%T Overview of NTCIR-13\n%A Kato, Makoto P\n%A Liu, Yiqun\n%A Gurrin, Cathal\n%A Joho, Hideo\n%A Hopfgartner, Frank\n%A Zhou, Liting\n%A Dang-Nguyen, Duc-Tien\n%A Gupta, Rashmi\n%A Albatal, Rami\n%A Yamamoto, Shuhei\n%B Proceedings of the 12th NTCIR Conference\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:aVqy_sW42-UJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEndd1u2NNMIIrTUU64jAczGo2DqM&scisf=3&ct=citation&cd=235&hl=en"}
[2018-03-02 15:29:52,838 DEBUG dbutils] Get paper id {"DOI": null, "title": "Overview of NTCIR-13", "auth_count": 10, "g_type": "Conference Proceedings", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:29:52,838 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Overview of NTCIR-13', 'auth_count': 10, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:29:52,838 DEBUG dbutils] Query result: []
[2018-03-02 15:29:52,838 DEBUG dbutils] Paper id = None.
[2018-03-02 15:29:52,838 DEBUG dbutils] Add new paper (title='Overview of NTCIR-13')
[2018-03-02 15:29:52,838 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Overview of NTCIR-13', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Overview of NTCIR-13\n%A Kato, Makoto P\n%A Liu, Yiqun\n%A Gurrin, Cathal\n%A Joho, Hideo\n%A Hopfgartner, Frank\n%A Zhou, Liting\n%A Dang-Nguyen, Duc-Tien\n%A Gupta, Rashmi\n%A Albatal, Rami\n%A Yamamoto, Shuhei\n%B Proceedings of the 12th NTCIR Conference\n%D 2016\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 15:29:52,839 DEBUG dbutils] Query result: 216
[2018-03-02 15:29:52,840 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html.
[2018-03-02 15:29:52,840 DEBUG scihub] Get page from sci-hub for paper with DOI=http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html.
[2018-03-02 15:29:52,855 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:29:53,167 DEBUG requests.packages.urllib3.connectionpool] "GET //http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html HTTP/1.1" 302 None
[2018-03-02 15:29:53,191 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): research.nii.ac.jp
[2018-03-02 15:29:54,784 DEBUG requests.packages.urllib3.connectionpool] "GET /ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html HTTP/1.1" 200 86214
[2018-03-02 15:29:55,847 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:29:55,847 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:29:56,042 DEBUG requests.packages.urllib3.connectionpool] "GET //http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html HTTP/1.1" 302 None
[2018-03-02 15:29:56,424 DEBUG requests.packages.urllib3.connectionpool] "GET /ntcir/workshop/OnlineProceedings13/NTCIR/abstract_ntcir.html HTTP/1.1" 200 86214
[2018-03-02 15:29:56,917 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:29:56,918 DEBUG scholar] Handle paper #237 (total 1170)
[2018-03-02 15:29:56,918 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:29:56,922 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:29:56,922 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:29:56,922 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for scholar.google.com
[2018-03-02 15:29:56,939 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:29:56,940 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:29:58,847 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ws1E35t5LR8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEhZSxE-67n8mb9w6Lyae3TsVlv1D&scisf=3&ct=citation&cd=236&hl=en HTTP/1.1" 200 282
[2018-03-02 15:29:58,847 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Natural language processing implementation on Romanian ChatBot
%A Fabian, Ralf
%A Alexandru-Nicolae, Marcu
%B WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering
%N 5
%@ 9604741136
%D 2009
%I WSEAS

[2018-03-02 15:29:58,848 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:29:58,848 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:29:58,848 DEBUG __main__] Process content of EndNote file #237
{"title": "Natural language processing implementation on Romanian ChatBot", "url": "https://www.researchgate.net/profile/Ralf_Fabian/publication/228651889_Natural_language_processing_implementation_on_Romanian_ChatBot/links/00b4952b59ab4875f4000000/Natural-language-processing-implementation-on-Romanian-ChatBot.pdf", "author": [{"shortname": "R Fabian", "gid": "XOroKSgAAAAJ"}, {"shortname": "M Alexandru", "gid": ""}], "year": 2009}
{"citedby": 3, "type": "Conference Proceedings", "title": "Natural language processing implementation on Romanian ChatBot", "author": ["Fabian, Ralf", "Alexandru-Nicolae, Marcu"], "secondarytitle": "WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering", "numberorissue": "5", "isbn/issn": "9604741136", "year": "2009", "publisher": "WSEAS", "EndNote": "%0 Conference Proceedings\n%T Natural language processing implementation on Romanian ChatBot\n%A Fabian, Ralf\n%A Alexandru-Nicolae, Marcu\n%B WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering\n%N 5\n%@ 9604741136\n%D 2009\n%I WSEAS\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ws1E35t5LR8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEhZSxE-67n8mb9w6Lyae3TsVlv1D&scisf=3&ct=citation&cd=236&hl=en"}
[2018-03-02 15:29:58,848 DEBUG dbutils] Get paper id {"DOI": null, "title": "Natural language processing implementation on Romanian ChatBot", "auth_count": 2, "g_type": "Conference Proceedings", "pages": null, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:29:58,848 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Natural language processing implementation on Romanian ChatBot', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:29:58,848 DEBUG dbutils] Query result: []
[2018-03-02 15:29:58,848 DEBUG dbutils] Paper id = None.
[2018-03-02 15:29:58,848 DEBUG dbutils] Add new paper (title='Natural language processing implementation on Romanian ChatBot')
[2018-03-02 15:29:58,848 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Natural language processing implementation on Romanian ChatBot', 'year': 2009, 'publisher': 'WSEAS', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Natural language processing implementation on Romanian ChatBot\n%A Fabian, Ralf\n%A Alexandru-Nicolae, Marcu\n%B WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering\n%N 5\n%@ 9604741136\n%D 2009\n%I WSEAS\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:29:58,849 DEBUG dbutils] Query result: 217
[2018-03-02 15:29:58,850 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Ralf_Fabian/publication/228651889_Natural_language_processing_implementation_on_Romanian_ChatBot/links/00b4952b59ab4875f4000000/Natural-language-processing-implementation-on-Romanian-ChatBot.pdf.
[2018-03-02 15:29:58,851 WARNING utils] Download file (url='https://www.researchgate.net/profile/Ralf_Fabian/publication/228651889_Natural_language_processing_implementation_on_Romanian_ChatBot/links/00b4952b59ab4875f4000000/Natural-language-processing-implementation-on-Romanian-ChatBot.pdf') and save (filename='PDF//217.pdf')
[2018-03-02 15:29:58,851 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:29:58,851 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:29:58,851 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for www.researchgate.net
[2018-03-02 15:29:58,866 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:30:01,045 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Ralf_Fabian/publication/228651889_Natural_language_processing_implementation_on_Romanian_ChatBot/links/00b4952b59ab4875f4000000/Natural-language-processing-implementation-on-Romanian-ChatBot.pdf HTTP/1.1" 200 570756
[2018-03-02 15:30:01,046 DEBUG utils] Content-length=570756
[2018-03-02 15:30:01,047 DEBUG utils] Create file PDF//217.pdf, start download.
[2018-03-02 15:30:03,190 DEBUG utils] End download file PDF//217.pdf.
[2018-03-02 15:30:03,192 DEBUG dbutils] Update pdf_transaction for paper id=217.
[2018-03-02 15:30:03,192 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 217'
[2018-03-02 15:30:03,192 DEBUG dbutils] Query result: null
[2018-03-02 15:30:03,193 DEBUG scholar] Handle paper #238 (total 1170)
[2018-03-02 15:30:03,193 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:30:03,196 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:03,197 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:30:03,544 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:FHy_Mn8w624J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEiHkQzxv4JPuRct4ox8PIfSvdH4U&scisf=3&ct=citation&cd=237&hl=en HTTP/1.1" 200 140
[2018-03-02 15:30:03,545 DEBUG scholar] EndNote file:
%0 Thesis
%T Data-driven Repair Models for Text Chat with Language Learners
%A Sviatlana, HOHN
%D 1978
%I Universitat Duisburg-Essen

[2018-03-02 15:30:03,545 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:03,545 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:03,545 DEBUG __main__] Process content of EndNote file #238
{"title": "Data-driven Repair Models for Text Chat with Language Learners", "url": "http://orbilu.uni.lu/bitstream/10993/28024/1/thesis-final-uni.pdf", "author": [{"shortname": "H Sviatlana", "gid": ""}], "year": 1978}
{"type": "Thesis", "title": "Data-driven Repair Models for Text Chat with Language Learners", "author": ["Sviatlana, H\u00d6HN"], "year": "1978", "publisher": "Universit\u00e4t Duisburg-Essen", "EndNote": "%0 Thesis\n%T Data-driven Repair Models for Text Chat with Language Learners\n%A Sviatlana, H\u00d6HN\n%D 1978\n%I Universit\u00e4t Duisburg-Essen\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:FHy_Mn8w624J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEiHkQzxv4JPuRct4ox8PIfSvdH4U&scisf=3&ct=citation&cd=237&hl=en"}
[2018-03-02 15:30:03,545 DEBUG dbutils] Get paper id {"DOI": null, "title": "Data-driven Repair Models for Text Chat with Language Learners", "auth_count": 1, "g_type": "Thesis", "pages": null, "year": 1978, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:30:03,545 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Data-driven Repair Models for Text Chat with Language Learners', 'auth_count': 1, 'g_type': 'Thesis', 'pages': None, 'year': 1978, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:30:03,546 DEBUG dbutils] Query result: []
[2018-03-02 15:30:03,546 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:03,546 DEBUG dbutils] Add new paper (title='Data-driven Repair Models for Text Chat with Language Learners')
[2018-03-02 15:30:03,546 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Data-driven Repair Models for Text Chat with Language Learners', 'year': 1978, 'publisher': 'Universitat Duisburg-Essen', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Thesis', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Thesis\n%T Data-driven Repair Models for Text Chat with Language Learners\n%A Sviatlana, HOHN\n%D 1978\n%I Universitat Duisburg-Essen\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:03,546 DEBUG dbutils] Query result: 218
[2018-03-02 15:30:03,548 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://orbilu.uni.lu/bitstream/10993/28024/1/thesis-final-uni.pdf.
[2018-03-02 15:30:03,548 WARNING utils] Download file (url='http://orbilu.uni.lu/bitstream/10993/28024/1/thesis-final-uni.pdf') and save (filename='PDF//218.pdf')
[2018-03-02 15:30:03,548 DEBUG utils] Get current proxy for orbilu.uni.lu.
[2018-03-02 15:30:03,548 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:30:03,563 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): orbilu.uni.lu
[2018-03-02 15:30:03,904 DEBUG requests.packages.urllib3.connectionpool] "GET /bitstream/10993/28024/1/thesis-final-uni.pdf HTTP/1.1" 200 1878159
[2018-03-02 15:30:03,905 DEBUG utils] Content-length=1878159
[2018-03-02 15:30:03,905 DEBUG utils] Create file PDF//218.pdf, start download.
[2018-03-02 15:30:06,560 DEBUG utils] End download file PDF//218.pdf.
[2018-03-02 15:30:06,561 DEBUG dbutils] Update pdf_transaction for paper id=218.
[2018-03-02 15:30:06,561 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 218'
[2018-03-02 15:30:06,561 DEBUG dbutils] Query result: null
[2018-03-02 15:30:06,562 DEBUG scholar] Handle paper #239 (total 1170)
[2018-03-02 15:30:06,562 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:30:06,565 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:06,566 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:30:06,566 DEBUG utils] Change proxy to {'https': '91.82.85.154:3128'} for scholar.google.com
[2018-03-02 15:30:06,585 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:06,587 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:08,113 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Bj-yMU-o0tMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEg42jpXpkD8tvPYvCPOKoqdfY3_Y&scisf=3&ct=citation&cd=238&hl=en HTTP/1.1" 200 87
[2018-03-02 15:30:08,114 DEBUG scholar] EndNote file:
%0 Journal Article
%T Imitation Technology
%A Gupta, Ankit
%A Grand, Gabe
%D 2015

[2018-03-02 15:30:08,114 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:08,114 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:08,114 DEBUG __main__] Process content of EndNote file #239
{"title": "Imitation Technology", "url": "http://gabegrand.com/files/Grand%20&%20Gupta%20-%20Imitation%20Technology%20(2015).pdf", "author": [{"shortname": "A Gupta", "gid": ""}, {"shortname": "G Grand", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "Imitation Technology", "author": ["Gupta, Ankit", "Grand, Gabe"], "year": "2015", "EndNote": "%0 Journal Article\n%T Imitation Technology\n%A Gupta, Ankit\n%A Grand, Gabe\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Bj-yMU-o0tMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEg42jpXpkD8tvPYvCPOKoqdfY3_Y&scisf=3&ct=citation&cd=238&hl=en"}
[2018-03-02 15:30:08,114 DEBUG dbutils] Get paper id {"DOI": null, "title": "Imitation Technology", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:30:08,114 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Imitation Technology', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:30:08,114 DEBUG dbutils] Query result: []
[2018-03-02 15:30:08,115 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:08,115 DEBUG dbutils] Add new paper (title='Imitation Technology')
[2018-03-02 15:30:08,115 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Imitation Technology', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Imitation Technology\n%A Gupta, Ankit\n%A Grand, Gabe\n%D 2015\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:08,115 DEBUG dbutils] Query result: 219
[2018-03-02 15:30:08,121 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://gabegrand.com/files/Grand%20&%20Gupta%20-%20Imitation%20Technology%20(2015).pdf.
[2018-03-02 15:30:08,122 WARNING utils] Download file (url='http://gabegrand.com/files/Grand%20&%20Gupta%20-%20Imitation%20Technology%20(2015).pdf') and save (filename='PDF//219.pdf')
[2018-03-02 15:30:08,122 DEBUG utils] Get current proxy for gabegrand.com.
[2018-03-02 15:30:08,122 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:30:08,122 DEBUG utils] Change proxy to {'https': '47.88.89.70:3128'} for otherhost
[2018-03-02 15:30:08,137 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): gabegrand.com
[2018-03-02 15:30:08,614 DEBUG requests.packages.urllib3.connectionpool] "GET /files/Grand%20&%20Gupta%20-%20Imitation%20Technology%20(2015).pdf HTTP/1.1" 200 5591258
[2018-03-02 15:30:08,614 DEBUG utils] Content-length=5591258
[2018-03-02 15:30:08,614 DEBUG utils] Create file PDF//219.pdf, start download.
[2018-03-02 15:30:15,514 DEBUG utils] End download file PDF//219.pdf.
[2018-03-02 15:30:15,516 DEBUG dbutils] Update pdf_transaction for paper id=219.
[2018-03-02 15:30:15,516 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 219'
[2018-03-02 15:30:15,516 DEBUG dbutils] Query result: null
[2018-03-02 15:30:15,516 DEBUG scholar] Handle paper #240 (total 1170)
[2018-03-02 15:30:15,517 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:30:15,522 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:15,522 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:30:15,813 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:j_c3MZJg4sUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGEnZs57dm2VtKkgX-LAwu-v8Zhhx6&scisf=3&ct=citation&cd=239&hl=en HTTP/1.1" 200 72
[2018-03-02 15:30:15,814 DEBUG scholar] EndNote file:
%0 Journal Article
%T DE22 1GB
%A Parson, Vanessa
%A Bignell, Simon

[2018-03-02 15:30:15,814 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:15,814 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:15,814 DEBUG __main__] Skip paper #240, empty year or authors fields.
[2018-03-02 15:30:15,833 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:30:15,833 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:30:15,833 DEBUG utils] Proxy: {'https': '91.82.85.154:3128'}
[2018-03-02 15:30:15,833 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for scholar.google.com
[2018-03-02 15:30:15,847 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:30:16,765 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=240&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:30:16,965 DEBUG scholar] Find papers on page #25 (max_google_papers = 300)
[2018-03-02 15:30:16,965 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:30:16,965 DEBUG scholar] Handle paper #241 (total 1170)
[2018-03-02 15:30:16,965 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:30:16,969 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:16,969 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:30:16,985 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:16,987 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:18,163 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:j_c3MZJg4sUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdfWT5RNSqJ_wN0tglyeHeeFny_5c&scisf=3&ct=citation&cd=240&hl=en HTTP/1.1" 200 72
[2018-03-02 15:30:18,163 DEBUG scholar] EndNote file:
%0 Journal Article
%T DE22 1GB
%A Parson, Vanessa
%A Bignell, Simon

[2018-03-02 15:30:18,164 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:18,164 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:18,164 DEBUG __main__] Skip paper #241, empty year or authors fields.
[2018-03-02 15:30:18,164 DEBUG scholar] Handle paper #242 (total 1170)
[2018-03-02 15:30:18,164 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:30:18,168 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:18,168 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:30:18,168 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for scholar.google.com
[2018-03-02 15:30:18,184 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:18,185 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:24,003 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:M6DKfetdCyEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdd5bEOuS3HYhYfX4TGjNdYWnqaP0&scisf=3&ct=citation&cd=241&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:M6DKfetdCyEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdd5bEOuS3HYhYfX4TGjNdYWnqaP0&scisf=3&ct=citation&cd=241&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:30:24,003 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for scholar.google.com
[2018-03-02 15:30:24,004 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:24,004 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:30:24,017 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:24,018 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:25,324 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:M6DKfetdCyEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdd5bEOuS3HYhYfX4TGjNdYWnqaP0&scisf=3&ct=citation&cd=241&hl=en HTTP/1.1" 200 294
[2018-03-02 15:30:25,325 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T A training tool for Global Software Development
%A Monasor, Miguel J
%A Vizcaino, Aurora
%A Piattini, Mario
%B Information Technology Based Higher Education and Training (ITHET), 2010 9th International Conference on
%P 9-16
%@ 1424457920
%D 2010
%I IEEE

[2018-03-02 15:30:25,325 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:25,325 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:25,325 DEBUG __main__] Process content of EndNote file #242
{"title": "A training tool for Global Software Development", "url": "http://ieeexplore.ieee.org/abstract/document/5480073/", "author": [{"shortname": "MJ Monasor", "gid": "14krTnoAAAAJ"}, {"shortname": "A Vizca\u00edno", "gid": "6QWUv4kAAAAJ"}], "year": 2010}
{"citedby": 5, "type": "Conference Proceedings", "title": "A training tool for Global Software Development", "author": ["Monasor, Miguel J", "Vizca\u00edno, Aurora", "Piattini, Mario"], "secondarytitle": "Information Technology Based Higher Education and Training (ITHET), 2010 9th International Conference on", "pages": "9-16", "isbn/issn": "1424457920", "year": "2010", "publisher": "IEEE", "start_page": 9, "end_page": 16, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T A training tool for Global Software Development\n%A Monasor, Miguel J\n%A Vizca\u00edno, Aurora\n%A Piattini, Mario\n%B Information Technology Based Higher Education and Training (ITHET), 2010 9th International Conference on\n%P 9-16\n%@ 1424457920\n%D 2010\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:M6DKfetdCyEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdd5bEOuS3HYhYfX4TGjNdYWnqaP0&scisf=3&ct=citation&cd=241&hl=en"}
[2018-03-02 15:30:25,325 DEBUG dbutils] Get paper id {"DOI": null, "title": "A training tool for Global Software Development", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 8, "year": 2010, "rg_id": null, "start_page": 9, "end_page": 16}.
[2018-03-02 15:30:25,325 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A training tool for Global Software Development', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2010, 'rg_id': None, 'start_page': 9, 'end_page': 16}
[2018-03-02 15:30:25,325 DEBUG dbutils] Query result: []
[2018-03-02 15:30:25,325 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:25,325 DEBUG dbutils] Add new paper (title='A training tool for Global Software Development')
[2018-03-02 15:30:25,326 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A training tool for Global Software Development', 'year': 2010, 'publisher': 'IEEE', 'start_page': 9, 'end_page': 16, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T A training tool for Global Software Development\n%A Monasor, Miguel J\n%A Vizcaino, Aurora\n%A Piattini, Mario\n%B Information Technology Based Higher Education and Training (ITHET), 2010 9th International Conference on\n%P 9-16\n%@ 1424457920\n%D 2010\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:25,326 DEBUG dbutils] Query result: 220
[2018-03-02 15:30:25,327 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Miguel_Monasor/publication/224143873_A_training_tool_for_Global_Software_Development/links/57ad9ec508ae3765c3bcd32a.pdf.
[2018-03-02 15:30:25,328 WARNING utils] Download file (url='https://www.researchgate.net/profile/Miguel_Monasor/publication/224143873_A_training_tool_for_Global_Software_Development/links/57ad9ec508ae3765c3bcd32a.pdf') and save (filename='PDF//220.pdf')
[2018-03-02 15:30:25,328 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:30:25,328 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:30:26,473 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Miguel_Monasor/publication/224143873_A_training_tool_for_Global_Software_Development/links/57ad9ec508ae3765c3bcd32a.pdf HTTP/1.1" 200 427506
[2018-03-02 15:30:26,474 DEBUG utils] Content-length=427506
[2018-03-02 15:30:26,475 DEBUG utils] Create file PDF//220.pdf, start download.
[2018-03-02 15:30:27,860 DEBUG utils] End download file PDF//220.pdf.
[2018-03-02 15:30:27,863 DEBUG dbutils] Update pdf_transaction for paper id=220.
[2018-03-02 15:30:27,863 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 220'
[2018-03-02 15:30:27,863 DEBUG dbutils] Query result: null
[2018-03-02 15:30:27,864 DEBUG scholar] Handle paper #243 (total 1170)
[2018-03-02 15:30:27,864 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:30:27,868 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:27,868 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:30:27,869 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for scholar.google.com
[2018-03-02 15:30:27,882 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:27,884 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:29,403 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:cgT2hmOWQ6oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdSFq1YgLv7ojj4pflqy-etLHzCi7&scisf=3&ct=citation&cd=242&hl=en HTTP/1.1" 200 268
[2018-03-02 15:30:29,404 DEBUG scholar] EndNote file:
%0 Journal Article
%T Understanding and learning to reconcile differences between disciplines through constructing an artificial personality
%A Kadri, Faisal L
%J Kybernetes
%V 43
%N 9/10
%P 1338-1345
%@ 0368-492X
%D 2014
%I Emerald Group Publishing Limited

[2018-03-02 15:30:29,404 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:29,404 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:29,404 DEBUG __main__] Process content of EndNote file #243
{"title": "Understanding and learning to reconcile differences between disciplines through constructing an artificial personality", "url": "http://www.emeraldinsight.com/doi/abs/10.1108/K-07-2014-0152", "author": [{"shortname": "FL Kadri", "gid": ""}], "year": 2014}
{"type": "Journal Article", "title": "Understanding and learning to reconcile differences between disciplines through constructing an artificial personality", "author": ["Kadri, Faisal L"], "journal": "Kybernetes", "volume": 8, "numberorissue": "9/10", "pages": "1338-1345", "isbn/issn": "0368-492X", "year": "2014", "publisher": "Emerald Group Publishing Limited", "start_page": 1338, "end_page": 1345, "EndNote": "%0 Journal Article\n%T Understanding and learning to reconcile differences between disciplines through constructing an artificial personality\n%A Kadri, Faisal L\n%J Kybernetes\n%V 43\n%N 9/10\n%P 1338-1345\n%@ 0368-492X\n%D 2014\n%I Emerald Group Publishing Limited\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:cgT2hmOWQ6oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdSFq1YgLv7ojj4pflqy-etLHzCi7&scisf=3&ct=citation&cd=242&hl=en"}
[2018-03-02 15:30:29,404 DEBUG dbutils] Get paper id {"DOI": null, "title": "Understanding and learning to reconcile differences between disciplines through constructing an artificial personality", "auth_count": 1, "g_type": "Journal Article", "pages": 8, "year": 2014, "rg_id": null, "start_page": 1338, "end_page": 1345}.
[2018-03-02 15:30:29,404 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Understanding and learning to reconcile differences between disciplines through constructing an artificial personality', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 8, 'year': 2014, 'rg_id': None, 'start_page': 1338, 'end_page': 1345}
[2018-03-02 15:30:29,405 DEBUG dbutils] Query result: []
[2018-03-02 15:30:29,405 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:29,405 DEBUG dbutils] Add new paper (title='Understanding and learning to reconcile differences between disciplines through constructing an artificial personality')
[2018-03-02 15:30:29,405 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Understanding and learning to reconcile differences between disciplines through constructing an artificial personality', 'year': 2014, 'publisher': 'Emerald Group Publishing Limited', 'start_page': 1338, 'end_page': 1345, 'pages': 8, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Understanding and learning to reconcile differences between disciplines through constructing an artificial personality\n%A Kadri, Faisal L\n%J Kybernetes\n%V 43\n%N 9/10\n%P 1338-1345\n%@ 0368-492X\n%D 2014\n%I Emerald Group Publishing Limited\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:29,405 DEBUG dbutils] Query result: 221
[2018-03-02 15:30:29,406 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.emeraldinsight.com/doi/abs/10.1108/K-07-2014-0152.
[2018-03-02 15:30:29,406 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.emeraldinsight.com/doi/abs/10.1108/K-07-2014-0152.
[2018-03-02 15:30:29,623 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.emeraldinsight.com/doi/abs/10.1108/K-07-2014-0152 HTTP/1.1" 200 None
[2018-03-02 15:30:29,624 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:30:29,624 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:30:29,624 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for sci-hub.tw
[2018-03-02 15:30:29,813 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.emeraldinsight.com/doi/abs/10.1108/K-07-2014-0152 HTTP/1.1" 200 None
[2018-03-02 15:30:29,819 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true.
[2018-03-02 15:30:29,819 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true') and save (filename='PDF//221.pdf')
[2018-03-02 15:30:29,834 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: dabamirror.sci-hub.tw
[2018-03-02 15:30:30,023 DEBUG requests.packages.urllib3.connectionpool] "GET /19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:30,024 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:30,024 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:30:30,039 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): dabamirror.sci-hub.tw
[2018-03-02 15:30:30,243 DEBUG requests.packages.urllib3.connectionpool] "GET /19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:30,246 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:30,246 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:30:33,842 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:30:33,842 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:30:34,081 DEBUG requests.packages.urllib3.connectionpool] "GET /19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:34,082 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:34,082 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:30:34,082 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for sci-hub.tw
[2018-03-02 15:30:34,097 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): dabamirror.sci-hub.tw
[2018-03-02 15:30:34,372 DEBUG requests.packages.urllib3.connectionpool] "GET /19373485dafd86be22086f09aa0fdfb0/kadri2014.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:34,377 DEBUG scholar] Handle paper #244 (total 1170)
[2018-03-02 15:30:34,378 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:30:34,383 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:34,383 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:30:34,803 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AoCOQaYEbjMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdZgfiBuVSpI7f_BoAbUzEZ7Z4viZ&scisf=3&ct=citation&cd=243&hl=en HTTP/1.1" 200 190
[2018-03-02 15:30:34,804 DEBUG scholar] EndNote file:
%0 Journal Article
%T MAPIT: a pedagogical-relational ITS
%A Rossi, Pier Giuseppe
%A Carletti, Simone
%J Procedia Computer Science
%V 3
%P 820-826
%@ 1877-0509
%D 2011
%I Elsevier

[2018-03-02 15:30:34,804 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:34,805 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:34,805 DEBUG __main__] Process content of EndNote file #244
{"title": "MAPIT: a pedagogical-relational ITS", "url": "https://www.sciencedirect.com/science/article/pii/S1877050910005107", "author": [{"shortname": "PG Rossi", "gid": "-Aiv3BEAAAAJ"}, {"shortname": "S Carletti", "gid": ""}], "year": 2011}
{"citedby": 4, "type": "Journal Article", "title": "MAPIT: a pedagogical-relational ITS", "author": ["Rossi, Pier Giuseppe", "Carletti, Simone"], "journal": "Procedia Computer Science", "volume": 7, "pages": "820-826", "isbn/issn": "1877-0509", "year": "2011", "publisher": "Elsevier", "start_page": 820, "end_page": 826, "EndNote": "%0 Journal Article\n%T MAPIT: a pedagogical-relational ITS\n%A Rossi, Pier Giuseppe\n%A Carletti, Simone\n%J Procedia Computer Science\n%V 3\n%P 820-826\n%@ 1877-0509\n%D 2011\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:AoCOQaYEbjMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdZgfiBuVSpI7f_BoAbUzEZ7Z4viZ&scisf=3&ct=citation&cd=243&hl=en"}
[2018-03-02 15:30:34,805 DEBUG dbutils] Get paper id {"DOI": null, "title": "MAPIT: a pedagogical-relational ITS", "auth_count": 2, "g_type": "Journal Article", "pages": 7, "year": 2011, "rg_id": null, "start_page": 820, "end_page": 826}.
[2018-03-02 15:30:34,805 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'MAPIT: a pedagogical-relational ITS', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 7, 'year': 2011, 'rg_id': None, 'start_page': 820, 'end_page': 826}
[2018-03-02 15:30:34,805 DEBUG dbutils] Query result: []
[2018-03-02 15:30:34,805 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:34,805 DEBUG dbutils] Add new paper (title='MAPIT: a pedagogical-relational ITS')
[2018-03-02 15:30:34,805 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'MAPIT: a pedagogical-relational ITS', 'year': 2011, 'publisher': 'Elsevier', 'start_page': 820, 'end_page': 826, 'pages': 7, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T MAPIT: a pedagogical-relational ITS\n%A Rossi, Pier Giuseppe\n%A Carletti, Simone\n%J Procedia Computer Science\n%V 3\n%P 820-826\n%@ 1877-0509\n%D 2011\n%I Elsevier\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:34,805 DEBUG dbutils] Query result: 222
[2018-03-02 15:30:34,807 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.sciencedirect.com/science/article/pii/S1877050910005107/pdf?md5=2f6ba0c04ea344bf9fe9a77640fd1da8&pid=1-s2.0-S1877050910005107-main.pdf&_valck=1.
[2018-03-02 15:30:34,810 WARNING utils] Download file (url='https://www.sciencedirect.com/science/article/pii/S1877050910005107/pdf?md5=2f6ba0c04ea344bf9fe9a77640fd1da8&pid=1-s2.0-S1877050910005107-main.pdf&_valck=1') and save (filename='PDF//222.pdf')
[2018-03-02 15:30:34,810 DEBUG utils] Get current proxy for www.sciencedirect.com.
[2018-03-02 15:30:34,810 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:30:34,832 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.sciencedirect.com
[2018-03-02 15:30:37,150 DEBUG requests.packages.urllib3.connectionpool] "GET /science/article/pii/S1877050910005107/pdf?md5=2f6ba0c04ea344bf9fe9a77640fd1da8&pid=1-s2.0-S1877050910005107-main.pdf&_valck=1 HTTP/1.1" 200 1726
[2018-03-02 15:30:37,155 DEBUG utils] Content-length=1726
[2018-03-02 15:30:37,155 DEBUG utils] Create file PDF//222.pdf, start download.
[2018-03-02 15:30:37,157 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 1726

[2018-03-02 15:30:37,157 DEBUG __main__] Failed get_pdf from Google Scholar for paper #222. URL=222
[2018-03-02 15:30:37,160 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.sciencedirect.com/science/article/pii/S1877050910005107.
[2018-03-02 15:30:37,160 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.sciencedirect.com/science/article/pii/S1877050910005107.
[2018-03-02 15:30:37,409 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S1877050910005107 HTTP/1.1" 200 None
[2018-03-02 15:30:37,411 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:30:37,411 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:30:37,565 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.sciencedirect.com/science/article/pii/S1877050910005107 HTTP/1.1" 200 None
[2018-03-02 15:30:37,573 DEBUG scihub] URL for PDF: http://dacemirror.sci-hub.tw/journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true.
[2018-03-02 15:30:37,573 WARNING utils] Download file (url='http://dacemirror.sci-hub.tw/journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true') and save (filename='PDF//222.pdf')
[2018-03-02 15:30:37,590 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): dacemirror.sci-hub.tw
[2018-03-02 15:30:38,164 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:38,165 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 15:30:38,165 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:30:38,165 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for sci-hub.tw
[2018-03-02 15:30:38,190 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): dacemirror.sci-hub.tw
[2018-03-02 15:30:38,362 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:38,366 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 15:30:38,366 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:30:42,201 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:30:42,202 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:30:42,475 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:42,476 DEBUG utils] Get current proxy for dacemirror.sci-hub.tw.
[2018-03-02 15:30:42,477 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:30:42,493 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): dacemirror.sci-hub.tw
[2018-03-02 15:30:42,662 DEBUG requests.packages.urllib3.connectionpool] "GET /journal-article/e59cf2426e4457c6ebf4a44fcae4434c/rossi2011.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:42,668 DEBUG scholar] Handle paper #245 (total 1170)
[2018-03-02 15:30:42,668 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:30:42,672 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:42,672 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:30:42,672 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for scholar.google.com
[2018-03-02 15:30:42,691 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:42,692 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:45,095 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:3eirOclFLrsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdV79juVQms6E3AGgoopGXoBpTfpy&scisf=3&ct=citation&cd=244&hl=en HTTP/1.1" 200 165
[2018-03-02 15:30:45,096 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatbot Design-Reasoning about design options using i* and process architecture
%A Babar, Zia
%A Lapouchnian, Alexei
%A Yu, Eric
%D 2011

[2018-03-02 15:30:45,096 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:45,096 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:45,096 DEBUG __main__] Process content of EndNote file #245
{"title": "Chatbot Design-Reasoning about design options using i* and process architecture", "url": "http://www.cs.toronto.edu/~alexei/pub/istar2017.pdf", "author": [{"shortname": "Z Babar", "gid": "UU9oH78AAAAJ"}, {"shortname": "A Lapouchnian", "gid": "NOYEeuEAAAAJ"}, {"shortname": "E Yu", "gid": "c36OREEAAAAJ"}], "year": 2011}
{"type": "Journal Article", "title": "Chatbot Design-Reasoning about design options using i* and process architecture", "author": ["Babar, Zia", "Lapouchnian, Alexei", "Yu, Eric"], "year": "2011", "EndNote": "%0 Journal Article\n%T Chatbot Design-Reasoning about design options using i* and process architecture\n%A Babar, Zia\n%A Lapouchnian, Alexei\n%A Yu, Eric\n%D 2011\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:3eirOclFLrsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdV79juVQms6E3AGgoopGXoBpTfpy&scisf=3&ct=citation&cd=244&hl=en"}
[2018-03-02 15:30:45,097 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbot Design-Reasoning about design options using i* and process architecture", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:30:45,097 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbot Design-Reasoning about design options using i* and process architecture', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:30:45,097 DEBUG dbutils] Query result: []
[2018-03-02 15:30:45,097 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:45,097 DEBUG dbutils] Add new paper (title='Chatbot Design-Reasoning about design options using i* and process architecture')
[2018-03-02 15:30:45,097 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbot Design-Reasoning about design options using i* and process architecture', 'year': 2011, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Chatbot Design-Reasoning about design options using i* and process architecture\n%A Babar, Zia\n%A Lapouchnian, Alexei\n%A Yu, Eric\n%D 2011\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:45,097 DEBUG dbutils] Query result: 223
[2018-03-02 15:30:45,099 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.cs.toronto.edu/~alexei/pub/istar2017.pdf.
[2018-03-02 15:30:45,100 WARNING utils] Download file (url='http://www.cs.toronto.edu/~alexei/pub/istar2017.pdf') and save (filename='PDF//223.pdf')
[2018-03-02 15:30:45,100 DEBUG utils] Get current proxy for www.cs.toronto.edu.
[2018-03-02 15:30:45,100 DEBUG utils] Proxy: {'https': '47.88.89.70:3128'}
[2018-03-02 15:30:45,100 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for otherhost
[2018-03-02 15:30:45,118 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.cs.toronto.edu
[2018-03-02 15:30:46,182 DEBUG requests.packages.urllib3.connectionpool] "GET /~alexei/pub/istar2017.pdf HTTP/1.1" 200 408314
[2018-03-02 15:30:46,183 DEBUG utils] Content-length=408314
[2018-03-02 15:30:46,184 DEBUG utils] Create file PDF//223.pdf, start download.
[2018-03-02 15:30:49,655 DEBUG utils] End download file PDF//223.pdf.
[2018-03-02 15:30:49,656 DEBUG dbutils] Update pdf_transaction for paper id=223.
[2018-03-02 15:30:49,657 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 223'
[2018-03-02 15:30:49,657 DEBUG dbutils] Query result: null
[2018-03-02 15:30:49,657 DEBUG scholar] Handle paper #246 (total 1170)
[2018-03-02 15:30:49,658 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:30:49,661 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:49,662 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:30:50,152 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QzNAIJ7LUJYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdbAxq75fYRYwfqKHo-agjJTWf6uX&scisf=3&ct=citation&cd=245&hl=en HTTP/1.1" 200 228
[2018-03-02 15:30:50,153 DEBUG scholar] EndNote file:
%0 Journal Article
%T Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.
%A Campbell, Sarah
%J IEEE pulse
%V 6
%N 6
%P 4-8
%@ 2154-2287
%D 2015
%I IEEE

[2018-03-02 15:30:50,154 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:50,154 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:50,154 DEBUG __main__] Process content of EndNote file #246
{"title": "Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.", "url": "http://ieeexplore.ieee.org/abstract/document/7328834/", "author": [{"shortname": "S Campbell", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.", "author": ["Campbell, Sarah"], "journal": "IEEE pulse", "volume": 5, "numberorissue": "6", "pages": "4-8", "isbn/issn": "2154-2287", "year": "2015", "publisher": "IEEE", "start_page": 4, "end_page": 8, "EndNote": "%0 Journal Article\n%T Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.\n%A Campbell, Sarah\n%J IEEE pulse\n%V 6\n%N 6\n%P 4-8\n%@ 2154-2287\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QzNAIJ7LUJYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdbAxq75fYRYwfqKHo-agjJTWf6uX&scisf=3&ct=citation&cd=245&hl=en"}
[2018-03-02 15:30:50,154 DEBUG dbutils] Get paper id {"DOI": null, "title": "Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.", "auth_count": 1, "g_type": "Journal Article", "pages": 5, "year": 2015, "rg_id": null, "start_page": 4, "end_page": 8}.
[2018-03-02 15:30:50,154 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 5, 'year': 2015, 'rg_id': None, 'start_page': 4, 'end_page': 8}
[2018-03-02 15:30:50,154 DEBUG dbutils] Query result: []
[2018-03-02 15:30:50,154 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:50,154 DEBUG dbutils] Add new paper (title='Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.')
[2018-03-02 15:30:50,154 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.', 'year': 2015, 'publisher': 'IEEE', 'start_page': 4, 'end_page': 8, 'pages': 5, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Baby, Where Did You Get Those Eyes?: IEEE Pulse talks with Mark Sagar about the new face of artificial intelligence.\n%A Campbell, Sarah\n%J IEEE pulse\n%V 6\n%N 6\n%P 4-8\n%@ 2154-2287\n%D 2015\n%I IEEE\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:50,154 DEBUG dbutils] Query result: 224
[2018-03-02 15:30:50,156 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7328834/.
[2018-03-02 15:30:50,156 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7328834/.
[2018-03-02 15:30:50,343 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7328834/ HTTP/1.1" 200 None
[2018-03-02 15:30:50,345 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:30:50,346 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:30:50,346 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for sci-hub.tw
[2018-03-02 15:30:50,535 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7328834/ HTTP/1.1" 200 None
[2018-03-02 15:30:50,541 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true.
[2018-03-02 15:30:50,541 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true') and save (filename='PDF//224.pdf')
[2018-03-02 15:30:50,686 DEBUG requests.packages.urllib3.connectionpool] "GET /31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:50,687 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:50,687 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:30:50,702 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): dabamirror.sci-hub.tw
[2018-03-02 15:30:51,093 DEBUG requests.packages.urllib3.connectionpool] "GET /31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:51,098 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:51,099 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:30:56,695 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:30:56,695 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:30:56,952 DEBUG requests.packages.urllib3.connectionpool] "GET /31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true HTTP/1.1" 200 1763064
[2018-03-02 15:30:56,953 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:30:56,953 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:30:56,953 DEBUG utils] Change proxy to {'https': '192.99.245.228:3128'} for sci-hub.tw
[2018-03-02 15:30:56,969 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): dabamirror.sci-hub.tw
[2018-03-02 15:30:57,212 DEBUG requests.packages.urllib3.connectionpool] "GET /31b8aa16154d8e4e9b180f18666e4416/campbell2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:30:57,218 DEBUG scholar] Handle paper #247 (total 1170)
[2018-03-02 15:30:57,218 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:30:57,222 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:30:57,222 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:30:57,222 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for scholar.google.com
[2018-03-02 15:30:57,246 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:30:57,249 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:30:59,552 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:yCUGXaIChm0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdTCXmlNS5Ms3FJmPMD8xHykCF3Q6&scisf=3&ct=citation&cd=246&hl=en HTTP/1.1" 200 210
[2018-03-02 15:30:59,553 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Intelligent Tutoring Systems
%A Aimeur, E
%A Lajoie, Roger Nkambou Susanne
%B 9th International Conference on Intelligent Tutoring Systems, ITS
%P 23-27
%D 2008
%I Springer

[2018-03-02 15:30:59,553 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:30:59,553 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:30:59,553 DEBUG __main__] Process content of EndNote file #247
{"title": "Intelligent Tutoring Systems", "url": "https://link.springer.com/content/pdf/10.1007/978-3-540-69132-7.pdf", "author": [{"shortname": "E Aimeur", "gid": "rBTFbxYAAAAJ"}, {"shortname": "RNS Lajoie", "gid": "q2Aef0sAAAAJ"}], "year": 2008}
{"citedby": 23, "type": "Conference Proceedings", "title": "Intelligent Tutoring Systems", "author": ["Aimeur, E", "Lajoie, Roger Nkambou Susanne"], "secondarytitle": "9th International Conference on Intelligent Tutoring Systems, ITS", "pages": "23-27", "year": "2008", "publisher": "Springer", "start_page": 23, "end_page": 27, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T Intelligent Tutoring Systems\n%A Aimeur, E\n%A Lajoie, Roger Nkambou Susanne\n%B 9th International Conference on Intelligent Tutoring Systems, ITS\n%P 23-27\n%D 2008\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:yCUGXaIChm0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdTCXmlNS5Ms3FJmPMD8xHykCF3Q6&scisf=3&ct=citation&cd=246&hl=en"}
[2018-03-02 15:30:59,554 DEBUG dbutils] Get paper id {"DOI": null, "title": "Intelligent Tutoring Systems", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 5, "year": 2008, "rg_id": null, "start_page": 23, "end_page": 27}.
[2018-03-02 15:30:59,554 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Intelligent Tutoring Systems', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2008, 'rg_id': None, 'start_page': 23, 'end_page': 27}
[2018-03-02 15:30:59,554 DEBUG dbutils] Query result: []
[2018-03-02 15:30:59,554 DEBUG dbutils] Paper id = None.
[2018-03-02 15:30:59,554 DEBUG dbutils] Add new paper (title='Intelligent Tutoring Systems')
[2018-03-02 15:30:59,554 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Intelligent Tutoring Systems', 'year': 2008, 'publisher': 'Springer', 'start_page': 23, 'end_page': 27, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Intelligent Tutoring Systems\n%A Aimeur, E\n%A Lajoie, Roger Nkambou Susanne\n%B 9th International Conference on Intelligent Tutoring Systems, ITS\n%P 23-27\n%D 2008\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:30:59,554 DEBUG dbutils] Query result: 225
[2018-03-02 15:31:00,012 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf.
[2018-03-02 15:31:00,013 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf') and save (filename='PDF//225.pdf')
[2018-03-02 15:31:00,013 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:00,013 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:31:00,037 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:00,038 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:31:01,442 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:01,443 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:01,443 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for otherhost
[2018-03-02 15:31:01,445 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:01,445 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:31:01,459 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:03,214 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:03,215 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:03,215 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for otherhost
[2018-03-02 15:31:03,217 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:03,217 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 15:31:03,231 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:08,313 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:31:08,314 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for otherhost
[2018-03-02 15:31:08,314 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:08,314 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:31:08,330 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:11,584 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:11,585 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:11,585 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for otherhost
[2018-03-02 15:31:11,587 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:11,587 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:31:11,602 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:13,002 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:13,003 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:13,003 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for otherhost
[2018-03-02 15:31:13,004 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:13,005 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:31:13,019 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:15,102 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:15,103 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:15,103 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for otherhost
[2018-03-02 15:31:15,104 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:15,104 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:31:15,118 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:15,972 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:15,972 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:15,973 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for otherhost
[2018-03-02 15:31:15,974 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:15,974 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:31:15,988 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:18,771 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:18,772 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:18,772 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for otherhost
[2018-03-02 15:31:18,774 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:18,774 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:31:18,788 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:18,790 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:31:21,751 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:21,752 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:21,752 DEBUG utils] Change proxy to {'https': '177.37.160.202:3128'} for otherhost
[2018-03-02 15:31:21,753 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:21,753 DEBUG utils] Proxy: {'https': '177.37.160.202:3128'}
[2018-03-02 15:31:21,767 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:24,141 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:24,142 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:24,142 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for otherhost
[2018-03-02 15:31:24,143 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:24,144 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:31:24,157 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:24,159 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:31:24,981 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:24,982 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:24,982 DEBUG utils] Change proxy to {'https': '194.88.105.156:3128'} for otherhost
[2018-03-02 15:31:24,984 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:24,984 DEBUG utils] Proxy: {'https': '194.88.105.156:3128'}
[2018-03-02 15:31:24,998 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:25,802 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:25,803 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:25,803 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for otherhost
[2018-03-02 15:31:25,804 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:25,805 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:31:25,820 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:25,821 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:31:29,180 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:29,182 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:29,182 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for otherhost
[2018-03-02 15:31:29,183 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:29,184 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 15:31:29,198 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:35,022 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:31:35,023 DEBUG utils] Change proxy to {'https': '217.170.252.60:3128'} for otherhost
[2018-03-02 15:31:35,023 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:35,023 DEBUG utils] Proxy: {'https': '217.170.252.60:3128'}
[2018-03-02 15:31:35,038 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:37,886 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:37,887 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:37,887 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for otherhost
[2018-03-02 15:31:37,889 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:37,889 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:31:37,905 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:40,271 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:40,272 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:40,272 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for otherhost
[2018-03-02 15:31:40,273 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:40,273 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:31:40,305 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:40,307 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:31:41,642 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:41,643 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:41,643 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for otherhost
[2018-03-02 15:31:41,645 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:41,645 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:31:41,660 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:31:41,662 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:31:44,236 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:44,237 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:44,237 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for otherhost
[2018-03-02 15:31:44,239 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:44,239 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:31:44,253 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:45,581 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:45,582 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:45,582 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for otherhost
[2018-03-02 15:31:45,584 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:31:45,584 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:31:45,599 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:31:48,611 DEBUG requests.packages.urllib3.connectionpool] "GET /5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf HTTP/1.1" 404 None
[2018-03-02 15:31:48,611 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:31:48,611 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for otherhost
[2018-03-02 15:31:48,615 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/content/pdf/10.1007/978-3-540-69132-7.pdf.
[2018-03-02 15:31:48,616 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/content/pdf/10.1007/978-3-540-69132-7.pdf.
[2018-03-02 15:31:48,815 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-540-69132-7.pdf HTTP/1.1" 302 None
[2018-03-02 15:31:48,840 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): libgen.io
[2018-03-02 15:31:49,261 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D2372F1DF269EED1AA97031349DE57AF HTTP/1.1" 200 13704
[2018-03-02 15:31:49,374 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:31:49,374 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:31:49,561 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/content/pdf/10.1007/978-3-540-69132-7.pdf HTTP/1.1" 302 None
[2018-03-02 15:31:49,841 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=D2372F1DF269EED1AA97031349DE57AF HTTP/1.1" 200 13704
[2018-03-02 15:31:50,927 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:31:50,928 DEBUG scholar] Handle paper #248 (total 1170)
[2018-03-02 15:31:50,928 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:31:50,933 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:31:50,933 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:31:51,381 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:SdYoVoxSIa0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdfWDS5FeEoEXgVMRytuldmZqJTQ7&scisf=3&ct=citation&cd=247&hl=en HTTP/1.1" 200 277
[2018-03-02 15:31:51,382 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Ranking responses oriented to conversational relevance in chat-bots
%A Wu, Bowen
%A Wang, Baoxun
%A Xue, Hui
%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers
%P 652-662
%D 2016

[2018-03-02 15:31:51,383 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:31:51,383 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:31:51,383 DEBUG __main__] Process content of EndNote file #248
{"title": "Ranking responses oriented to conversational relevance in chat-bots", "url": "http://www.aclweb.org/anthology/C16-1063", "author": [{"shortname": "B Wu", "gid": "B2zuDnwAAAAJ"}, {"shortname": "B Wang", "gid": "HPFpDpoAAAAJ"}, {"shortname": "H Xue", "gid": ""}], "year": 2016}
{"citedby": 6, "type": "Conference Proceedings", "title": "Ranking responses oriented to conversational relevance in chat-bots", "author": ["Wu, Bowen", "Wang, Baoxun", "Xue, Hui"], "secondarytitle": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers", "pages": "652-662", "year": "2016", "start_page": 652, "end_page": 662, "volume": 11, "EndNote": "%0 Conference Proceedings\n%T Ranking responses oriented to conversational relevance in chat-bots\n%A Wu, Bowen\n%A Wang, Baoxun\n%A Xue, Hui\n%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\n%P 652-662\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:SdYoVoxSIa0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdfWDS5FeEoEXgVMRytuldmZqJTQ7&scisf=3&ct=citation&cd=247&hl=en"}
[2018-03-02 15:31:51,383 DEBUG dbutils] Get paper id {"DOI": null, "title": "Ranking responses oriented to conversational relevance in chat-bots", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 11, "year": 2016, "rg_id": null, "start_page": 652, "end_page": 662}.
[2018-03-02 15:31:51,383 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Ranking responses oriented to conversational relevance in chat-bots', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 11, 'year': 2016, 'rg_id': None, 'start_page': 652, 'end_page': 662}
[2018-03-02 15:31:51,384 DEBUG dbutils] Query result: []
[2018-03-02 15:31:51,384 DEBUG dbutils] Paper id = None.
[2018-03-02 15:31:51,384 DEBUG dbutils] Add new paper (title='Ranking responses oriented to conversational relevance in chat-bots')
[2018-03-02 15:31:51,384 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Ranking responses oriented to conversational relevance in chat-bots', 'year': 2016, 'publisher': None, 'start_page': 652, 'end_page': 662, 'pages': 11, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Ranking responses oriented to conversational relevance in chat-bots\n%A Wu, Bowen\n%A Wang, Baoxun\n%A Xue, Hui\n%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\n%P 652-662\n%D 2016\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:31:51,384 DEBUG dbutils] Query result: 226
[2018-03-02 15:31:51,385 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/C16-1063.
[2018-03-02 15:31:51,386 WARNING utils] Download file (url='http://www.aclweb.org/anthology/C16-1063') and save (filename='PDF//226.pdf')
[2018-03-02 15:31:51,386 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:31:51,386 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:31:51,403 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 15:31:53,246 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1063 HTTP/1.1" 200 None
[2018-03-02 15:31:53,247 DEBUG utils] Downloading the entire file.
[2018-03-02 15:31:53,247 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:31:53,247 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:31:53,247 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for otherhost
[2018-03-02 15:31:53,262 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 15:31:53,845 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1063 HTTP/1.1" 200 None
[2018-03-02 15:31:55,476 DEBUG utils] Save file PDF//226.pdf.
[2018-03-02 15:31:55,477 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/C16-1063.
[2018-03-02 15:31:55,478 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/C16-1063.
[2018-03-02 15:31:55,641 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/C16-1063 HTTP/1.1" 302 None
[2018-03-02 15:31:55,991 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1063 HTTP/1.1" 200 None
[2018-03-02 15:31:56,927 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:31:56,927 DEBUG utils] Proxy: {'https': '192.99.245.228:3128'}
[2018-03-02 15:31:56,927 DEBUG utils] Change proxy to {'https': '177.37.160.198:3128'} for sci-hub.tw
[2018-03-02 15:31:57,090 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/C16-1063 HTTP/1.1" 302 None
[2018-03-02 15:31:57,401 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1063 HTTP/1.1" 200 None
[2018-03-02 15:32:01,229 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:32:01,230 DEBUG scholar] Handle paper #249 (total 1170)
[2018-03-02 15:32:01,231 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:32:01,234 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:32:01,235 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:32:01,235 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for scholar.google.com
[2018-03-02 15:32:01,250 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:32:01,252 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:32:03,891 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:BPti0W9tDZQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdTTHSiZUa8P6Qo60h3f6LfX2Mdfu&scisf=3&ct=citation&cd=248&hl=en HTTP/1.1" 200 254
[2018-03-02 15:32:03,892 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Joke retrieval: recognizing the same joke told differently
%A Friedland, Lisa
%A Allan, James
%B Proceedings of the 17th ACM conference on Information and knowledge management
%P 883-892
%@ 1595939911
%D 2008
%I ACM

[2018-03-02 15:32:03,892 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:32:03,892 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:32:03,892 DEBUG __main__] Process content of EndNote file #249
{"title": "Joke retrieval: recognizing the same joke told differently", "url": "https://dl.acm.org/citation.cfm?id=1458199", "author": [{"shortname": "L Friedland", "gid": "YbOjx-kAAAAJ"}, {"shortname": "J Allan", "gid": "-bLGeg0AAAAJ"}], "year": 2008}
{"citedby": 14, "type": "Conference Proceedings", "title": "Joke retrieval: recognizing the same joke told differently", "author": ["Friedland, Lisa", "Allan, James"], "secondarytitle": "Proceedings of the 17th ACM conference on Information and knowledge management", "pages": "883-892", "isbn/issn": "1595939911", "year": "2008", "publisher": "ACM", "start_page": 883, "end_page": 892, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Joke retrieval: recognizing the same joke told differently\n%A Friedland, Lisa\n%A Allan, James\n%B Proceedings of the 17th ACM conference on Information and knowledge management\n%P 883-892\n%@ 1595939911\n%D 2008\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:BPti0W9tDZQJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdTTHSiZUa8P6Qo60h3f6LfX2Mdfu&scisf=3&ct=citation&cd=248&hl=en"}
[2018-03-02 15:32:03,892 DEBUG dbutils] Get paper id {"DOI": null, "title": "Joke retrieval: recognizing the same joke told differently", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2008, "rg_id": null, "start_page": 883, "end_page": 892}.
[2018-03-02 15:32:03,892 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Joke retrieval: recognizing the same joke told differently', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2008, 'rg_id': None, 'start_page': 883, 'end_page': 892}
[2018-03-02 15:32:03,893 DEBUG dbutils] Query result: []
[2018-03-02 15:32:03,893 DEBUG dbutils] Paper id = None.
[2018-03-02 15:32:03,893 DEBUG dbutils] Add new paper (title='Joke retrieval: recognizing the same joke told differently')
[2018-03-02 15:32:03,893 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Joke retrieval: recognizing the same joke told differently', 'year': 2008, 'publisher': 'ACM', 'start_page': 883, 'end_page': 892, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Joke retrieval: recognizing the same joke told differently\n%A Friedland, Lisa\n%A Allan, James\n%B Proceedings of the 17th ACM conference on Information and knowledge management\n%P 883-892\n%@ 1595939911\n%D 2008\n%I ACM\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:32:03,893 DEBUG dbutils] Query result: 227
[2018-03-02 15:32:03,895 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/3238010/friedland-allan-cikm08.pdf.
[2018-03-02 15:32:03,895 WARNING utils] Download file (url='http://www.academia.edu/download/3238010/friedland-allan-cikm08.pdf') and save (filename='PDF//227.pdf')
[2018-03-02 15:32:03,895 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 15:32:03,896 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:32:03,911 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 15:32:04,362 DEBUG requests.packages.urllib3.connectionpool] "GET /download/3238010/friedland-allan-cikm08.pdf HTTP/1.1" 404 None
[2018-03-02 15:32:04,366 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=1458199.
[2018-03-02 15:32:04,366 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=1458199.
[2018-03-02 15:32:06,111 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1458199 HTTP/1.1" 200 None
[2018-03-02 15:32:06,112 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:32:06,112 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:32:06,301 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=1458199 HTTP/1.1" 200 None
[2018-03-02 15:32:06,308 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true.
[2018-03-02 15:32:06,308 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true') and save (filename='PDF//227.pdf')
[2018-03-02 15:32:06,323 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: dabamirror.sci-hub.tw
[2018-03-02 15:32:06,531 DEBUG requests.packages.urllib3.connectionpool] "GET /2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:32:06,532 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:32:06,532 DEBUG utils] Proxy: {'https': '177.37.160.198:3128'}
[2018-03-02 15:32:06,532 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for sci-hub.tw
[2018-03-02 15:32:06,547 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (8): dabamirror.sci-hub.tw
[2018-03-02 15:32:06,720 DEBUG requests.packages.urllib3.connectionpool] "GET /2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:32:06,723 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:32:06,724 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:32:12,448 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:32:12,448 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:32:12,680 DEBUG requests.packages.urllib3.connectionpool] "GET /2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:32:12,681 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:32:12,681 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:32:12,695 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (9): dabamirror.sci-hub.tw
[2018-03-02 15:32:12,891 DEBUG requests.packages.urllib3.connectionpool] "GET /2ed313086122ba030e5990480362e70c/friedland2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:32:12,895 DEBUG scholar] Handle paper #250 (total 1170)
[2018-03-02 15:32:12,896 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:32:12,898 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:32:12,899 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:32:13,431 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:JyZCQXP13FwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdUzSD3ARkCXaY46Y6kTUsXaQGZtA&scisf=3&ct=citation&cd=249&hl=en HTTP/1.1" 200 149
[2018-03-02 15:32:13,432 DEBUG scholar] EndNote file:
%0 Journal Article
%T The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics
%A Panczyszyn, Tomasz
%D 2016

[2018-03-02 15:32:13,432 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:32:13,432 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:32:13,433 DEBUG __main__] Process content of EndNote file #250
{"title": "The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics", "url": "http://ceur-ws.org/Vol-1730/p12.pdf", "author": [{"shortname": "T Panczyszyn", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics", "author": ["Panczyszyn, Tomasz"], "year": "2016", "EndNote": "%0 Journal Article\n%T The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics\n%A Panczyszyn, Tomasz\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:JyZCQXP13FwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplGdUzSD3ARkCXaY46Y6kTUsXaQGZtA&scisf=3&ct=citation&cd=249&hl=en"}
[2018-03-02 15:32:13,433 DEBUG dbutils] Get paper id {"DOI": null, "title": "The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:32:13,433 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:32:13,433 DEBUG dbutils] Query result: []
[2018-03-02 15:32:13,433 DEBUG dbutils] Paper id = None.
[2018-03-02 15:32:13,433 DEBUG dbutils] Add new paper (title='The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics')
[2018-03-02 15:32:13,433 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The Specifics of Natural Language and Ways of Processing It in the Computational Linguistics\n%A Panczyszyn, Tomasz\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:32:13,433 DEBUG dbutils] Query result: 228
[2018-03-02 15:32:13,435 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://ceur-ws.org/Vol-1730/p12.pdf.
[2018-03-02 15:32:13,436 WARNING utils] Download file (url='http://ceur-ws.org/Vol-1730/p12.pdf') and save (filename='PDF//228.pdf')
[2018-03-02 15:32:13,436 DEBUG utils] Get current proxy for ceur-ws.org.
[2018-03-02 15:32:13,437 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:32:13,437 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for otherhost
[2018-03-02 15:32:13,456 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): ceur-ws.org
[2018-03-02 15:32:18,105 DEBUG requests.packages.urllib3.connectionpool] "GET /Vol-1730/p12.pdf HTTP/1.1" 200 454390
[2018-03-02 15:32:18,105 DEBUG utils] Content-length=454390
[2018-03-02 15:32:18,106 DEBUG utils] Create file PDF//228.pdf, start download.
[2018-03-02 15:32:19,959 DEBUG utils] End download file PDF//228.pdf.
[2018-03-02 15:32:19,960 DEBUG dbutils] Update pdf_transaction for paper id=228.
[2018-03-02 15:32:19,960 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 228'
[2018-03-02 15:32:19,960 DEBUG dbutils] Query result: null
[2018-03-02 15:32:19,979 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:32:19,979 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:32:19,979 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:32:19,979 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for scholar.google.com
[2018-03-02 15:32:19,994 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:32:21,934 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=250&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:32:22,448 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:32:22,448 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:32:45,916 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:32:45,916 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:32:46,058 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:32:46,058 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:32:46,423 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=250&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:32:47,030 DEBUG scholar] Find papers on page #26 (max_google_papers = 300)
[2018-03-02 15:32:47,031 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:32:47,031 DEBUG scholar] Handle paper #251 (total 1170)
[2018-03-02 15:32:47,031 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:32:47,035 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:32:47,036 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:32:47,036 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for scholar.google.com
[2018-03-02 15:32:47,053 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:32:47,054 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:32:48,720 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KEPtz34Q27oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC4gFODhJYF_6meCMtl7kh_nMpaiI&scisf=3&ct=citation&cd=250&hl=en HTTP/1.1" 200 321
[2018-03-02 15:32:48,721 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability
%A Goertzel, Ben
%B Neural Networks, 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on
%P 2956-2965
%@ 1424418208
%D 2008
%I IEEE

[2018-03-02 15:32:48,721 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:32:48,721 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:32:48,721 DEBUG __main__] Process content of EndNote file #251
{"title": "A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability", "url": "http://ieeexplore.ieee.org/abstract/document/4634214/", "author": [{"shortname": "B Goertzel", "gid": ""}], "year": 2008}
{"citedby": 17, "type": "Conference Proceedings", "title": "A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability", "author": ["Goertzel, Ben"], "secondarytitle": "Neural Networks, 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on", "pages": "2956-2965", "isbn/issn": "1424418208", "year": "2008", "publisher": "IEEE", "start_page": 2956, "end_page": 2965, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability\n%A Goertzel, Ben\n%B Neural Networks, 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on\n%P 2956-2965\n%@ 1424418208\n%D 2008\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KEPtz34Q27oJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC4gFODhJYF_6meCMtl7kh_nMpaiI&scisf=3&ct=citation&cd=250&hl=en"}
[2018-03-02 15:32:48,721 DEBUG dbutils] Get paper id {"DOI": null, "title": "A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability", "auth_count": 1, "g_type": "Conference Proceedings", "pages": 10, "year": 2008, "rg_id": null, "start_page": 2956, "end_page": 2965}.
[2018-03-02 15:32:48,721 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2008, 'rg_id': None, 'start_page': 2956, 'end_page': 2965}
[2018-03-02 15:32:48,722 DEBUG dbutils] Query result: []
[2018-03-02 15:32:48,722 DEBUG dbutils] Paper id = None.
[2018-03-02 15:32:48,722 DEBUG dbutils] Add new paper (title='A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability')
[2018-03-02 15:32:48,722 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability', 'year': 2008, 'publisher': 'IEEE', 'start_page': 2956, 'end_page': 2965, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T A pragmatic path toward endowing virtually-embodied ais with human-level linguistic capability\n%A Goertzel, Ben\n%B Neural Networks, 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on\n%P 2956-2965\n%@ 1424418208\n%D 2008\n%I IEEE\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:32:48,722 DEBUG dbutils] Query result: 229
[2018-03-02 15:32:48,723 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/94d3/7941cd8eec306bb9e0bc83e700b94262cf38.pdf.
[2018-03-02 15:32:48,724 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/94d3/7941cd8eec306bb9e0bc83e700b94262cf38.pdf') and save (filename='PDF//229.pdf')
[2018-03-02 15:32:48,725 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:32:48,725 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:32:48,741 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:32:52,636 DEBUG requests.packages.urllib3.connectionpool] "GET /94d3/7941cd8eec306bb9e0bc83e700b94262cf38.pdf HTTP/1.1" 200 546140
[2018-03-02 15:32:52,637 DEBUG utils] Content-length=546140
[2018-03-02 15:32:52,637 DEBUG utils] Create file PDF//229.pdf, start download.
[2018-03-02 15:33:01,903 DEBUG utils] End download file PDF//229.pdf.
[2018-03-02 15:33:01,903 DEBUG dbutils] Update pdf_transaction for paper id=229.
[2018-03-02 15:33:01,904 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 229'
[2018-03-02 15:33:01,904 DEBUG dbutils] Query result: null
[2018-03-02 15:33:01,904 DEBUG scholar] Handle paper #252 (total 1170)
[2018-03-02 15:33:01,904 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:33:01,908 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:01,908 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:33:02,282 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:hw7unYnXS70J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC9s7GEfAQR0-oJd-1DjlIYDCID8p&scisf=3&ct=citation&cd=251&hl=en HTTP/1.1" 200 259
[2018-03-02 15:33:02,283 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Evaluation of Embodied Conversational Agents
%A Brandao, Cesar
%A Reis, Luis Paulo
%A Rocha, Ana Paula
%B Information Systems and Technologies (CISTI), 2013 8th Iberian Conference on
%P 1-6
%@ 9899843407
%D 2013
%I IEEE

[2018-03-02 15:33:02,284 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:02,285 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:02,286 DEBUG __main__] Process content of EndNote file #252
{"title": "Evaluation of Embodied Conversational Agents", "url": "http://ieeexplore.ieee.org/abstract/document/6615734/", "author": [{"shortname": "C Brandao", "gid": ""}, {"shortname": "LP Reis", "gid": "bCKD3moAAAAJ"}, {"shortname": "AP Rocha", "gid": ""}], "year": 2013}
{"citedby": 2, "type": "Conference Proceedings", "title": "Evaluation of Embodied Conversational Agents", "author": ["Brandao, Cesar", "Reis, Luis Paulo", "Rocha, Ana Paula"], "secondarytitle": "Information Systems and Technologies (CISTI), 2013 8th Iberian Conference on", "pages": "1-6", "isbn/issn": "9899843407", "year": "2013", "publisher": "IEEE", "start_page": 1, "end_page": 6, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Evaluation of Embodied Conversational Agents\n%A Brandao, Cesar\n%A Reis, Luis Paulo\n%A Rocha, Ana Paula\n%B Information Systems and Technologies (CISTI), 2013 8th Iberian Conference on\n%P 1-6\n%@ 9899843407\n%D 2013\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:hw7unYnXS70J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC9s7GEfAQR0-oJd-1DjlIYDCID8p&scisf=3&ct=citation&cd=251&hl=en"}
[2018-03-02 15:33:02,287 DEBUG dbutils] Get paper id {"DOI": null, "title": "Evaluation of Embodied Conversational Agents", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 6, "year": 2013, "rg_id": null, "start_page": 1, "end_page": 6}.
[2018-03-02 15:33:02,287 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Evaluation of Embodied Conversational Agents', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2013, 'rg_id': None, 'start_page': 1, 'end_page': 6}
[2018-03-02 15:33:02,288 DEBUG dbutils] Query result: []
[2018-03-02 15:33:02,288 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:02,288 DEBUG dbutils] Add new paper (title='Evaluation of Embodied Conversational Agents')
[2018-03-02 15:33:02,288 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Evaluation of Embodied Conversational Agents', 'year': 2013, 'publisher': 'IEEE', 'start_page': 1, 'end_page': 6, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Evaluation of Embodied Conversational Agents\n%A Brandao, Cesar\n%A Reis, Luis Paulo\n%A Rocha, Ana Paula\n%B Information Systems and Technologies (CISTI), 2013 8th Iberian Conference on\n%P 1-6\n%@ 9899843407\n%D 2013\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:02,289 DEBUG dbutils] Query result: 230
[2018-03-02 15:33:02,291 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/6615734/.
[2018-03-02 15:33:02,291 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/6615734/.
[2018-03-02 15:33:04,235 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/6615734/ HTTP/1.1" 200 None
[2018-03-02 15:33:04,236 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:04,236 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:33:04,236 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for sci-hub.tw
[2018-03-02 15:33:04,434 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/6615734/ HTTP/1.1" 200 None
[2018-03-02 15:33:04,440 DEBUG scihub] URL for PDF: http://direct.sci-hub.tw/ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true.
[2018-03-02 15:33:04,440 WARNING utils] Download file (url='http://direct.sci-hub.tw/ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true') and save (filename='PDF//230.pdf')
[2018-03-02 15:33:04,454 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): direct.sci-hub.tw
[2018-03-02 15:33:04,630 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:04,631 DEBUG utils] Get current proxy for direct.sci-hub.tw.
[2018-03-02 15:33:04,631 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:33:04,646 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): direct.sci-hub.tw
[2018-03-02 15:33:04,839 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:04,842 DEBUG utils] Get current proxy for direct.sci-hub.tw.
[2018-03-02 15:33:04,842 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:33:14,887 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:33:14,887 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:33:15,151 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:15,152 DEBUG utils] Get current proxy for direct.sci-hub.tw.
[2018-03-02 15:33:15,152 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:33:15,152 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for sci-hub.tw
[2018-03-02 15:33:15,168 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): direct.sci-hub.tw
[2018-03-02 15:33:15,339 DEBUG requests.packages.urllib3.connectionpool] "GET /ieeexplore.ieee.org/eee39b1f03f35e294c9a8f949e3c7883.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:15,345 DEBUG scholar] Handle paper #253 (total 1170)
[2018-03-02 15:33:15,345 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:33:15,349 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:15,350 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:33:15,350 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for scholar.google.com
[2018-03-02 15:33:15,370 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:33:15,372 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:33:18,209 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:TDfWEwgq338J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC3xOmtpnMT37paF16IWrYH1qh3_D&scisf=3&ct=citation&cd=252&hl=en HTTP/1.1" 200 270
[2018-03-02 15:33:18,210 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects
%A Portela, Manuel
%A Granell-Canut, Carlos
%B International Conference on Ubiquitous Computing and Ambient Intelligence
%P 385-392
%D 2016
%I Springer

[2018-03-02 15:33:18,210 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:18,210 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:18,210 DEBUG __main__] Process content of EndNote file #253
{"title": "Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects", "url": "https://link.springer.com/chapter/10.1007/978-3-319-48746-5_39", "author": [{"shortname": "M Portela", "gid": "f9Oxg48AAAAJ"}, {"shortname": "C Granell", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Conference Proceedings", "title": "Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects", "author": ["Portela, Manuel", "Granell-Canut, Carlos"], "secondarytitle": "International Conference on Ubiquitous Computing and Ambient Intelligence", "pages": "385-392", "year": "2016", "publisher": "Springer", "start_page": 385, "end_page": 392, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects\n%A Portela, Manuel\n%A Granell-Canut, Carlos\n%B International Conference on Ubiquitous Computing and Ambient Intelligence\n%P 385-392\n%D 2016\n%I Springer\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:TDfWEwgq338J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC3xOmtpnMT37paF16IWrYH1qh3_D&scisf=3&ct=citation&cd=252&hl=en"}
[2018-03-02 15:33:18,211 DEBUG dbutils] Get paper id {"DOI": null, "title": "Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 8, "year": 2016, "rg_id": null, "start_page": 385, "end_page": 392}.
[2018-03-02 15:33:18,211 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2016, 'rg_id': None, 'start_page': 385, 'end_page': 392}
[2018-03-02 15:33:18,211 DEBUG dbutils] Query result: []
[2018-03-02 15:33:18,211 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:18,211 DEBUG dbutils] Add new paper (title='Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects')
[2018-03-02 15:33:18,211 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects', 'year': 2016, 'publisher': 'Springer', 'start_page': 385, 'end_page': 392, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Methods to Observe and Evaluate Interactions with Everyday Context-Aware Objects\n%A Portela, Manuel\n%A Granell-Canut, Carlos\n%B International Conference on Ubiquitous Computing and Ambient Intelligence\n%P 385-392\n%D 2016\n%I Springer\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:18,211 DEBUG dbutils] Query result: 231
[2018-03-02 15:33:18,213 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://link.springer.com/chapter/10.1007/978-3-319-48746-5_39.
[2018-03-02 15:33:18,213 DEBUG scihub] Get page from sci-hub for paper with DOI=https://link.springer.com/chapter/10.1007/978-3-319-48746-5_39.
[2018-03-02 15:33:18,429 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-48746-5_39 HTTP/1.1" 302 None
[2018-03-02 15:33:18,452 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: libgen.io
[2018-03-02 15:33:18,803 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=2388C98E2D9CD7FAD8A6FD1D16F280EE HTTP/1.1" 200 11966
[2018-03-02 15:33:18,933 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:18,933 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:33:19,129 DEBUG requests.packages.urllib3.connectionpool] "GET //https://link.springer.com/chapter/10.1007/978-3-319-48746-5_39 HTTP/1.1" 302 None
[2018-03-02 15:33:19,379 DEBUG requests.packages.urllib3.connectionpool] "GET /book/index.php?md5=2388C98E2D9CD7FAD8A6FD1D16F280EE HTTP/1.1" 200 11966
[2018-03-02 15:33:19,619 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:33:19,620 DEBUG scholar] Handle paper #254 (total 1170)
[2018-03-02 15:33:19,620 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:33:19,624 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:19,624 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:33:20,099 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:4K_dEvriZwYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC583nKYP-uNj8YAVcfXGYUvDyXzq&scisf=3&ct=citation&cd=253&hl=en HTTP/1.1" 200 319
[2018-03-02 15:33:20,100 DEBUG scholar] EndNote file:
%0 Journal Article
%T Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates
%A Pilkington, Rachel M
%J International Journal of Continuing Engineering Education and Life Long Learning
%V 13
%N 3-4
%P 318-335
%@ 1560-4624
%D 2003
%I Inderscience Publishers

[2018-03-02 15:33:20,101 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:20,101 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:20,101 DEBUG __main__] Process content of EndNote file #254
{"title": "Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates", "url": "https://www.inderscienceonline.com/doi/abs/10.1504/IJCEELL.2003.003271", "author": [{"shortname": "RM Pilkington", "gid": ""}], "year": 2003}
{"citedby": 15, "type": "Journal Article", "title": "Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates", "author": ["Pilkington, Rachel M"], "journal": "International Journal of Continuing Engineering Education and Life Long Learning", "volume": 18, "numberorissue": "3-4", "pages": "318-335", "isbn/issn": "1560-4624", "year": "2003", "publisher": "Inderscience Publishers", "start_page": 318, "end_page": 335, "EndNote": "%0 Journal Article\n%T Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates\n%A Pilkington, Rachel M\n%J International Journal of Continuing Engineering Education and Life Long Learning\n%V 13\n%N 3-4\n%P 318-335\n%@ 1560-4624\n%D 2003\n%I Inderscience Publishers\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:4K_dEvriZwYJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC583nKYP-uNj8YAVcfXGYUvDyXzq&scisf=3&ct=citation&cd=253&hl=en"}
[2018-03-02 15:33:20,101 DEBUG dbutils] Get paper id {"DOI": null, "title": "Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates", "auth_count": 1, "g_type": "Journal Article", "pages": 18, "year": 2003, "rg_id": null, "start_page": 318, "end_page": 335}.
[2018-03-02 15:33:20,101 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 18, 'year': 2003, 'rg_id': None, 'start_page': 318, 'end_page': 335}
[2018-03-02 15:33:20,101 DEBUG dbutils] Query result: []
[2018-03-02 15:33:20,101 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:20,101 DEBUG dbutils] Add new paper (title='Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates')
[2018-03-02 15:33:20,102 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates', 'year': 2003, 'publisher': 'Inderscience Publishers', 'start_page': 318, 'end_page': 335, 'pages': 18, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Reflecting on roles: Using synchronous cmc to develop a knowledge-building community amongst postgraduates\n%A Pilkington, Rachel M\n%J International Journal of Continuing Engineering Education and Life Long Learning\n%V 13\n%N 3-4\n%P 318-335\n%@ 1560-4624\n%D 2003\n%I Inderscience Publishers\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:20,102 DEBUG dbutils] Query result: 232
[2018-03-02 15:33:20,103 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.inderscienceonline.com/doi/abs/10.1504/IJCEELL.2003.003271.
[2018-03-02 15:33:20,103 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.inderscienceonline.com/doi/abs/10.1504/IJCEELL.2003.003271.
[2018-03-02 15:33:20,289 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.inderscienceonline.com/doi/abs/10.1504/IJCEELL.2003.003271 HTTP/1.1" 200 None
[2018-03-02 15:33:20,290 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:20,291 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:33:20,291 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for sci-hub.tw
[2018-03-02 15:33:20,479 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.inderscienceonline.com/doi/abs/10.1504/IJCEELL.2003.003271 HTTP/1.1" 200 None
[2018-03-02 15:33:20,485 DEBUG scihub] URL for PDF: http://twin.sci-hub.tw/7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true.
[2018-03-02 15:33:20,485 WARNING utils] Download file (url='http://twin.sci-hub.tw/7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true') and save (filename='PDF//232.pdf')
[2018-03-02 15:33:20,500 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): twin.sci-hub.tw
[2018-03-02 15:33:20,710 DEBUG requests.packages.urllib3.connectionpool] "GET /7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:20,711 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:33:20,711 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:33:20,727 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): twin.sci-hub.tw
[2018-03-02 15:33:20,914 DEBUG requests.packages.urllib3.connectionpool] "GET /7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:20,917 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:33:20,917 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:33:26,585 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:33:26,585 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:33:26,849 DEBUG requests.packages.urllib3.connectionpool] "GET /7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:26,850 DEBUG utils] Get current proxy for twin.sci-hub.tw.
[2018-03-02 15:33:26,850 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:33:26,851 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for sci-hub.tw
[2018-03-02 15:33:26,867 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): twin.sci-hub.tw
[2018-03-02 15:33:27,049 DEBUG requests.packages.urllib3.connectionpool] "GET /7daecb18d54c05e7e403ee184cce3c11/pilkington2003.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:27,054 DEBUG scholar] Handle paper #255 (total 1170)
[2018-03-02 15:33:27,054 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:33:27,058 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:27,058 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:33:27,058 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for scholar.google.com
[2018-03-02 15:33:27,076 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:33:27,077 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:33:28,479 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:cd1cVTSOzdkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC6FtOW8uwI7JieZLwrxvy6i2FvKk&scisf=3&ct=citation&cd=254&hl=en HTTP/1.1" 200 211
[2018-03-02 15:33:28,480 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatbots in the Metropolis
%A Cummings, Kevin
%A Kunzelman, Cameron
%J Communication and Control: Tools, Systems, and New Dimensions
%P 97
%@ 0739198769
%D 2015
%I Lexington Books

[2018-03-02 15:33:28,480 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:28,480 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:28,481 DEBUG __main__] Process content of EndNote file #255
{"title": "Chatbots in the Metropolis", "url": "https://books.google.com/books?hl=en&lr=&id=aNLRCQAAQBAJ&oi=fnd&pg=PA97&dq=Use+deep+learning+to+create+a+chatbot&ots=Mj-rLobCll&sig=RYoXEgLFq2DjpJWC4yYjElfQ08I", "author": [{"shortname": "K Cummings", "gid": ""}, {"shortname": "C Kunzelman", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "Chatbots in the Metropolis", "author": ["Cummings, Kevin", "Kunzelman, Cameron"], "journal": "Communication and Control: Tools, Systems, and New Dimensions", "pages": "97", "isbn/issn": "0739198769", "year": "2015", "publisher": "Lexington Books", "EndNote": "%0 Journal Article\n%T Chatbots in the Metropolis\n%A Cummings, Kevin\n%A Kunzelman, Cameron\n%J Communication and Control: Tools, Systems, and New Dimensions\n%P 97\n%@ 0739198769\n%D 2015\n%I Lexington Books\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:cd1cVTSOzdkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC6FtOW8uwI7JieZLwrxvy6i2FvKk&scisf=3&ct=citation&cd=254&hl=en"}
[2018-03-02 15:33:28,481 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatbots in the Metropolis", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:33:28,481 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatbots in the Metropolis', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:33:28,481 DEBUG dbutils] Query result: []
[2018-03-02 15:33:28,481 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:28,481 DEBUG dbutils] Add new paper (title='Chatbots in the Metropolis')
[2018-03-02 15:33:28,481 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatbots in the Metropolis', 'year': 2015, 'publisher': 'Lexington Books', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Chatbots in the Metropolis\n%A Cummings, Kevin\n%A Kunzelman, Cameron\n%J Communication and Control: Tools, Systems, and New Dimensions\n%P 97\n%@ 0739198769\n%D 2015\n%I Lexington Books\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:28,482 DEBUG dbutils] Query result: 233
[2018-03-02 15:33:28,484 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=aNLRCQAAQBAJ&oi=fnd&pg=PA97&dq=Use+deep+learning+to+create+a+chatbot&ots=Mj-rLobCll&sig=RYoXEgLFq2DjpJWC4yYjElfQ08I.
[2018-03-02 15:33:28,484 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=aNLRCQAAQBAJ&oi=fnd&pg=PA97&dq=Use+deep+learning+to+create+a+chatbot&ots=Mj-rLobCll&sig=RYoXEgLFq2DjpJWC4yYjElfQ08I.
[2018-03-02 15:33:28,660 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=aNLRCQAAQBAJ&oi=fnd&pg=PA97&dq=Use+deep+learning+to+create+a+chatbot&ots=Mj-rLobCll&sig=RYoXEgLFq2DjpJWC4yYjElfQ08I HTTP/1.1" 302 None
[2018-03-02 15:33:28,849 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:33:28,869 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:28,870 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:33:29,099 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=aNLRCQAAQBAJ&oi=fnd&pg=PA97&dq=Use+deep+learning+to+create+a+chatbot&ots=Mj-rLobCll&sig=RYoXEgLFq2DjpJWC4yYjElfQ08I HTTP/1.1" 302 None
[2018-03-02 15:33:29,289 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:33:29,321 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:33:29,323 DEBUG scholar] Handle paper #256 (total 1170)
[2018-03-02 15:33:29,323 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:33:29,327 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:29,327 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:33:29,716 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Up_VVmu1z_cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC5_4kAS84UkzfcmX9jRC2N7D8o5I&scisf=3&ct=citation&cd=255&hl=en HTTP/1.1" 200 277
[2018-03-02 15:33:29,717 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind
%A Liu, Wei
%A Zhang, Jie
%A Feng, Sheng
%B Computational and Business Intelligence (ISCBI), 2015 3rd International Symposium on
%P 95-99
%@ 1467385018
%D 2015
%I IEEE

[2018-03-02 15:33:29,717 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:29,717 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:29,717 DEBUG __main__] Process content of EndNote file #256
{"title": "An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind", "url": "http://ieeexplore.ieee.org/abstract/document/7383544/", "author": [{"shortname": "W Liu", "gid": ""}, {"shortname": "J Zhang", "gid": ""}, {"shortname": "S Feng", "gid": ""}], "year": 2015}
{"citedby": 1, "type": "Conference Proceedings", "title": "An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind", "author": ["Liu, Wei", "Zhang, Jie", "Feng, Sheng"], "secondarytitle": "Computational and Business Intelligence (ISCBI), 2015 3rd International Symposium on", "pages": "95-99", "isbn/issn": "1467385018", "year": "2015", "publisher": "IEEE", "start_page": 95, "end_page": 99, "volume": 5, "EndNote": "%0 Conference Proceedings\n%T An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind\n%A Liu, Wei\n%A Zhang, Jie\n%A Feng, Sheng\n%B Computational and Business Intelligence (ISCBI), 2015 3rd International Symposium on\n%P 95-99\n%@ 1467385018\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Up_VVmu1z_cJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC5_4kAS84UkzfcmX9jRC2N7D8o5I&scisf=3&ct=citation&cd=255&hl=en"}
[2018-03-02 15:33:29,717 DEBUG dbutils] Get paper id {"DOI": null, "title": "An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 5, "year": 2015, "rg_id": null, "start_page": 95, "end_page": 99}.
[2018-03-02 15:33:29,717 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 5, 'year': 2015, 'rg_id': None, 'start_page': 95, 'end_page': 99}
[2018-03-02 15:33:29,718 DEBUG dbutils] Query result: []
[2018-03-02 15:33:29,718 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:29,718 DEBUG dbutils] Add new paper (title='An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind')
[2018-03-02 15:33:29,718 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind', 'year': 2015, 'publisher': 'IEEE', 'start_page': 95, 'end_page': 99, 'pages': 5, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T An Ergonomics Evaluation to Chatbot Equipped with Knowledge-Rich Mind\n%A Liu, Wei\n%A Zhang, Jie\n%A Feng, Sheng\n%B Computational and Business Intelligence (ISCBI), 2015 3rd International Symposium on\n%P 95-99\n%@ 1467385018\n%D 2015\n%I IEEE\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:29,718 DEBUG dbutils] Query result: 234
[2018-03-02 15:33:29,719 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7383544/.
[2018-03-02 15:33:29,719 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7383544/.
[2018-03-02 15:33:29,869 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7383544/ HTTP/1.1" 200 None
[2018-03-02 15:33:29,870 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:29,870 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:33:29,870 DEBUG utils] Change proxy to {'https': '113.53.230.200:3128'} for sci-hub.tw
[2018-03-02 15:33:30,073 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7383544/ HTTP/1.1" 200 None
[2018-03-02 15:33:30,080 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true.
[2018-03-02 15:33:30,081 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true') and save (filename='PDF//234.pdf')
[2018-03-02 15:33:30,097 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): cyber.sci-hub.tw
[2018-03-02 15:33:30,310 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:30,310 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:33:30,311 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 15:33:30,324 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): cyber.sci-hub.tw
[2018-03-02 15:33:30,569 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:30,572 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:33:30,572 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 15:33:39,074 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:33:39,074 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:33:39,414 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:39,415 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:33:39,415 DEBUG utils] Proxy: {'https': '113.53.230.200:3128'}
[2018-03-02 15:33:39,415 DEBUG utils] Change proxy to {'https': '103.85.24.48:6666'} for sci-hub.tw
[2018-03-02 15:33:39,431 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): cyber.sci-hub.tw
[2018-03-02 15:33:39,669 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9pc2NiaS4yMDE1LjI0/liu2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:33:39,675 DEBUG scholar] Handle paper #257 (total 1170)
[2018-03-02 15:33:39,675 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:33:39,679 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:39,679 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:33:39,679 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for scholar.google.com
[2018-03-02 15:33:39,702 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:33:39,703 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:33:41,349 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:QHIeNb9LFj8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC2VhFDXY9kg3HbTF9uxbVPUxJghK&scisf=3&ct=citation&cd=256&hl=en HTTP/1.1" 200 187
[2018-03-02 15:33:41,350 DEBUG scholar] EndNote file:
%0 Journal Article
%T The racial formation of chatbots
%A Marino, Mark C
%J CLCWeb: Comparative Literature and Culture
%V 16
%N 5
%@ 1481-4374
%D 2014
%I Purdue University Press

[2018-03-02 15:33:41,350 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:41,350 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:41,350 DEBUG __main__] Process content of EndNote file #257
{"title": "The racial formation of chatbots", "url": "http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w", "author": [{"shortname": "MC Marino", "gid": "5M-pJqIAAAAJ"}], "year": 2014}
{"type": "Journal Article", "title": "The racial formation of chatbots", "author": ["Marino, Mark C"], "journal": "CLCWeb: Comparative Literature and Culture", "volume": "16", "numberorissue": "5", "isbn/issn": "1481-4374", "year": "2014", "publisher": "Purdue University Press", "EndNote": "%0 Journal Article\n%T The racial formation of chatbots\n%A Marino, Mark C\n%J CLCWeb: Comparative Literature and Culture\n%V 16\n%N 5\n%@ 1481-4374\n%D 2014\n%I Purdue University Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:QHIeNb9LFj8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC2VhFDXY9kg3HbTF9uxbVPUxJghK&scisf=3&ct=citation&cd=256&hl=en"}
[2018-03-02 15:33:41,350 DEBUG dbutils] Get paper id {"DOI": null, "title": "The racial formation of chatbots", "auth_count": 1, "g_type": "Journal Article", "pages": 16, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:33:41,351 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The racial formation of chatbots', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 16, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:33:41,351 DEBUG dbutils] Query result: []
[2018-03-02 15:33:41,351 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:41,351 DEBUG dbutils] Add new paper (title='The racial formation of chatbots')
[2018-03-02 15:33:41,351 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The racial formation of chatbots', 'year': 2014, 'publisher': 'Purdue University Press', 'start_page': None, 'end_page': None, 'pages': 16, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The racial formation of chatbots\n%A Marino, Mark C\n%J CLCWeb: Comparative Literature and Culture\n%V 16\n%N 5\n%@ 1481-4374\n%D 2014\n%I Purdue University Press\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:41,351 DEBUG dbutils] Query result: 235
[2018-03-02 15:33:41,354 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w.
[2018-03-02 15:33:41,354 DEBUG scihub] Get page from sci-hub for paper with DOI=http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w.
[2018-03-02 15:33:42,263 DEBUG requests.packages.urllib3.connectionpool] "GET //http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w HTTP/1.1" 302 None
[2018-03-02 15:33:43,039 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/auth/capmAuthentication.do?&sid=googleScholar&origURL=http%3A%2F%2Fgo.galegroup.com%2Fps%2Fi.do%3Fid%3DGALE%257CA451229415%26sid%3DgoogleScholar%26v%3D2.1%26it%3Dr%26linkaccess%3Dfulltext%26issn%3D14814374%26p%3DAONE%26sw%3Dw%26authCount%3D1&productShortName=AONE&linkaccess=fulltext&isStartUrlRequest=false HTTP/1.1" 302 None
[2018-03-02 15:33:43,859 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/auth/capmAuthentication.do?&sid=googleScholar&origURL=http%3A%2F%2Fgo.galegroup.com%2Fps%2Fi.do%3Fid%3DGALE%257CA451229415%26sid%3DgoogleScholar%26v%3D2.1%26it%3Dr%26linkaccess%3Dfulltext%26issn%3D14814374%26p%3DAONE%26sw%3Dw%26authCount%3D1&productShortName=AONE&linkaccess=fulltext&isStartUrlRequest=false&isCookieCheckDone=false HTTP/1.1" 302 None
[2018-03-02 15:33:44,654 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w&authCount=1 HTTP/1.1" 302 None
[2018-03-02 15:33:46,471 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/ps/i.do;jsessionid=099FF8D043900B9F6813C64C63E80864.omni_as02?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w&authCount=1&u=crepuq_bishop&selfRedirect=true HTTP/1.1" 200 None
[2018-03-02 15:33:46,633 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:33:46,633 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:33:47,519 DEBUG requests.packages.urllib3.connectionpool] "GET //http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w HTTP/1.1" 302 None
[2018-03-02 15:33:48,445 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/auth/capmAuthentication.do?&sid=googleScholar&origURL=http%3A%2F%2Fgo.galegroup.com%2Fps%2Fi.do%3Fid%3DGALE%257CA451229415%26sid%3DgoogleScholar%26v%3D2.1%26it%3Dr%26linkaccess%3Dfulltext%26issn%3D14814374%26p%3DAONE%26sw%3Dw%26authCount%3D1&productShortName=AONE&productLongName=Academic+OneFile&linkaccess=fulltext&isStartUrlRequest=false HTTP/1.1" 302 None
[2018-03-02 15:33:49,436 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/auth/capmAuthentication.do?&sid=googleScholar&origURL=http%3A%2F%2Fgo.galegroup.com%2Fps%2Fi.do%3Fid%3DGALE%257CA451229415%26sid%3DgoogleScholar%26v%3D2.1%26it%3Dr%26linkaccess%3Dfulltext%26issn%3D14814374%26p%3DAONE%26sw%3Dw%26authCount%3D1&productShortName=AONE&productLongName=Academic+OneFile&linkaccess=fulltext&isStartUrlRequest=false&isCookieCheckDone=false HTTP/1.1" 302 None
[2018-03-02 15:33:50,329 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/ps/i.do?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w&authCount=1 HTTP/1.1" 302 None
[2018-03-02 15:33:51,959 DEBUG requests.packages.urllib3.connectionpool] "GET /http://go.galegroup.com/ps/i.do;jsessionid=97DC7BFA3DA353E604397F8A65C76BD8.omni_as02?id=GALE%7CA451229415&sid=googleScholar&v=2.1&it=r&linkaccess=fulltext&issn=14814374&p=AONE&sw=w&authCount=1&u=crepuq_bishop&selfRedirect=true HTTP/1.1" 200 None
[2018-03-02 15:33:52,240 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:33:52,241 DEBUG scholar] Handle paper #258 (total 1170)
[2018-03-02 15:33:52,241 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:33:52,245 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:33:52,245 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:33:52,589 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:kg8m6t6vpFoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC49vv-CarA35ft18m7MmFnk-8txW&scisf=3&ct=citation&cd=257&hl=en HTTP/1.1" 200 237
[2018-03-02 15:33:52,590 DEBUG scholar] EndNote file:
%0 Journal Article
%T Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents
%A Mazur, Michal
%A Rzepka, Rafal
%A Araki, Kenji
%J LINGUISTIC AND COGNITIVE APPROACHES TO DIALOGUE AGENTS
%P 61
%D 2012

[2018-03-02 15:33:52,590 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:33:52,590 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:33:52,590 DEBUG __main__] Process content of EndNote file #258
{"title": "Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents", "url": "http://arakilab.media.eng.hokudai.ac.jp/~araki/2012/2012-A-9.pdf", "author": [{"shortname": "M Mazur", "gid": ""}, {"shortname": "R Rzepka", "gid": "KUiGeGMAAAAJ"}, {"shortname": "K Araki", "gid": ""}], "year": 2012}
{"citedby": 1, "type": "Journal Article", "title": "Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents", "author": ["Mazur, Michal", "Rzepka, Rafal", "Araki, Kenji"], "journal": "LINGUISTIC AND COGNITIVE APPROACHES TO DIALOGUE AGENTS", "pages": "61", "year": "2012", "EndNote": "%0 Journal Article\n%T Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents\n%A Mazur, Michal\n%A Rzepka, Rafal\n%A Araki, Kenji\n%J LINGUISTIC AND COGNITIVE APPROACHES TO DIALOGUE AGENTS\n%P 61\n%D 2012\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:kg8m6t6vpFoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC49vv-CarA35ft18m7MmFnk-8txW&scisf=3&ct=citation&cd=257&hl=en"}
[2018-03-02 15:33:52,590 DEBUG dbutils] Get paper id {"DOI": null, "title": "Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents", "auth_count": 3, "g_type": "Journal Article", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:33:52,590 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:33:52,590 DEBUG dbutils] Query result: []
[2018-03-02 15:33:52,590 DEBUG dbutils] Paper id = None.
[2018-03-02 15:33:52,591 DEBUG dbutils] Add new paper (title='Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents')
[2018-03-02 15:33:52,591 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents', 'year': 2012, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Chatterbots with Occupation-Between Non Task and Task Oriented Conversational Agents\n%A Mazur, Michal\n%A Rzepka, Rafal\n%A Araki, Kenji\n%J LINGUISTIC AND COGNITIVE APPROACHES TO DIALOGUE AGENTS\n%P 61\n%D 2012\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:33:52,591 DEBUG dbutils] Query result: 236
[2018-03-02 15:33:52,592 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://arakilab.media.eng.hokudai.ac.jp/~araki/2012/2012-A-9.pdf.
[2018-03-02 15:33:52,593 WARNING utils] Download file (url='http://arakilab.media.eng.hokudai.ac.jp/~araki/2012/2012-A-9.pdf') and save (filename='PDF//236.pdf')
[2018-03-02 15:33:52,593 DEBUG utils] Get current proxy for arakilab.media.eng.hokudai.ac.jp.
[2018-03-02 15:33:52,593 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:33:52,594 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for otherhost
[2018-03-02 15:33:52,611 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): arakilab.media.eng.hokudai.ac.jp
[2018-03-02 15:33:53,408 DEBUG requests.packages.urllib3.connectionpool] "GET /~araki/2012/2012-A-9.pdf HTTP/1.1" 200 1496679
[2018-03-02 15:33:53,408 DEBUG utils] Content-length=1496679
[2018-03-02 15:33:53,409 DEBUG utils] Create file PDF//236.pdf, start download.
[2018-03-02 15:34:11,783 DEBUG utils] End download file PDF//236.pdf.
[2018-03-02 15:34:11,784 DEBUG dbutils] Update pdf_transaction for paper id=236.
[2018-03-02 15:34:11,784 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 236'
[2018-03-02 15:34:11,784 DEBUG dbutils] Query result: null
[2018-03-02 15:34:11,785 DEBUG scholar] Handle paper #259 (total 1170)
[2018-03-02 15:34:11,785 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:34:11,793 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:11,793 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:34:11,793 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for scholar.google.com
[2018-03-02 15:34:11,813 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:34:16,815 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708E39E10>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:VJZLpwCr6d4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHCzkWiiAFdkPi8tTDrqOTP5Qfot5q&scisf=3&ct=citation&cd=258&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708E39E10>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:VJZLpwCr6d4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHCzkWiiAFdkPi8tTDrqOTP5Qfot5q&scisf=3&ct=citation&cd=258&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007708E39E10>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 15:34:16,815 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for scholar.google.com
[2018-03-02 15:34:16,815 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:16,815 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:34:16,837 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:34:16,838 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:34:18,463 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:VJZLpwCr6d4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHCzkWiiAFdkPi8tTDrqOTP5Qfot5q&scisf=3&ct=citation&cd=258&hl=en HTTP/1.1" 200 242
[2018-03-02 15:34:18,464 DEBUG scholar] EndNote file:
%0 Journal Article
%T Designing an interactive open-domain question answering system
%A Quarteroni, Silvia
%A Manandhar, Suresh
%J Natural Language Engineering
%V 15
%N 1
%P 73-95
%@ 1469-8110
%D 2009
%I Cambridge University Press

[2018-03-02 15:34:18,464 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:18,464 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:18,464 DEBUG __main__] Process content of EndNote file #259
{"title": "Designing an interactive open-domain question answering system", "url": "https://www.cambridge.org/core/journals/natural-language-engineering/article/designing-an-interactive-opendomain-question-answering-system/87865E4C810D55354EF37DA968540FAA", "author": [{"shortname": "S Quarteroni", "gid": ""}, {"shortname": "S Manandhar", "gid": "5iH8GVIAAAAJ"}], "year": 2009}
{"citedby": 83, "type": "Journal Article", "title": "Designing an interactive open-domain question answering system", "author": ["Quarteroni, Silvia", "Manandhar, Suresh"], "journal": "Natural Language Engineering", "volume": 23, "numberorissue": "1", "pages": "73-95", "isbn/issn": "1469-8110", "year": "2009", "publisher": "Cambridge University Press", "start_page": 73, "end_page": 95, "EndNote": "%0 Journal Article\n%T Designing an interactive open-domain question answering system\n%A Quarteroni, Silvia\n%A Manandhar, Suresh\n%J Natural Language Engineering\n%V 15\n%N 1\n%P 73-95\n%@ 1469-8110\n%D 2009\n%I Cambridge University Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:VJZLpwCr6d4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHCzkWiiAFdkPi8tTDrqOTP5Qfot5q&scisf=3&ct=citation&cd=258&hl=en"}
[2018-03-02 15:34:18,464 DEBUG dbutils] Get paper id {"DOI": null, "title": "Designing an interactive open-domain question answering system", "auth_count": 2, "g_type": "Journal Article", "pages": 23, "year": 2009, "rg_id": null, "start_page": 73, "end_page": 95}.
[2018-03-02 15:34:18,464 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Designing an interactive open-domain question answering system', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 23, 'year': 2009, 'rg_id': None, 'start_page': 73, 'end_page': 95}
[2018-03-02 15:34:18,465 DEBUG dbutils] Query result: []
[2018-03-02 15:34:18,465 DEBUG dbutils] Paper id = None.
[2018-03-02 15:34:18,465 DEBUG dbutils] Add new paper (title='Designing an interactive open-domain question answering system')
[2018-03-02 15:34:18,465 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Designing an interactive open-domain question answering system', 'year': 2009, 'publisher': 'Cambridge University Press', 'start_page': 73, 'end_page': 95, 'pages': 23, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Designing an interactive open-domain question answering system\n%A Quarteroni, Silvia\n%A Manandhar, Suresh\n%J Natural Language Engineering\n%V 15\n%N 1\n%P 73-95\n%@ 1469-8110\n%D 2009\n%I Cambridge University Press\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:34:18,465 DEBUG dbutils] Query result: 237
[2018-03-02 15:34:18,466 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.cambridge.org/core/journals/natural-language-engineering/article/designing-an-interactive-opendomain-question-answering-system/87865E4C810D55354EF37DA968540FAA.
[2018-03-02 15:34:18,466 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.cambridge.org/core/journals/natural-language-engineering/article/designing-an-interactive-opendomain-question-answering-system/87865E4C810D55354EF37DA968540FAA.
[2018-03-02 15:34:18,803 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/natural-language-engineering/article/designing-an-interactive-opendomain-question-answering-system/87865E4C810D55354EF37DA968540FAA HTTP/1.1" 200 None
[2018-03-02 15:34:18,804 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:34:18,804 DEBUG utils] Proxy: {'https': '103.85.24.48:6666'}
[2018-03-02 15:34:18,804 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for sci-hub.tw
[2018-03-02 15:34:19,068 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.cambridge.org/core/journals/natural-language-engineering/article/designing-an-interactive-opendomain-question-answering-system/87865E4C810D55354EF37DA968540FAA HTTP/1.1" 200 None
[2018-03-02 15:34:19,090 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true.
[2018-03-02 15:34:19,091 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true') and save (filename='PDF//237.pdf')
[2018-03-02 15:34:19,279 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:34:19,280 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:34:19,280 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:34:19,294 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (4): cyber.sci-hub.tw
[2018-03-02 15:34:19,518 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:34:19,521 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:34:19,521 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:34:30,398 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:34:30,398 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:34:30,762 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true HTTP/1.1" 200 690283
[2018-03-02 15:34:30,763 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:34:30,763 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:34:30,763 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for sci-hub.tw
[2018-03-02 15:34:30,779 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (5): cyber.sci-hub.tw
[2018-03-02 15:34:31,004 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTAxNy9zMTM1MTMyNDkwODAwNDkxOQ==/quarteroni2008.pdf?download=true HTTP/1.1" 200 690283
[2018-03-02 15:34:31,005 DEBUG utils] Content-length=690283
[2018-03-02 15:34:31,005 DEBUG utils] Create file PDF//237.pdf, start download.
[2018-03-02 15:34:31,830 DEBUG utils] End download file PDF//237.pdf.
[2018-03-02 15:34:31,831 DEBUG dbutils] Update pdf_transaction for paper id=237.
[2018-03-02 15:34:31,831 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 237'
[2018-03-02 15:34:31,831 DEBUG dbutils] Query result: null
[2018-03-02 15:34:31,831 DEBUG scholar] Handle paper #260 (total 1170)
[2018-03-02 15:34:31,832 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:34:31,835 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:31,836 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:34:31,836 DEBUG utils] Change proxy to {'https': '13.56.78.34:3128'} for scholar.google.com
[2018-03-02 15:34:31,853 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:34:31,855 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:34:33,798 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:xq465OPfAZUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHC5ENPHnQNSZVajCGeklzxHmUV1lJ&scisf=3&ct=citation&cd=259&hl=en HTTP/1.1" 200 185
[2018-03-02 15:34:33,799 DEBUG scholar] EndNote file:
%0 Journal Article
%T Symposium: Current and Future Issues in Research into ICT in Education
%A Cox, Margaret
%A Webb, Andrew Fluck2 Mary
%A Twining, Peter
%A Bottino, Rosa Maria

[2018-03-02 15:34:33,799 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:33,799 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:33,800 DEBUG __main__] Skip paper #260, empty year or authors fields.
[2018-03-02 15:34:33,816 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:34:33,817 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:34:33,817 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:34:33,831 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:34:35,850 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=260&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:34:36,229 DEBUG scholar] Find papers on page #27 (max_google_papers = 300)
[2018-03-02 15:34:36,229 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:34:36,230 DEBUG scholar] Handle paper #261 (total 1170)
[2018-03-02 15:34:36,230 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:34:36,233 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:36,234 DEBUG utils] Proxy: {'https': '13.56.78.34:3128'}
[2018-03-02 15:34:36,234 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for scholar.google.com
[2018-03-02 15:34:36,251 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:34:36,254 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:34:37,888 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nmKRZRHm4DUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHePeZo2SxxudyUbtIKINZEZ9amZIN&scisf=3&ct=citation&cd=260&hl=en HTTP/1.1" 200 242
[2018-03-02 15:34:37,889 DEBUG scholar] EndNote file:
%0 Journal Article
%T Role patterns in discussion forum interaction and its criteria in e-learning
%A Mohamad, Nadirah
%A Yusof, Norazah
%A Suhaimi, Shaffika Mohd
%A Othman, Mohd Shahizan
%J Published and Printed in Malaysia by
%P 67

[2018-03-02 15:34:37,889 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:37,889 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:37,889 DEBUG __main__] Skip paper #261, empty year or authors fields.
[2018-03-02 15:34:37,889 DEBUG scholar] Handle paper #262 (total 1170)
[2018-03-02 15:34:37,889 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:34:37,891 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:37,891 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:34:38,208 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:VcpUqFljXgkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeBJRl8JjgytE20Qe6int_4_CXnOg&scisf=3&ct=citation&cd=261&hl=en HTTP/1.1" 200 255
[2018-03-02 15:34:38,209 DEBUG scholar] EndNote file:
%0 Journal Article
%T An artificial intelligence experiment in college math education
%A Knill, Oliver
%A Carlsson, Johnny
%A Chi, Andrew
%A Lezama, Mark
%J Preprint available at http://www. math. harvard. edu/~ knill/preprints/sofia. pdf
%D 2004

[2018-03-02 15:34:38,209 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:38,209 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:38,209 DEBUG __main__] Process content of EndNote file #262
{"title": "An artificial intelligence experiment in college math education", "url": "http://www.math.harvard.edu/~knill/preprints/sofia.pdf", "author": [{"shortname": "O Knill", "gid": "JBgNO68AAAAJ"}, {"shortname": "J Carlsson", "gid": ""}, {"shortname": "A Chi", "gid": ""}], "year": 2004}
{"citedby": 11, "type": "Journal Article", "title": "An artificial intelligence experiment in college math education", "author": ["Knill, Oliver", "Carlsson, Johnny", "Chi, Andrew", "Lezama, Mark"], "journal": "Preprint available at http://www. math. harvard. edu/~ knill/preprints/sofia. pdf", "year": "2004", "EndNote": "%0 Journal Article\n%T An artificial intelligence experiment in college math education\n%A Knill, Oliver\n%A Carlsson, Johnny\n%A Chi, Andrew\n%A Lezama, Mark\n%J Preprint available at http://www. math. harvard. edu/~ knill/preprints/sofia. pdf\n%D 2004\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:VcpUqFljXgkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeBJRl8JjgytE20Qe6int_4_CXnOg&scisf=3&ct=citation&cd=261&hl=en"}
[2018-03-02 15:34:38,209 DEBUG dbutils] Get paper id {"DOI": null, "title": "An artificial intelligence experiment in college math education", "auth_count": 4, "g_type": "Journal Article", "pages": null, "year": 2004, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:34:38,210 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An artificial intelligence experiment in college math education', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': None, 'year': 2004, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:34:38,210 DEBUG dbutils] Query result: []
[2018-03-02 15:34:38,210 DEBUG dbutils] Paper id = None.
[2018-03-02 15:34:38,210 DEBUG dbutils] Add new paper (title='An artificial intelligence experiment in college math education')
[2018-03-02 15:34:38,210 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An artificial intelligence experiment in college math education', 'year': 2004, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T An artificial intelligence experiment in college math education\n%A Knill, Oliver\n%A Carlsson, Johnny\n%A Chi, Andrew\n%A Lezama, Mark\n%J Preprint available at http://www. math. harvard. edu/~ knill/preprints/sofia. pdf\n%D 2004\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:34:38,210 DEBUG dbutils] Query result: 238
[2018-03-02 15:34:38,212 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.math.harvard.edu/~knill/preprints/sofia.pdf.
[2018-03-02 15:34:38,212 WARNING utils] Download file (url='http://www.math.harvard.edu/~knill/preprints/sofia.pdf') and save (filename='PDF//238.pdf')
[2018-03-02 15:34:38,212 DEBUG utils] Get current proxy for www.math.harvard.edu.
[2018-03-02 15:34:38,213 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:34:38,231 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.math.harvard.edu
[2018-03-02 15:34:38,820 DEBUG requests.packages.urllib3.connectionpool] "GET /~knill/preprints/sofia.pdf HTTP/1.1" 200 132947
[2018-03-02 15:34:38,820 DEBUG utils] Content-length=132947
[2018-03-02 15:34:38,820 DEBUG utils] Create file PDF//238.pdf, start download.
[2018-03-02 15:34:39,625 DEBUG utils] End download file PDF//238.pdf.
[2018-03-02 15:34:39,626 DEBUG dbutils] Update pdf_transaction for paper id=238.
[2018-03-02 15:34:39,627 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 238'
[2018-03-02 15:34:39,627 DEBUG dbutils] Query result: null
[2018-03-02 15:34:39,627 DEBUG scholar] Handle paper #263 (total 1170)
[2018-03-02 15:34:39,627 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:34:39,631 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:39,631 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:34:39,631 DEBUG utils] Change proxy to {'https': '103.228.117.244:8080'} for scholar.google.com
[2018-03-02 15:34:39,648 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:34:39,651 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:34:43,322 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ZpI76sImsAkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHePf04x_DVYL6ralnDxduWTCyW530&scisf=3&ct=citation&cd=262&hl=en HTTP/1.1" 200 296
[2018-03-02 15:34:43,323 DEBUG scholar] EndNote file:
%0 Journal Article
%T An easy to author dialogue management system for serious games
%A Mori, Daniele
%A Berta, Riccardo
%A De Gloria, Alessandro
%A Fiore, Valentina
%A Magnani, Lauto
%J Journal on Computing and Cultural Heritage (JOCCH)
%V 6
%N 2
%P 10
%@ 1556-4673
%D 2013
%I ACM

[2018-03-02 15:34:43,323 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:43,323 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:43,323 DEBUG __main__] Process content of EndNote file #263
{"title": "An easy to author dialogue management system for serious games", "url": "https://dl.acm.org/citation.cfm?id=2460381", "author": [{"shortname": "D Mori", "gid": ""}, {"shortname": "R Berta", "gid": "Y9h_TMwAAAAJ"}, {"shortname": "A De Gloria", "gid": ""}, {"shortname": "V Fiore", "gid": ""}], "year": 2013}
{"citedby": 19, "type": "Journal Article", "title": "An easy to author dialogue management system for serious games", "author": ["Mori, Daniele", "Berta, Riccardo", "De Gloria, Alessandro", "Fiore, Valentina", "Magnani, Lauto"], "journal": "Journal on Computing and Cultural Heritage (JOCCH)", "volume": "6", "numberorissue": "2", "pages": "10", "isbn/issn": "1556-4673", "year": "2013", "publisher": "ACM", "EndNote": "%0 Journal Article\n%T An easy to author dialogue management system for serious games\n%A Mori, Daniele\n%A Berta, Riccardo\n%A De Gloria, Alessandro\n%A Fiore, Valentina\n%A Magnani, Lauto\n%J Journal on Computing and Cultural Heritage (JOCCH)\n%V 6\n%N 2\n%P 10\n%@ 1556-4673\n%D 2013\n%I ACM\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ZpI76sImsAkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHePf04x_DVYL6ralnDxduWTCyW530&scisf=3&ct=citation&cd=262&hl=en"}
[2018-03-02 15:34:43,324 DEBUG dbutils] Get paper id {"DOI": null, "title": "An easy to author dialogue management system for serious games", "auth_count": 5, "g_type": "Journal Article", "pages": 6, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:34:43,324 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'An easy to author dialogue management system for serious games', 'auth_count': 5, 'g_type': 'Journal Article', 'pages': 6, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:34:43,324 DEBUG dbutils] Query result: []
[2018-03-02 15:34:43,324 DEBUG dbutils] Paper id = None.
[2018-03-02 15:34:43,324 DEBUG dbutils] Add new paper (title='An easy to author dialogue management system for serious games')
[2018-03-02 15:34:43,324 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'An easy to author dialogue management system for serious games', 'year': 2013, 'publisher': 'ACM', 'start_page': None, 'end_page': None, 'pages': 6, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T An easy to author dialogue management system for serious games\n%A Mori, Daniele\n%A Berta, Riccardo\n%A De Gloria, Alessandro\n%A Fiore, Valentina\n%A Magnani, Lauto\n%J Journal on Computing and Cultural Heritage (JOCCH)\n%V 6\n%N 2\n%P 10\n%@ 1556-4673\n%D 2013\n%I ACM\n', 'RIS': None, 'authors': 5, 'ignore': False, 'transaction': 1}
[2018-03-02 15:34:43,324 DEBUG dbutils] Query result: 239
[2018-03-02 15:34:43,326 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://dl.acm.org/citation.cfm?id=2460381.
[2018-03-02 15:34:43,326 DEBUG scihub] Get page from sci-hub for paper with DOI=https://dl.acm.org/citation.cfm?id=2460381.
[2018-03-02 15:34:44,658 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2460381 HTTP/1.1" 200 None
[2018-03-02 15:34:44,659 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:34:44,659 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:34:44,848 DEBUG requests.packages.urllib3.connectionpool] "GET //https://dl.acm.org/citation.cfm?id=2460381 HTTP/1.1" 200 None
[2018-03-02 15:34:44,854 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true.
[2018-03-02 15:34:44,855 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true') and save (filename='PDF//239.pdf')
[2018-03-02 15:34:44,870 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: dabamirror.sci-hub.tw
[2018-03-02 15:34:45,085 DEBUG requests.packages.urllib3.connectionpool] "GET /eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:34:45,086 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:34:45,086 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:34:45,086 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for sci-hub.tw
[2018-03-02 15:34:45,104 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (10): dabamirror.sci-hub.tw
[2018-03-02 15:34:45,278 DEBUG requests.packages.urllib3.connectionpool] "GET /eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:34:45,282 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:34:45,282 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:34:57,599 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:34:57,599 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:34:57,886 DEBUG requests.packages.urllib3.connectionpool] "GET /eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true HTTP/1.1" 200 298815
[2018-03-02 15:34:57,887 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:34:57,887 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:34:57,933 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (11): dabamirror.sci-hub.tw
[2018-03-02 15:34:58,151 DEBUG requests.packages.urllib3.connectionpool] "GET /eadfa2ff865b9de9da06a54588c2f485/mori2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:34:58,156 DEBUG scholar] Handle paper #264 (total 1170)
[2018-03-02 15:34:58,157 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:34:58,160 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:58,160 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:34:58,738 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:2H1h53MCfukJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeKoNHyKqI21OpbNdJKAGnk8FCcP9&scisf=3&ct=citation&cd=263&hl=en HTTP/1.1" 200 62
[2018-03-02 15:34:58,738 DEBUG scholar] EndNote file:
%0 Journal Article
%T Internship Report
%A Treglia, Chiara

[2018-03-02 15:34:58,738 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:34:58,738 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:34:58,739 DEBUG __main__] Skip paper #264, empty year or authors fields.
[2018-03-02 15:34:58,739 DEBUG scholar] Handle paper #265 (total 1170)
[2018-03-02 15:34:58,739 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:34:58,742 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:34:58,742 DEBUG utils] Proxy: {'https': '103.228.117.244:8080'}
[2018-03-02 15:34:58,742 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for scholar.google.com
[2018-03-02 15:34:58,760 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:35:00,118 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:vWazEQxMFuwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeMh5ORxIyB--kKd_ZXGHfB5IvFXO&scisf=3&ct=citation&cd=264&hl=en HTTP/1.1" 200 159
[2018-03-02 15:35:00,119 DEBUG scholar] EndNote file:
%0 Journal Article
%T Key pedagogical issues in online learning or using online facilitation to create learning that resonates
%A Brown, Stephen C
%D 2003

[2018-03-02 15:35:00,119 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:35:00,119 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:35:00,119 DEBUG __main__] Process content of EndNote file #265
{"title": "Key pedagogical issues in online learning or using online facilitation to create learning that resonates", "url": "https://www.researchgate.net/profile/Stephen_Brown19/publication/289505515_Key_pedagogical_issues_in_online_learning_or_using_online_facilitation_to_create_learning_that_resonates/links/568d4ec508aeaa1481ae49f0.pdf", "author": [{"shortname": "SC Brown", "gid": ""}], "year": 2003}
{"type": "Journal Article", "title": "Key pedagogical issues in online learning or using online facilitation to create learning that resonates", "author": ["Brown, Stephen C"], "year": "2003", "EndNote": "%0 Journal Article\n%T Key pedagogical issues in online learning or using online facilitation to create learning that resonates\n%A Brown, Stephen C\n%D 2003\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:vWazEQxMFuwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeMh5ORxIyB--kKd_ZXGHfB5IvFXO&scisf=3&ct=citation&cd=264&hl=en"}
[2018-03-02 15:35:00,119 DEBUG dbutils] Get paper id {"DOI": null, "title": "Key pedagogical issues in online learning or using online facilitation to create learning that resonates", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2003, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:35:00,119 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Key pedagogical issues in online learning or using online facilitation to create learning that resonates', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2003, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:35:00,120 DEBUG dbutils] Query result: []
[2018-03-02 15:35:00,120 DEBUG dbutils] Paper id = None.
[2018-03-02 15:35:00,120 DEBUG dbutils] Add new paper (title='Key pedagogical issues in online learning or using online facilitation to create learning that resonates')
[2018-03-02 15:35:00,120 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Key pedagogical issues in online learning or using online facilitation to create learning that resonates', 'year': 2003, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Key pedagogical issues in online learning or using online facilitation to create learning that resonates\n%A Brown, Stephen C\n%D 2003\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:35:00,120 DEBUG dbutils] Query result: 240
[2018-03-02 15:35:00,122 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Stephen_Brown19/publication/289505515_Key_pedagogical_issues_in_online_learning_or_using_online_facilitation_to_create_learning_that_resonates/links/568d4ec508aeaa1481ae49f0.pdf.
[2018-03-02 15:35:00,124 WARNING utils] Download file (url='https://www.researchgate.net/profile/Stephen_Brown19/publication/289505515_Key_pedagogical_issues_in_online_learning_or_using_online_facilitation_to_create_learning_that_resonates/links/568d4ec508aeaa1481ae49f0.pdf') and save (filename='PDF//240.pdf')
[2018-03-02 15:35:00,124 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:35:00,124 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:35:00,124 DEBUG utils] Change proxy to {'https': '193.194.69.36:3128'} for www.researchgate.net
[2018-03-02 15:35:00,139 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:35:03,300 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Stephen_Brown19/publication/289505515_Key_pedagogical_issues_in_online_learning_or_using_online_facilitation_to_create_learning_that_resonates/links/568d4ec508aeaa1481ae49f0.pdf HTTP/1.1" 200 207773
[2018-03-02 15:35:03,301 DEBUG utils] Content-length=207773
[2018-03-02 15:35:03,302 DEBUG utils] Create file PDF//240.pdf, start download.
[2018-03-02 15:35:06,285 DEBUG utils] End download file PDF//240.pdf.
[2018-03-02 15:35:06,287 DEBUG dbutils] Update pdf_transaction for paper id=240.
[2018-03-02 15:35:06,287 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 240'
[2018-03-02 15:35:06,287 DEBUG dbutils] Query result: null
[2018-03-02 15:35:06,287 DEBUG scholar] Handle paper #266 (total 1170)
[2018-03-02 15:35:06,287 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:35:06,291 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:35:06,291 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:35:06,557 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ZsvI_WjqXygJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeMXdxFuvNF-1ypLBBDbGcUYzfJsz&scisf=3&ct=citation&cd=265&hl=en HTTP/1.1" 200 184
[2018-03-02 15:35:06,558 DEBUG scholar] EndNote file:
%0 Journal Article
%T Haciendolo realidad: ganador del Premio Loebner del diseno chatbot
%A Wilcox, Bruce
%A Wilcox, Sue
%J arbor
%V 189
%N 764
%P 086
%@ 1988-303X
%D 2013

[2018-03-02 15:35:06,558 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:35:06,558 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:35:06,559 DEBUG __main__] Process content of EndNote file #266
{"title": "Haci\u00e9ndolo realidad: ganador del Premio Loebner del dise\u00f1o chatbot", "url": "http://arbor.revistas.csic.es/index.php/arbor/article/view/1888", "author": [{"shortname": "B Wilcox", "gid": ""}, {"shortname": "S Wilcox", "gid": ""}], "year": 2013}
{"type": "Journal Article", "title": "Haci\u00e9ndolo realidad: ganador del Premio Loebner del dise\u00f1o chatbot", "author": ["Wilcox, Bruce", "Wilcox, Sue"], "journal": "arbor", "volume": "189", "numberorissue": "764", "pages": "086", "isbn/issn": "1988-303X", "year": "2013", "EndNote": "%0 Journal Article\n%T Haci\u00e9ndolo realidad: ganador del Premio Loebner del dise\u00f1o chatbot\n%A Wilcox, Bruce\n%A Wilcox, Sue\n%J arbor\n%V 189\n%N 764\n%P 086\n%@ 1988-303X\n%D 2013\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:ZsvI_WjqXygJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeMXdxFuvNF-1ypLBBDbGcUYzfJsz&scisf=3&ct=citation&cd=265&hl=en"}
[2018-03-02 15:35:06,559 DEBUG dbutils] Get paper id {"DOI": null, "title": "Haci\u00e9ndolo realidad: ganador del Premio Loebner del dise\u00f1o chatbot", "auth_count": 2, "g_type": "Journal Article", "pages": 189, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:35:06,559 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Haciendolo realidad: ganador del Premio Loebner del diseno chatbot', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 189, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:35:06,559 DEBUG dbutils] Query result: []
[2018-03-02 15:35:06,559 DEBUG dbutils] Paper id = None.
[2018-03-02 15:35:06,559 DEBUG dbutils] Add new paper (title='Haciendolo realidad: ganador del Premio Loebner del diseno chatbot')
[2018-03-02 15:35:06,559 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Haciendolo realidad: ganador del Premio Loebner del diseno chatbot', 'year': 2013, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 189, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Haciendolo realidad: ganador del Premio Loebner del diseno chatbot\n%A Wilcox, Bruce\n%A Wilcox, Sue\n%J arbor\n%V 189\n%N 764\n%P 086\n%@ 1988-303X\n%D 2013\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:35:06,559 DEBUG dbutils] Query result: 241
[2018-03-02 15:35:06,561 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://arbor.revistas.csic.es/index.php/arbor/article/view/1888.
[2018-03-02 15:35:06,561 DEBUG scihub] Get page from sci-hub for paper with DOI=http://arbor.revistas.csic.es/index.php/arbor/article/view/1888.
[2018-03-02 15:35:06,737 DEBUG requests.packages.urllib3.connectionpool] "GET //http://arbor.revistas.csic.es/index.php/arbor/article/view/1888 HTTP/1.1" 404 None
[2018-03-02 15:35:06,738 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:35:06,738 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:35:06,739 DEBUG utils] Change proxy to {'https': '95.183.27.105:8080'} for sci-hub.tw
[2018-03-02 15:35:06,917 DEBUG requests.packages.urllib3.connectionpool] "GET //http://arbor.revistas.csic.es/index.php/arbor/article/view/1888 HTTP/1.1" 404 None
[2018-03-02 15:35:06,920 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:35:06,920 DEBUG __main__] Failed get_pdf from sci-hub for paper #241. URL=241
[2018-03-02 15:35:06,921 DEBUG scholar] Handle paper #267 (total 1170)
[2018-03-02 15:35:06,921 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:35:06,924 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:35:06,925 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:35:06,925 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for scholar.google.com
[2018-03-02 15:35:06,940 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:35:06,942 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:35:08,708 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:P0v66T2WrlsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeBzEuf9-hyCAVKn_8pCC6hdppRUQ&scisf=3&ct=citation&cd=266&hl=en HTTP/1.1" 200 324
[2018-03-02 15:35:08,709 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Towards identifying unresolved discussions in student online forums
%A Kim, Jihie
%A Li, Jia
%A Kim, Taehwan
%B Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications
%P 84-91
%D 2010
%I Association for Computational Linguistics

[2018-03-02 15:35:08,709 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:35:08,709 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:35:08,709 DEBUG __main__] Process content of EndNote file #267
{"title": "Towards identifying unresolved discussions in student online forums", "url": "https://dl.acm.org/citation.cfm?id=1866807", "author": [{"shortname": "J Kim", "gid": "7JVMeT4AAAAJ"}, {"shortname": "J Li", "gid": ""}, {"shortname": "T Kim", "gid": "5dGWexcAAAAJ"}], "year": 2010}
{"citedby": 14, "type": "Conference Proceedings", "title": "Towards identifying unresolved discussions in student online forums", "author": ["Kim, Jihie", "Li, Jia", "Kim, Taehwan"], "secondarytitle": "Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications", "pages": "84-91", "year": "2010", "publisher": "Association for Computational Linguistics", "start_page": 84, "end_page": 91, "volume": 8, "EndNote": "%0 Conference Proceedings\n%T Towards identifying unresolved discussions in student online forums\n%A Kim, Jihie\n%A Li, Jia\n%A Kim, Taehwan\n%B Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications\n%P 84-91\n%D 2010\n%I Association for Computational Linguistics\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:P0v66T2WrlsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeBzEuf9-hyCAVKn_8pCC6hdppRUQ&scisf=3&ct=citation&cd=266&hl=en"}
[2018-03-02 15:35:08,709 DEBUG dbutils] Get paper id {"DOI": null, "title": "Towards identifying unresolved discussions in student online forums", "auth_count": 3, "g_type": "Conference Proceedings", "pages": 8, "year": 2010, "rg_id": null, "start_page": 84, "end_page": 91}.
[2018-03-02 15:35:08,709 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Towards identifying unresolved discussions in student online forums', 'auth_count': 3, 'g_type': 'Conference Proceedings', 'pages': 8, 'year': 2010, 'rg_id': None, 'start_page': 84, 'end_page': 91}
[2018-03-02 15:35:08,710 DEBUG dbutils] Query result: []
[2018-03-02 15:35:08,710 DEBUG dbutils] Paper id = None.
[2018-03-02 15:35:08,710 DEBUG dbutils] Add new paper (title='Towards identifying unresolved discussions in student online forums')
[2018-03-02 15:35:08,710 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Towards identifying unresolved discussions in student online forums', 'year': 2010, 'publisher': 'Association for Computational Linguistics', 'start_page': 84, 'end_page': 91, 'pages': 8, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Towards identifying unresolved discussions in student online forums\n%A Kim, Jihie\n%A Li, Jia\n%A Kim, Taehwan\n%B Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications\n%P 84-91\n%D 2010\n%I Association for Computational Linguistics\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:35:08,710 DEBUG dbutils] Query result: 242
[2018-03-02 15:35:08,711 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://aclanthology.info/pdf/W/W10/W10-1012.pdf.
[2018-03-02 15:35:08,712 WARNING utils] Download file (url='https://aclanthology.info/pdf/W/W10/W10-1012.pdf') and save (filename='PDF//242.pdf')
[2018-03-02 15:35:08,713 DEBUG utils] Get current proxy for aclanthology.info.
[2018-03-02 15:35:08,713 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:35:08,713 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for otherhost
[2018-03-02 15:35:08,727 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): aclanthology.info
[2018-03-02 15:35:12,912 DEBUG requests.packages.urllib3.connectionpool] "GET /pdf/W/W10/W10-1012.pdf HTTP/1.1" 200 209924
[2018-03-02 15:35:12,913 DEBUG utils] Content-length=209924
[2018-03-02 15:35:12,913 DEBUG utils] Create file PDF//242.pdf, start download.
[2018-03-02 15:35:13,408 DEBUG utils] End download file PDF//242.pdf.
[2018-03-02 15:35:13,409 DEBUG dbutils] Update pdf_transaction for paper id=242.
[2018-03-02 15:35:13,409 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 242'
[2018-03-02 15:35:13,409 DEBUG dbutils] Query result: null
[2018-03-02 15:35:13,410 DEBUG scholar] Handle paper #268 (total 1170)
[2018-03-02 15:35:13,410 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:35:13,413 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:35:13,413 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:35:13,697 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:ewwsHS_qVLIJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeIbJs1nlzQXO8VxxZwxsS5xY-rwd&scisf=3&ct=citation&cd=267&hl=en HTTP/1.1" 200 163
[2018-03-02 15:35:13,698 DEBUG scholar] EndNote file:
%0 Journal Article
%T Intelligence Assessment for Early-Stage Software Systems Aimed at Human-Level, Roughly Human-Like AGI
%A Goertzel, Ben
%A Novamente, LLC

[2018-03-02 15:35:13,699 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:35:13,699 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:35:13,699 DEBUG __main__] Skip paper #268, empty year or authors fields.
[2018-03-02 15:35:13,699 DEBUG scholar] Handle paper #269 (total 1170)
[2018-03-02 15:35:13,699 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:35:13,702 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:35:13,702 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:35:13,702 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for scholar.google.com
[2018-03-02 15:35:13,717 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:35:13,718 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:35:15,157 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:wrBZdNMoAbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeLk56PKhl3-_ymGkFstGZ1EMGBxI&scisf=3&ct=citation&cd=268&hl=en HTTP/1.1" 200 101
[2018-03-02 15:35:15,158 DEBUG scholar] EndNote file:
%0 Journal Article
%T Introduction to Artificial Intelligence CS540-2
%A Gibson, Bryan R
%D 2014

[2018-03-02 15:35:15,158 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:35:15,159 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:35:15,159 DEBUG __main__] Process content of EndNote file #269
{"title": "Introduction to Artificial Intelligence CS540-2", "url": "https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf", "author": [{"shortname": "BR Gibson", "gid": ""}], "year": 2014}
{"type": "Journal Article", "title": "Introduction to Artificial Intelligence CS540-2", "author": ["Gibson, Bryan R"], "year": "2014", "EndNote": "%0 Journal Article\n%T Introduction to Artificial Intelligence CS540-2\n%A Gibson, Bryan R\n%D 2014\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:wrBZdNMoAbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeLk56PKhl3-_ymGkFstGZ1EMGBxI&scisf=3&ct=citation&cd=268&hl=en"}
[2018-03-02 15:35:15,159 DEBUG dbutils] Get paper id {"DOI": null, "title": "Introduction to Artificial Intelligence CS540-2", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:35:15,159 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Introduction to Artificial Intelligence CS540-2', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:35:15,159 DEBUG dbutils] Query result: []
[2018-03-02 15:35:15,159 DEBUG dbutils] Paper id = None.
[2018-03-02 15:35:15,159 DEBUG dbutils] Add new paper (title='Introduction to Artificial Intelligence CS540-2')
[2018-03-02 15:35:15,159 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Introduction to Artificial Intelligence CS540-2', 'year': 2014, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Introduction to Artificial Intelligence CS540-2\n%A Gibson, Bryan R\n%D 2014\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:35:15,159 DEBUG dbutils] Query result: 243
[2018-03-02 15:35:15,161 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf.
[2018-03-02 15:35:15,162 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf') and save (filename='PDF//243.pdf')
[2018-03-02 15:35:15,162 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:15,162 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:35:15,177 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:16,396 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:16,397 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:16,397 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for otherhost
[2018-03-02 15:35:16,398 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:16,398 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:35:16,413 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:18,317 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:18,318 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:18,318 DEBUG utils] Change proxy to {'https': '159.65.169.14:53'} for otherhost
[2018-03-02 15:35:18,320 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:18,320 DEBUG utils] Proxy: {'https': '159.65.169.14:53'}
[2018-03-02 15:35:18,334 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:19,557 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:19,558 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:19,558 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for otherhost
[2018-03-02 15:35:19,559 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:19,559 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:35:19,573 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:20,737 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:20,738 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:20,738 DEBUG utils] Change proxy to {'https': '192.116.142.153:8080'} for otherhost
[2018-03-02 15:35:20,739 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:20,739 DEBUG utils] Proxy: {'https': '192.116.142.153:8080'}
[2018-03-02 15:35:20,753 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:23,052 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:23,052 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:23,052 DEBUG utils] Change proxy to {'https': '46.163.186.9:3129'} for otherhost
[2018-03-02 15:35:23,054 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:23,054 DEBUG utils] Proxy: {'https': '46.163.186.9:3129'}
[2018-03-02 15:35:23,068 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:24,007 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:24,008 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:24,008 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for otherhost
[2018-03-02 15:35:24,009 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:24,010 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:35:24,024 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:24,917 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:24,917 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:24,917 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for otherhost
[2018-03-02 15:35:24,919 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:24,919 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:35:24,933 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:31,287 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:31,288 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:31,288 DEBUG utils] Change proxy to {'https': '190.242.119.194:3128'} for otherhost
[2018-03-02 15:35:31,290 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:31,290 DEBUG utils] Proxy: {'https': '190.242.119.194:3128'}
[2018-03-02 15:35:31,304 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:33,306 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:33,307 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:33,307 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for otherhost
[2018-03-02 15:35:33,309 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:33,309 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:35:33,323 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:34,607 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:34,608 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:34,608 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for otherhost
[2018-03-02 15:35:34,609 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:34,609 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:35:34,623 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:36,697 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:36,698 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:36,698 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for otherhost
[2018-03-02 15:35:36,700 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:36,700 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:35:36,713 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:39,717 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:39,717 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:39,717 DEBUG utils] Change proxy to {'https': '190.242.119.197:3128'} for otherhost
[2018-03-02 15:35:39,719 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:39,719 DEBUG utils] Proxy: {'https': '190.242.119.197:3128'}
[2018-03-02 15:35:39,733 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:41,566 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:41,567 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:41,567 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for otherhost
[2018-03-02 15:35:41,568 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:41,568 DEBUG utils] Proxy: {'https': '187.1.51.122:3128'}
[2018-03-02 15:35:41,583 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:44,357 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:44,357 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:44,358 DEBUG utils] Change proxy to {'https': '159.65.227.89:3128'} for otherhost
[2018-03-02 15:35:44,359 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:44,359 DEBUG utils] Proxy: {'https': '159.65.227.89:3128'}
[2018-03-02 15:35:44,373 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:45,737 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:45,737 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:45,737 DEBUG utils] Change proxy to {'https': '35.195.65.241:3128'} for otherhost
[2018-03-02 15:35:45,739 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:45,739 DEBUG utils] Proxy: {'https': '35.195.65.241:3128'}
[2018-03-02 15:35:45,755 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:35:45,756 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:35:46,527 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:46,527 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:46,527 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for otherhost
[2018-03-02 15:35:46,529 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:46,529 DEBUG utils] Proxy: {'https': '177.37.160.211:3128'}
[2018-03-02 15:35:46,545 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:35:46,546 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:35:48,949 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:48,949 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:48,950 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for otherhost
[2018-03-02 15:35:48,951 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:48,951 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:35:48,966 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:51,486 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:51,487 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:51,487 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for otherhost
[2018-03-02 15:35:51,488 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:51,488 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:35:51,503 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:35:52,656 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:52,657 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:52,657 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for otherhost
[2018-03-02 15:35:52,659 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:35:52,659 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:35:52,672 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:35:55,556 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:55,557 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:35:55,557 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for otherhost
[2018-03-02 15:35:55,561 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf.
[2018-03-02 15:35:55,561 DEBUG scihub] Get page from sci-hub for paper with DOI=https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf.
[2018-03-02 15:35:55,766 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:35:55,790 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:35:56,326 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:35:56,327 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:35:56,328 DEBUG utils] Proxy: {'https': '95.183.27.105:8080'}
[2018-03-02 15:35:56,517 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:35:56,538 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:01,539 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703DD2780>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703DD2780>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007703DD2780>, 'Connection to 95.183.27.105 timed out. (connect timeout=5)'))

[2018-03-02 15:36:01,540 DEBUG utils] Change proxy to {'https': '212.237.25.158:3128'} for sci-hub.tw
[2018-03-02 15:36:01,728 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:01,866 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:01,868 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:01,868 DEBUG utils] Proxy: {'https': '212.237.25.158:3128'}
[2018-03-02 15:36:02,056 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:02,080 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): pdfs.semanticscholar.org
[2018-03-02 15:36:03,166 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:03,167 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:03,167 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for sci-hub.tw
[2018-03-02 15:36:03,356 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:03,501 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:03,502 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:03,502 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:36:03,686 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:03,707 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:04,836 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:04,837 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:04,837 DEBUG utils] Change proxy to {'https': '148.217.94.54:3128'} for sci-hub.tw
[2018-03-02 15:36:05,036 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:05,176 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:05,177 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:05,177 DEBUG utils] Proxy: {'https': '148.217.94.54:3128'}
[2018-03-02 15:36:05,376 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:05,398 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:07,245 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:07,247 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:07,247 DEBUG utils] Change proxy to {'https': '159.65.227.89:8080'} for sci-hub.tw
[2018-03-02 15:36:07,436 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:07,566 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:07,567 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:07,567 DEBUG utils] Proxy: {'https': '159.65.227.89:8080'}
[2018-03-02 15:36:07,756 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:07,779 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:36:07,780 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:09,016 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:09,018 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:09,018 DEBUG utils] Change proxy to {'https': '31.173.188.190:3128'} for sci-hub.tw
[2018-03-02 15:36:09,216 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:09,346 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:09,347 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:09,347 DEBUG utils] Proxy: {'https': '31.173.188.190:3128'}
[2018-03-02 15:36:09,536 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:09,558 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:10,707 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:10,708 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:10,708 DEBUG utils] Change proxy to {'https': '94.253.77.137:8080'} for sci-hub.tw
[2018-03-02 15:36:10,896 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:11,036 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:11,038 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:11,038 DEBUG utils] Proxy: {'https': '94.253.77.137:8080'}
[2018-03-02 15:36:11,237 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:11,264 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:12,065 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:12,067 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:12,067 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for sci-hub.tw
[2018-03-02 15:36:12,269 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:12,406 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:12,407 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:12,407 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:36:12,598 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:12,622 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:17,756 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='pdfs.semanticscholar.org', port=443): Max retries exceeded with url: /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:36:17,757 DEBUG utils] Change proxy to {'https': '159.65.202.9:3128'} for sci-hub.tw
[2018-03-02 15:36:17,955 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:18,086 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:18,087 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:18,087 DEBUG utils] Proxy: {'https': '159.65.202.9:3128'}
[2018-03-02 15:36:18,276 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:18,299 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:19,000 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:19,001 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:19,001 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for sci-hub.tw
[2018-03-02 15:36:19,186 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:19,318 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:19,319 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:19,319 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:36:19,506 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:19,528 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:20,935 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:20,937 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:20,937 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for sci-hub.tw
[2018-03-02 15:36:21,126 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:21,256 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:21,257 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:21,257 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:36:21,446 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:21,469 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:22,646 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:22,647 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:22,647 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for sci-hub.tw
[2018-03-02 15:36:22,835 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:22,966 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:22,967 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:22,967 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:36:23,186 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:23,207 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:25,896 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:25,897 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:25,897 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for sci-hub.tw
[2018-03-02 15:36:26,106 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:26,236 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:26,237 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:26,237 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:36:26,426 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:26,449 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:28,465 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:28,466 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:28,467 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for sci-hub.tw
[2018-03-02 15:36:28,696 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:28,845 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:28,846 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:28,846 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:36:29,035 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:29,058 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:31,026 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:31,027 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:31,028 DEBUG utils] Change proxy to {'https': '103.23.101.117:3128'} for sci-hub.tw
[2018-03-02 15:36:31,215 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:31,345 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:31,347 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:31,347 DEBUG utils] Proxy: {'https': '103.23.101.117:3128'}
[2018-03-02 15:36:31,536 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:31,557 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:36:33,965 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:33,967 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:33,967 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for sci-hub.tw
[2018-03-02 15:36:34,156 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:34,286 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:34,287 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:34,287 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:36:34,475 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:34,498 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: pdfs.semanticscholar.org
[2018-03-02 15:36:34,500 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:37,251 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:37,253 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:37,253 DEBUG utils] Change proxy to {'https': '66.70.255.195:3128'} for sci-hub.tw
[2018-03-02 15:36:37,435 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:37,565 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:37,566 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:37,566 DEBUG utils] Proxy: {'https': '66.70.255.195:3128'}
[2018-03-02 15:36:37,765 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:37,789 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:39,155 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:39,156 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:39,156 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for sci-hub.tw
[2018-03-02 15:36:39,346 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:39,485 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:39,486 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:39,486 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:36:39,675 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:39,697 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): pdfs.semanticscholar.org
[2018-03-02 15:36:42,105 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:42,107 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:42,107 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for sci-hub.tw
[2018-03-02 15:36:42,305 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:42,435 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:42,436 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:42,436 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:36:42,625 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:42,652 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:43,556 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:43,557 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:43,557 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for sci-hub.tw
[2018-03-02 15:36:43,745 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:43,876 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:43,876 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:43,877 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:36:44,057 DEBUG requests.packages.urllib3.connectionpool] "GET //https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 302 None
[2018-03-02 15:36:44,082 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): pdfs.semanticscholar.org
[2018-03-02 15:36:45,315 DEBUG requests.packages.urllib3.connectionpool] "GET /7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf HTTP/1.1" 404 None
[2018-03-02 15:36:45,317 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 351, in get_request
    if 'text/html' in resp.headers['Content-Type']:
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-type'

[2018-03-02 15:36:45,317 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for sci-hub.tw
[2018-03-02 15:36:45,319 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:36:45,319 DEBUG __main__] Failed get_pdf from sci-hub for paper #243. URL=243
[2018-03-02 15:36:45,320 DEBUG scholar] Handle paper #270 (total 1170)
[2018-03-02 15:36:45,320 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:36:45,325 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:36:45,325 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:36:45,606 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nF_8dpbvMR0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeF9IA2C19xuHj7oEhkf4Pxt75YET&scisf=3&ct=citation&cd=269&hl=en HTTP/1.1" 200 255
[2018-03-02 15:36:45,607 DEBUG scholar] EndNote file:
%0 Journal Article
%T Towards the derivation of verbal content relations from patent claims using deep syntactic structures
%A Ferraro, Gabriela
%A Wanner, Leo
%J Knowledge-Based Systems
%V 24
%N 8
%P 1233-1244
%@ 0950-7051
%D 2011
%I Elsevier

[2018-03-02 15:36:45,607 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:36:45,607 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:36:45,607 DEBUG __main__] Process content of EndNote file #270
{"title": "Towards the derivation of verbal content relations from patent claims using deep syntactic structures", "url": "https://www.sciencedirect.com/science/article/pii/S0950705111001080", "author": [{"shortname": "G Ferraro", "gid": "6eIm55MAAAAJ"}, {"shortname": "L Wanner", "gid": "kSyWwEIAAAAJ"}], "year": 2011}
{"citedby": 5, "type": "Journal Article", "title": "Towards the derivation of verbal content relations from patent claims using deep syntactic structures", "author": ["Ferraro, Gabriela", "Wanner, Leo"], "journal": "Knowledge-Based Systems", "volume": 12, "numberorissue": "8", "pages": "1233-1244", "isbn/issn": "0950-7051", "year": "2011", "publisher": "Elsevier", "start_page": 1233, "end_page": 1244, "EndNote": "%0 Journal Article\n%T Towards the derivation of verbal content relations from patent claims using deep syntactic structures\n%A Ferraro, Gabriela\n%A Wanner, Leo\n%J Knowledge-Based Systems\n%V 24\n%N 8\n%P 1233-1244\n%@ 0950-7051\n%D 2011\n%I Elsevier\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:nF_8dpbvMR0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplHeF9IA2C19xuHj7oEhkf4Pxt75YET&scisf=3&ct=citation&cd=269&hl=en"}
[2018-03-02 15:36:45,607 DEBUG dbutils] Get paper id {"DOI": null, "title": "Towards the derivation of verbal content relations from patent claims using deep syntactic structures", "auth_count": 2, "g_type": "Journal Article", "pages": 12, "year": 2011, "rg_id": null, "start_page": 1233, "end_page": 1244}.
[2018-03-02 15:36:45,607 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Towards the derivation of verbal content relations from patent claims using deep syntactic structures', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 12, 'year': 2011, 'rg_id': None, 'start_page': 1233, 'end_page': 1244}
[2018-03-02 15:36:45,608 DEBUG dbutils] Query result: []
[2018-03-02 15:36:45,608 DEBUG dbutils] Paper id = None.
[2018-03-02 15:36:45,608 DEBUG dbutils] Add new paper (title='Towards the derivation of verbal content relations from patent claims using deep syntactic structures')
[2018-03-02 15:36:45,608 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Towards the derivation of verbal content relations from patent claims using deep syntactic structures', 'year': 2011, 'publisher': 'Elsevier', 'start_page': 1233, 'end_page': 1244, 'pages': 12, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Towards the derivation of verbal content relations from patent claims using deep syntactic structures\n%A Ferraro, Gabriela\n%A Wanner, Leo\n%J Knowledge-Based Systems\n%V 24\n%N 8\n%P 1233-1244\n%@ 0950-7051\n%D 2011\n%I Elsevier\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:36:45,608 DEBUG dbutils] Query result: 244
[2018-03-02 15:36:45,609 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://pdfs.semanticscholar.org/2538/b5c8991a98d3887cb25200253b0e20834876.pdf.
[2018-03-02 15:36:45,610 WARNING utils] Download file (url='https://pdfs.semanticscholar.org/2538/b5c8991a98d3887cb25200253b0e20834876.pdf') and save (filename='PDF//244.pdf')
[2018-03-02 15:36:45,610 DEBUG utils] Get current proxy for pdfs.semanticscholar.org.
[2018-03-02 15:36:45,610 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:36:45,624 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): pdfs.semanticscholar.org
[2018-03-02 15:36:47,473 DEBUG requests.packages.urllib3.connectionpool] "GET /2538/b5c8991a98d3887cb25200253b0e20834876.pdf HTTP/1.1" 200 571937
[2018-03-02 15:36:47,474 DEBUG utils] Content-length=571937
[2018-03-02 15:36:47,474 DEBUG utils] Create file PDF//244.pdf, start download.
[2018-03-02 15:36:49,585 DEBUG utils] End download file PDF//244.pdf.
[2018-03-02 15:36:49,587 DEBUG dbutils] Update pdf_transaction for paper id=244.
[2018-03-02 15:36:49,587 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 244'
[2018-03-02 15:36:49,587 DEBUG dbutils] Query result: null
[2018-03-02 15:36:49,611 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:36:49,611 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:36:49,611 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:36:49,611 DEBUG utils] Change proxy to {'https': '62.210.105.103:3128'} for scholar.google.com
[2018-03-02 15:36:49,626 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:36:51,128 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=270&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:36:51,380 DEBUG scholar] Find papers on page #28 (max_google_papers = 300)
[2018-03-02 15:36:51,380 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:36:51,380 DEBUG scholar] Handle paper #271 (total 1170)
[2018-03-02 15:36:51,380 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:36:51,384 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:36:51,384 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:36:51,403 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:36:51,405 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:36:52,847 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:5FAMw52PgS4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_5EFy4sobaQ_25DW4b-jYRYhnPuV&scisf=3&ct=citation&cd=270&hl=en HTTP/1.1" 200 149
[2018-03-02 15:36:52,848 DEBUG scholar] EndNote file:
%0 Book
%T Creating Synthetic Emotions through Technological and Robotic Advancements
%A Vallverdu, Jordi
%@ 1466615966
%D 2012
%I IGI Global

[2018-03-02 15:36:52,848 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:36:52,848 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:36:52,849 DEBUG __main__] Process content of EndNote file #271
{"title": "Creating Synthetic Emotions through Technological and Robotic Advancements", "url": "https://books.google.com/books?hl=en&lr=&id=saeeBQAAQBAJ&oi=fnd&pg=PR1&dq=Use+deep+learning+to+create+a+chatbot&ots=sMHjJ7GzcN&sig=Yq9bqBSCy7eLFw1bt58wLFkmX7Q", "author": [{"shortname": "J Vallverd\u00fa", "gid": "Y_Q8AQkAAAAJ"}], "year": 2012}
{"citedby": 4, "type": "Book", "title": "Creating Synthetic Emotions through Technological and Robotic Advancements", "author": ["Vallverd\u00fa, Jordi"], "isbn/issn": "1466615966", "year": "2012", "publisher": "IGI Global", "EndNote": "%0 Book\n%T Creating Synthetic Emotions through Technological and Robotic Advancements\n%A Vallverd\u00fa, Jordi\n%@ 1466615966\n%D 2012\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:5FAMw52PgS4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_5EFy4sobaQ_25DW4b-jYRYhnPuV&scisf=3&ct=citation&cd=270&hl=en"}
[2018-03-02 15:36:52,849 DEBUG dbutils] Get paper id {"DOI": null, "title": "Creating Synthetic Emotions through Technological and Robotic Advancements", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2012, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:36:52,849 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Creating Synthetic Emotions through Technological and Robotic Advancements', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2012, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:36:52,849 DEBUG dbutils] Query result: []
[2018-03-02 15:36:52,849 DEBUG dbutils] Paper id = None.
[2018-03-02 15:36:52,849 DEBUG dbutils] Add new paper (title='Creating Synthetic Emotions through Technological and Robotic Advancements')
[2018-03-02 15:36:52,850 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Creating Synthetic Emotions through Technological and Robotic Advancements', 'year': 2012, 'publisher': 'IGI Global', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Creating Synthetic Emotions through Technological and Robotic Advancements\n%A Vallverdu, Jordi\n%@ 1466615966\n%D 2012\n%I IGI Global\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:36:52,850 DEBUG dbutils] Query result: 245
[2018-03-02 15:36:52,851 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=saeeBQAAQBAJ&oi=fnd&pg=PR1&dq=Use+deep+learning+to+create+a+chatbot&ots=sMHjJ7GzcN&sig=Yq9bqBSCy7eLFw1bt58wLFkmX7Q.
[2018-03-02 15:36:52,851 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=saeeBQAAQBAJ&oi=fnd&pg=PR1&dq=Use+deep+learning+to+create+a+chatbot&ots=sMHjJ7GzcN&sig=Yq9bqBSCy7eLFw1bt58wLFkmX7Q.
[2018-03-02 15:36:53,026 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=saeeBQAAQBAJ&oi=fnd&pg=PR1&dq=Use+deep+learning+to+create+a+chatbot&ots=sMHjJ7GzcN&sig=Yq9bqBSCy7eLFw1bt58wLFkmX7Q HTTP/1.1" 302 None
[2018-03-02 15:36:53,215 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:36:53,222 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:36:53,222 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:36:53,397 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=saeeBQAAQBAJ&oi=fnd&pg=PR1&dq=Use+deep+learning+to+create+a+chatbot&ots=sMHjJ7GzcN&sig=Yq9bqBSCy7eLFw1bt58wLFkmX7Q HTTP/1.1" 302 None
[2018-03-02 15:36:53,606 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:36:53,648 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:36:53,650 DEBUG scholar] Handle paper #272 (total 1170)
[2018-03-02 15:36:53,650 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:36:53,655 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:36:53,655 DEBUG utils] Proxy: {'https': '62.210.105.103:3128'}
[2018-03-02 15:36:53,655 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for scholar.google.com
[2018-03-02 15:36:53,670 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:36:58,797 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:KOpDHDLS-csJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH__CTeKYj2vkxUJ45X8qwTQnvpAfx&scisf=3&ct=citation&cd=271&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:KOpDHDLS-csJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH__CTeKYj2vkxUJ45X8qwTQnvpAfx&scisf=3&ct=citation&cd=271&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:36:58,797 DEBUG utils] Change proxy to {'https': '159.65.227.89:80'} for scholar.google.com
[2018-03-02 15:36:58,797 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:36:58,798 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:36:58,812 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:36:58,813 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:37:00,115 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KOpDHDLS-csJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH__CTeKYj2vkxUJ45X8qwTQnvpAfx&scisf=3&ct=citation&cd=271&hl=en HTTP/1.1" 200 160
[2018-03-02 15:37:00,116 DEBUG scholar] EndNote file:
%0 Journal Article
%T MULTITUTOR: A UNIVERSAL SPEECH ANALYZER
%A Bhad, Mr Swapnil M
%A Kale, Ms Tanaya J
%A Kalikar, Ms Gayatri V
%A Sonule, Mr Vinayak P

[2018-03-02 15:37:00,116 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:00,117 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:00,117 DEBUG __main__] Skip paper #272, empty year or authors fields.
[2018-03-02 15:37:00,117 DEBUG scholar] Handle paper #273 (total 1170)
[2018-03-02 15:37:00,117 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:37:00,120 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:00,120 DEBUG utils] Proxy: {'https': '159.65.227.89:80'}
[2018-03-02 15:37:00,120 DEBUG utils] Change proxy to {'https': '35.227.107.243:3128'} for scholar.google.com
[2018-03-02 15:37:00,160 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:37:00,162 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:37:01,415 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:s0iT-wMhha4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_7ZtAY6LW261wiwcBs4Zcgk7SMoC&scisf=3&ct=citation&cd=272&hl=en HTTP/1.1" 200 178
[2018-03-02 15:37:01,416 DEBUG scholar] EndNote file:
%0 Journal Article
%T Artificial General Intelligence: Concept, State of the Art, and Future Prospects early preliminary draft, for comment-solicitation only
%A Goertzel, Ben

[2018-03-02 15:37:01,416 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:01,416 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:01,416 DEBUG __main__] Skip paper #273, empty year or authors fields.
[2018-03-02 15:37:01,418 DEBUG scholar] Handle paper #274 (total 1170)
[2018-03-02 15:37:01,418 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:37:01,421 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:01,421 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:37:01,685 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:u4_shQR8jIEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_zalsPuNSwXg6XNSmAKj4KFFeuHU&scisf=3&ct=citation&cd=273&hl=en HTTP/1.1" 200 345
[2018-03-02 15:37:01,686 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments
%A Ellis, Allan
%A Phillips, Jill
%B EdMedia: World Conference on Educational Media and Technology
%P 933-942
%@ 1880094894
%D 2011
%I Association for the Advancement of Computing in Education (AACE)

[2018-03-02 15:37:01,686 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:01,686 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:01,687 DEBUG __main__] Process content of EndNote file #274
{"title": "Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments", "url": "https://www.learntechlib.org/p/37983/", "author": [{"shortname": "A Ellis", "gid": ""}, {"shortname": "J Phillips", "gid": ""}], "year": 2011}
{"type": "Conference Proceedings", "title": "Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments", "author": ["Ellis, Allan", "Phillips, Jill"], "secondarytitle": "EdMedia: World Conference on Educational Media and Technology", "pages": "933-942", "isbn/issn": "1880094894", "year": "2011", "publisher": "Association for the Advancement of Computing in Education (AACE)", "start_page": 933, "end_page": 942, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments\n%A Ellis, Allan\n%A Phillips, Jill\n%B EdMedia: World Conference on Educational Media and Technology\n%P 933-942\n%@ 1880094894\n%D 2011\n%I Association for the Advancement of Computing in Education (AACE)\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:u4_shQR8jIEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_zalsPuNSwXg6XNSmAKj4KFFeuHU&scisf=3&ct=citation&cd=273&hl=en"}
[2018-03-02 15:37:01,687 DEBUG dbutils] Get paper id {"DOI": null, "title": "Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2011, "rg_id": null, "start_page": 933, "end_page": 942}.
[2018-03-02 15:37:01,687 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2011, 'rg_id': None, 'start_page': 933, 'end_page': 942}
[2018-03-02 15:37:01,687 DEBUG dbutils] Query result: []
[2018-03-02 15:37:01,687 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:01,687 DEBUG dbutils] Add new paper (title='Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments')
[2018-03-02 15:37:01,687 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments', 'year': 2011, 'publisher': 'Association for the Advancement of Computing in Education (AACE)', 'start_page': 933, 'end_page': 942, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Learning in context: Moving courses from 2D Web-based materials to simulated 3D virtual-world environments\n%A Ellis, Allan\n%A Phillips, Jill\n%B EdMedia: World Conference on Educational Media and Technology\n%P 933-942\n%@ 1880094894\n%D 2011\n%I Association for the Advancement of Computing in Education (AACE)\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:01,687 DEBUG dbutils] Query result: 246
[2018-03-02 15:37:01,689 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.learntechlib.org/p/37983/proceedings_37983.pdf.
[2018-03-02 15:37:01,690 WARNING utils] Download file (url='https://www.learntechlib.org/p/37983/proceedings_37983.pdf') and save (filename='PDF//246.pdf')
[2018-03-02 15:37:01,690 DEBUG utils] Get current proxy for www.learntechlib.org.
[2018-03-02 15:37:01,690 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:37:01,690 DEBUG utils] Change proxy to {'https': '200.60.130.162:3128'} for otherhost
[2018-03-02 15:37:01,705 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 15:37:04,586 DEBUG requests.packages.urllib3.connectionpool] "GET /p/37983/proceedings_37983.pdf HTTP/1.1" 302 137
[2018-03-02 15:37:05,045 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/37983 HTTP/1.1" 301 0
[2018-03-02 15:37:06,725 DEBUG requests.packages.urllib3.connectionpool] "GET /noaccess/37983/ HTTP/1.1" 200 17770
[2018-03-02 15:37:06,775 DEBUG utils] Content-length=17770
[2018-03-02 15:37:06,775 DEBUG utils] Create file PDF//246.pdf, start download.
[2018-03-02 15:37:06,777 WARNING scholar] Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\internet_resources\scholar.py", line 151, in get_pdf
    return utils.download_file(url, filename)
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 507, in download_file
    progress.update(downloaded_size)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\progressbar\bar.py", line 497, in update
    % (self.min_value, self.max_value))
ValueError: Value out of range, should be between 0 and 17770

[2018-03-02 15:37:06,777 DEBUG __main__] Failed get_pdf from Google Scholar for paper #246. URL=246
[2018-03-02 15:37:06,779 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.learntechlib.org/p/37983/.
[2018-03-02 15:37:06,780 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.learntechlib.org/p/37983/.
[2018-03-02 15:37:06,955 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/37983/ HTTP/1.1" 302 None
[2018-03-02 15:37:06,980 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.learntechlib.org
[2018-03-02 15:37:08,245 DEBUG requests.packages.urllib3.connectionpool] "GET /p/37983/ HTTP/1.1" 200 17973
[2018-03-02 15:37:08,247 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:37:08,247 DEBUG utils] Proxy: {'https': '199.195.253.124:3128'}
[2018-03-02 15:37:08,247 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for sci-hub.tw
[2018-03-02 15:37:08,515 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.learntechlib.org/p/37983/ HTTP/1.1" 302 None
[2018-03-02 15:37:08,542 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.learntechlib.org
[2018-03-02 15:37:10,630 DEBUG requests.packages.urllib3.connectionpool] "GET /p/37983/ HTTP/1.1" 200 16223
[2018-03-02 15:37:10,729 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:37:10,730 DEBUG scholar] Handle paper #275 (total 1170)
[2018-03-02 15:37:10,730 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:37:10,735 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:10,735 DEBUG utils] Proxy: {'https': '35.227.107.243:3128'}
[2018-03-02 15:37:10,736 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for scholar.google.com
[2018-03-02 15:37:10,752 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:37:10,753 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:37:12,355 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:1J84qq2v6-4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_znf0Hm_5Hg4so41hO2PjgYgt6p8&scisf=3&ct=citation&cd=274&hl=en HTTP/1.1" 200 311
[2018-03-02 15:37:12,356 DEBUG scholar] EndNote file:
%0 Journal Article
%T Its Almost Like Talking to a Person: Student Disclosure to Pedagogical Agents in Sensitive Settings.
%A Savin-Baden, Maggi
%A Tombs, Gemma
%A Burden, David
%A Wood, Clare
%J International Journal of Mobile and Blended Learning
%V 5
%N 2
%P 78-93
%D 2013
%I IGI Global

[2018-03-02 15:37:12,356 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:12,356 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:12,357 DEBUG __main__] Process content of EndNote file #275
{"title": "'It's Almost Like Talking to a Person': Student Disclosure to Pedagogical Agents in Sensitive Settings.", "url": "http://eprints.worc.ac.uk/3532/", "author": [{"shortname": "M Savin", "gid": ""}], "year": 2013}
{"citedby": 6, "type": "Journal Article", "title": "\u2018It\u2019s Almost Like Talking to a Person\u2019: Student Disclosure to Pedagogical Agents in Sensitive Settings.", "author": ["Savin-Baden, Maggi", "Tombs, Gemma", "Burden, David", "Wood, Clare"], "journal": "International Journal of Mobile and Blended Learning", "volume": 16, "numberorissue": "2", "pages": "78-93", "year": "2013", "publisher": "IGI Global", "start_page": 78, "end_page": 93, "EndNote": "%0 Journal Article\n%T \u2018It\u2019s Almost Like Talking to a Person\u2019: Student Disclosure to Pedagogical Agents in Sensitive Settings.\n%A Savin-Baden, Maggi\n%A Tombs, Gemma\n%A Burden, David\n%A Wood, Clare\n%J International Journal of Mobile and Blended Learning\n%V 5\n%N 2\n%P 78-93\n%D 2013\n%I IGI Global\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:1J84qq2v6-4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_znf0Hm_5Hg4so41hO2PjgYgt6p8&scisf=3&ct=citation&cd=274&hl=en"}
[2018-03-02 15:37:12,357 DEBUG dbutils] Get paper id {"DOI": null, "title": "\u2018It\u2019s Almost Like Talking to a Person\u2019: Student Disclosure to Pedagogical Agents in Sensitive Settings.", "auth_count": 4, "g_type": "Journal Article", "pages": 16, "year": 2013, "rg_id": null, "start_page": 78, "end_page": 93}.
[2018-03-02 15:37:12,357 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Its Almost Like Talking to a Person: Student Disclosure to Pedagogical Agents in Sensitive Settings.', 'auth_count': 4, 'g_type': 'Journal Article', 'pages': 16, 'year': 2013, 'rg_id': None, 'start_page': 78, 'end_page': 93}
[2018-03-02 15:37:12,357 DEBUG dbutils] Query result: []
[2018-03-02 15:37:12,357 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:12,357 DEBUG dbutils] Add new paper (title='Its Almost Like Talking to a Person: Student Disclosure to Pedagogical Agents in Sensitive Settings.')
[2018-03-02 15:37:12,357 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Its Almost Like Talking to a Person: Student Disclosure to Pedagogical Agents in Sensitive Settings.', 'year': 2013, 'publisher': 'IGI Global', 'start_page': 78, 'end_page': 93, 'pages': 16, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Its Almost Like Talking to a Person: Student Disclosure to Pedagogical Agents in Sensitive Settings.\n%A Savin-Baden, Maggi\n%A Tombs, Gemma\n%A Burden, David\n%A Wood, Clare\n%J International Journal of Mobile and Blended Learning\n%V 5\n%N 2\n%P 78-93\n%D 2013\n%I IGI Global\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:12,357 DEBUG dbutils] Query result: 247
[2018-03-02 15:37:12,359 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://eprints.worc.ac.uk/3532/7/savin-baden%20IJMBL%205(2).pdf.
[2018-03-02 15:37:12,360 WARNING utils] Download file (url='http://eprints.worc.ac.uk/3532/7/savin-baden%20IJMBL%205(2).pdf') and save (filename='PDF//247.pdf')
[2018-03-02 15:37:12,360 DEBUG utils] Get current proxy for eprints.worc.ac.uk.
[2018-03-02 15:37:12,360 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:37:12,379 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): eprints.worc.ac.uk
[2018-03-02 15:37:12,936 DEBUG requests.packages.urllib3.connectionpool] "GET /3532/7/savin-baden%20IJMBL%205(2).pdf HTTP/1.1" 200 997834
[2018-03-02 15:37:12,936 DEBUG utils] Content-length=997834
[2018-03-02 15:37:12,937 DEBUG utils] Create file PDF//247.pdf, start download.
[2018-03-02 15:37:14,242 DEBUG utils] End download file PDF//247.pdf.
[2018-03-02 15:37:14,243 DEBUG dbutils] Update pdf_transaction for paper id=247.
[2018-03-02 15:37:14,243 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 247'
[2018-03-02 15:37:14,243 DEBUG dbutils] Query result: null
[2018-03-02 15:37:14,244 DEBUG scholar] Handle paper #276 (total 1170)
[2018-03-02 15:37:14,244 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:37:14,250 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:14,250 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:37:14,575 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:eVjCfEKpqx4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_2tsqJxmaFa6c--uzvVMzwb6SQuk&scisf=3&ct=citation&cd=275&hl=en HTTP/1.1" 200 121
[2018-03-02 15:37:14,576 DEBUG scholar] EndNote file:
%0 Journal Article
%T The great AI awakening
%A Lewis-Kraus, Gideon
%J The New York Times Magazine
%P 1-37
%D 2016

[2018-03-02 15:37:14,576 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:14,576 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:14,576 DEBUG __main__] Process content of EndNote file #276
{"title": "The great AI awakening", "url": "http://publicservicesalliance.org/wp-content/uploads/2016/12/The-Great-A.I.-Awakening-The-New-York-Times.pdf", "author": [{"shortname": "G Lewis", "gid": ""}], "year": 2016}
{"citedby": 27, "type": "Journal Article", "title": "The great AI awakening", "author": ["Lewis-Kraus, Gideon"], "journal": "The New York Times Magazine", "pages": "1-37", "year": "2016", "start_page": 1, "end_page": 37, "volume": 37, "EndNote": "%0 Journal Article\n%T The great AI awakening\n%A Lewis-Kraus, Gideon\n%J The New York Times Magazine\n%P 1-37\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:eVjCfEKpqx4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_2tsqJxmaFa6c--uzvVMzwb6SQuk&scisf=3&ct=citation&cd=275&hl=en"}
[2018-03-02 15:37:14,576 DEBUG dbutils] Get paper id {"DOI": null, "title": "The great AI awakening", "auth_count": 1, "g_type": "Journal Article", "pages": 37, "year": 2016, "rg_id": null, "start_page": 1, "end_page": 37}.
[2018-03-02 15:37:14,576 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The great AI awakening', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 37, 'year': 2016, 'rg_id': None, 'start_page': 1, 'end_page': 37}
[2018-03-02 15:37:14,576 DEBUG dbutils] Query result: []
[2018-03-02 15:37:14,576 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:14,576 DEBUG dbutils] Add new paper (title='The great AI awakening')
[2018-03-02 15:37:14,577 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The great AI awakening', 'year': 2016, 'publisher': None, 'start_page': 1, 'end_page': 37, 'pages': 37, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The great AI awakening\n%A Lewis-Kraus, Gideon\n%J The New York Times Magazine\n%P 1-37\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:14,577 DEBUG dbutils] Query result: 248
[2018-03-02 15:37:14,578 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://publicservicesalliance.org/wp-content/uploads/2016/12/The-Great-A.I.-Awakening-The-New-York-Times.pdf.
[2018-03-02 15:37:14,579 WARNING utils] Download file (url='http://publicservicesalliance.org/wp-content/uploads/2016/12/The-Great-A.I.-Awakening-The-New-York-Times.pdf') and save (filename='PDF//248.pdf')
[2018-03-02 15:37:14,579 DEBUG utils] Get current proxy for publicservicesalliance.org.
[2018-03-02 15:37:14,579 DEBUG utils] Proxy: {'https': '200.60.130.162:3128'}
[2018-03-02 15:37:14,581 DEBUG utils] Change proxy to {'https': '189.84.173.241:3128'} for otherhost
[2018-03-02 15:37:14,597 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): publicservicesalliance.org
[2018-03-02 15:37:15,585 DEBUG requests.packages.urllib3.connectionpool] "GET /wp-content/uploads/2016/12/The-Great-A.I.-Awakening-The-New-York-Times.pdf HTTP/1.1" 200 3730562
[2018-03-02 15:37:15,586 DEBUG utils] Content-length=3730562
[2018-03-02 15:37:15,586 DEBUG utils] Create file PDF//248.pdf, start download.
[2018-03-02 15:37:23,808 DEBUG utils] End download file PDF//248.pdf.
[2018-03-02 15:37:23,809 DEBUG dbutils] Update pdf_transaction for paper id=248.
[2018-03-02 15:37:23,810 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 248'
[2018-03-02 15:37:23,810 DEBUG dbutils] Query result: null
[2018-03-02 15:37:23,810 DEBUG scholar] Handle paper #277 (total 1170)
[2018-03-02 15:37:23,810 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:37:23,814 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:23,814 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:37:23,814 DEBUG utils] Change proxy to {'https': '217.150.80.59:3128'} for scholar.google.com
[2018-03-02 15:37:23,838 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:37:23,840 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:37:25,925 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Pi-BbMYjBQ4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH__wb_RrzX_5Xf2nUkvsb8hd4Ff67&scisf=3&ct=citation&cd=276&hl=en HTTP/1.1" 200 259
[2018-03-02 15:37:25,926 DEBUG scholar] EndNote file:
%0 Journal Article
%T Tracking the path of communities of inquiry in TEFL: A literature review
%A Gonzalez Miy, Darlene
%A Herrera Diaz, Luz Edith
%J How
%V 22
%N 1
%P 80-94
%@ 0120-5927
%D 2015
%I Asociacion Colombiana de Profesores de Ingles

[2018-03-02 15:37:25,926 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:25,926 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:25,926 DEBUG __main__] Process content of EndNote file #277
{"title": "Tracking the path of communities of inquiry in TEFL: A literature review", "url": "http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006", "author": [{"shortname": "D Gonz\u00e1lez Miy", "gid": "636uu1wAAAAJ"}, {"shortname": "LE Herrera D\u00edaz", "gid": "GXnPfvIAAAAJ"}], "year": 2015}
{"citedby": 1, "type": "Journal Article", "title": "Tracking the path of communities of inquiry in TEFL: A literature review", "author": ["Gonz\u00e1lez Miy, Darlene", "Herrera D\u00edaz, Luz Edith"], "journal": "How", "volume": 15, "numberorissue": "1", "pages": "80-94", "isbn/issn": "0120-5927", "year": "2015", "publisher": "Asociaci\u00f3n Colombiana de Profesores de Ingl\u00e9s", "start_page": 80, "end_page": 94, "EndNote": "%0 Journal Article\n%T Tracking the path of communities of inquiry in TEFL: A literature review\n%A Gonz\u00e1lez Miy, Darlene\n%A Herrera D\u00edaz, Luz Edith\n%J How\n%V 22\n%N 1\n%P 80-94\n%@ 0120-5927\n%D 2015\n%I Asociaci\u00f3n Colombiana de Profesores de Ingl\u00e9s\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Pi-BbMYjBQ4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH__wb_RrzX_5Xf2nUkvsb8hd4Ff67&scisf=3&ct=citation&cd=276&hl=en"}
[2018-03-02 15:37:25,927 DEBUG dbutils] Get paper id {"DOI": null, "title": "Tracking the path of communities of inquiry in TEFL: A literature review", "auth_count": 2, "g_type": "Journal Article", "pages": 15, "year": 2015, "rg_id": null, "start_page": 80, "end_page": 94}.
[2018-03-02 15:37:25,927 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Tracking the path of communities of inquiry in TEFL: A literature review', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 15, 'year': 2015, 'rg_id': None, 'start_page': 80, 'end_page': 94}
[2018-03-02 15:37:25,927 DEBUG dbutils] Query result: []
[2018-03-02 15:37:25,927 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:25,927 DEBUG dbutils] Add new paper (title='Tracking the path of communities of inquiry in TEFL: A literature review')
[2018-03-02 15:37:25,927 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Tracking the path of communities of inquiry in TEFL: A literature review', 'year': 2015, 'publisher': 'Asociacion Colombiana de Profesores de Ingles', 'start_page': 80, 'end_page': 94, 'pages': 15, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Tracking the path of communities of inquiry in TEFL: A literature review\n%A Gonzalez Miy, Darlene\n%A Herrera Diaz, Luz Edith\n%J How\n%V 22\n%N 1\n%P 80-94\n%@ 0120-5927\n%D 2015\n%I Asociacion Colombiana de Profesores de Ingles\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:25,927 DEBUG dbutils] Query result: 249
[2018-03-02 15:37:25,929 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006.
[2018-03-02 15:37:25,929 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006.
[2018-03-02 15:37:30,155 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006 HTTP/1.1" 307 None
[2018-03-02 15:37:32,034 DEBUG requests.packages.urllib3.connectionpool] "GET /http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006 HTTP/1.1" 200 None
[2018-03-02 15:37:32,184 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:37:32,184 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:37:34,075 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.scielo.org.co/scielo.php?script=sci_arttext&pid=S0120-59272015000100006 HTTP/1.1" 200 None
[2018-03-02 15:37:34,248 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:37:34,249 DEBUG scholar] Handle paper #278 (total 1170)
[2018-03-02 15:37:34,249 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:37:34,254 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:34,254 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:37:34,655 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:n59MJy-lIwMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_9gWUEmwoNShafy53p6OXV7PmFAd&scisf=3&ct=citation&cd=277&hl=en HTTP/1.1" 200 317
[2018-03-02 15:37:34,655 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Open-domain personalized dialog system using user-interested topics in system responses
%A Bang, Jeesoo
%A Han, Sangdo
%A Lee, Kyusong
%A Lee, Gary Geunbae
%B Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on
%P 771-776
%@ 1479972916
%D 2015
%I IEEE

[2018-03-02 15:37:34,655 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:34,655 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:34,655 DEBUG __main__] Process content of EndNote file #278
{"title": "Open-domain personalized dialog system using user-interested topics in system responses", "url": "http://ieeexplore.ieee.org/abstract/document/7404866/", "author": [{"shortname": "J Bang", "gid": "bKssw7kAAAAJ"}, {"shortname": "S Han", "gid": "usS1O0cAAAAJ"}, {"shortname": "K Lee", "gid": "20KuF74AAAAJ"}, {"shortname": "GG Lee", "gid": "t30saScAAAAJ"}], "year": 2015}
{"citedby": 1, "type": "Conference Proceedings", "title": "Open-domain personalized dialog system using user-interested topics in system responses", "author": ["Bang, Jeesoo", "Han, Sangdo", "Lee, Kyusong", "Lee, Gary Geunbae"], "secondarytitle": "Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on", "pages": "771-776", "isbn/issn": "1479972916", "year": "2015", "publisher": "IEEE", "start_page": 771, "end_page": 776, "volume": 6, "EndNote": "%0 Conference Proceedings\n%T Open-domain personalized dialog system using user-interested topics in system responses\n%A Bang, Jeesoo\n%A Han, Sangdo\n%A Lee, Kyusong\n%A Lee, Gary Geunbae\n%B Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on\n%P 771-776\n%@ 1479972916\n%D 2015\n%I IEEE\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:n59MJy-lIwMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_9gWUEmwoNShafy53p6OXV7PmFAd&scisf=3&ct=citation&cd=277&hl=en"}
[2018-03-02 15:37:34,656 DEBUG dbutils] Get paper id {"DOI": null, "title": "Open-domain personalized dialog system using user-interested topics in system responses", "auth_count": 4, "g_type": "Conference Proceedings", "pages": 6, "year": 2015, "rg_id": null, "start_page": 771, "end_page": 776}.
[2018-03-02 15:37:34,656 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Open-domain personalized dialog system using user-interested topics in system responses', 'auth_count': 4, 'g_type': 'Conference Proceedings', 'pages': 6, 'year': 2015, 'rg_id': None, 'start_page': 771, 'end_page': 776}
[2018-03-02 15:37:34,656 DEBUG dbutils] Query result: []
[2018-03-02 15:37:34,656 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:34,656 DEBUG dbutils] Add new paper (title='Open-domain personalized dialog system using user-interested topics in system responses')
[2018-03-02 15:37:34,656 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Open-domain personalized dialog system using user-interested topics in system responses', 'year': 2015, 'publisher': 'IEEE', 'start_page': 771, 'end_page': 776, 'pages': 6, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Open-domain personalized dialog system using user-interested topics in system responses\n%A Bang, Jeesoo\n%A Han, Sangdo\n%A Lee, Kyusong\n%A Lee, Gary Geunbae\n%B Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Workshop on\n%P 771-776\n%@ 1479972916\n%D 2015\n%I IEEE\n', 'RIS': None, 'authors': 4, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:34,656 DEBUG dbutils] Query result: 250
[2018-03-02 15:37:34,658 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://ieeexplore.ieee.org/abstract/document/7404866/.
[2018-03-02 15:37:34,658 DEBUG scihub] Get page from sci-hub for paper with DOI=http://ieeexplore.ieee.org/abstract/document/7404866/.
[2018-03-02 15:37:34,845 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7404866/ HTTP/1.1" 200 None
[2018-03-02 15:37:34,846 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:37:34,846 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:37:34,846 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for sci-hub.tw
[2018-03-02 15:37:35,035 DEBUG requests.packages.urllib3.connectionpool] "GET //http://ieeexplore.ieee.org/abstract/document/7404866/ HTTP/1.1" 200 None
[2018-03-02 15:37:35,041 DEBUG scihub] URL for PDF: http://cyber.sci-hub.tw/MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true.
[2018-03-02 15:37:35,042 WARNING utils] Download file (url='http://cyber.sci-hub.tw/MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true') and save (filename='PDF//250.pdf')
[2018-03-02 15:37:35,057 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: cyber.sci-hub.tw
[2018-03-02 15:37:35,285 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:37:35,285 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:37:35,286 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:37:35,301 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (6): cyber.sci-hub.tw
[2018-03-02 15:37:35,575 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:37:35,578 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:37:35,578 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:37:51,266 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:37:51,266 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:37:51,605 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true HTTP/1.1" 200 228998
[2018-03-02 15:37:51,606 DEBUG utils] Get current proxy for cyber.sci-hub.tw.
[2018-03-02 15:37:51,606 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:37:51,606 DEBUG utils] Change proxy to {'https': '187.32.172.65:3128'} for sci-hub.tw
[2018-03-02 15:37:51,620 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (7): cyber.sci-hub.tw
[2018-03-02 15:37:51,875 DEBUG requests.packages.urllib3.connectionpool] "GET /MTAuMTEwOS9hc3J1LjIwMTUuNzQwNDg2Ng==/bang2015.pdf?download=true HTTP/1.1" 200 228998
[2018-03-02 15:37:51,876 DEBUG utils] Content-length=228998
[2018-03-02 15:37:51,877 DEBUG utils] Create file PDF//250.pdf, start download.
[2018-03-02 15:37:52,289 DEBUG utils] End download file PDF//250.pdf.
[2018-03-02 15:37:52,293 DEBUG dbutils] Update pdf_transaction for paper id=250.
[2018-03-02 15:37:52,294 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 250'
[2018-03-02 15:37:52,294 DEBUG dbutils] Query result: null
[2018-03-02 15:37:52,294 DEBUG scholar] Handle paper #279 (total 1170)
[2018-03-02 15:37:52,294 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:37:52,309 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:52,309 DEBUG utils] Proxy: {'https': '217.150.80.59:3128'}
[2018-03-02 15:37:52,309 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for scholar.google.com
[2018-03-02 15:37:52,327 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:37:52,329 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:37:54,044 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:-8gNNHeeb1YJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_8DqLYTJwa0N5aUeSsTIkWMeLHS6&scisf=3&ct=citation&cd=278&hl=en HTTP/1.1" 200 83
[2018-03-02 15:37:54,045 DEBUG scholar] EndNote file:
%0 Journal Article
%T THE TURING TEST AND THE 20 QUESTIONS GAME
%A Test, Turing

[2018-03-02 15:37:54,045 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:54,045 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:54,045 DEBUG __main__] Skip paper #279, empty year or authors fields.
[2018-03-02 15:37:54,046 DEBUG scholar] Handle paper #280 (total 1170)
[2018-03-02 15:37:54,046 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:37:54,049 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:37:54,049 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:37:54,374 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:wSVD5Nfy9VwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_yRJ_YpVnnvv6xIS13iQhqemtNpr&scisf=3&ct=citation&cd=279&hl=en HTTP/1.1" 200 269
[2018-03-02 15:37:54,376 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Context-aware natural language generation for spoken dialogue systems
%A Zhou, Hao
%A Huang, Minlie
%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers
%P 2032-2041
%D 2016

[2018-03-02 15:37:54,376 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:37:54,376 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:37:54,376 DEBUG __main__] Process content of EndNote file #280
{"title": "Context-aware natural language generation for spoken dialogue systems", "url": "http://www.aclweb.org/anthology/C16-1191", "author": [{"shortname": "H Zhou", "gid": "q3WaozcAAAAJ"}, {"shortname": "M Huang", "gid": ""}], "year": 2016}
{"citedby": 3, "type": "Conference Proceedings", "title": "Context-aware natural language generation for spoken dialogue systems", "author": ["Zhou, Hao", "Huang, Minlie"], "secondarytitle": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers", "pages": "2032-2041", "year": "2016", "start_page": 2032, "end_page": 2041, "volume": 10, "EndNote": "%0 Conference Proceedings\n%T Context-aware natural language generation for spoken dialogue systems\n%A Zhou, Hao\n%A Huang, Minlie\n%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\n%P 2032-2041\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:wSVD5Nfy9VwJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplH_yRJ_YpVnnvv6xIS13iQhqemtNpr&scisf=3&ct=citation&cd=279&hl=en"}
[2018-03-02 15:37:54,376 DEBUG dbutils] Get paper id {"DOI": null, "title": "Context-aware natural language generation for spoken dialogue systems", "auth_count": 2, "g_type": "Conference Proceedings", "pages": 10, "year": 2016, "rg_id": null, "start_page": 2032, "end_page": 2041}.
[2018-03-02 15:37:54,376 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Context-aware natural language generation for spoken dialogue systems', 'auth_count': 2, 'g_type': 'Conference Proceedings', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 2032, 'end_page': 2041}
[2018-03-02 15:37:54,376 DEBUG dbutils] Query result: []
[2018-03-02 15:37:54,376 DEBUG dbutils] Paper id = None.
[2018-03-02 15:37:54,376 DEBUG dbutils] Add new paper (title='Context-aware natural language generation for spoken dialogue systems')
[2018-03-02 15:37:54,376 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Context-aware natural language generation for spoken dialogue systems', 'year': 2016, 'publisher': None, 'start_page': 2032, 'end_page': 2041, 'pages': 10, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Context-aware natural language generation for spoken dialogue systems\n%A Zhou, Hao\n%A Huang, Minlie\n%B Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers\n%P 2032-2041\n%D 2016\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:37:54,376 DEBUG dbutils] Query result: 251
[2018-03-02 15:37:54,380 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.aclweb.org/anthology/C16-1191.
[2018-03-02 15:37:54,381 WARNING utils] Download file (url='http://www.aclweb.org/anthology/C16-1191') and save (filename='PDF//251.pdf')
[2018-03-02 15:37:54,381 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:37:54,382 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:37:54,398 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.aclweb.org
[2018-03-02 15:37:54,989 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1191 HTTP/1.1" 200 None
[2018-03-02 15:37:54,989 DEBUG utils] Downloading the entire file.
[2018-03-02 15:37:54,989 DEBUG utils] Get current proxy for www.aclweb.org.
[2018-03-02 15:37:54,989 DEBUG utils] Proxy: {'https': '189.84.173.241:3128'}
[2018-03-02 15:37:54,989 DEBUG utils] Change proxy to {'https': '179.106.37.39:8080'} for otherhost
[2018-03-02 15:37:55,005 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): www.aclweb.org
[2018-03-02 15:37:55,614 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1191 HTTP/1.1" 200 None
[2018-03-02 15:37:57,382 DEBUG utils] Save file PDF//251.pdf.
[2018-03-02 15:37:57,384 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.aclweb.org/anthology/C16-1191.
[2018-03-02 15:37:57,384 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.aclweb.org/anthology/C16-1191.
[2018-03-02 15:37:57,584 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/C16-1191 HTTP/1.1" 302 None
[2018-03-02 15:37:57,935 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1191 HTTP/1.1" 200 None
[2018-03-02 15:37:59,061 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:37:59,061 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:37:59,244 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.aclweb.org/anthology/C16-1191 HTTP/1.1" 302 None
[2018-03-02 15:37:59,555 DEBUG requests.packages.urllib3.connectionpool] "GET /anthology/C16-1191 HTTP/1.1" 200 None
[2018-03-02 15:38:05,037 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:38:05,037 DEBUG dbutils] Commiting transaction 280.
[2018-03-02 15:38:05,189 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:38:05,189 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:38:05,189 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:38:05,189 DEBUG utils] Change proxy to {'https': '178.218.45.58:8080'} for scholar.google.com
[2018-03-02 15:38:05,204 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:38:06,686 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=280&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:38:07,060 DEBUG scholar] Find papers on page #29 (max_google_papers = 300)
[2018-03-02 15:38:07,060 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:38:07,061 DEBUG scholar] Handle paper #281 (total 1170)
[2018-03-02 15:38:07,061 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:38:07,063 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:07,064 DEBUG utils] Proxy: {'https': '178.218.45.58:8080'}
[2018-03-02 15:38:07,083 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:14,486 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 289, in connect
    ssl_version=resolved_ssl_version)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\ssl_.py", line 308, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 401, in wrap_socket
    _context=self, _session=session)
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 808, in __init__
    self.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 1061, in do_handshake
    self._sslobj.do_handshake()
  File "D:\Programming\Python\ANACONDA3\lib\ssl.py", line 683, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:732: The handshake operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:auyAnN50rFsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS_N1NITAdZz7K-ULqcITJ6BrrsP_&scisf=3&ct=citation&cd=280&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:auyAnN50rFsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS_N1NITAdZz7K-ULqcITJ6BrrsP_&scisf=3&ct=citation&cd=280&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:732: The handshake operation timed out',)))

[2018-03-02 15:38:14,486 DEBUG utils] Change proxy to {'https': '200.29.191.151:3128'} for scholar.google.com
[2018-03-02 15:38:14,487 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:14,487 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:38:14,501 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:38:14,502 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:18,634 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:auyAnN50rFsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS_N1NITAdZz7K-ULqcITJ6BrrsP_&scisf=3&ct=citation&cd=280&hl=en HTTP/1.1" 200 131
[2018-03-02 15:38:18,634 DEBUG scholar] EndNote file:
%0 Book
%T Negotiated Learner Modelling with a Conversational Agent
%A Kerly, Alice Laura
%D 2009
%I University of Birmingham

[2018-03-02 15:38:18,635 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:18,635 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:18,635 DEBUG __main__] Process content of EndNote file #281
{"title": "Negotiated Learner Modelling with a Conversational Agent", "url": "http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf", "author": [{"shortname": "AL Kerly", "gid": ""}], "year": 2009}
{"citedby": 2, "type": "Book", "title": "Negotiated Learner Modelling with a Conversational Agent", "author": ["Kerly, Alice Laura"], "year": "2009", "publisher": "University of Birmingham", "EndNote": "%0 Book\n%T Negotiated Learner Modelling with a Conversational Agent\n%A Kerly, Alice Laura\n%D 2009\n%I University of Birmingham\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:auyAnN50rFsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS_N1NITAdZz7K-ULqcITJ6BrrsP_&scisf=3&ct=citation&cd=280&hl=en"}
[2018-03-02 15:38:18,635 DEBUG dbutils] Get paper id {"DOI": null, "title": "Negotiated Learner Modelling with a Conversational Agent", "auth_count": 1, "g_type": "Book", "pages": null, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:38:18,635 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Negotiated Learner Modelling with a Conversational Agent', 'auth_count': 1, 'g_type': 'Book', 'pages': None, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:38:18,635 DEBUG dbutils] Query result: []
[2018-03-02 15:38:18,636 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:18,636 DEBUG dbutils] Add new paper (title='Negotiated Learner Modelling with a Conversational Agent')
[2018-03-02 15:38:18,636 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Negotiated Learner Modelling with a Conversational Agent', 'year': 2009, 'publisher': 'University of Birmingham', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Book', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Book\n%T Negotiated Learner Modelling with a Conversational Agent\n%A Kerly, Alice Laura\n%D 2009\n%I University of Birmingham\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:18,637 DEBUG dbutils] Query result: 252
[2018-03-02 15:38:18,639 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf.
[2018-03-02 15:38:18,640 WARNING utils] Download file (url='http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf') and save (filename='PDF//252.pdf')
[2018-03-02 15:38:18,641 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 15:38:18,641 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:38:18,663 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.academia.edu
[2018-03-02 15:38:19,154 DEBUG requests.packages.urllib3.connectionpool] "GET /download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf HTTP/1.1" 404 None
[2018-03-02 15:38:19,158 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf.
[2018-03-02 15:38:19,158 DEBUG scihub] Get page from sci-hub for paper with DOI=http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf.
[2018-03-02 15:38:19,384 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf HTTP/1.1" 302 None
[2018-03-02 15:38:19,654 DEBUG requests.packages.urllib3.connectionpool] "GET /download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf HTTP/1.1" 404 None
[2018-03-02 15:38:19,656 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:38:19,656 DEBUG utils] Proxy: {'https': '187.32.172.65:3128'}
[2018-03-02 15:38:19,656 DEBUG utils] Change proxy to {'https': '177.69.237.53:3128'} for sci-hub.tw
[2018-03-02 15:38:19,861 DEBUG requests.packages.urllib3.connectionpool] "GET //http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf HTTP/1.1" 302 None
[2018-03-02 15:38:20,146 DEBUG requests.packages.urllib3.connectionpool] "GET /download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf HTTP/1.1" 404 None
[2018-03-02 15:38:20,150 DEBUG utils] Request is empty, don't create soup.
[2018-03-02 15:38:20,150 DEBUG __main__] Failed get_pdf from sci-hub for paper #252. URL=252
[2018-03-02 15:38:20,151 DEBUG scholar] Handle paper #282 (total 1170)
[2018-03-02 15:38:20,151 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:38:20,156 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:20,156 DEBUG utils] Proxy: {'https': '200.29.191.151:3128'}
[2018-03-02 15:38:20,156 DEBUG utils] Change proxy to {'https': '159.224.243.116:3128'} for scholar.google.com
[2018-03-02 15:38:20,171 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:38:20,172 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:21,773 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:m47DYQ939Q0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplISzcSPVQDGWMzHwPPQUKSaFZOYm7O&scisf=3&ct=citation&cd=281&hl=en HTTP/1.1" 200 348
[2018-03-02 15:38:21,774 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite
%A Kenyon, Shaun
%A Bridges, CP
%A Liddle, D
%A Dyer, R
%A Parsons, J
%A Feltham, D
%A Taylor, R
%A Mellor, D
%A Schofield, A
%A Linehan, R
%B Proceedings of the 2nd International Astronautical Congress 2011,(IAC11)
%D 2011

[2018-03-02 15:38:21,774 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:21,774 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:21,774 DEBUG __main__] Process content of EndNote file #282
{"title": "STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite", "url": "http://epubs.surrey.ac.uk/26828/", "author": [{"shortname": "S Kenyon", "gid": ""}, {"shortname": "CP Bridges", "gid": "iySVX8MAAAAJ"}, {"shortname": "D Liddle", "gid": ""}, {"shortname": "R Dyer", "gid": ""}], "year": 2011}
{"citedby": 30, "type": "Conference Proceedings", "title": "STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite", "author": ["Kenyon, Shaun", "Bridges, CP", "Liddle, D", "Dyer, R", "Parsons, J", "Feltham, D", "Taylor, R", "Mellor, D", "Schofield, A", "Linehan, R"], "secondarytitle": "Proceedings of the 2nd International Astronautical Congress 2011,(IAC\u201911)", "year": "2011", "EndNote": "%0 Conference Proceedings\n%T STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite\n%A Kenyon, Shaun\n%A Bridges, CP\n%A Liddle, D\n%A Dyer, R\n%A Parsons, J\n%A Feltham, D\n%A Taylor, R\n%A Mellor, D\n%A Schofield, A\n%A Linehan, R\n%B Proceedings of the 2nd International Astronautical Congress 2011,(IAC\u201911)\n%D 2011\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:m47DYQ939Q0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplISzcSPVQDGWMzHwPPQUKSaFZOYm7O&scisf=3&ct=citation&cd=281&hl=en"}
[2018-03-02 15:38:21,775 DEBUG dbutils] Get paper id {"DOI": null, "title": "STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite", "auth_count": 10, "g_type": "Conference Proceedings", "pages": null, "year": 2011, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:38:21,775 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite', 'auth_count': 10, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2011, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:38:21,775 DEBUG dbutils] Query result: []
[2018-03-02 15:38:21,775 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:21,775 DEBUG dbutils] Add new paper (title='STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite')
[2018-03-02 15:38:21,775 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite', 'year': 2011, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T STRaND-1: Use of a $500 Smartphone as the Central Avionics of a Nanosatellite\n%A Kenyon, Shaun\n%A Bridges, CP\n%A Liddle, D\n%A Dyer, R\n%A Parsons, J\n%A Feltham, D\n%A Taylor, R\n%A Mellor, D\n%A Schofield, A\n%A Linehan, R\n%B Proceedings of the 2nd International Astronautical Congress 2011,(IAC11)\n%D 2011\n', 'RIS': None, 'authors': 10, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:21,775 DEBUG dbutils] Query result: 253
[2018-03-02 15:38:21,777 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://epubs.surrey.ac.uk/26828/2/STRaND-1%20IAC%20Paper.pdf.
[2018-03-02 15:38:21,778 WARNING utils] Download file (url='http://epubs.surrey.ac.uk/26828/2/STRaND-1%20IAC%20Paper.pdf') and save (filename='PDF//253.pdf')
[2018-03-02 15:38:21,778 DEBUG utils] Get current proxy for epubs.surrey.ac.uk.
[2018-03-02 15:38:21,778 DEBUG utils] Proxy: {'https': '179.106.37.39:8080'}
[2018-03-02 15:38:21,778 DEBUG utils] Change proxy to {'https': '185.66.175.156:3128'} for otherhost
[2018-03-02 15:38:21,795 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): epubs.surrey.ac.uk
[2018-03-02 15:38:24,094 DEBUG requests.packages.urllib3.connectionpool] "GET /26828/2/STRaND-1%20IAC%20Paper.pdf HTTP/1.1" 200 5055826
[2018-03-02 15:38:24,094 DEBUG utils] Content-length=5055826
[2018-03-02 15:38:24,095 DEBUG utils] Create file PDF//253.pdf, start download.
[2018-03-02 15:38:28,680 DEBUG utils] End download file PDF//253.pdf.
[2018-03-02 15:38:28,680 DEBUG dbutils] Update pdf_transaction for paper id=253.
[2018-03-02 15:38:28,681 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 253'
[2018-03-02 15:38:28,681 DEBUG dbutils] Query result: null
[2018-03-02 15:38:28,682 DEBUG scholar] Handle paper #283 (total 1170)
[2018-03-02 15:38:28,682 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:38:28,686 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:28,687 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:38:28,984 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AAcFHtWZbhUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9RwYLFlzD5hP8WzWhaJE5ICFrnR&scisf=3&ct=citation&cd=282&hl=en HTTP/1.1" 200 265
[2018-03-02 15:38:28,985 DEBUG scholar] EndNote file:
%0 Journal Article
%T Smart talking robot Xiaotu: participatory library service based on artificial intelligence
%A Yao, Fei
%A Zhang, Chengyu
%A Chen, Wu
%J Library Hi Tech
%V 33
%N 2
%P 245-260
%@ 0737-8831
%D 2015
%I Emerald Group Publishing Limited

[2018-03-02 15:38:28,985 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:28,985 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:28,985 DEBUG __main__] Process content of EndNote file #283
{"title": "Smart talking robot Xiaotu: participatory library service based on artificial intelligence", "url": "http://www.emeraldinsight.com/doi/abs/10.1108/LHT-02-2015-0010", "author": [{"shortname": "F Yao", "gid": ""}, {"shortname": "C Zhang", "gid": ""}, {"shortname": "W Chen", "gid": ""}], "year": 2015}
{"citedby": 1, "type": "Journal Article", "title": "Smart talking robot Xiaotu: participatory library service based on artificial intelligence", "author": ["Yao, Fei", "Zhang, Chengyu", "Chen, Wu"], "journal": "Library Hi Tech", "volume": 16, "numberorissue": "2", "pages": "245-260", "isbn/issn": "0737-8831", "year": "2015", "publisher": "Emerald Group Publishing Limited", "start_page": 245, "end_page": 260, "EndNote": "%0 Journal Article\n%T Smart talking robot Xiaotu: participatory library service based on artificial intelligence\n%A Yao, Fei\n%A Zhang, Chengyu\n%A Chen, Wu\n%J Library Hi Tech\n%V 33\n%N 2\n%P 245-260\n%@ 0737-8831\n%D 2015\n%I Emerald Group Publishing Limited\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:AAcFHtWZbhUJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9RwYLFlzD5hP8WzWhaJE5ICFrnR&scisf=3&ct=citation&cd=282&hl=en"}
[2018-03-02 15:38:28,986 DEBUG dbutils] Get paper id {"DOI": null, "title": "Smart talking robot Xiaotu: participatory library service based on artificial intelligence", "auth_count": 3, "g_type": "Journal Article", "pages": 16, "year": 2015, "rg_id": null, "start_page": 245, "end_page": 260}.
[2018-03-02 15:38:28,986 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Smart talking robot Xiaotu: participatory library service based on artificial intelligence', 'auth_count': 3, 'g_type': 'Journal Article', 'pages': 16, 'year': 2015, 'rg_id': None, 'start_page': 245, 'end_page': 260}
[2018-03-02 15:38:28,986 DEBUG dbutils] Query result: []
[2018-03-02 15:38:28,986 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:28,986 DEBUG dbutils] Add new paper (title='Smart talking robot Xiaotu: participatory library service based on artificial intelligence')
[2018-03-02 15:38:28,986 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Smart talking robot Xiaotu: participatory library service based on artificial intelligence', 'year': 2015, 'publisher': 'Emerald Group Publishing Limited', 'start_page': 245, 'end_page': 260, 'pages': 16, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Smart talking robot Xiaotu: participatory library service based on artificial intelligence\n%A Yao, Fei\n%A Zhang, Chengyu\n%A Chen, Wu\n%J Library Hi Tech\n%V 33\n%N 2\n%P 245-260\n%@ 0737-8831\n%D 2015\n%I Emerald Group Publishing Limited\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:28,986 DEBUG dbutils] Query result: 254
[2018-03-02 15:38:28,988 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://cdn.tc-library.org/EdLab-blog/20180108142401-tsinghua_xiaotu_pdf_ffaa689c48f91b049022d41751aca730.pdf.
[2018-03-02 15:38:28,989 WARNING utils] Download file (url='https://cdn.tc-library.org/EdLab-blog/20180108142401-tsinghua_xiaotu_pdf_ffaa689c48f91b049022d41751aca730.pdf') and save (filename='PDF//254.pdf')
[2018-03-02 15:38:28,989 DEBUG utils] Get current proxy for cdn.tc-library.org.
[2018-03-02 15:38:28,989 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:38:29,003 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): cdn.tc-library.org
[2018-03-02 15:38:30,814 DEBUG requests.packages.urllib3.connectionpool] "GET /EdLab-blog/20180108142401-tsinghua_xiaotu_pdf_ffaa689c48f91b049022d41751aca730.pdf HTTP/1.1" 200 279332
[2018-03-02 15:38:30,815 DEBUG utils] Content-length=279332
[2018-03-02 15:38:30,815 DEBUG utils] Create file PDF//254.pdf, start download.
[2018-03-02 15:38:31,836 DEBUG utils] End download file PDF//254.pdf.
[2018-03-02 15:38:31,837 DEBUG dbutils] Update pdf_transaction for paper id=254.
[2018-03-02 15:38:31,837 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 254'
[2018-03-02 15:38:31,838 DEBUG dbutils] Query result: null
[2018-03-02 15:38:31,838 DEBUG scholar] Handle paper #284 (total 1170)
[2018-03-02 15:38:31,838 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:38:31,846 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:31,846 DEBUG utils] Proxy: {'https': '159.224.243.116:3128'}
[2018-03-02 15:38:31,846 DEBUG utils] Change proxy to {'https': '199.195.253.124:3128'} for scholar.google.com
[2018-03-02 15:38:31,870 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:37,054 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:AgVkrCMQQLoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9WuFtrCnCcIeIqbcmNHBTXONsU2&scisf=3&ct=citation&cd=283&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:AgVkrCMQQLoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9WuFtrCnCcIeIqbcmNHBTXONsU2&scisf=3&ct=citation&cd=283&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:38:37,054 DEBUG utils] Change proxy to {'https': '176.235.11.6:8080'} for scholar.google.com
[2018-03-02 15:38:37,055 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:37,055 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:38:37,069 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:38:37,070 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:38,933 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:AgVkrCMQQLoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9WuFtrCnCcIeIqbcmNHBTXONsU2&scisf=3&ct=citation&cd=283&hl=en HTTP/1.1" 200 415
[2018-03-02 15:38:38,934 DEBUG scholar] EndNote file:
%0 Conference Proceedings
%T Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities
%A Lambropoulos, Niki
%B the Proceedings of the 1st Conference on Usability and Internationalization, in the 11th International Conference on Human-Computer Interaction Las Vegas, Nevada, USA. Published by Lawrence Erlbaum Associates, Inc
%D 2005

[2018-03-02 15:38:38,935 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:38,935 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:38,935 DEBUG __main__] Process content of EndNote file #284
{"title": "Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities", "url": "https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/252895370_Sociability_and_Usability_for_Contribution_based_on_Situated_Informal_Learning_and_Consensus_Knowledge_Building_in_Online_Communities/links/5868f23208aebf17d3a385a9/Sociability-and-Usability-for-Contribution-based-on-Situated-Informal-Learning-and-Consensus-Knowledge-Building-in-Online-Communities.pdf", "author": [{"shortname": "N Lambropoulos", "gid": "_VULjWQAAAAJ"}], "year": 2005}
{"citedby": 10, "type": "Conference Proceedings", "title": "Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities", "author": ["Lambropoulos, Niki"], "secondarytitle": "the Proceedings of the 1st Conference on Usability and Internationalization, in the 11th International Conference on Human-Computer Interaction Las Vegas, Nevada, USA. Published by Lawrence Erlbaum Associates, Inc", "year": "2005", "EndNote": "%0 Conference Proceedings\n%T Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities\n%A Lambropoulos, Niki\n%B the Proceedings of the 1st Conference on Usability and Internationalization, in the 11th International Conference on Human-Computer Interaction Las Vegas, Nevada, USA. Published by Lawrence Erlbaum Associates, Inc\n%D 2005\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:AgVkrCMQQLoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS9WuFtrCnCcIeIqbcmNHBTXONsU2&scisf=3&ct=citation&cd=283&hl=en"}
[2018-03-02 15:38:38,935 DEBUG dbutils] Get paper id {"DOI": null, "title": "Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities", "auth_count": 1, "g_type": "Conference Proceedings", "pages": null, "year": 2005, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:38:38,935 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities', 'auth_count': 1, 'g_type': 'Conference Proceedings', 'pages': None, 'year': 2005, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:38:38,935 DEBUG dbutils] Query result: []
[2018-03-02 15:38:38,935 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:38,935 DEBUG dbutils] Add new paper (title='Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities')
[2018-03-02 15:38:38,935 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities', 'year': 2005, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Conference Proceedings', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Conference Proceedings\n%T Sociability and usability for contribution based on situated informal learning and consensus knowledge building in online communities\n%A Lambropoulos, Niki\n%B the Proceedings of the 1st Conference on Usability and Internationalization, in the 11th International Conference on Human-Computer Interaction Las Vegas, Nevada, USA. Published by Lawrence Erlbaum Associates, Inc\n%D 2005\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:38,936 DEBUG dbutils] Query result: 255
[2018-03-02 15:38:38,938 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/252895370_Sociability_and_Usability_for_Contribution_based_on_Situated_Informal_Learning_and_Consensus_Knowledge_Building_in_Online_Communities/links/5868f23208aebf17d3a385a9/Sociability-and-Usability-for-Contribution-based-on-Situated-Informal-Learning-and-Consensus-Knowledge-Building-in-Online-Communities.pdf.
[2018-03-02 15:38:38,940 WARNING utils] Download file (url='https://www.researchgate.net/profile/Niki_Lambropoulos2/publication/252895370_Sociability_and_Usability_for_Contribution_based_on_Situated_Informal_Learning_and_Consensus_Knowledge_Building_in_Online_Communities/links/5868f23208aebf17d3a385a9/Sociability-and-Usability-for-Contribution-based-on-Situated-Informal-Learning-and-Consensus-Knowledge-Building-in-Online-Communities.pdf') and save (filename='PDF//255.pdf')
[2018-03-02 15:38:38,940 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:38:38,940 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:38:39,866 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Niki_Lambropoulos2/publication/252895370_Sociability_and_Usability_for_Contribution_based_on_Situated_Informal_Learning_and_Consensus_Knowledge_Building_in_Online_Communities/links/5868f23208aebf17d3a385a9/Sociability-and-Usability-for-Contribution-based-on-Situated-Informal-Learning-and-Consensus-Knowledge-Building-in-Online-Communities.pdf HTTP/1.1" 200 327415
[2018-03-02 15:38:39,867 DEBUG utils] Content-length=327415
[2018-03-02 15:38:39,867 DEBUG utils] Create file PDF//255.pdf, start download.
[2018-03-02 15:38:44,634 DEBUG utils] End download file PDF//255.pdf.
[2018-03-02 15:38:44,636 DEBUG dbutils] Update pdf_transaction for paper id=255.
[2018-03-02 15:38:44,636 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 255'
[2018-03-02 15:38:44,636 DEBUG dbutils] Query result: null
[2018-03-02 15:38:44,637 DEBUG scholar] Handle paper #285 (total 1170)
[2018-03-02 15:38:44,637 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:38:44,640 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:44,640 DEBUG utils] Proxy: {'https': '176.235.11.6:8080'}
[2018-03-02 15:38:44,640 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for scholar.google.com
[2018-03-02 15:38:44,655 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:38:44,657 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:46,853 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Ry3LHFp36IMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS1d1jnC8FC9hOyc6DTr2H7gi5E4F&scisf=3&ct=citation&cd=284&hl=en HTTP/1.1" 200 135
[2018-03-02 15:38:46,854 DEBUG scholar] EndNote file:
%0 Journal Article
%T Do machines hold a key to business success
%A Floyd, Schenita A
%J PM World Journal
%V 10
%P 1-10
%D 2016

[2018-03-02 15:38:46,854 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:46,854 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:46,855 DEBUG __main__] Process content of EndNote file #285
{"title": "Do machines hold a key to business success", "url": "http://pmworldlibrary.net/wp-content/uploads/2016/10/pmwj51-Oct2016-Floyd-machines-hold-key-to-business-success-second-edition.pdf", "author": [{"shortname": "SA Floyd", "gid": ""}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Do machines hold a key to business success", "author": ["Floyd, Schenita A"], "journal": "PM World Journal", "volume": 10, "pages": "1-10", "year": "2016", "start_page": 1, "end_page": 10, "EndNote": "%0 Journal Article\n%T Do machines hold a key to business success\n%A Floyd, Schenita A\n%J PM World Journal\n%V 10\n%P 1-10\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Ry3LHFp36IMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS1d1jnC8FC9hOyc6DTr2H7gi5E4F&scisf=3&ct=citation&cd=284&hl=en"}
[2018-03-02 15:38:46,855 DEBUG dbutils] Get paper id {"DOI": null, "title": "Do machines hold a key to business success", "auth_count": 1, "g_type": "Journal Article", "pages": 10, "year": 2016, "rg_id": null, "start_page": 1, "end_page": 10}.
[2018-03-02 15:38:46,855 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Do machines hold a key to business success', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 10, 'year': 2016, 'rg_id': None, 'start_page': 1, 'end_page': 10}
[2018-03-02 15:38:46,855 DEBUG dbutils] Query result: []
[2018-03-02 15:38:46,855 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:46,855 DEBUG dbutils] Add new paper (title='Do machines hold a key to business success')
[2018-03-02 15:38:46,855 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Do machines hold a key to business success', 'year': 2016, 'publisher': None, 'start_page': 1, 'end_page': 10, 'pages': 10, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Do machines hold a key to business success\n%A Floyd, Schenita A\n%J PM World Journal\n%V 10\n%P 1-10\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:46,855 DEBUG dbutils] Query result: 256
[2018-03-02 15:38:46,857 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://pmworldlibrary.net/wp-content/uploads/2016/10/pmwj51-Oct2016-Floyd-machines-hold-key-to-business-success-second-edition.pdf.
[2018-03-02 15:38:46,858 WARNING utils] Download file (url='http://pmworldlibrary.net/wp-content/uploads/2016/10/pmwj51-Oct2016-Floyd-machines-hold-key-to-business-success-second-edition.pdf') and save (filename='PDF//256.pdf')
[2018-03-02 15:38:46,858 DEBUG utils] Get current proxy for pmworldlibrary.net.
[2018-03-02 15:38:46,858 DEBUG utils] Proxy: {'https': '185.66.175.156:3128'}
[2018-03-02 15:38:46,858 DEBUG utils] Change proxy to {'https': '213.233.57.134:80'} for otherhost
[2018-03-02 15:38:46,875 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): pmworldlibrary.net
[2018-03-02 15:38:47,725 DEBUG requests.packages.urllib3.connectionpool] "GET /wp-content/uploads/2016/10/pmwj51-Oct2016-Floyd-machines-hold-key-to-business-success-second-edition.pdf HTTP/1.1" 200 942142
[2018-03-02 15:38:47,727 DEBUG utils] Content-length=942142
[2018-03-02 15:38:47,727 DEBUG utils] Create file PDF//256.pdf, start download.
[2018-03-02 15:38:49,128 DEBUG utils] End download file PDF//256.pdf.
[2018-03-02 15:38:49,129 DEBUG dbutils] Update pdf_transaction for paper id=256.
[2018-03-02 15:38:49,129 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 256'
[2018-03-02 15:38:49,129 DEBUG dbutils] Query result: null
[2018-03-02 15:38:49,130 DEBUG scholar] Handle paper #286 (total 1170)
[2018-03-02 15:38:49,130 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:38:49,134 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:49,134 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:38:49,603 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:qu9CbAdLSq8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS3B0VcbmHWd5Lv3pPwUj68-YI4bd&scisf=3&ct=citation&cd=285&hl=en HTTP/1.1" 200 187
[2018-03-02 15:38:49,604 DEBUG scholar] EndNote file:
%0 Journal Article
%T An Integrative Cognitive Architecture Aimed at Emulating Early Childhood Intelligence in a Humanoid Robot
%A Goertzel, Ben
%A Arel, Itamar
%A Pennachin, Cassio

[2018-03-02 15:38:49,604 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:49,604 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:49,604 DEBUG __main__] Skip paper #286, empty year or authors fields.
[2018-03-02 15:38:49,605 DEBUG scholar] Handle paper #287 (total 1170)
[2018-03-02 15:38:49,605 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:38:49,608 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:38:49,608 DEBUG utils] Proxy: {'https': '13.59.54.80:3128'}
[2018-03-02 15:38:49,608 DEBUG utils] Change proxy to {'https': '54.37.18.54:3128'} for scholar.google.com
[2018-03-02 15:38:49,625 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:38:49,627 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:38:50,493 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:Y-IbnL-00j0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS0xmMiZImPIc3biEOnyFOe2g1sC6&scisf=3&ct=citation&cd=286&hl=en HTTP/1.1" 200 226
[2018-03-02 15:38:50,494 DEBUG scholar] EndNote file:
%0 Journal Article
%T ?????????????????????????? (NDLtutor) ?????????????????????????
%A Suleman, Raja Muhammad
%D 2016

[2018-03-02 15:38:50,494 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:38:50,494 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:38:50,494 DEBUG __main__] Process content of EndNote file #287
{"title": "\u30a4\u30f3\u30bf\u30ec\u30b9\u30c8\u30d9\u30fc\u30b9\u306e\u4ea4\u6e09\u3092\u4f7f\u7528\u3057\u305f\u81ea\u52d5\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8 (NDLtutor) \u3092\u901a\u3058\u305f\u30aa\u30fc\u30d7\u30f3\u5b66\u7fd2\u8005\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u5bfe\u8a71\u306e\u5f79\u5272\u5f37\u5316", "url": "https://dspace.jaist.ac.jp/dspace/bitstream/10119/13816/3/paper.pdf", "author": [{"shortname": "RM Suleman", "gid": "bLQu4GMAAAAJ"}], "year": 2016}
{"type": "Journal Article", "title": "\u30a4\u30f3\u30bf\u30ec\u30b9\u30c8\u30d9\u30fc\u30b9\u306e\u4ea4\u6e09\u3092\u4f7f\u7528\u3057\u305f\u81ea\u52d5\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8 (NDLtutor) \u3092\u901a\u3058\u305f\u30aa\u30fc\u30d7\u30f3\u5b66\u7fd2\u8005\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u5bfe\u8a71\u306e\u5f79\u5272\u5f37\u5316", "author": ["Suleman, Raja Muhammad"], "year": "2016", "EndNote": "%0 Journal Article\n%T \u30a4\u30f3\u30bf\u30ec\u30b9\u30c8\u30d9\u30fc\u30b9\u306e\u4ea4\u6e09\u3092\u4f7f\u7528\u3057\u305f\u81ea\u52d5\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8 (NDLtutor) \u3092\u901a\u3058\u305f\u30aa\u30fc\u30d7\u30f3\u5b66\u7fd2\u8005\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u5bfe\u8a71\u306e\u5f79\u5272\u5f37\u5316\n%A Suleman, Raja Muhammad\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:Y-IbnL-00j0J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS0xmMiZImPIc3biEOnyFOe2g1sC6&scisf=3&ct=citation&cd=286&hl=en"}
[2018-03-02 15:38:50,494 DEBUG dbutils] Get paper id {"DOI": null, "title": "\u30a4\u30f3\u30bf\u30ec\u30b9\u30c8\u30d9\u30fc\u30b9\u306e\u4ea4\u6e09\u3092\u4f7f\u7528\u3057\u305f\u81ea\u52d5\u30c1\u30e3\u30c3\u30c8\u30dc\u30c3\u30c8 (NDLtutor) \u3092\u901a\u3058\u305f\u30aa\u30fc\u30d7\u30f3\u5b66\u7fd2\u8005\u30e2\u30c7\u30eb\u306b\u304a\u3051\u308b\u5bfe\u8a71\u306e\u5f79\u5272\u5f37\u5316", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:38:50,494 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': '?????????????????????????? (NDLtutor) ?????????????????????????', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:38:50,495 DEBUG dbutils] Query result: []
[2018-03-02 15:38:50,495 DEBUG dbutils] Paper id = None.
[2018-03-02 15:38:50,495 DEBUG dbutils] Add new paper (title='?????????????????????????? (NDLtutor) ?????????????????????????')
[2018-03-02 15:38:50,495 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': '?????????????????????????? (NDLtutor) ?????????????????????????', 'year': 2016, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T ?????????????????????????? (NDLtutor) ?????????????????????????\n%A Suleman, Raja Muhammad\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:38:50,495 DEBUG dbutils] Query result: 257
[2018-03-02 15:38:50,498 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://dspace.jaist.ac.jp/dspace/bitstream/10119/13816/3/paper.pdf.
[2018-03-02 15:38:50,499 WARNING utils] Download file (url='https://dspace.jaist.ac.jp/dspace/bitstream/10119/13816/3/paper.pdf') and save (filename='PDF//257.pdf')
[2018-03-02 15:38:50,499 DEBUG utils] Get current proxy for dspace.jaist.ac.jp.
[2018-03-02 15:38:50,499 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:38:50,514 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): dspace.jaist.ac.jp
[2018-03-02 15:38:58,234 DEBUG requests.packages.urllib3.connectionpool] "GET /dspace/bitstream/10119/13816/3/paper.pdf HTTP/1.1" 200 2285120
[2018-03-02 15:38:58,234 DEBUG utils] Content-length=2285120
[2018-03-02 15:38:58,236 DEBUG utils] Create file PDF//257.pdf, start download.
[2018-03-02 15:39:43,930 DEBUG utils] End download file PDF//257.pdf.
[2018-03-02 15:39:43,931 DEBUG dbutils] Update pdf_transaction for paper id=257.
[2018-03-02 15:39:43,932 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 257'
[2018-03-02 15:39:43,932 DEBUG dbutils] Query result: null
[2018-03-02 15:39:43,932 DEBUG scholar] Handle paper #288 (total 1170)
[2018-03-02 15:39:43,932 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:39:43,938 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:39:43,938 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:39:44,232 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:prBR5ColSVAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplISy1HK3zxEOz9Y5-gmeapSWSXmo18&scisf=3&ct=citation&cd=287&hl=en HTTP/1.1" 200 129
[2018-03-02 15:39:44,233 DEBUG scholar] EndNote file:
%0 Journal Article
%T Review of state-of-the-arts in artificial intelligence. Present and future of AI.
%A Shakirov, Vladimir

[2018-03-02 15:39:44,233 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:39:44,233 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:39:44,233 DEBUG __main__] Skip paper #288, empty year or authors fields.
[2018-03-02 15:39:44,234 DEBUG scholar] Handle paper #289 (total 1170)
[2018-03-02 15:39:44,234 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:39:44,237 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:39:44,237 DEBUG utils] Proxy: {'https': '54.37.18.54:3128'}
[2018-03-02 15:39:44,237 DEBUG utils] Change proxy to {'https': '47.52.44.31:8080'} for scholar.google.com
[2018-03-02 15:39:44,253 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:39:44,254 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:39:47,402 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:nh6D7MEiYY4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIS-1mJM8NWK3vAI_4zvp21OObm5HV&scisf=3&ct=citation&cd=288&hl=en HTTP/1.1" 200 264
[2018-03-02 15:39:47,403 DEBUG scholar] EndNote file:
%0 Journal Article
%T Peer Editing Process through Wikispaces in Correcting L2 Students Writing
%A Singh, Amreet Kaur Jageer
%A Harun, Raja Nor Safinas Binti Raja
%J The Asian Journal of English Language & Pedagogy
%V 1
%N 2013
%P 119-147
%@ 1823-6820

[2018-03-02 15:39:47,403 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:39:47,403 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:39:47,403 DEBUG __main__] Skip paper #289, empty year or authors fields.
[2018-03-02 15:39:47,404 DEBUG scholar] Handle paper #290 (total 1170)
[2018-03-02 15:39:47,404 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:39:47,407 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:39:47,407 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:39:47,942 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:2ewAb2NOXDEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplISwE8uQ9719LKjM9ZUVtgXUcJ7zia&scisf=3&ct=citation&cd=289&hl=en HTTP/1.1" 200 193
[2018-03-02 15:39:47,943 DEBUG scholar] EndNote file:
%0 Journal Article
%T Computing machinery and the individual: the personal Turing test
%A Carpenter, Rollo
%A Freeman, Jonathan
%J ??? _, Accessed September
%V 22
%P 2009
%D 2005

[2018-03-02 15:39:47,944 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:39:47,944 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:39:47,944 DEBUG __main__] Process content of EndNote file #290
{"title": "Computing machinery and the individual: the personal Turing test", "url": "https://www.researchgate.net/profile/Jonathan_Freeman2/publication/228975840_Computing_machinery_and_the_individual_the_personal_Turing_test/links/09e4150d05771759c6000000/Computing-machinery-and-the-individual-the-personal-Turing-test.pdf", "author": [{"shortname": "R Carpenter", "gid": ""}, {"shortname": "J Freeman", "gid": "HCBmDWEshdcC"}], "year": 2005}
{"citedby": 10, "type": "Journal Article", "title": "Computing machinery and the individual: the personal Turing test", "author": ["Carpenter, Rollo", "Freeman, Jonathan"], "journal": "\u5f51\u5e7d\u4e00 _, Accessed September", "volume": "22", "pages": "2009", "year": "2005", "EndNote": "%0 Journal Article\n%T Computing machinery and the individual: the personal Turing test\n%A Carpenter, Rollo\n%A Freeman, Jonathan\n%J \u5f51\u5e7d\u4e00 _, Accessed September\n%V 22\n%P 2009\n%D 2005\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:2ewAb2NOXDEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplISwE8uQ9719LKjM9ZUVtgXUcJ7zia&scisf=3&ct=citation&cd=289&hl=en"}
[2018-03-02 15:39:47,944 DEBUG dbutils] Get paper id {"DOI": null, "title": "Computing machinery and the individual: the personal Turing test", "auth_count": 2, "g_type": "Journal Article", "pages": 22, "year": 2005, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:39:47,944 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Computing machinery and the individual: the personal Turing test', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': 22, 'year': 2005, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:39:47,944 DEBUG dbutils] Query result: []
[2018-03-02 15:39:47,944 DEBUG dbutils] Paper id = None.
[2018-03-02 15:39:47,945 DEBUG dbutils] Add new paper (title='Computing machinery and the individual: the personal Turing test')
[2018-03-02 15:39:47,945 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Computing machinery and the individual: the personal Turing test', 'year': 2005, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': 22, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Computing machinery and the individual: the personal Turing test\n%A Carpenter, Rollo\n%A Freeman, Jonathan\n%J ??? _, Accessed September\n%V 22\n%P 2009\n%D 2005\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:39:47,945 DEBUG dbutils] Query result: 258
[2018-03-02 15:39:47,947 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Jonathan_Freeman2/publication/228975840_Computing_machinery_and_the_individual_the_personal_Turing_test/links/09e4150d05771759c6000000/Computing-machinery-and-the-individual-the-personal-Turing-test.pdf.
[2018-03-02 15:39:47,948 WARNING utils] Download file (url='https://www.researchgate.net/profile/Jonathan_Freeman2/publication/228975840_Computing_machinery_and_the_individual_the_personal_Turing_test/links/09e4150d05771759c6000000/Computing-machinery-and-the-individual-the-personal-Turing-test.pdf') and save (filename='PDF//258.pdf')
[2018-03-02 15:39:47,949 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:39:47,949 DEBUG utils] Proxy: {'https': '193.194.69.36:3128'}
[2018-03-02 15:39:47,949 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for www.researchgate.net
[2018-03-02 15:39:47,964 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:39:49,496 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Jonathan_Freeman2/publication/228975840_Computing_machinery_and_the_individual_the_personal_Turing_test/links/09e4150d05771759c6000000/Computing-machinery-and-the-individual-the-personal-Turing-test.pdf HTTP/1.1" 429 None
[2018-03-02 15:39:49,673 DEBUG utils] Change proxy to {'https': '195.191.109.165:80'} for www.researchgate.net
[2018-03-02 15:39:49,673 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:39:49,673 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:39:49,687 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:39:51,294 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Jonathan_Freeman2/publication/228975840_Computing_machinery_and_the_individual_the_personal_Turing_test/links/09e4150d05771759c6000000/Computing-machinery-and-the-individual-the-personal-Turing-test.pdf HTTP/1.1" 200 270122
[2018-03-02 15:39:51,294 DEBUG utils] Content-length=270122
[2018-03-02 15:39:51,295 DEBUG utils] Create file PDF//258.pdf, start download.
[2018-03-02 15:39:52,054 DEBUG utils] End download file PDF//258.pdf.
[2018-03-02 15:39:52,055 DEBUG dbutils] Update pdf_transaction for paper id=258.
[2018-03-02 15:39:52,055 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 258'
[2018-03-02 15:39:52,056 DEBUG dbutils] Query result: null
[2018-03-02 15:39:52,075 DEBUG scholar] Load next page in resulting query selection.
[2018-03-02 15:39:52,075 DEBUG utils] Get current proxy for scholar.google.com.
[2018-03-02 15:39:52,075 DEBUG utils] Proxy: {'https': '47.52.44.31:8080'}
[2018-03-02 15:39:52,076 DEBUG utils] Change proxy to {'https': '200.146.77.134:80'} for scholar.google.com
[2018-03-02 15:39:52,090 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): scholar.google.com
[2018-03-02 15:39:55,245 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar?start=290&q=Use+deep+learning+to+create+a+chatbot&hl=en&as_sdt=1,5&as_yhi=2016&as_vis=1 HTTP/1.1" 200 None
[2018-03-02 15:39:55,988 DEBUG scholar] Find papers on page #30 (max_google_papers = 300)
[2018-03-02 15:39:55,988 DEBUG scholar] Total 10 papers on page.
[2018-03-02 15:39:55,988 DEBUG scholar] Handle paper #291 (total 1170)
[2018-03-02 15:39:55,989 DEBUG scholar] Parse html and get info about paper #1 on searching page (total 10 on page)
[2018-03-02 15:39:55,994 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:39:55,994 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:39:56,011 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:39:56,013 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:39:58,992 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:9mFpS0mydG4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt7j2OHefdh80a1wzWlqRO32JCpUw&scisf=3&ct=citation&cd=290&hl=en HTTP/1.1" 200 195
[2018-03-02 15:39:58,993 DEBUG scholar] EndNote file:
%0 Report
%T Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems
%A Sottilare, Robert A
%A Sinatra, Anne M
%D 2014
%I ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD

[2018-03-02 15:39:58,993 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:39:58,993 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:39:58,994 DEBUG __main__] Process content of EndNote file #291
{"title": "Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems", "url": "http://www.dtic.mil/docs/citations/ADA612882", "author": [{"shortname": "RA Sottilare", "gid": "Gs6R8SsAAAAJ"}, {"shortname": "AM Sinatra", "gid": "fDnKL-wAAAAJ"}], "year": 2014}
{"type": "Report", "title": "Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems", "author": ["Sottilare, Robert A", "Sinatra, Anne M"], "year": "2014", "publisher": "ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD", "EndNote": "%0 Report\n%T Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems\n%A Sottilare, Robert A\n%A Sinatra, Anne M\n%D 2014\n%I ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:9mFpS0mydG4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt7j2OHefdh80a1wzWlqRO32JCpUw&scisf=3&ct=citation&cd=290&hl=en"}
[2018-03-02 15:39:58,994 DEBUG dbutils] Get paper id {"DOI": null, "title": "Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems", "auth_count": 2, "g_type": "Report", "pages": null, "year": 2014, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:39:58,994 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems', 'auth_count': 2, 'g_type': 'Report', 'pages': None, 'year': 2014, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:39:58,994 DEBUG dbutils] Query result: []
[2018-03-02 15:39:58,994 DEBUG dbutils] Paper id = None.
[2018-03-02 15:39:58,994 DEBUG dbutils] Add new paper (title='Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems')
[2018-03-02 15:39:58,994 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems', 'year': 2014, 'publisher': 'ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Report', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Report\n%T Adaptive Tutoring for Self-Regulated Learning: A Tutorial on Tutoring Systems\n%A Sottilare, Robert A\n%A Sinatra, Anne M\n%D 2014\n%I ARMY RESEARCH LAB ABERDEEN PROVING GROUND MD\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:39:58,994 DEBUG dbutils] Query result: 259
[2018-03-02 15:39:58,996 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.dtic.mil/get-tr-doc/pdf?AD=ADA612882.
[2018-03-02 15:39:58,997 WARNING utils] Download file (url='http://www.dtic.mil/get-tr-doc/pdf?AD=ADA612882') and save (filename='PDF//259.pdf')
[2018-03-02 15:39:58,997 DEBUG utils] Get current proxy for www.dtic.mil.
[2018-03-02 15:39:58,997 DEBUG utils] Proxy: {'https': '213.233.57.134:80'}
[2018-03-02 15:39:58,997 DEBUG utils] Change proxy to {'https': '5.189.173.222:3128'} for otherhost
[2018-03-02 15:39:59,017 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.dtic.mil
[2018-03-02 15:39:59,724 DEBUG requests.packages.urllib3.connectionpool] "GET /get-tr-doc/pdf?AD=ADA612882 HTTP/1.1" 200 5626878
[2018-03-02 15:39:59,725 DEBUG utils] Content-length=5626878
[2018-03-02 15:39:59,725 DEBUG utils] Create file PDF//259.pdf, start download.
[2018-03-02 15:41:46,913 DEBUG utils] End download file PDF//259.pdf.
[2018-03-02 15:41:46,914 DEBUG dbutils] Update pdf_transaction for paper id=259.
[2018-03-02 15:41:46,915 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 259'
[2018-03-02 15:41:46,915 DEBUG dbutils] Query result: null
[2018-03-02 15:41:46,917 DEBUG scholar] Handle paper #292 (total 1170)
[2018-03-02 15:41:46,917 DEBUG scholar] Parse html and get info about paper #2 on searching page (total 10 on page)
[2018-03-02 15:41:46,922 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:41:46,922 DEBUG utils] Proxy: {'https': '200.146.77.134:80'}
[2018-03-02 15:41:46,922 DEBUG utils] Change proxy to {'https': '201.62.99.208:3128'} for scholar.google.com
[2018-03-02 15:41:46,938 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:41:46,940 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:41:50,209 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:jna8KfSmZLMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt72bXieaa4ywmwb2gF5NrNNeinM4&scisf=3&ct=citation&cd=291&hl=en HTTP/1.1" 200 452
[2018-03-02 15:41:50,209 DEBUG scholar] EndNote file:
%0 Journal Article
%T Language and Computers Markus Dickinson*, Chris Brew, and Detmar Meurers(* Indiana University, Educational Testing Service, and University of T?bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99
%A Wiren, Mats
%J Computational Linguistics
%V 39
%N 3
%P 777-780
%@ 0891-2017
%D 2013
%I MIT Press

[2018-03-02 15:41:50,210 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:41:50,210 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:41:50,210 DEBUG __main__] Process content of EndNote file #292
{"title": "Language and Computers Markus Dickinson*, Chris Brew\u2021, and Detmar Meurers\u00b6(* Indiana University,\u2021 Educational Testing Service, and\u00b6 University of\u00a0\u2026", "url": "https://www.mitpressjournals.org/doi/full/10.1162/COLI_r_00165", "author": [{"shortname": "M Wir\u00e9n", "gid": ""}], "year": 2013}
{"type": "Journal Article", "title": "Language and Computers Markus Dickinson*, Chris Brew\u2021, and Detmar Meurers\u00b6(* Indiana University,\u2021 Educational Testing Service, and\u00b6 University of T\u0252bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99", "author": ["Wir\u00e9n, Mats"], "journal": "Computational Linguistics", "volume": 4, "numberorissue": "3", "pages": "777-780", "isbn/issn": "0891-2017", "year": "2013", "publisher": "MIT Press", "start_page": 777, "end_page": 780, "EndNote": "%0 Journal Article\n%T Language and Computers Markus Dickinson*, Chris Brew\u2021, and Detmar Meurers\u00b6(* Indiana University,\u2021 Educational Testing Service, and\u00b6 University of T\u0252bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99\n%A Wir\u00e9n, Mats\n%J Computational Linguistics\n%V 39\n%N 3\n%P 777-780\n%@ 0891-2017\n%D 2013\n%I MIT Press\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:jna8KfSmZLMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt72bXieaa4ywmwb2gF5NrNNeinM4&scisf=3&ct=citation&cd=291&hl=en"}
[2018-03-02 15:41:50,210 DEBUG dbutils] Get paper id {"DOI": null, "title": "Language and Computers Markus Dickinson*, Chris Brew\u2021, and Detmar Meurers\u00b6(* Indiana University,\u2021 Educational Testing Service, and\u00b6 University of T\u0252bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99", "auth_count": 1, "g_type": "Journal Article", "pages": 4, "year": 2013, "rg_id": null, "start_page": 777, "end_page": 780}.
[2018-03-02 15:41:50,210 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Language and Computers Markus Dickinson*, Chris Brew, and Detmar Meurers(* Indiana University, Educational Testing Service, and University of T?bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 4, 'year': 2013, 'rg_id': None, 'start_page': 777, 'end_page': 780}
[2018-03-02 15:41:50,210 DEBUG dbutils] Query result: []
[2018-03-02 15:41:50,210 DEBUG dbutils] Paper id = None.
[2018-03-02 15:41:50,210 DEBUG dbutils] Add new paper (title='Language and Computers Markus Dickinson*, Chris Brew, and Detmar Meurers(* Indiana University, Educational Testing Service, and University of T?bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99')
[2018-03-02 15:41:50,211 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Language and Computers Markus Dickinson*, Chris Brew, and Detmar Meurers(* Indiana University, Educational Testing Service, and University of T?bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99', 'year': 2013, 'publisher': 'MIT Press', 'start_page': 777, 'end_page': 780, 'pages': 4, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Language and Computers Markus Dickinson*, Chris Brew, and Detmar Meurers(* Indiana University, Educational Testing Service, and University of T?bingen) Wiley-Blackwell, 2013, xviii+ 232 pp; paperbound, ISBN 978-1-4051-8305-5, 34.95;hardbound,ISBN978-4051-8306-2, 87.95; e-book, ISBN 978-1-1183-2316-8, 22.99\n%A Wiren, Mats\n%J Computational Linguistics\n%V 39\n%N 3\n%P 777-780\n%@ 0891-2017\n%D 2013\n%I MIT Press\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:41:50,211 DEBUG dbutils] Query result: 260
[2018-03-02 15:41:50,212 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.mitpressjournals.org/doi/full/10.1162/COLI_r_00165.
[2018-03-02 15:41:50,213 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.mitpressjournals.org/doi/full/10.1162/COLI_r_00165.
[2018-03-02 15:41:50,228 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: sci-hub.tw
[2018-03-02 15:41:50,542 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.mitpressjournals.org/doi/full/10.1162/COLI_r_00165 HTTP/1.1" 200 None
[2018-03-02 15:41:50,543 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:41:50,543 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:41:50,744 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.mitpressjournals.org/doi/full/10.1162/COLI_r_00165 HTTP/1.1" 200 None
[2018-03-02 15:41:50,750 DEBUG scihub] URL for PDF: http://dabamirror.sci-hub.tw/25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true.
[2018-03-02 15:41:50,750 WARNING utils] Download file (url='http://dabamirror.sci-hub.tw/25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true') and save (filename='PDF//260.pdf')
[2018-03-02 15:41:50,766 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: dabamirror.sci-hub.tw
[2018-03-02 15:41:50,984 DEBUG requests.packages.urllib3.connectionpool] "GET /25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:41:50,985 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:41:50,985 DEBUG utils] Proxy: {'https': '177.69.237.53:3128'}
[2018-03-02 15:41:50,985 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for sci-hub.tw
[2018-03-02 15:41:51,000 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (12): dabamirror.sci-hub.tw
[2018-03-02 15:41:51,360 DEBUG requests.packages.urllib3.connectionpool] "GET /25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:41:51,372 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:41:51,372 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:41:58,340 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:41:58,340 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:41:58,612 DEBUG requests.packages.urllib3.connectionpool] "GET /25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:41:58,614 DEBUG utils] Get current proxy for dabamirror.sci-hub.tw.
[2018-03-02 15:41:58,614 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:41:58,629 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (13): dabamirror.sci-hub.tw
[2018-03-02 15:41:58,870 DEBUG requests.packages.urllib3.connectionpool] "GET /25484775559dce478d8442b28dad5543/wirn2013.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:41:58,875 DEBUG scholar] Handle paper #293 (total 1170)
[2018-03-02 15:41:58,875 DEBUG scholar] Parse html and get info about paper #3 on searching page (total 10 on page)
[2018-03-02 15:41:58,879 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:41:58,879 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:41:59,532 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:KwzcjWD-rtoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIty497dF6X1uIbMW4XquskrMSpBwk&scisf=3&ct=citation&cd=292&hl=en HTTP/1.1" 200 242
[2018-03-02 15:41:59,533 DEBUG scholar] EndNote file:
%0 Journal Article
%T Posthuman literacy in heterotopic space
%A Bayne, Sian
%A Ross, Jen
%J Literacy in the Digital University: Critical Perspectives on Learning, Scholarship and Technology
%P 95
%@ 1135108595
%D 2013
%I Routledge

[2018-03-02 15:41:59,533 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:41:59,533 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:41:59,533 DEBUG __main__] Process content of EndNote file #293
{"title": "Posthuman literacy in heterotopic space", "url": "https://books.google.com/books?hl=en&lr=&id=WVpHAQAAQBAJ&oi=fnd&pg=PA95&dq=Use+deep+learning+to+create+a+chatbot&ots=rDvSumzb2I&sig=UKGykQ9N1GTntt2Gh6zBiRujs40", "author": [{"shortname": "S Bayne", "gid": ""}, {"shortname": "J Ross", "gid": "zikOKmEAAAAJ"}], "year": 2013}
{"citedby": 14, "type": "Journal Article", "title": "Posthuman literacy in heterotopic space", "author": ["Bayne, Si\u00e2n", "Ross, Jen"], "journal": "Literacy in the Digital University: Critical Perspectives on Learning, Scholarship and Technology", "pages": "95", "isbn/issn": "1135108595", "year": "2013", "publisher": "Routledge", "EndNote": "%0 Journal Article\n%T Posthuman literacy in heterotopic space\n%A Bayne, Si\u00e2n\n%A Ross, Jen\n%J Literacy in the Digital University: Critical Perspectives on Learning, Scholarship and Technology\n%P 95\n%@ 1135108595\n%D 2013\n%I Routledge\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:KwzcjWD-rtoJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIty497dF6X1uIbMW4XquskrMSpBwk&scisf=3&ct=citation&cd=292&hl=en"}
[2018-03-02 15:41:59,533 DEBUG dbutils] Get paper id {"DOI": null, "title": "Posthuman literacy in heterotopic space", "auth_count": 2, "g_type": "Journal Article", "pages": null, "year": 2013, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:41:59,534 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Posthuman literacy in heterotopic space', 'auth_count': 2, 'g_type': 'Journal Article', 'pages': None, 'year': 2013, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:41:59,534 DEBUG dbutils] Query result: []
[2018-03-02 15:41:59,534 DEBUG dbutils] Paper id = None.
[2018-03-02 15:41:59,534 DEBUG dbutils] Add new paper (title='Posthuman literacy in heterotopic space')
[2018-03-02 15:41:59,534 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Posthuman literacy in heterotopic space', 'year': 2013, 'publisher': 'Routledge', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Posthuman literacy in heterotopic space\n%A Bayne, Sian\n%A Ross, Jen\n%J Literacy in the Digital University: Critical Perspectives on Learning, Scholarship and Technology\n%P 95\n%@ 1135108595\n%D 2013\n%I Routledge\n', 'RIS': None, 'authors': 2, 'ignore': False, 'transaction': 1}
[2018-03-02 15:41:59,534 DEBUG dbutils] Query result: 261
[2018-03-02 15:41:59,536 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.academia.edu/download/31800125/Bayne-and-Ross-heterotopia.pdf.
[2018-03-02 15:41:59,536 WARNING utils] Download file (url='http://www.academia.edu/download/31800125/Bayne-and-Ross-heterotopia.pdf') and save (filename='PDF//261.pdf')
[2018-03-02 15:41:59,537 DEBUG utils] Get current proxy for www.academia.edu.
[2018-03-02 15:41:59,537 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:41:59,553 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: www.academia.edu
[2018-03-02 15:41:59,954 DEBUG requests.packages.urllib3.connectionpool] "GET /download/31800125/Bayne-and-Ross-heterotopia.pdf HTTP/1.1" 404 None
[2018-03-02 15:41:59,958 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://books.google.com/books?hl=en&lr=&id=WVpHAQAAQBAJ&oi=fnd&pg=PA95&dq=Use+deep+learning+to+create+a+chatbot&ots=rDvSumzb2I&sig=UKGykQ9N1GTntt2Gh6zBiRujs40.
[2018-03-02 15:41:59,958 DEBUG scihub] Get page from sci-hub for paper with DOI=https://books.google.com/books?hl=en&lr=&id=WVpHAQAAQBAJ&oi=fnd&pg=PA95&dq=Use+deep+learning+to+create+a+chatbot&ots=rDvSumzb2I&sig=UKGykQ9N1GTntt2Gh6zBiRujs40.
[2018-03-02 15:42:00,141 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=WVpHAQAAQBAJ&oi=fnd&pg=PA95&dq=Use+deep+learning+to+create+a+chatbot&ots=rDvSumzb2I&sig=UKGykQ9N1GTntt2Gh6zBiRujs40 HTTP/1.1" 302 None
[2018-03-02 15:42:00,344 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:42:00,354 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:42:00,355 DEBUG utils] Proxy: {'https': '72.10.162.250:3128'}
[2018-03-02 15:42:00,355 DEBUG utils] Change proxy to {'https': '202.55.176.12:3128'} for sci-hub.tw
[2018-03-02 15:42:00,529 DEBUG requests.packages.urllib3.connectionpool] "GET //https://books.google.com/books?hl=en&lr=&id=WVpHAQAAQBAJ&oi=fnd&pg=PA95&dq=Use+deep+learning+to+create+a+chatbot&ots=rDvSumzb2I&sig=UKGykQ9N1GTntt2Gh6zBiRujs40 HTTP/1.1" 302 None
[2018-03-02 15:42:00,730 DEBUG requests.packages.urllib3.connectionpool] "GET / HTTP/1.1" 200 None
[2018-03-02 15:42:00,773 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:42:00,774 DEBUG scholar] Handle paper #294 (total 1170)
[2018-03-02 15:42:00,775 DEBUG scholar] Parse html and get info about paper #4 on searching page (total 10 on page)
[2018-03-02 15:42:00,778 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:00,778 DEBUG utils] Proxy: {'https': '201.62.99.208:3128'}
[2018-03-02 15:42:00,778 DEBUG utils] Change proxy to {'https': '186.195.37.42:8080'} for scholar.google.com
[2018-03-02 15:42:00,796 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:42:00,799 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:42:03,654 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:39jFE8JkSjEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2Nb903q7OdnHNpnpfRMUrt9qcRn&scisf=3&ct=citation&cd=293&hl=en HTTP/1.1" 200 129
[2018-03-02 15:42:03,655 DEBUG scholar] EndNote file:
%0 Journal Article
%T Introduction to Intellectual Conversational Agents
%A Panesar, Kulvinder
%J Epicurious
%P 67
%D 2015

[2018-03-02 15:42:03,655 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:42:03,655 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:42:03,655 DEBUG __main__] Process content of EndNote file #294
{"title": "Introduction to Intellectual Conversational Agents", "url": "https://www.bradfordcollege.ac.uk/sites/default/files/documents/Epicurious%201.pdf#page=67", "author": [{"shortname": "K Panesar", "gid": ""}], "year": 2015}
{"type": "Journal Article", "title": "Introduction to Intellectual Conversational Agents", "author": ["Panesar, Kulvinder"], "journal": "Epicurious", "pages": "67", "year": "2015", "EndNote": "%0 Journal Article\n%T Introduction to Intellectual Conversational Agents\n%A Panesar, Kulvinder\n%J Epicurious\n%P 67\n%D 2015\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:39jFE8JkSjEJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2Nb903q7OdnHNpnpfRMUrt9qcRn&scisf=3&ct=citation&cd=293&hl=en"}
[2018-03-02 15:42:03,655 DEBUG dbutils] Get paper id {"DOI": null, "title": "Introduction to Intellectual Conversational Agents", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:42:03,655 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Introduction to Intellectual Conversational Agents', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:42:03,655 DEBUG dbutils] Query result: []
[2018-03-02 15:42:03,655 DEBUG dbutils] Paper id = None.
[2018-03-02 15:42:03,656 DEBUG dbutils] Add new paper (title='Introduction to Intellectual Conversational Agents')
[2018-03-02 15:42:03,656 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Introduction to Intellectual Conversational Agents', 'year': 2015, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Introduction to Intellectual Conversational Agents\n%A Panesar, Kulvinder\n%J Epicurious\n%P 67\n%D 2015\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:42:03,656 DEBUG dbutils] Query result: 262
[2018-03-02 15:42:03,657 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.bradfordcollege.ac.uk/sites/default/files/documents/Epicurious%201.pdf#page=67.
[2018-03-02 15:42:03,658 WARNING utils] Download file (url='https://www.bradfordcollege.ac.uk/sites/default/files/documents/Epicurious%201.pdf#page=67') and save (filename='PDF//262.pdf')
[2018-03-02 15:42:03,659 DEBUG utils] Get current proxy for www.bradfordcollege.ac.uk.
[2018-03-02 15:42:03,659 DEBUG utils] Proxy: {'https': '5.189.173.222:3128'}
[2018-03-02 15:42:03,659 DEBUG utils] Change proxy to {'https': '216.98.8.115:3128'} for otherhost
[2018-03-02 15:42:03,676 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.bradfordcollege.ac.uk
[2018-03-02 15:42:05,624 DEBUG requests.packages.urllib3.connectionpool] "GET /sites/default/files/documents/Epicurious%201.pdf HTTP/1.1" 200 3544502
[2018-03-02 15:42:05,625 DEBUG utils] Content-length=3544502
[2018-03-02 15:42:05,626 DEBUG utils] Create file PDF//262.pdf, start download.
[2018-03-02 15:42:17,947 DEBUG utils] End download file PDF//262.pdf.
[2018-03-02 15:42:17,948 DEBUG dbutils] Update pdf_transaction for paper id=262.
[2018-03-02 15:42:17,948 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 262'
[2018-03-02 15:42:17,948 DEBUG dbutils] Query result: null
[2018-03-02 15:42:17,949 DEBUG scholar] Handle paper #295 (total 1170)
[2018-03-02 15:42:17,949 DEBUG scholar] Parse html and get info about paper #5 on searching page (total 10 on page)
[2018-03-02 15:42:17,952 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:17,952 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:42:18,476 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:1yDNweFbrksJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt9R7VsACJYOwJGuUr783toco6c8l&scisf=3&ct=citation&cd=294&hl=en HTTP/1.1" 200 220
[2018-03-02 15:42:18,477 DEBUG scholar] EndNote file:
%0 Generic
%T Networked Realms and Hoped-for Futures: a trans-generational dialogue
%A Jandric, Petar
%A Sinclair, Christine
%A Macleod, Hamish
%@ 2042-7530
%D 2015
%I SAGE Publications Sage UK: London, England

[2018-03-02 15:42:18,477 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:42:18,477 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:42:18,477 DEBUG __main__] Process content of EndNote file #295
{"title": "Networked Realms and Hoped-for Futures: a trans-generational dialogue", "url": "http://journals.sagepub.com/doi/full/10.1177/2042753015571037", "author": [{"shortname": "P Jandri\u0107", "gid": "n0tOR3kAAAAJ"}, {"shortname": "C Sinclair", "gid": ""}, {"shortname": "H Macleod", "gid": ""}], "year": 2015}
{"citedby": 2, "type": "Generic", "title": "Networked Realms and Hoped-for Futures: a trans-generational dialogue", "author": ["Jandri\u0107, Petar", "Sinclair, Christine", "Macleod, Hamish"], "isbn/issn": "2042-7530", "year": "2015", "publisher": "SAGE Publications Sage UK: London, England", "EndNote": "%0 Generic\n%T Networked Realms and Hoped-for Futures: a trans-generational dialogue\n%A Jandri\u0107, Petar\n%A Sinclair, Christine\n%A Macleod, Hamish\n%@ 2042-7530\n%D 2015\n%I SAGE Publications Sage UK: London, England\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:1yDNweFbrksJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt9R7VsACJYOwJGuUr783toco6c8l&scisf=3&ct=citation&cd=294&hl=en"}
[2018-03-02 15:42:18,477 DEBUG dbutils] Get paper id {"DOI": null, "title": "Networked Realms and Hoped-for Futures: a trans-generational dialogue", "auth_count": 3, "g_type": "Generic", "pages": null, "year": 2015, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:42:18,477 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Networked Realms and Hoped-for Futures: a trans-generational dialogue', 'auth_count': 3, 'g_type': 'Generic', 'pages': None, 'year': 2015, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:42:18,477 DEBUG dbutils] Query result: []
[2018-03-02 15:42:18,477 DEBUG dbutils] Paper id = None.
[2018-03-02 15:42:18,478 DEBUG dbutils] Add new paper (title='Networked Realms and Hoped-for Futures: a trans-generational dialogue')
[2018-03-02 15:42:18,478 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Networked Realms and Hoped-for Futures: a trans-generational dialogue', 'year': 2015, 'publisher': 'SAGE Publications Sage UK: London, England', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Networked Realms and Hoped-for Futures: a trans-generational dialogue\n%A Jandric, Petar\n%A Sinclair, Christine\n%A Macleod, Hamish\n%@ 2042-7530\n%D 2015\n%I SAGE Publications Sage UK: London, England\n', 'RIS': None, 'authors': 3, 'ignore': False, 'transaction': 1}
[2018-03-02 15:42:18,478 DEBUG dbutils] Query result: 263
[2018-03-02 15:42:18,479 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://petarjandric.com/images/pdf/ELEA_Editorial.pdf.
[2018-03-02 15:42:18,480 WARNING utils] Download file (url='http://petarjandric.com/images/pdf/ELEA_Editorial.pdf') and save (filename='PDF//263.pdf')
[2018-03-02 15:42:18,480 DEBUG utils] Get current proxy for petarjandric.com.
[2018-03-02 15:42:18,480 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:42:18,499 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): petarjandric.com
[2018-03-02 15:42:18,851 DEBUG requests.packages.urllib3.connectionpool] "GET /images/pdf/ELEA_Editorial.pdf HTTP/1.1" 200 None
[2018-03-02 15:42:18,852 DEBUG utils] Downloading the entire file.
[2018-03-02 15:42:18,852 DEBUG utils] Get current proxy for petarjandric.com.
[2018-03-02 15:42:18,852 DEBUG utils] Proxy: {'https': '216.98.8.115:3128'}
[2018-03-02 15:42:18,852 DEBUG utils] Change proxy to {'https': '185.93.3.123:8080'} for otherhost
[2018-03-02 15:42:18,867 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): petarjandric.com
[2018-03-02 15:42:19,140 DEBUG requests.packages.urllib3.connectionpool] "GET /images/pdf/ELEA_Editorial.pdf HTTP/1.1" 200 None
[2018-03-02 15:42:19,470 DEBUG utils] Save file PDF//263.pdf.
[2018-03-02 15:42:19,472 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://journals.sagepub.com/doi/full/10.1177/2042753015571037.
[2018-03-02 15:42:19,472 DEBUG scihub] Get page from sci-hub for paper with DOI=http://journals.sagepub.com/doi/full/10.1177/2042753015571037.
[2018-03-02 15:42:19,675 DEBUG requests.packages.urllib3.connectionpool] "GET //http://journals.sagepub.com/doi/full/10.1177/2042753015571037 HTTP/1.1" 200 None
[2018-03-02 15:42:19,677 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:42:19,677 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:42:19,873 DEBUG requests.packages.urllib3.connectionpool] "GET //http://journals.sagepub.com/doi/full/10.1177/2042753015571037 HTTP/1.1" 200 None
[2018-03-02 15:42:19,879 DEBUG scihub] URL for PDF: http://zeze.sci-hub.tw/a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true.
[2018-03-02 15:42:19,880 WARNING utils] Download file (url='http://zeze.sci-hub.tw/a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true') and save (filename='PDF//263.pdf')
[2018-03-02 15:42:19,896 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): zeze.sci-hub.tw
[2018-03-02 15:42:20,069 DEBUG requests.packages.urllib3.connectionpool] "GET /a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:42:20,070 DEBUG utils] Get current proxy for zeze.sci-hub.tw.
[2018-03-02 15:42:20,070 DEBUG utils] Proxy: {'https': '202.55.176.12:3128'}
[2018-03-02 15:42:20,070 DEBUG utils] Change proxy to {'https': '35.227.107.243:80'} for sci-hub.tw
[2018-03-02 15:42:20,087 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (2): zeze.sci-hub.tw
[2018-03-02 15:42:20,259 DEBUG requests.packages.urllib3.connectionpool] "GET /a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:42:20,263 DEBUG utils] Get current proxy for zeze.sci-hub.tw.
[2018-03-02 15:42:20,263 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:42:25,247 DEBUG utils] Waiting for cookies to be updated.
[2018-03-02 15:42:25,248 DEBUG utils] Load cookie from chrome.
[2018-03-02 15:42:25,512 DEBUG requests.packages.urllib3.connectionpool] "GET /a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:42:25,512 DEBUG utils] Get current proxy for zeze.sci-hub.tw.
[2018-03-02 15:42:25,512 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:42:25,533 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (3): zeze.sci-hub.tw
[2018-03-02 15:42:25,713 DEBUG requests.packages.urllib3.connectionpool] "GET /a536f73c47e14e7688a6f6846ec7247b/jandri2015.pdf?download=true HTTP/1.1" 200 None
[2018-03-02 15:42:25,719 DEBUG scholar] Handle paper #296 (total 1170)
[2018-03-02 15:42:25,719 DEBUG scholar] Parse html and get info about paper #6 on searching page (total 10 on page)
[2018-03-02 15:42:25,722 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:25,723 DEBUG utils] Proxy: {'https': '186.195.37.42:8080'}
[2018-03-02 15:42:25,723 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for scholar.google.com
[2018-03-02 15:42:25,744 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:42:30,970 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 914, in _tunnel
    (version, code, message) = response._read_status()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "D:\Programming\Python\ANACONDA3\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out',)))

[2018-03-02 15:42:30,970 DEBUG utils] Change proxy to {'https': '78.132.183.100:8080'} for scholar.google.com
[2018-03-02 15:42:30,971 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:30,971 DEBUG utils] Proxy: {'https': '78.132.183.100:8080'}
[2018-03-02 15:42:30,984 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:42:35,986 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 142, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 98, in create_connection
    raise err
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\connection.py", line 88, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 254, in connect
    conn = self._new_conn()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 147, in _new_conn
    (self.host, self.timeout))
requests.packages.urllib3.exceptions.ConnectTimeoutError: (<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007704067668>, 'Connection to 78.132.183.100 timed out. (connect timeout=5)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007704067668>, 'Connection to 78.132.183.100 timed out. (connect timeout=5)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 479, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='scholar.googleusercontent.com', port=443): Max retries exceeded with url: /scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en (Caused by ConnectTimeoutError(<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000007704067668>, 'Connection to 78.132.183.100 timed out. (connect timeout=5)'))

[2018-03-02 15:42:35,987 DEBUG utils] Change proxy to {'https': '125.212.207.121:3128'} for scholar.google.com
[2018-03-02 15:42:35,987 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:35,987 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:42:36,002 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:42:36,003 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:42:39,665 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en HTTP/1.1" 200 167
[2018-03-02 15:42:39,666 DEBUG scholar] EndNote file:
%0 Journal Article
%T Learners self-transcriptions for improving classroom interaction
%A Rog, Tomasz
%J Koninskie Studia Jezykowe
%V 4
%P 89-108
%D 2016

[2018-03-02 15:42:39,666 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:42:39,666 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:42:39,666 DEBUG __main__] Process content of EndNote file #296
{"title": "Learners' self-transcriptions for improving classroom interaction", "url": "https://www.ceeol.com/content-files/document-513536.pdf", "author": [{"shortname": "T R\u00f3g", "gid": "mBvF1yIAAAAJ"}], "year": 2016}
{"citedby": 1, "type": "Journal Article", "title": "Learners\u2019 self-transcriptions for improving classroom interaction", "author": ["R\u00f3g, Tomasz"], "journal": "Koni\u0144skie Studia J\u0119zykowe", "volume": 20, "pages": "89-108", "year": "2016", "start_page": 89, "end_page": 108, "EndNote": "%0 Journal Article\n%T Learners\u2019 self-transcriptions for improving classroom interaction\n%A R\u00f3g, Tomasz\n%J Koni\u0144skie Studia J\u0119zykowe\n%V 4\n%P 89-108\n%D 2016\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:G9KAzDrRIbsJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt2-9SE9swt6-zUGhLYvJJmL9bTxm&scisf=3&ct=citation&cd=295&hl=en"}
[2018-03-02 15:42:39,666 DEBUG dbutils] Get paper id {"DOI": null, "title": "Learners\u2019 self-transcriptions for improving classroom interaction", "auth_count": 1, "g_type": "Journal Article", "pages": 20, "year": 2016, "rg_id": null, "start_page": 89, "end_page": 108}.
[2018-03-02 15:42:39,667 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Learners self-transcriptions for improving classroom interaction', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 20, 'year': 2016, 'rg_id': None, 'start_page': 89, 'end_page': 108}
[2018-03-02 15:42:39,667 DEBUG dbutils] Query result: []
[2018-03-02 15:42:39,667 DEBUG dbutils] Paper id = None.
[2018-03-02 15:42:39,667 DEBUG dbutils] Add new paper (title='Learners self-transcriptions for improving classroom interaction')
[2018-03-02 15:42:39,667 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Learners self-transcriptions for improving classroom interaction', 'year': 2016, 'publisher': None, 'start_page': 89, 'end_page': 108, 'pages': 20, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Learners self-transcriptions for improving classroom interaction\n%A Rog, Tomasz\n%J Koninskie Studia Jezykowe\n%V 4\n%P 89-108\n%D 2016\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:42:39,667 DEBUG dbutils] Query result: 264
[2018-03-02 15:42:39,669 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.researchgate.net/profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf.
[2018-03-02 15:42:39,671 WARNING utils] Download file (url='https://www.researchgate.net/profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf') and save (filename='PDF//264.pdf')
[2018-03-02 15:42:39,672 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:42:39,672 DEBUG utils] Proxy: {'https': '195.191.109.165:80'}
[2018-03-02 15:42:39,672 DEBUG utils] Change proxy to {'https': '13.59.54.80:3128'} for www.researchgate.net
[2018-03-02 15:42:39,688 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:42:41,271 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf HTTP/1.1" 429 None
[2018-03-02 15:42:41,503 DEBUG utils] Change proxy to {'https': '190.242.119.196:3128'} for www.researchgate.net
[2018-03-02 15:42:41,504 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:42:41,504 DEBUG utils] Proxy: {'https': '190.242.119.196:3128'}
[2018-03-02 15:42:41,520 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:42:42,305 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.researchgate.net', port=443): Max retries exceeded with url: /profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:42:42,306 DEBUG utils] Change proxy to {'https': '170.185.68.14:8088'} for www.researchgate.net
[2018-03-02 15:42:42,306 DEBUG utils] Get current proxy for www.researchgate.net.
[2018-03-02 15:42:42,306 DEBUG utils] Proxy: {'https': '170.185.68.14:8088'}
[2018-03-02 15:42:42,321 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.researchgate.net
[2018-03-02 15:42:44,683 DEBUG requests.packages.urllib3.connectionpool] "GET /profile/Tomasz_Rog/publication/313139162_2016_Learners%27_self-transcriptions_for_improving_classroom_interaction_KSJ-42-89-108/links/5890f8fda6fdcc1b41453649/2016-Learners-self-transcriptions-for-improving-classroom-interaction-KSJ-42-89-108.pdf HTTP/1.1" 200 170736
[2018-03-02 15:42:44,684 DEBUG utils] Content-length=170736
[2018-03-02 15:42:44,684 DEBUG utils] Create file PDF//264.pdf, start download.
[2018-03-02 15:42:47,780 DEBUG utils] End download file PDF//264.pdf.
[2018-03-02 15:42:47,781 DEBUG dbutils] Update pdf_transaction for paper id=264.
[2018-03-02 15:42:47,781 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 264'
[2018-03-02 15:42:47,781 DEBUG dbutils] Query result: null
[2018-03-02 15:42:47,781 DEBUG scholar] Handle paper #297 (total 1170)
[2018-03-02 15:42:47,781 DEBUG scholar] Parse html and get info about paper #7 on searching page (total 10 on page)
[2018-03-02 15:42:47,785 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:47,786 DEBUG utils] Proxy: {'https': '125.212.207.121:3128'}
[2018-03-02 15:42:47,786 DEBUG utils] Change proxy to {'https': '159.65.169.14:3128'} for scholar.google.com
[2018-03-02 15:42:47,803 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:42:47,805 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (3): scholar.googleusercontent.com
[2018-03-02 15:42:49,159 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:6eorcL_kacMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt4_zn_2hpjWUr7p1085BVyHScyVQ&scisf=3&ct=citation&cd=296&hl=en HTTP/1.1" 200 186
[2018-03-02 15:42:49,159 DEBUG scholar] EndNote file:
%0 Journal Article
%T The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis
%A Schurkus, Jan
%D 2016
%I University of Aarhus Aarhus, Denmark

[2018-03-02 15:42:49,160 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:42:49,160 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:42:49,160 DEBUG __main__] Process content of EndNote file #297
{"title": "The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis", "url": "http://content.grin.com/document/v370496.pdf", "author": [{"shortname": "J Schurkus", "gid": ""}], "year": 2016}
{"type": "Journal Article", "title": "The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis", "author": ["Schurkus, Jan"], "year": "2016", "publisher": "University of Aarhus Aarhus, Denmark", "EndNote": "%0 Journal Article\n%T The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis\n%A Schurkus, Jan\n%D 2016\n%I University of Aarhus Aarhus, Denmark\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:6eorcL_kacMJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt4_zn_2hpjWUr7p1085BVyHScyVQ&scisf=3&ct=citation&cd=296&hl=en"}
[2018-03-02 15:42:49,160 DEBUG dbutils] Get paper id {"DOI": null, "title": "The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis", "auth_count": 1, "g_type": "Journal Article", "pages": null, "year": 2016, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:42:49,160 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': None, 'year': 2016, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:42:49,160 DEBUG dbutils] Query result: []
[2018-03-02 15:42:49,160 DEBUG dbutils] Paper id = None.
[2018-03-02 15:42:49,160 DEBUG dbutils] Add new paper (title='The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis')
[2018-03-02 15:42:49,160 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis', 'year': 2016, 'publisher': 'University of Aarhus Aarhus, Denmark', 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T The Prospects of Intelligent Technologies for Strategic Decision Making: A Theoretical Thesis\n%A Schurkus, Jan\n%D 2016\n%I University of Aarhus Aarhus, Denmark\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:42:49,160 DEBUG dbutils] Query result: 265
[2018-03-02 15:42:49,162 DEBUG __main__] Getting PDF-file on Sci-Hub by url : http://content.grin.com/document/v370496.pdf.
[2018-03-02 15:42:49,162 DEBUG scihub] Get page from sci-hub for paper with DOI=http://content.grin.com/document/v370496.pdf.
[2018-03-02 15:42:49,369 DEBUG requests.packages.urllib3.connectionpool] "GET //http://content.grin.com/document/v370496.pdf HTTP/1.1" 302 None
[2018-03-02 15:42:49,394 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): content.grin.com
[2018-03-02 15:42:49,798 DEBUG requests.packages.urllib3.connectionpool] "GET /document/v370496.pdf HTTP/1.1" 301 None
[2018-03-02 15:42:49,822 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.grin.com
[2018-03-02 15:42:50,823 DEBUG requests.packages.urllib3.connectionpool] "GET /document/370496 HTTP/1.1" 200 None
[2018-03-02 15:42:51,208 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:42:51,208 DEBUG utils] Proxy: {'https': '35.227.107.243:80'}
[2018-03-02 15:42:51,208 DEBUG utils] Change proxy to {'https': '187.1.51.122:3128'} for sci-hub.tw
[2018-03-02 15:42:51,399 DEBUG requests.packages.urllib3.connectionpool] "GET //http://content.grin.com/document/v370496.pdf HTTP/1.1" 302 None
[2018-03-02 15:42:51,585 DEBUG requests.packages.urllib3.connectionpool] "GET /document/v370496.pdf HTTP/1.1" 301 None
[2018-03-02 15:42:51,607 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.grin.com
[2018-03-02 15:42:52,502 WARNING utils] Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 589, in urlopen
    self._prepare_proxy(conn)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 797, in _prepare_proxy
    conn.connect()
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connection.py", line 267, in connect
    self._tunnel()
  File "D:\Programming\Python\ANACONDA3\lib\http\client.py", line 919, in _tunnel
    message.strip()))
OSError: Tunnel connection failed: 403 Forbidden

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 423, in send
    timeout=timeout
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\connectionpool.py", line 640, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\packages\urllib3\util\retry.py", line 287, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.grin.com', port=443): Max retries exceeded with url: /document/370496 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Programming\GitHub\Biblio-Meter\utils\utils.py", line 349, in get_request
    resp = SESSION.get(url, proxies=proxy, stream=stream, timeout=5)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 488, in get
    return self.request('GET', url, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 475, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in send
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 617, in <listcomp>
    history = [resp for resp in gen] if allow_redirects else []
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 177, in resolve_redirects
    **adapter_kwargs
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\sessions.py", line 596, in send
    r = adapter.send(request, **kwargs)
  File "D:\Programming\Python\ANACONDA3\lib\site-packages\requests\adapters.py", line 485, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.grin.com', port=443): Max retries exceeded with url: /document/370496 (Caused by ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden',)))

[2018-03-02 15:42:52,502 DEBUG utils] Change proxy to {'https': '37.187.121.169:3128'} for sci-hub.tw
[2018-03-02 15:42:52,719 DEBUG requests.packages.urllib3.connectionpool] "GET //http://content.grin.com/document/v370496.pdf HTTP/1.1" 302 None
[2018-03-02 15:42:52,888 DEBUG requests.packages.urllib3.connectionpool] "GET /document/v370496.pdf HTTP/1.1" 301 None
[2018-03-02 15:42:53,366 DEBUG requests.packages.urllib3.connectionpool] "GET /document/370496 HTTP/1.1" 200 None
[2018-03-02 15:42:53,713 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:42:53,714 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:42:53,899 DEBUG requests.packages.urllib3.connectionpool] "GET //http://content.grin.com/document/v370496.pdf HTTP/1.1" 302 None
[2018-03-02 15:42:54,068 DEBUG requests.packages.urllib3.connectionpool] "GET /document/v370496.pdf HTTP/1.1" 301 None
[2018-03-02 15:42:54,093 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.grin.com
[2018-03-02 15:42:55,253 DEBUG requests.packages.urllib3.connectionpool] "GET /document/370496 HTTP/1.1" 200 None
[2018-03-02 15:42:55,819 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:42:55,820 DEBUG scholar] Handle paper #298 (total 1170)
[2018-03-02 15:42:55,820 DEBUG scholar] Parse html and get info about paper #8 on searching page (total 10 on page)
[2018-03-02 15:42:55,823 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:42:55,823 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:42:56,049 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:3TueoIDBEp4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt52cKqifjRvZ4POX5LZv-B58EQGv&scisf=3&ct=citation&cd=297&hl=en HTTP/1.1" 200 215
[2018-03-02 15:42:56,050 DEBUG scholar] EndNote file:
%0 Journal Article
%T A Chatbot as a natural web Interface to Arabic web QA
%A Shawar, Bayan Abu
%J International Journal of Emerging Technologies in Learning (iJET)
%V 6
%N 1
%P 37-43
%@ 1863-0383
%D 2011

[2018-03-02 15:42:56,050 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:42:56,050 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:42:56,050 DEBUG __main__] Process content of EndNote file #298
{"title": "A Chatbot as a natural web Interface to Arabic web QA", "url": "http://www.online-journals.org/index.php/i-jet/article/view/1502", "author": [{"shortname": "BA Shawar", "gid": ""}], "year": 2011}
{"citedby": 6, "type": "Journal Article", "title": "A Chatbot as a natural web Interface to Arabic web QA", "author": ["Shawar, Bayan Abu"], "journal": "International Journal of Emerging Technologies in Learning (iJET)", "volume": 7, "numberorissue": "1", "pages": "37-43", "isbn/issn": "1863-0383", "year": "2011", "start_page": 37, "end_page": 43, "EndNote": "%0 Journal Article\n%T A Chatbot as a natural web Interface to Arabic web QA\n%A Shawar, Bayan Abu\n%J International Journal of Emerging Technologies in Learning (iJET)\n%V 6\n%N 1\n%P 37-43\n%@ 1863-0383\n%D 2011\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:3TueoIDBEp4J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt52cKqifjRvZ4POX5LZv-B58EQGv&scisf=3&ct=citation&cd=297&hl=en"}
[2018-03-02 15:42:56,050 DEBUG dbutils] Get paper id {"DOI": null, "title": "A Chatbot as a natural web Interface to Arabic web QA", "auth_count": 1, "g_type": "Journal Article", "pages": 7, "year": 2011, "rg_id": null, "start_page": 37, "end_page": 43}.
[2018-03-02 15:42:56,051 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'A Chatbot as a natural web Interface to Arabic web QA', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 7, 'year': 2011, 'rg_id': None, 'start_page': 37, 'end_page': 43}
[2018-03-02 15:42:56,051 DEBUG dbutils] Query result: []
[2018-03-02 15:42:56,051 DEBUG dbutils] Paper id = None.
[2018-03-02 15:42:56,051 DEBUG dbutils] Add new paper (title='A Chatbot as a natural web Interface to Arabic web QA')
[2018-03-02 15:42:56,051 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'A Chatbot as a natural web Interface to Arabic web QA', 'year': 2011, 'publisher': None, 'start_page': 37, 'end_page': 43, 'pages': 7, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T A Chatbot as a natural web Interface to Arabic web QA\n%A Shawar, Bayan Abu\n%J International Journal of Emerging Technologies in Learning (iJET)\n%V 6\n%N 1\n%P 37-43\n%@ 1863-0383\n%D 2011\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:42:56,051 DEBUG dbutils] Query result: 266
[2018-03-02 15:42:56,053 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.online-journals.org/index.php/i-jet/article/viewFile/1502/1664.
[2018-03-02 15:42:56,055 WARNING utils] Download file (url='http://www.online-journals.org/index.php/i-jet/article/viewFile/1502/1664') and save (filename='PDF//266.pdf')
[2018-03-02 15:42:56,055 DEBUG utils] Get current proxy for www.online-journals.org.
[2018-03-02 15:42:56,055 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:42:56,073 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.online-journals.org
[2018-03-02 15:42:57,733 DEBUG requests.packages.urllib3.connectionpool] "GET /index.php/i-jet/article/viewFile/1502/1664 HTTP/1.1" 200 587485
[2018-03-02 15:42:57,734 DEBUG utils] Content-length=587485
[2018-03-02 15:42:57,734 DEBUG utils] Create file PDF//266.pdf, start download.
[2018-03-02 15:43:00,850 DEBUG utils] End download file PDF//266.pdf.
[2018-03-02 15:43:00,851 DEBUG dbutils] Update pdf_transaction for paper id=266.
[2018-03-02 15:43:00,851 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 266'
[2018-03-02 15:43:00,852 DEBUG dbutils] Query result: null
[2018-03-02 15:43:00,852 DEBUG scholar] Handle paper #299 (total 1170)
[2018-03-02 15:43:00,852 DEBUG scholar] Parse html and get info about paper #9 on searching page (total 10 on page)
[2018-03-02 15:43:00,856 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:43:00,856 DEBUG utils] Proxy: {'https': '159.65.169.14:3128'}
[2018-03-02 15:43:00,856 DEBUG utils] Change proxy to {'https': '212.47.252.49:3128'} for scholar.google.com
[2018-03-02 15:43:00,877 INFO requests.packages.urllib3.connectionpool] Resetting dropped connection: scholar.googleusercontent.com
[2018-03-02 15:43:00,881 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (4): scholar.googleusercontent.com
[2018-03-02 15:43:02,228 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EebWekc7PJgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt54AK98a7fi0uao9k3ghCpRu6Yhn&scisf=3&ct=citation&cd=298&hl=en HTTP/1.1" 200 277
[2018-03-02 15:43:02,229 DEBUG scholar] EndNote file:
%0 Journal Article
%T Practice Makes Perfect?: The Practice Approach in E-Learning
%A Friesen, Norm
%J Revue internationale des technologies en pedagogie universitaire/International Journal of Technologies in Higher Education
%V 6
%N 2-3
%P 8-12
%@ 1708-7570
%D 2009

[2018-03-02 15:43:02,229 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:43:02,229 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:43:02,230 DEBUG __main__] Process content of EndNote file #299
{"title": "Practice Makes Perfect?: The Practice Approach in E-Learning", "url": "https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar/abstract/", "author": [{"shortname": "N Friesen", "gid": "vjGTaG4AAAAJ"}], "year": 2009}
{"type": "Journal Article", "title": "Practice Makes Perfect?: The Practice Approach in E-Learning", "author": ["Friesen, Norm"], "journal": "Revue internationale des technologies en p\u00e9dagogie universitaire/International Journal of Technologies in Higher Education", "volume": 5, "numberorissue": "2-3", "pages": "8-12", "isbn/issn": "1708-7570", "year": "2009", "start_page": 8, "end_page": 12, "EndNote": "%0 Journal Article\n%T Practice Makes Perfect?: The Practice Approach in E-Learning\n%A Friesen, Norm\n%J Revue internationale des technologies en p\u00e9dagogie universitaire/International Journal of Technologies in Higher Education\n%V 6\n%N 2-3\n%P 8-12\n%@ 1708-7570\n%D 2009\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:EebWekc7PJgJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplIt54AK98a7fi0uao9k3ghCpRu6Yhn&scisf=3&ct=citation&cd=298&hl=en"}
[2018-03-02 15:43:02,230 DEBUG dbutils] Get paper id {"DOI": null, "title": "Practice Makes Perfect?: The Practice Approach in E-Learning", "auth_count": 1, "g_type": "Journal Article", "pages": 5, "year": 2009, "rg_id": null, "start_page": 8, "end_page": 12}.
[2018-03-02 15:43:02,230 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Practice Makes Perfect?: The Practice Approach in E-Learning', 'auth_count': 1, 'g_type': 'Journal Article', 'pages': 5, 'year': 2009, 'rg_id': None, 'start_page': 8, 'end_page': 12}
[2018-03-02 15:43:02,230 DEBUG dbutils] Query result: []
[2018-03-02 15:43:02,230 DEBUG dbutils] Paper id = None.
[2018-03-02 15:43:02,230 DEBUG dbutils] Add new paper (title='Practice Makes Perfect?: The Practice Approach in E-Learning')
[2018-03-02 15:43:02,230 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Practice Makes Perfect?: The Practice Approach in E-Learning', 'year': 2009, 'publisher': None, 'start_page': 8, 'end_page': 12, 'pages': 5, 'g_type': 'Journal Article', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Journal Article\n%T Practice Makes Perfect?: The Practice Approach in E-Learning\n%A Friesen, Norm\n%J Revue internationale des technologies en pedagogie universitaire/International Journal of Technologies in Higher Education\n%V 6\n%N 2-3\n%P 8-12\n%@ 1708-7570\n%D 2009\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:43:02,230 DEBUG dbutils] Query result: 267
[2018-03-02 15:43:02,232 DEBUG __main__] Getting PDF-file on Google Scholar by url : https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar.pdf.
[2018-03-02 15:43:02,233 WARNING utils] Download file (url='https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar.pdf') and save (filename='PDF//267.pdf')
[2018-03-02 15:43:02,233 DEBUG utils] Get current proxy for www.erudit.org.
[2018-03-02 15:43:02,233 DEBUG utils] Proxy: {'https': '185.93.3.123:8080'}
[2018-03-02 15:43:02,233 DEBUG utils] Change proxy to {'https': '200.146.77.133:80'} for otherhost
[2018-03-02 15:43:02,251 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (1): www.erudit.org
[2018-03-02 15:43:07,021 DEBUG requests.packages.urllib3.connectionpool] "GET /en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar.pdf HTTP/1.1" 200 None
[2018-03-02 15:43:07,022 DEBUG utils] Downloading the entire file.
[2018-03-02 15:43:07,022 DEBUG utils] Get current proxy for www.erudit.org.
[2018-03-02 15:43:07,022 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:43:07,036 INFO requests.packages.urllib3.connectionpool] Starting new HTTPS connection (2): www.erudit.org
[2018-03-02 15:43:11,133 DEBUG requests.packages.urllib3.connectionpool] "GET /en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar.pdf HTTP/1.1" 200 None
[2018-03-02 15:43:19,277 DEBUG utils] Save file PDF//267.pdf.
[2018-03-02 15:43:19,280 DEBUG __main__] Getting PDF-file on Sci-Hub by url : https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar/abstract/.
[2018-03-02 15:43:19,280 DEBUG scihub] Get page from sci-hub for paper with DOI=https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar/abstract/.
[2018-03-02 15:43:21,670 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar/abstract/ HTTP/1.1" 200 None
[2018-03-02 15:43:21,805 DEBUG utils] Get current proxy for sci-hub.tw.
[2018-03-02 15:43:21,805 DEBUG utils] Proxy: {'https': '37.187.121.169:3128'}
[2018-03-02 15:43:21,805 DEBUG utils] Change proxy to {'https': '177.37.160.211:3128'} for sci-hub.tw
[2018-03-02 15:43:23,573 DEBUG requests.packages.urllib3.connectionpool] "GET //https://www.erudit.org/en/journals/ritpu/2009-v6-n2-3-ritpu1395677/1000006ar/abstract/ HTTP/1.1" 200 None
[2018-03-02 15:43:23,740 DEBUG scihub] PDF for this paper is anavailable.
[2018-03-02 15:43:23,741 DEBUG scholar] Handle paper #300 (total 1170)
[2018-03-02 15:43:23,741 DEBUG scholar] Parse html and get info about paper #10 on searching page (total 10 on page)
[2018-03-02 15:43:23,747 DEBUG utils] Get current proxy for scholar.googleusercontent.com.
[2018-03-02 15:43:23,747 DEBUG utils] Proxy: {'https': '212.47.252.49:3128'}
[2018-03-02 15:43:24,018 DEBUG requests.packages.urllib3.connectionpool] "GET /scholar.enw?q=info:EdcqKKD88RkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplItz514-MOpRzfy86QeBRhV2uknPMM&scisf=3&ct=citation&cd=299&hl=en HTTP/1.1" 200 111
[2018-03-02 15:43:24,019 DEBUG scholar] EndNote file:
%0 Generic
%T Using a Chatbot to Prevent Identity Fraud By Social Engineering
%A Bjornhed, Joakim
%D 2009

[2018-03-02 15:43:24,019 DEBUG endnoteparser] Parsing EndNode text.
[2018-03-02 15:43:24,019 DEBUG endnoteparser] Successful EndNode text parsing.
[2018-03-02 15:43:24,020 DEBUG __main__] Process content of EndNote file #300
{"title": "Using a Chatbot to Prevent Identity Fraud By Social Engineering", "url": "http://www.diva-portal.org/smash/record.jsf?pid=diva2:237296", "author": [{"shortname": "J Bj\u00f6rnhed", "gid": ""}], "year": 2009}
{"type": "Generic", "title": "Using a Chatbot to Prevent Identity Fraud By Social Engineering", "author": ["Bj\u00f6rnhed, Joakim"], "year": "2009", "EndNote": "%0 Generic\n%T Using a Chatbot to Prevent Identity Fraud By Social Engineering\n%A Bj\u00f6rnhed, Joakim\n%D 2009\n", "url_scholarbib": "https://scholar.googleusercontent.com/scholar.enw?q=info:EdcqKKD88RkJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplItz514-MOpRzfy86QeBRhV2uknPMM&scisf=3&ct=citation&cd=299&hl=en"}
[2018-03-02 15:43:24,020 DEBUG dbutils] Get paper id {"DOI": null, "title": "Using a Chatbot to Prevent Identity Fraud By Social Engineering", "auth_count": 1, "g_type": "Generic", "pages": null, "year": 2009, "rg_id": null, "start_page": null, "end_page": null}.
[2018-03-02 15:43:24,020 DEBUG dbutils] Execute sql with params: type=select sql='
        select id from papers
        where (
              title = :title
              and authors = :auth_count
              and (g_type = :g_type or g_type is null or :g_type is null)
              and (year = :year or year is null or :year is null)
              and (pages = :pages or pages is null or :pages is null)
              --and (start_page = :start_page or start_page is null or :start_page is null)
              --and (end_page = :end_page or end_page is null or :end_page is null)
              )
              or
              (DOI = :DOI)
              or
              (rg_id = :rg_id)
        '; params={'DOI': None, 'title': 'Using a Chatbot to Prevent Identity Fraud By Social Engineering', 'auth_count': 1, 'g_type': 'Generic', 'pages': None, 'year': 2009, 'rg_id': None, 'start_page': None, 'end_page': None}
[2018-03-02 15:43:24,020 DEBUG dbutils] Query result: []
[2018-03-02 15:43:24,020 DEBUG dbutils] Paper id = None.
[2018-03-02 15:43:24,020 DEBUG dbutils] Add new paper (title='Using a Chatbot to Prevent Identity Fraud By Social Engineering')
[2018-03-02 15:43:24,020 DEBUG dbutils] Execute sql with params: type=insert sql='
        INSERT INTO papers(
            title, year, publisher, start_page, end_page, pages, g_type,
            DOI, abstract, abstract_ru, rg_id, references_count, rg_type,
            g_endnote, rg_ris, authors, r_transaction, ignore
        ) VALUES(
            :title, :year, :publisher, :start_page, :end_page, :pages, :g_type,
            :DOI, :abstract, :abstract_ru, :rg_id, :references_count, :rg_type,
            :EndNote, :RIS, :authors, :transaction, :ignore
        )
        '; params={'title': 'Using a Chatbot to Prevent Identity Fraud By Social Engineering', 'year': 2009, 'publisher': None, 'start_page': None, 'end_page': None, 'pages': None, 'g_type': 'Generic', 'DOI': None, 'abstract': None, 'abstract_ru': None, 'rg_id': None, 'references_count': None, 'rg_type': None, 'EndNote': '%0 Generic\n%T Using a Chatbot to Prevent Identity Fraud By Social Engineering\n%A Bjornhed, Joakim\n%D 2009\n', 'RIS': None, 'authors': 1, 'ignore': False, 'transaction': 1}
[2018-03-02 15:43:24,020 DEBUG dbutils] Query result: 268
[2018-03-02 15:43:24,022 DEBUG __main__] Getting PDF-file on Google Scholar by url : http://www.diva-portal.org/smash/get/diva2:237296/FULLTEXT01.pdf.
[2018-03-02 15:43:24,023 WARNING utils] Download file (url='http://www.diva-portal.org/smash/get/diva2:237296/FULLTEXT01.pdf') and save (filename='PDF//268.pdf')
[2018-03-02 15:43:24,023 DEBUG utils] Get current proxy for www.diva-portal.org.
[2018-03-02 15:43:24,023 DEBUG utils] Proxy: {'https': '200.146.77.133:80'}
[2018-03-02 15:43:24,023 DEBUG utils] Change proxy to {'https': '72.10.162.250:3128'} for otherhost
[2018-03-02 15:43:24,040 INFO requests.packages.urllib3.connectionpool] Starting new HTTP connection (1): www.diva-portal.org
[2018-03-02 15:43:24,335 DEBUG requests.packages.urllib3.connectionpool] "GET /smash/get/diva2:237296/FULLTEXT01.pdf HTTP/1.1" 200 793209
[2018-03-02 15:43:24,335 DEBUG utils] Content-length=793209
[2018-03-02 15:43:24,336 DEBUG utils] Create file PDF//268.pdf, start download.
[2018-03-02 15:43:25,904 DEBUG utils] End download file PDF//268.pdf.
[2018-03-02 15:43:25,905 DEBUG dbutils] Update pdf_transaction for paper id=268.
[2018-03-02 15:43:25,906 DEBUG dbutils] Execute sql: type=update sql='UPDATE papers SET pdf_transaction = 1 where id = 268'
[2018-03-02 15:43:25,906 DEBUG dbutils] Query result: null
[2018-03-02 15:43:25,917 DEBUG __main__] End processing. Changes in DB: 269.
[2018-03-02 15:43:25,918 DEBUG __main__] Processing was successful. Added new papers: 269. Added new authors: 0. Processed total papers: 300. Try load 134 scihub pdfs. Success load from scihub 24 pdfs.Try load 182 gs pdfs. Success load from gs 135 pdfs. 
[2018-03-02 15:43:25,918 DEBUG dbutils] Commiting transaction .
[2018-03-02 15:43:26,080 DEBUG __main__] Run began on 2018-03-02 14:35:19.078110
[2018-03-02 15:43:26,080 DEBUG __main__] Run ended on 2018-03-02 15:43:26.079066
[2018-03-02 15:43:26,081 DEBUG __main__] Elapsed time was: 1:08:07.000956
[2018-03-02 15:43:26,081 INFO __main__] HTTP-requests: 697(52 failed)
[2018-03-02 15:43:26,081 INFO __main__] List failed HTTP-requests:
http://cyber.sci-hub.tw/MTAuMTExMS9qLjE1NDAtNDc4MS4yMDA5LjAwOTcyLng=/levy2009.pdf?download=true
https://www.learntechlib.org/p/20691/proceedings_20691.pdf
http://www.academia.edu/download/34070923/what_psychological_fac_llc_yamada.pdf
http://www.academia.edu/download/20440893/v15n3.pdf#page=17
http://sci-hub.tw//http://www.academia.edu/download/20440893/v15n3.pdf#page=17
http://www.academia.edu/download/20440893/v15n3.pdf#page=17
http://sci-hub.tw//http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.734.8303&rep=rep1&type=pdf
https://sci-hub.tw/saveme/c94d/10.1007@978-3-319-69365-13.pdf
https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf
http://sci-hub.tw//https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf
https://www.ml.cmu.edu/research/dap-papers/F16/dap_kandasamy_kirthevasan.pdf
http://www.academia.edu/download/39912769/What_information_does_this_question_conv20151111-30318-mfimgn.pdf
http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf
http://sci-hub.tw//http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf
http://www.academia.edu/download/37589003/AI_Science_Impact_v14_.pdf
https://sci-hub.tw/saveme/3fab/10.0000@dl.acm.org@1858806.pdf
http://e-space.mmu.ac.uk/313169/1/ALatham%20PhD%20thesis.pdf
http://sci-hub.tw//https://e-space.mmu.ac.uk/313169/
https://e-space.mmu.ac.uk/313169/
https://pdfs.semanticscholar.org/bc25/0f10b30cdc6986959a81c9be3451cf2bf200.pdf
http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf
http://sci-hub.tw//http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf
http://www.academia.edu/download/35768291/ArabicQuestionAnswering.pdf
http://theater.dukejournals.org/content/42/2/79.full.pdf
http://sci-hub.tw//http://theater.dukejournals.org/content/42/2/79.full.pdf
http://theater.dukejournals.org/content/42/2/79.full.pdf
https://www.sciencedirect.com/science/article/pii/S0004370213000234/pdf?md5=4aef30693a7815a16f6bc466b91470c4&pid=1-s2.0-S0004370213000234-main.pdf&_valck=1
http://sci-hub.tw//http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.663.1075&rep=rep1&type=pdf
https://www.learntechlib.org/p/41629/proceeding_41629.pdf
https://sci-hub.tw/saveme/05a6/10.1007@978-94-007-7194-9135-1.pdf
https://scholar.googleusercontent.com/scholar.enw?q=info:AJOJQKi__WAJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1jb2ii9NxH6dY34PjXacPOmVR94Y&scisf=3&ct=citation&cd=188&hl=en
https://scholar.googleusercontent.com/scholar.enw?q=info:EcYw7s68n8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWplB1o-plCuTrXlk0G20_cQG_It2aq82&scisf=3&ct=citation&cd=189&hl=en
http://orbilu.uni.lu/bitstream/10993/27057/1/hoehn-introduction.pdf
http://www.academia.edu/download/5624539/10.1.1.81.4758.pdf
ftp://dmz02.kom.e-technik.tu-darmstadt.de/papers/HRG+14.pdf
https://pdfs.semanticscholar.org/432a/baa1d8ec2eab0a67b3f1f8094e5eecbe94e7.pdf
http://search.proquest.com/openview/83c97a209c174153d8a7b05d1321d374/1.pdf?pq-origsite=gscholar&cbl=47776
https://www.sciencedirect.com/science/article/pii/S1877050910005107/pdf?md5=2f6ba0c04ea344bf9fe9a77640fd1da8&pid=1-s2.0-S1877050910005107-main.pdf&_valck=1
https://pdfs.semanticscholar.org/5982/40a8a7fe0dcda05da3d8663d0a25c4b2cf9e.pdf
http://www.academia.edu/download/3238010/friedland-allan-cikm08.pdf
http://sci-hub.tw//http://arbor.revistas.csic.es/index.php/arbor/article/view/1888
http://arbor.revistas.csic.es/index.php/arbor/article/view/1888
https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf
http://sci-hub.tw//https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf
https://pdfs.semanticscholar.org/7f2c/3a3afc52900e57fa99ef3d0ef5620db0d86a.pdf
https://www.learntechlib.org/p/37983/proceedings_37983.pdf
http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf
http://sci-hub.tw//http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf
http://www.academia.edu/download/1475756/Negotiated_Learner_Modelling_with_a_Conversational_Agent_-_Alice_Kerly_PhDThesis_-_Updated_June_2009.pdf
http://www.academia.edu/download/31800125/Bayne-and-Ross-heterotopia.pdf
[2018-03-02 15:43:26,082 DEBUG dbutils] Enters transaction proxy for function: UPDATE_Transaction.
[2018-03-02 15:43:26,082 DEBUG dbutils] Execute sql with params: type=update sql='
            UPDATE transactions 
            SET to_date = :to_date, result = :result WHERE ID = :ID
            '; params={'to_date': datetime.datetime(2018, 3, 2, 15, 43, 26, 82576), 'result': 'SUCCESS', 'ID': 1}
[2018-03-02 15:43:26,083 DEBUG dbutils] Query result: null
[2018-03-02 15:43:26,083 DEBUG dbutils] Commiting transaction for function: UPDATE_Transaction.
[2018-03-02 15:43:26,219 INFO dbutils] Close database.
[2018-03-02 15:43:26,219 INFO settings] Close logbook
